<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Report &bull; 623 tests</title>
    <!-- Optional: Inter font from rsms.me CDN. Falls back to system fonts if unavailable. -->
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <style>
/* Modern Color Palette */
:root {
    --bg-color: #f8fafc;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --border-color: #e2e8f0;
    --card-bg: #ffffff;
    --surface-muted: #f1f5f9;
    --primary-color: #3b82f6;
    color-scheme: light dark;

    /* Status Colors */
    --passed-bg: #dcfce7;
    --passed-text: #166534;
    --failed-bg: #fee2e2;
    --failed-text: #991b1b;
    --skipped-bg: #fef9c3;
    --skipped-text: #854d0e;
    --xfailed-bg: #ffedd5;
    --xfailed-text: #9a3412;
    --xpassed-bg: #f3e8ff;
    --xpassed-text: #6b21a8;
    --error-bg: #fee2e2;
    --error-text: #991b1b;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background-color: var(--bg-color);
    color: var(--text-primary);
    line-height: 1.5;
    margin: 0;
    padding: 0;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
}

/* Header */
header {
    margin-bottom: 2rem;
    border-bottom: 1px solid var(--border-color);
    padding-bottom: 1rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

h1 {
    font-size: 1.875rem;
    font-weight: 700;
    color: var(--text-primary);
    margin: 0;
}

.meta {
    font-size: 0.875rem;
    color: var(--text-secondary);
}

/* Summary Grid */
.summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 1rem;
    margin-bottom: 2rem;
}

.summary-card {
    background: var(--card-bg);
    border-radius: 0.5rem;
    padding: 1.5rem;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
    text-align: center;
    border: 1px solid var(--border-color);
    transition: transform 0.2s;
}

.summary-card:hover {
    transform: translateY(-2px);
}

.summary-card .count {
    font-size: 2.25rem;
    font-weight: 700;
    line-height: 1;
    margin-bottom: 0.5rem;
}

.summary-card .label {
    text-transform: uppercase;
    font-size: 0.75rem;
    font-weight: 600;
    letter-spacing: 0.05em;
    color: var(--text-secondary);
}

/* Status Colors for Summary */
.summary-card.passed .count {
    color: var(--passed-text);
}

.summary-card.failed .count {
    color: var(--failed-text);
}

.summary-card.skipped .count {
    color: var(--skipped-text);
}

.summary-card.xfailed .count {
    color: var(--xfailed-text);
}

.summary-card.xpassed .count {
    color: var(--xpassed-text);
}

.summary-card.coverage .count {
    color: var(--primary-color);
}

/* Filters */
.filters {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid var(--border-color);
    margin-bottom: 1.5rem;
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.filter-input {
    flex: 1;
    padding: 0.5rem 1rem;
    border: 1px solid var(--border-color);
    border-radius: 0.375rem;
    font-size: 0.875rem;
    background: var(--card-bg);
    color: var(--text-primary);
}

.filter-input::placeholder {
    color: var(--text-secondary);
}

.filter-statuses {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
}

.filter-chip {
    display: inline-flex;
    align-items: center;
    gap: 0.35rem;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    border: 1px solid var(--border-color);
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.04em;
}

.filter-chip input {
    margin: 0;
}

.filter-chip.passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.filter-chip.failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.filter-chip.skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.filter-chip.xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.filter-chip.xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.filter-chip.error {
    background: var(--error-bg);
    color: var(--error-text);
}

/* Test List */
.test-list {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.test-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
    overflow: hidden;
}

.test-header {
    padding: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    cursor: pointer;
    background: var(--card-bg);
}

.test-header:hover {
    background: var(--surface-muted);
}

.status-badge {
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
}

.status-passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.status-failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.status-skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.status-xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.status-xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.status-error {
    background: var(--error-bg);
    color: var(--error-text);
}

.test-name {
    flex: 1;
    font-family: monospace;
    font-size: 0.9rem;
    color: var(--text-primary);
    word-break: break-all;
}

.test-meta {
    display: flex;
    gap: 1rem;
    align-items: center;
    color: var(--text-secondary);
    font-size: 0.875rem;
}

/* Details Section */
.test-details {
    padding: 0 1rem 1rem 1rem;
    border-top: 1px solid var(--border-color);
    background: var(--surface-muted);
}

.detail-section {
    margin-top: 1rem;
}

.detail-title {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    color: var(--text-secondary);
    margin-bottom: 0.5rem;
}

.coverage-item {
    font-family: monospace;
    font-size: 0.85rem;
    padding: 0.25rem 0;
    border-bottom: 1px solid var(--border-color);
    display: grid;
    grid-template-columns: minmax(200px, 2fr) minmax(120px, 1fr);
    gap: 1rem;
}

.coverage-list {
    background: var(--card-bg);
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
    overflow: hidden;
}

.source-coverage {
    margin-top: 2rem;
}

.source-coverage h2 {
    margin: 0 0 1rem;
    font-size: 1.5rem;
}

.source-coverage-table {
    display: grid;
    gap: 0.35rem;
}

.source-coverage-header,
.source-coverage-row {
    display: grid;
    grid-template-columns: minmax(200px, 2fr) repeat(4, minmax(60px, 0.5fr)) minmax(
            140px,
            1fr
        ) minmax(140px, 1fr);
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
}

.source-coverage-header {
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.04em;
    color: var(--text-secondary);
}

.source-coverage-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    font-size: 0.85rem;
}

.source-path {
    font-family: monospace;
    word-break: break-word;
}

.source-lines {
    font-family: monospace;
    color: var(--text-secondary);
    word-break: break-word;
}

.llm-annotation {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
}

.llm-annotation p {
    margin: 0 0 0.5rem 0;
}

.llm-annotation p:last-child {
    margin-bottom: 0;
}

.llm-annotation ul {
    margin: 0.5rem 0 0;
    padding-left: 1.25rem;
}

.llm-annotation li {
    margin-bottom: 0.25rem;
}

.error-message {
    font-family: monospace;
    color: var(--failed-text);
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--failed-bg);
    white-space: pre-wrap;
    overflow-x: auto;
}

/* HTML5 Progress Bar for Coverage */
progress {
    width: 60px;
}

/* Utility: Hidden state for filtering */
.hidden {
    display: none !important;
}

/* Dark Mode Support */
@media (prefers-color-scheme: dark) {
    :root {
        --bg-color: #0f172a;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
        --border-color: #334155;
        --card-bg: #1e293b;
        --surface-muted: #0b1220;
        --primary-color: #60a5fa;

        /* Status Colors - Adjusted for dark mode */
        --passed-bg: #14532d;
        --passed-text: #86efac;
        --failed-bg: #7f1d1d;
        --failed-text: #fca5a5;
        --skipped-bg: #713f12;
        --skipped-text: #fde047;
        --xfailed-bg: #7c2d12;
        --xfailed-text: #fdba74;
        --error-bg: #7f1d1d;
        --error-text: #fca5a5;
    }

    /* Adjust box shadows for dark mode */
    .summary-card {
        box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.3), 0 1px 2px -1px rgb(0 0 0 / 0.3);
    }
}

@media print {
    body {
        background: #ffffff;
        color: #0f172a;
    }

    .container {
        max-width: none;
        padding: 1rem 1.5rem;
    }

    header {
        border-bottom: 2px solid var(--border-color);
    }

    .filters {
        display: none;
    }

    .summary-card,
    .test-row {
        box-shadow: none;
    }

    .test-header {
        background: #ffffff;
    }

    .test-row {
        page-break-inside: avoid;
        break-inside: avoid;
    }

    .test-details {
        background: #ffffff;
    }

    .llm-annotation {
        background: var(--surface-muted);
    }

    progress {
        width: 80px;
    }
}

body.pdf-mode .filters {
    display: none;
}

body.pdf-mode .test-row {
    page-break-inside: avoid;
    break-inside: avoid;
}

/* TOC Styling */
.toc {
    margin-bottom: 2rem;
    padding: 1rem;
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
}
.toc ul {
    list-style: none;
    padding: 0;
    margin: 0;
    display: flex;
    gap: 1.5rem;
    flex-wrap: wrap;
}
.toc a {
    color: var(--primary-color);
    text-decoration: none;
    font-weight: 600;
    cursor: pointer;
}
.toc a:hover {
    text-decoration: underline;
}

/* File Group Styling */
.test-file-group {
    margin-bottom: 2rem;
}
.test-file-header {
    font-size: 1.1rem;
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid var(--border-color);
    display: flex;
    justify-content: space-between;
    align-items: center;
}    </style>
    <script>
// pytest-llm-report interactive features

// Global state for filters
const activeStatuses = new Set(['passed', 'failed', 'skipped', 'xfailed', 'xpassed', 'error']);

// Filter tests based on search input and outcome filters
function filterTests() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    document.querySelectorAll('.test-row').forEach(row => {
        const nodeid = row.querySelector('.test-name').textContent.toLowerCase();
        const statusMatch = row.dataset.status ? activeStatuses.has(row.dataset.status) : false;
        const matchesSearch = nodeid.includes(query);
        row.classList.toggle('hidden', !matchesSearch || !statusMatch);
    });
}

// Show only failures and scroll to list
function showFailuresOnly() {
    document.querySelectorAll('.filter-chip input').forEach(cb => {
        const s = cb.dataset.status;
        if (s === 'failed' || s === 'error') {
            cb.checked = true;
            activeStatuses.add(s);
        } else {
            cb.checked = false;
            activeStatuses.delete(s);
        }
    });
    filterTests();
    const testList = document.getElementById('test-list');
    if (testList) {
        testList.scrollIntoView({ behavior: 'smooth' });
    }
}

// Toggle visibility of status filters
function toggleStatus(checkbox) {
    const status = checkbox.dataset.status;
    if (checkbox.checked) {
        activeStatuses.add(status);
    } else {
        activeStatuses.delete(status);
    }
    filterTests();
}

// Initialize interactive features after DOM is ready
document.addEventListener('DOMContentLoaded', function () {
    'use strict';

    // Toggle dark mode on preference
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.documentElement.dataset.theme = 'dark';
    }

    // Default: expand all details
    document.querySelectorAll('details').forEach(details => {
        details.setAttribute('open', '');
    });

    const params = new URLSearchParams(window.location.search);
    if (params.get('pdf') === '1') {
        document.body.classList.add('pdf-mode');
    }
});    </script>
</head>
<body>
    <div class="container">
        <header>
            <div>
                <h1>Test Report</h1>
                <div class="meta">
                    Run ID: 21201358217-py3.12 &bull;
                    Generated: 2026-01-21 07:48:14 &bull;
                    Duration: 120.44s<br>
                    <strong>Plugin:</strong> v0.2.1
                        (a03dbe622cdc018f89b74731aed91adf1a582867)
[dirty]<br>
                    <strong>Repo:</strong> v0.2.1
                        (af30b58f9617c57b114b26afe3e20619a38888d8)
[dirty]<br>
                    <strong>LLM:</strong> ollama / llama3.2:1b
                        (minimal context,
                         620 annotated, 2 errors)
                        <br><strong>Token Usage:</strong>
                        135663 input,
                        75900 output
                        (Total: 211563)
                </div>
            </div>
            <div style="text-align: right">
                <div style="font-size: 2rem; font-weight: 700; color: var(--primary-color)">
                    93.04%
                </div>
                <div class="meta">Total Coverage</div>
            </div>
        </header>

        <!-- Summary Cards -->
        <div class="summary">
            <div class="summary-card">
                <div class="count">623</div>
                <div class="label">Total Tests</div>
            </div>
            <div class="summary-card passed">
                <div class="count">623</div>
                <div class="label">Passed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Failed</div>
            </div>
            <div class="summary-card skipped">
                <div class="count">0</div>
                <div class="label">Skipped</div>
            </div>
            <div class="summary-card xfailed">
                <div class="count">0</div>
                <div class="label">XFailed</div>
            </div>
            <div class="summary-card xpassed">
                <div class="count">0</div>
                <div class="label">XPassed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Errors</div>
            </div>
        </div>

        <!-- Table of Contents -->
        <nav class="toc">
            <ul>
                <li><a href="#source-coverage">Source Coverage</a></li>
                <li><a href="#test-list">Per Test Details</a></li>
                <li><a onclick="showFailuresOnly()">Failures Only</a></li>
            </ul>
        </nav>

        <section class="source-coverage" id="source-coverage">
            <h2>Source Coverage</h2>
            <div class="source-coverage-table">
                <div class="source-coverage-header">
                    <span>File</span>
                    <span>Stmts</span>
                    <span>Miss</span>
                    <span>Cover</span>
                    <span>%</span>
                    <span>Covered Lines</span>
                    <span>Missed Lines</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/_git_info.py</span>
                    <span>2</span>
                    <span>0</span>
                    <span>2</span>
                    <span>100.0%</span>
                    <span class="source-lines">2-3</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/aggregation.py</span>
                    <span>121</span>
                    <span>6</span>
                    <span>115</span>
                    <span>95.04%</span>
                    <span class="source-lines">13, 15-19, 21, 36, 39, 45, 47, 53-54, 56-58, 60, 62-65, 70, 74-75, 78-81, 85, 88-90, 94, 104, 110, 113-115, 117-121, 123-124, 129, 131-132, 134-135, 138-139, 145-147, 149, 152, 155, 158, 160, 162, 176, 178, 182, 184, 186, 196, 198-202, 204-205, 208, 210, 219, 231, 233-247, 249, 251, 259-260, 262-263, 265, 267-269, 273, 276-277, 279-280, 283, 285-286, 288, 290-291, 295</span>
                    <span class="source-lines">67, 91-92, 111, 206, 217</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/cache.py</span>
                    <span>47</span>
                    <span>3</span>
                    <span>44</span>
                    <span>93.62%</span>
                    <span class="source-lines">13, 15-19, 21, 27, 33, 39-41, 43, 53, 55-56, 58, 60-62, 68-69, 78, 86, 88, 90, 92, 94, 97, 103, 107, 118-119, 121, 123, 129, 132-136, 141, 144, 153</span>
                    <span class="source-lines">64-65, 130</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/collector.py</span>
                    <span>111</span>
                    <span>1</span>
                    <span>110</span>
                    <span>99.1%</span>
                    <span class="source-lines">19, 21-22, 24, 26-27, 33-34, 45-50, 52, 58, 60-62, 69, 78-79, 81, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127-128, 130, 132-133, 135-137, 140-141, 143, 155, 163-164, 167-169, 171, 173, 181-182, 185-189, 191, 198-200, 202, 209-210, 212-214, 216, 218, 227-228, 230-236, 238, 241, 250-252, 254, 261, 264-265, 268-269, 271, 277, 279, 285</span>
                    <span class="source-lines">239</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/context_util.py</span>
                    <span>53</span>
                    <span>3</span>
                    <span>50</span>
                    <span>94.34%</span>
                    <span class="source-lines">13-15, 18, 27, 29-31, 33, 35-36, 38-41, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 72, 81-82, 86, 88-90, 93, 96, 108, 111, 124, 126-127, 129-130, 133, 135</span>
                    <span class="source-lines">53, 83-84</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/coverage_map.py</span>
                    <span>135</span>
                    <span>6</span>
                    <span>129</span>
                    <span>95.56%</span>
                    <span class="source-lines">13, 15-17, 19-22, 30, 38, 44-45, 47, 58-60, 64, 72-73, 83, 86, 88-90, 92, 94-96, 98, 101-104, 106-108, 114, 116, 118, 121-122, 127-128, 131-135, 137-140, 144-146, 148, 150, 152-153, 156, 160-162, 165, 167-168, 173, 176, 178-184, 187-189, 191, 196, 199-200, 202, 204, 216-217, 220, 224-225, 228-234, 236, 239, 241, 243-244, 246-250, 252-254, 257, 259-260, 263-264, 271, 273-274, 276-279, 281-283, 285, 299-300, 302, 308</span>
                    <span class="source-lines">62, 123, 125, 157, 221, 251</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/errors.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">8-9, 12, 25-28, 31-36, 39-42, 45-46, 49-51, 54-55, 64-66, 68, 70, 73, 77-79, 83, 132, 142</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/__init__.py</span>
                    <span>3</span>
                    <span>0</span>
                    <span>3</span>
                    <span>100.0%</span>
                    <span class="source-lines">4-5, 7</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/annotator.py</span>
                    <span>154</span>
                    <span>21</span>
                    <span>133</span>
                    <span>86.36%</span>
                    <span class="source-lines">4, 6-10, 12-15, 21-22, 25-30, 33, 47-48, 50-52, 56, 58-59, 65, 67-68, 70, 73-74, 76, 84, 86-90, 95-96, 98-99, 106-107, 112-113, 116, 121-126, 130, 132, 134, 137, 144, 156, 181-182, 184, 186, 188-189, 199, 211, 213-216, 221-223, 226, 249-252, 254-255, 260, 262, 264-267, 269-270, 277-279, 281, 283-284, 289-290, 292-293, 298-301, 303, 306, 329-332, 334, 336, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381</span>
                    <span class="source-lines">77-81, 160-168, 173, 286-287, 345, 364-365, 371</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/base.py</span>
                    <span>131</span>
                    <span>6</span>
                    <span>125</span>
                    <span>95.42%</span>
                    <span class="source-lines">13, 15-18, 20, 30, 33, 47, 50, 53, 59, 65-66, 68, 87-88, 96, 101, 103, 105, 128, 134-135, 137-138, 149, 155, 157, 163, 165, 174, 176, 185-186, 188, 191-198, 200, 202, 212, 214-217, 219-222, 224, 232, 243, 245, 247, 264, 266-267, 270-272, 274-275, 277, 279, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314, 316, 325-326, 329-331, 333-334, 337-339, 342-347, 351, 353, 359-360, 363-364, 367-369, 372, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404, 406</span>
                    <span class="source-lines">91-92, 230, 284, 292, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/batching.py</span>
                    <span>90</span>
                    <span>4</span>
                    <span>86</span>
                    <span>95.56%</span>
                    <span class="source-lines">8, 10-13, 20, 23-24, 27-29, 31-32, 34, 36-37, 39, 44, 53-55, 58, 67-68, 70, 73, 92-93, 95, 97, 103-106, 108-110, 112, 122-123, 126-128, 136, 139, 156-157, 160, 162, 164-167, 170-176, 181-185, 187-188, 190, 192-194, 196-197, 203-206, 209-210, 213-214, 216-218, 222, 224</span>
                    <span class="source-lines">158, 207, 211, 220</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/gemini.py</span>
                    <span>325</span>
                    <span>7</span>
                    <span>318</span>
                    <span>97.85%</span>
                    <span class="source-lines">7, 9-13, 15-16, 23-27, 30-34, 37-42, 44-46, 48-50, 52, 57-63, 65-70, 72-73, 75-78, 80-85, 87-89, 91-97, 99-114, 121-122, 125, 128, 134-135, 137-141, 143-144, 146, 164-166, 173-175, 178, 181-182, 184, 186-189, 191-192, 198-206, 208-210, 212-213, 215, 218, 221-230, 232-233, 235-237, 239-243, 246-247, 249-252, 254-255, 259, 261, 263, 268, 272-276, 279-281, 283, 288-293, 295, 299-305, 308-309, 311-312, 318-319, 322, 326, 332-333, 335, 339-343, 345-349, 352-353, 358-359, 366-367, 369, 383, 385-386, 390, 410, 413-415, 418-422, 424-427, 432, 434-435, 437, 441-444, 446, 449-463, 469, 471-473, 475-478, 480, 486, 488-491, 493, 495, 497-498, 502-508, 511, 514-516, 518-521, 523-528, 534, 537, 539-543, 547-548, 550-559, 562-564, 567-570, 574</span>
                    <span class="source-lines">115-117, 298, 310, 313-314</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/litellm_provider.py</span>
                    <span>77</span>
                    <span>1</span>
                    <span>76</span>
                    <span>98.7%</span>
                    <span class="source-lines">8, 10, 12-13, 21, 31, 37-38, 41-42, 44, 51, 60-62, 64, 82-83, 89, 92, 95-96, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 122, 124-126, 129-130, 132, 135, 137, 139, 141-142, 144, 148, 170, 182-183, 186-188, 190, 192-193, 196-198, 204, 206, 211, 213, 215, 221-222, 224, 227-231, 234, 236, 242-243, 245</span>
                    <span class="source-lines">207</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/noop.py</span>
                    <span>13</span>
                    <span>0</span>
                    <span>13</span>
                    <span>100.0%</span>
                    <span class="source-lines">8, 10, 12-13, 20, 26, 32, 34, 51, 53, 59, 61, 67</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/ollama.py</span>
                    <span>72</span>
                    <span>1</span>
                    <span>71</span>
                    <span>98.61%</span>
                    <span class="source-lines">7, 9, 11-12, 18, 24, 42-43, 49, 52-53, 55, 58, 60-61, 63-67, 70, 74-77, 83, 85-86, 92, 94, 96-98, 100-101, 103, 107, 113-114, 116-118, 122, 128, 130, 138, 140, 142-144, 149-150, 156, 158, 160-162, 165-167, 172-173, 178, 180, 190, 192-193, 204, 209, 211-212</span>
                    <span class="source-lines">90</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/schemas.py</span>
                    <span>36</span>
                    <span>1</span>
                    <span>35</span>
                    <span>97.22%</span>
                    <span class="source-lines">8, 10-12, 16, 22, 38, 42-44, 46-47, 50-53, 55, 58-59, 62-65, 67-68, 77, 84, 90, 94-98, 102, 130</span>
                    <span class="source-lines">39</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/token_refresh.py</span>
                    <span>71</span>
                    <span>0</span>
                    <span>71</span>
                    <span>100.0%</span>
                    <span class="source-lines">7, 9-14, 17, 20, 23-24, 36-39, 41-43, 47, 59-60, 63-66, 69-72, 74, 83, 85-88, 90-91, 93, 101-103, 107-109, 111, 113-116, 120, 132-136, 139-140, 143-145, 148-150, 153-156, 158, 160-162</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/utils.py</span>
                    <span>33</span>
                    <span>2</span>
                    <span>31</span>
                    <span>93.94%</span>
                    <span class="source-lines">4, 6, 9, 20, 23, 42-43, 46-47, 51-53, 55-56, 66, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90, 93-94, 96, 98</span>
                    <span class="source-lines">48, 78</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/models.py</span>
                    <span>253</span>
                    <span>0</span>
                    <span>253</span>
                    <span>100.0%</span>
                    <span class="source-lines">17-18, 20, 23, 26-27, 36-38, 40, 42, 49-50, 59-61, 63, 65, 72-73, 86-92, 94, 96, 107-108, 120-126, 128, 130, 135-143, 146-147, 169-185, 187-188, 190, 192, 194, 201-224, 227-228, 236-237, 239, 241, 247-248, 257-259, 261, 263, 270-271, 280-282, 284, 286, 290-292, 295-296, 333-362, 364-372, 374, 376, 394-417, 419-437, 440-441, 455-463, 465, 467, 477-479, 482-483, 500-510, 512, 518, 520, 526-540</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/options.py</span>
                    <span>268</span>
                    <span>57</span>
                    <span>211</span>
                    <span>78.73%</span>
                    <span class="source-lines">122, 170, 199, 202-204, 209-211, 217-219, 225-227, 233-235, 241-242, 245-254, 257-259, 265-267, 271-274, 276, 284, 293, 308, 311-312, 320-325, 327, 332-337, 340-345, 348-349, 352-353, 356-357, 360-369, 372-375, 378-393, 396-397, 400-405, 408-409, 412-413, 416-421, 426-427, 430-431, 436-439, 444-447, 449, 451, 453, 460-461, 463-464, 466-467, 470-475, 479, 482-495, 498, 502-503, 507, 510, 514-515, 519-520, 524, 527, 531, 534-536, 540-541, 545-546, 550, 553, 557, 560, 564-565, 569, 572-574, 578, 581-584, 587, 591-592, 596, 599-608, 611, 613</span>
                    <span class="source-lines">13-15, 21-22, 98-102, 105-107, 110-115, 118-121, 138-139, 142-149, 152-155, 158-160, 163-166, 169, 180-184, 187-188, 191, 193, 278, 287, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/plugin.py</span>
                    <span>182</span>
                    <span>24</span>
                    <span>158</span>
                    <span>86.81%</span>
                    <span class="source-lines">41, 44, 50, 56, 62, 68, 74, 81, 90, 96, 102, 108, 114, 122, 128, 134, 142, 148, 155, 161, 169, 176, 185, 192, 199, 208, 215, 223, 229, 235, 241, 247, 254, 260, 268, 274, 283, 289, 297, 304, 311, 328, 332, 336, 342-343, 346-347, 349, 351, 354-356, 362-363, 371-372, 399-400, 403-404, 407, 410-411, 413-414, 417-418, 420, 422-426, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 476-477, 485-487, 491-494, 497, 499, 502-507, 509, 512-514, 516-521, 523, 534-535, 558-559, 562-563, 566-568, 579-580, 583, 586-587, 590-592, 602-603, 606-608, 619-620, 623, 626, 628-629</span>
                    <span class="source-lines">13, 15-18, 20-21, 23, 29-32, 35, 319, 377, 481-482, 488, 548-549, 571, 595, 611-612</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/prompts.py</span>
                    <span>110</span>
                    <span>3</span>
                    <span>107</span>
                    <span>97.27%</span>
                    <span class="source-lines">13, 15-17, 24, 27, 33, 35, 49, 52, 55, 58-61, 63, 65, 67, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 114, 116, 118, 139-140, 142-144, 147, 152-153, 155-157, 159-161, 163-164, 166-167, 170-171, 173, 177, 180, 189, 192-194, 196-197, 201, 203, 216-217, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249, 251, 268, 275, 284-287</span>
                    <span class="source-lines">80, 185, 233</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/render.py</span>
                    <span>65</span>
                    <span>6</span>
                    <span>59</span>
                    <span>90.77%</span>
                    <span class="source-lines">13, 15-16, 18, 24, 30-31, 34, 40, 42, 50-51, 53, 56, 65-67, 70, 79, 87, 90, 99, 101-102, 107, 110, 121-124, 126-129, 131-134, 140-142, 147, 155-157, 159, 172-177, 191, 210-211, 224, 267, 269, 285</span>
                    <span class="source-lines">148-149, 212, 217-218, 222</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/report_writer.py</span>
                    <span>167</span>
                    <span>3</span>
                    <span>164</span>
                    <span>98.2%</span>
                    <span class="source-lines">13, 15-25, 27-29, 46, 55, 58, 67-68, 76, 83-84, 89, 98-100, 102, 105-108, 110, 113, 116, 127-128, 130, 142, 150, 156-158, 160, 186-189, 192, 197-199, 202-203, 211, 222-223, 226-227, 230-231, 233, 235, 254, 256-259, 262-264, 266, 268, 310, 319, 321-322, 324-335, 337, 339, 347, 350-352, 355-356, 359-361, 364, 367, 375, 383, 385-386, 389, 392, 395, 398, 406, 408-409, 415, 417, 419, 421-432, 439, 441-442, 444-446, 454-458, 460, 462, 465, 468-469, 471, 477-481, 487-488, 495, 502, 504, 506-508, 510, 513-514, 516, 522-523</span>
                    <span class="source-lines">135-137</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/fs.py</span>
                    <span>34</span>
                    <span>1</span>
                    <span>33</span>
                    <span>97.06%</span>
                    <span class="source-lines">11, 13-14, 17, 30, 33, 36, 39, 42, 45, 55-56, 58-60, 63-65, 67, 70, 79, 82, 100, 103, 111-113, 116-117, 119-121, 123</span>
                    <span class="source-lines">40</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/hashing.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 14-17, 23, 32, 35, 44-48, 51, 61, 64, 73-74, 76-78, 80-81, 86, 96, 103-104, 107, 113-114, 116-121</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/ranges.py</span>
                    <span>33</span>
                    <span>0</span>
                    <span>33</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 15, 29-30, 33, 35-37, 39-40, 42, 45-47, 50, 52, 55, 65-67, 70, 81-82, 84-91, 93, 95</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/time.py</span>
                    <span>16</span>
                    <span>0</span>
                    <span>16</span>
                    <span>100.0%</span>
                    <span class="source-lines">4, 6, 9, 15, 18, 27, 30, 39-44, 46-48</span>
                    <span class="source-lines">-</span>
                </div>
            </div>
        </section>

        <section class="per-test-details" id="test-list">
            <h2>Per Test Details</h2>

        <!-- Filters -->
        <div class="filters">
            <input type="text" id="searchInput" class="filter-input" placeholder="Search tests..." onkeyup="filterTests()">
            <div class="filter-statuses" aria-label="Filter by status">
                <label class="filter-chip passed">
                    <input type="checkbox" data-status="passed" checked onchange="toggleStatus(this)">
                    Passed
                </label>
                <label class="filter-chip failed">
                    <input type="checkbox" data-status="failed" checked onchange="toggleStatus(this)">
                    Failed
                </label>
                <label class="filter-chip skipped">
                    <input type="checkbox" data-status="skipped" checked onchange="toggleStatus(this)">
                    Skipped
                </label>
                <label class="filter-chip xfailed">
                    <input type="checkbox" data-status="xfailed" checked onchange="toggleStatus(this)">
                    XFailed
                </label>
                <label class="filter-chip xpassed">
                    <input type="checkbox" data-status="xpassed" checked onchange="toggleStatus(this)">
                    XPassed
                </label>
                <label class="filter-chip error">
                    <input type="checkbox" data-status="error" checked onchange="toggleStatus(this)">
                    Error
                </label>
            </div>
        </div>

        <!-- Test List -->
        <div class="test-list">
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_adaptive_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks for complexity estimation in tests that have mocks and multiple assertions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assertion 1', 'description': 'Assertion 1 should be executed before the assertion 2', 'expected_result': True}</li>
                                            <li>{'name': 'assertion 2', 'description': 'Assertion 2 should be executed after the assertion 3', 'expected_result': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        139 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</p>
                                    <p><strong>Why Needed:</strong> The test is needed because it checks the behavior of the `Config` class when given an empty source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert provider._estimate_test_complexity() == 0', 'expected_value': 0, 'message': 'Expected provider._estimate_test_complexity to return 0'}</li>
                                            <li>{'name': 'assert provider._estimate_test_complexity(None) == 0', 'expected_value': 0, 'message': 'Expected provider._estimate_test_complexity to return 0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        158 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 185-186, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</p>
                                    <p><strong>Why Needed:</strong> To ensure that simple tests have low complexity scores and are not misleading.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'complexity_score', 'description': 'The complexity score of the test should be low.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        86 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid prompt tier configuration</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` field is validated correctly and raises an error when it's not a valid value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "The provided 'prompt_tier' should be one of: 'basic', 'advanced', or 'none'.", 'code': 400}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        93 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_valid_prompt_tiers</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Valid prompt tiers</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` parameter is correctly validated and does not cause any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Should return an empty list for valid values', 'expected_result': [], 'actual_result': 'errors'}</li>
                                            <li>{'message': 'Should throw an AssertionError for invalid values', 'expected_result': 'TestError', 'actual_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        113 output =
                                        255 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</p>
                                    <p><strong>Why Needed:</strong> Auto mode should use standard prompt for complex tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'use_standard_prompt_for_complex_tests', 'expected_value': True, 'actual_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        83 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-220, 222, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</p>
                                    <p><strong>Why Needed:</strong> To ensure that the auto-tiering mechanism is working correctly for simple tests, where minimal prompts are sufficient.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'selected_prompt_type', 'value': 'MINIMAL_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        155 input +
                                        88 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</p>
                                    <p><strong>Why Needed:</strong> To ensure that the minimal prompt is always used for config override tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config_override', 'description': 'The config override should be applied to the test provider.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        85 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 212, 214-215, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_standard_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Config override to standard should always use standard prompt.</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because it ensures that the config override to standard does not cause any issues with the system prompts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'standard_system_prompt', 'actual_result': 'STANDARD_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        82 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 212, 214, 216-217, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_all_policy</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test aggregating all policy for multiple test cases in a single run</p>
                                    <p><strong>Why Needed:</strong> Prevents regression when running multiple test cases with the same aggregate policy</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregated report contains both tests from each individual report.</li>
                                            <li>All retained tests are present in the aggregated report.</li>
                                            <li>No duplicate tests are included in the aggregated report.</li>
                                            <li>The number of tests in the aggregated report matches the expected value.</li>
                                            <li>Each test is included only once in the aggregated report.</li>
                                            <li>Duplicate test names are not included in the aggregated report.</li>
                                            <li>All retained tests have a unique outcome.</li>
                                            <li>The aggregate policy 'all' is applied to all test cases.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        154 output =
                                        518 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">71 lines (ranges: 53, 56-57, 60, 62-64, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</p>
                                    <p><strong>Why Needed:</strong> To test that the aggregate function returns None when the aggregation directory does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert aggregator.aggregate() is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        80 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 53, 56-58, 110, 113-115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_latest_policy</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the latest policy is picked when aggregating reports with different times.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the latest policy might not be chosen due to inconsistent report times.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result from `aggregate()` should contain only one test.</li>
                                            <li>The outcome of the first test in the result should be 'passed'.</li>
                                            <li>The second test in the result should have an outcome of 'passed' (latest).</li>
                                            <li>The aggregated run meta should indicate that both runs were aggregated.</li>
                                            <li>The summary for the aggregated run should show 1 passed and 0 failed tests.</li>
                                            <li>The `run_meta` object should contain a `is_aggregated` flag set to True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        162 output =
                                        639 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">79 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 204-205, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the aggregator requires a directory to aggregate data from.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'agg', 'expected_type': 'NoneType', 'message': "Expected agg to be None, but got <type 'Aggregator'>"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        96 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 45, 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that aggregate function returns None when no reports exist and no files are found.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the aggregate function returns an empty list or None when there are no reports or files to aggregate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>aggregator.aggregate() should return None.</li>
                                            <li>pathlib.Path.exists() should return True for a non-empty directory.</li>
                                            <li>pathlib.Path.glob() should return [] for a non-existent file or directory.</li>
                                            <li>The aggregate function should not attempt to aggregate any files or reports.</li>
                                            <li>No error should be raised when calling the aggregate function with no reports or files.</li>
                                            <li>The aggregate function should return an empty list or None as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        154 output =
                                        355 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 53, 56-58, 110, 113-114, 117-118, 184)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_coverage_and_llm_annotations</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that coverage and LLM annotations are properly deserialized and can be re-serialized.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in core functionality by ensuring proper deserialization of coverage and LLM annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>coverage is properly deserialized with the correct file paths, line ranges, and line counts.</li>
                                            <li>LLM annotation is properly deserialized with the correct scenario, why needed message, key assertions, confidence level, and token usage information.</li>
                                            <li>Coverage and LLM annotation can be re-serialized without any issues.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        1002 input +
                                        124 output =
                                        1126 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">87 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138-141, 145-147, 149-150, 152-153, 155, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-45, 65-68, 130-133, 135-137, 139, 141-143, 190, 194-199, 201, 203, 205, 207, 210-214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_source_coverage</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the aggregation function with source coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the aggregation function, where it fails to correctly handle source coverage summaries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `source_coverage` attribute of each report should contain a single `SourceCoverageEntry` object.</li>
                                            <li>The `file_path` attribute of the `SourceCoverageEntry` object should match the expected file path.</li>
                                            <li>All statements in the `coverage_percent` and `covered_ranges` attributes should be integers or floats.</li>
                                            <li>All statements in the `missed` attribute should be less than or equal to 0.</li>
                                            <li>The `source_coverage` attribute of each report should contain a list with exactly one element.</li>
                                            <li>Each `SourceCoverageEntry` object should have all required attributes (file_path, statements, missed, covered, coverage_percent, covered_ranges, missed_ranges).</li>
                                            <li>All values in the `coverage_percent` and `covered_ranges` attributes should be within valid ranges for source coverage percentages and ranges.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        221 output =
                                        616 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">67 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 162-169, 171-173, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_load_coverage_from_source</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading coverage from configured source file when option is not set.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case the user doesn't configure a source file for LLM coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that calling _load_coverage_from_source() returns None when llm_coverage_source is set to None.</li>
                                            <li>Verify that calling _load_coverage_from_source() raises a UserWarning with message 'Coverage source not found' when llm_coverage_source is set to '/nonexistent/coverage'.</li>
                                            <li>Verify that calling _load_coverage_from_source() returns the mock coverage object created by mocking Coverage in pytest_llm_report.coverage_map.CoverageMapper.</li>
                                            <li>Verify that calling _load_coverage_from_source() calls the mock cov.report() method with a return value of 80.0 when llm_coverage_source is set to '.coverage' and coverage_percentage is 80.0.</li>
                                            <li>Verify that calling _load_coverage_from_source() returns None when llm_coverage_source is set to a valid file path.</li>
                                            <li>Verify that the mock cov.report() method was called with the correct arguments (cov, mapper) in all test scenarios.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        584 input +
                                        247 output =
                                        831 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 259-260, 262-263, 265, 267-271, 273, 276-277, 279-280, 283, 285-286, 288)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_recalculate_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the recalculate_summary method updates the latest summary correctly when new test results are added.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the aggregation process, where the total count of tests might not be updated correctly if new test results are added after recalculating the summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of tests is updated to match the latest summary.</li>
                                            <li>The passed count remains unchanged.</li>
                                            <li>The failed count remains unchanged.</li>
                                            <li>The skipped count remains unchanged.</li>
                                            <li>The xfailed count remains unchanged.</li>
                                            <li>The xpassed count remains unchanged.</li>
                                            <li>The error count remains unchanged.</li>
                                            <li>The coverage percentage is preserved and updated correctly.</li>
                                            <li>The total duration of the latest summary is updated to match the new test results.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        170 output =
                                        643 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 231, 233-247, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_skips_invalid_json</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping an invalid JSON report prevents regression.</p>
                                    <p><strong>Why Needed:</strong> This test verifies that the aggregation function correctly skips reports with invalid JSON files, preventing potential regressions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that only valid reports are counted in the aggregate result.</li>
                                            <li>The test verifies that missing fields in an invalid JSON report are not included in the aggregate result.</li>
                                            <li>The test verifies that a UserWarning is raised when skipping an invalid JSON report, indicating that it's being handled correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        352 input +
                                        116 output =
                                        468 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123-124, 129, 131-132, 162-167, 169, 171-173, 176, 178-180, 182, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation_maximal.py::TestAggregationMaximal::test_recalculate_summary_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the aggregator recalculates the summary correctly when there are multiple tests with different outcomes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a single test's outcome affects the overall coverage calculation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>summary.total == 2</li>
                                            <li>summary.passed == 1</li>
                                            <li>summary.failed == 1</li>
                                            <li>summary.coverage_total_percent == 88.5</li>
                                            <li>summary.total_duration == 3.0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        113 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 45, 231, 233-239, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_annotator.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of batch optimization message generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'Mock provider instance'}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 'Mock cache instance'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_value': 'Mock assembler instance'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        119 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-91, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the progress reporting is cached correctly and not lost in case of a failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked cache should be initialized with mock provider', 'expected_value': 'mock_provider', 'actual_value': 'mock_cache'}</li>
                                            <li>{'name': 'Mocked cache should have no pending operations when not in use', 'expected_value': [], 'actual_value': 'mock_cache'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        133 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-128, 130, 134, 156, 181-182, 184, 211, 213-219, 221, 223)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</p>
                                    <p><strong>Why Needed:</strong> To ensure that cached tests are skipped correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'value': 'The mock provider is not called during test execution.'}</li>
                                            <li>{'name': 'mock_cache', 'value': 'The mock cache is not populated with test results.'}</li>
                                            <li>{'name': 'mock_assembler', 'value': 'The mock assembler does not call the annotated function.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        134 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">95 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-124, 130, 132, 134, 137-141, 144-151, 156, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestConcurrentAnnotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotators can annotate data concurrently without causing performance issues or data corruption.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should not raise an exception when called concurrently', 'expected_value': 'None'}</li>
                                            <li>{'name': 'Mock cache should be created and populated correctly when called concurrently', 'expected_value': {'key1': 'value1', 'key2': 'value2'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        122 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221, 223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that concurrent annotation handles failures correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Mocked annotator failed to annotate the document.', 'expected_exception': 'annotator.exceptions.AnnotatorException'}</li>
                                            <li>{'message': 'Mocked annotator encountered an error while annotating the document.', 'expected_exception': 'annotator.exceptions.AnnotatorException'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        126 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221-223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator is reporting progress correctly and accurately.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked progress bar updates are being reported correctly', 'expected_value': 'True'}</li>
                                            <li>{'name': 'The progress bar is not being updated when it should be', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        109 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator correctly displays progress messages during report generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'Mock provider instance'}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 'Mock cache instance'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_value': 'Mock assembler instance'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        122 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</p>
                                    <p><strong>Why Needed:</strong> The test respects the opt-out and limit settings for annotators.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_type': 'MockProvider'}</li>
                                            <li>{'name': 'mock_cache', 'expected_type': 'MockCache'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_type': 'MockAssembler'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        121 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 47, 50-51, 58-59, 65, 67-68, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator respects rate limits and does not exceed them.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider.get_rate_limit() returns a valid limit', 'expected_value': 10, 'actual_value': 5}</li>
                                            <li>{'name': 'mock_provider.get_rate_limit() returns an invalid limit', 'expected_value': 20, 'actual_value': 15}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        129 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-257, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation</span>
                            <div class="test-meta">
                                <span>12.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Sequential annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotations are applied in the correct order and to avoid any potential issues with concurrent access to the annotator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Annotations are applied sequentially', 'description': 'The annotator should apply each annotation in sequence, without skipping any steps.'}</li>
                                            <li>{'name': 'No annotations are skipped due to cache or provider issues', 'description': 'Even if the cache or provider is experiencing issues, the annotator should still apply all annotations in sequence.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        130 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</span>
                            <div class="test-meta">
                                <span>24.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Sequential annotation error tracking</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the annotator correctly handles errors during sequential annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'Error message should be logged and returned in the response', 'actual': 'Mocked logging and caching are not being used correctly.'}</li>
                                            <li>{'expected': 'Error message should be logged and returned in the response with a specific key', 'actual': 'Mocked logging is not being used to log error messages.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        122 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator does not skip tests when LLM is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'does_not_call_config', 'description': "The config function should be called with a Config object that has 'llm' set to False"}</li>
                                            <li>{'name': 'does_not_skip_test', 'description': 'The test should not skip when LLM is disabled'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        127 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 47-48)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</p>
                                    <p><strong>Why Needed:</strong> Because the annotator should not be skipped when a provider is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected': 'MockProvider instance was created'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        81 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 47, 50-54, 56)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_coverage_v2.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_malformed_json_after_extract</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Base Parse Response Malformed JSON After Extract</p>
                                    <p><strong>Why Needed:</strong> To test that the `extract_json_from_response` function correctly handles malformed JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error message', 'description': "The error message returned by `extract_json_from_response` should be 'Failed to parse LLM response as JSON'."}</li>
                                            <li>{'name': 'Expected invalid JSON string', 'description': 'The input JSON string should contain invalid characters or syntax.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        122 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 325-326, 329-330, 333-334, 359-360)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_non_string_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests that the `base_parse_response` function handles non-string fields correctly when provided with a JSON object containing integers, lists, and other types.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the `base_parse_response` function is modified to handle non-string fields without proper error handling or validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of the 'scenario' key should be an integer.</li>
                                            <li>The value of the 'why_needed' key should contain a list.</li>
                                            <li>The value of the 'key_assertions' key should contain the string 'a'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        130 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342-346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_gemini_provider` function returns a valid instance of `GeminiProvider`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected_type': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        83 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To test that a ValueError is raised when an unknown LLM provider is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected exception message', 'value': 'Unknown LLM provider: invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        80 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_litellm_provider` function returns a valid instance of `LiteLLMProvider`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of `LiteLLMProvider`', 'expected_type': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        97 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of getting a provider without any configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected_type': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        74 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_ollama_provider` function returns an instance of `OllamaProvider` as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of OllamaProvider', 'expected_result': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        96 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_available_caches_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test function checks for available caches correctly when a provider implements _check_availability.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where a provider does not implement _check_availability, causing tests to fail due to missing cache availability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>provider.is_available() is True</li>
                                            <li>provider.is_available() is True</li>
                                            <li>checks == 1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        94 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 134-135, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_model_name_defaults_to_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_model_name` method returns the default model name from the configuration when no custom model is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert provider.get_model_name() == 'test-model'", 'expected_value': 'test-model'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        90 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_rate_limits_defaults_to_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the rate limits are set to None by default when creating a ConcreteProvider instance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.get_rate_limits() is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        75 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_is_local_defaults_to_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults::test_is_local_defaults_to_false</p>
                                    <p><strong>Why Needed:</strong> To test that the default value for `is_local` is indeed `False`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_local() should return False', 'expected_value': False, 'actual_value': 'is_local'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        93 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 174)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_batching.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_context_files_included</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that context files are included in the batch prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where context files are not added to the prompt, potentially causing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Context files should be added to the prompt.</li>
                                            <li>The prompt should include the source file `src/module.py`.</li>
                                            <li>The prompt should include the function `def helper()` from the source file `src/module.py`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        261 input +
                                        105 output =
                                        366 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 192-194, 196-200, 203-206, 209-210, 213-214, 216-218, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_parametrized_batch_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the parametrized batch prompt functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using parameterized batches, ensuring that all variants are included in the prompt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The prompt should include 'Test Group: test.py::test_add[*]' and 'Parameterizations (2 variants)'</li>
                                            <li>The prompt should contain '[1+1=2]' and '[0+0=0]'</li>
                                            <li>The prompt should mention 'ONE annotation'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        330 input +
                                        110 output =
                                        440 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 34, 39-40, 156-157, 160, 162, 164-168, 170-177, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_single_test_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that a single test generates the expected normal prompt.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression when testing batched requests with multiple tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The generated prompt should contain 'Test: test.py::test_foo'.</li>
                                            <li>'```python' is present in the prompt.</li>
                                            <li>The source code of the test should be included in the prompt.</li>
                                            <li>The presence of 'Parameterizations' in the prompt should be avoided.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        107 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the same source code produces the same hash for consistent hashing.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where different versions of the test function produce different hashes, potentially leading to inconsistent results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The source code should be the same across all executions.</li>
                                            <li>The length of the resulting hash should remain constant at 32 bytes.</li>
                                            <li>If the source code changes, the hash should not change.</li>
                                            <li>_compute_source_hash(source) should return the same hash for different source codes.</li>
                                            <li>The hash should be a valid SHA-256 hash.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        131 output =
                                        351 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that different sources produce different hashes, which is a requirement for batch processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'different', 'condition': {'source': 'def test_a(): pass'}, 'expected_result': {'hash': '1234567890abcdef'}}</li>
                                            <li>{'assertion_type': 'different', 'condition': {'source': 'def test_b(): pass'}, 'expected_result': {'hash': 'fedcba987654321'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        143 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> The current implementation of compute_source_hash() does not handle an empty source correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _compute_source_hash() returns an empty string for an empty input', 'expected_result': '', 'actual_result': '_compute_source_hash()'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        94 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</p>
                                    <p><strong>Why Needed:</strong> The `batch_max_tests` configuration value is required to ensure the correct behavior of batched tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() returns errors', 'description': 'The `validate()` method should return an error if `batch_max_tests` is not set or is less than 1.', 'expected_type': 'list[str]', 'expected_value': ['batch_max_tests']}</li>
                                            <li>{'name': "any('batch_max_tests' in e for e in errors)", 'description': "The method should return True if 'batch_max_tests' is present in any of the error messages.", 'expected_type': 'bool'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        178 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</p>
                                    <p><strong>Why Needed:</strong> Context line padding must be non-negative.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding must be a non-negative integer', 'value': -1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        74 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To test that an invalid compression mode fails the validation process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() returns an error message', 'description': 'The validate method should return a list of errors.', 'expected': ["context_compression must be one of 'none', 'gzip', or 'lz4'"], 'actual': ["context_compression must be one of 'invalid', 'none', 'gzip', 'lz4'"]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        121 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_valid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> Valid compression modes should pass.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Context compression mode is required for valid context compression.', 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        60 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_nested_params</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_nested_params</p>
                                    <p><strong>Why Needed:</strong> To ensure that complex parameters are fully stripped from the base node ID.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'value': 'test.py::test[a-b-c]'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        78 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `parametrized_nodeid` function correctly strips parameters from nodeids.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'tests/test_foo.py::test_add[1+1=2]', 'actual': '_get_base_nodeid('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        96 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</p>
                                    <p><strong>Why Needed:</strong> This test checks that a simple nodeid without params returns unchanged.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'tests/test_foo.py::test_bar', 'actual_value': 'tests/test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        87 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batch_max_size_respected</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Large groups should be split by batch_max_tests to avoid memory issues.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential memory leak in large group sizes where the tests are not properly split into batches.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>len(batches) == 3</li>
                                            <li>len(batches[0].tests) == 2</li>
                                            <li>len(batches[1].tests) == 2</li>
                                            <li>len(batches[2].tests) == 1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        113 output =
                                        477 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 53-54, 67-68, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batching_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case for batching disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that each test is separate and not affected by the batch parameterization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Number of batches should be equal to number of tests', 'expected_value': 2, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        81 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 92-93, 95, 97-99)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_parametrized_tests_grouped</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that parametrized tests are grouped together by batch.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where parametrized tests are not properly grouped together in batches.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of batches should be equal to 1.</li>
                                            <li>Each batch should contain exactly 3 tests.</li>
                                            <li>Each batch should have an is_parametrized attribute set to True.</li>
                                            <li>Each batch's base nodeid should match the path 'test.py::test_add'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        113 output =
                                        459 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 34, 39-40, 53-54, 67, 70, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_single_tests_no_grouping</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_single_tests_no_grouping' verifies that single tests are handled correctly without grouping.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of batch testing with no groupings, ensuring each test is executed individually.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Each test should be a separate batch.</li>
                                            <li>Batching should not affect the number or structure of individual tests.</li>
                                            <li>The expected number of batches (2) and individual tests (1+1=2) should match the actual output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        114 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_cache.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_consistent_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache is storing and retrieving data from the same source, which produces the same hash.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'same_source', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        78 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is working correctly and producing different hashes for different source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Different source should produce different hash.', 'expected_result': 'different', 'actual_result': 'same'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        82 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_hash_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_hash_length</p>
                                    <p><strong>Why Needed:</strong> The hash length is not sufficient to uniquely identify the cache key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'hash', 'expected': "a string of 16 hexadecimal digits (e.g., '1234567890abcdef')", 'actual': '<hash object>'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        92 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_clear</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the cache is cleared and all entries are removed.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a bug where the cache might not be properly cleared when adding multiple entries, potentially leading to incorrect results or data loss.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Clearing the cache should remove all existing entries.</li>
                                            <li>Adding multiple entries should result in only two remaining entries.</li>
                                            <li>Cache should return None for both 'test::a' and 'test::b' after clearing.</li>
                                            <li>The cache should be empty after clearing, with no matching annotations.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        124 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 129, 132-136, 141)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotations with errors are not cached.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotation is set and retrieved correctly', 'expected_result': 'abc123'}</li>
                                            <li>{'name': 'result is None when annotation is retrieved from cache', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        90 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_get_missing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_get_missing</p>
                                    <p><strong>Why Needed:</strong> To test that the cache returns None for missing entries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cache entry should be None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        71 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 39-41, 53, 55-56, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_set_and_get</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotations are stored and retrieved correctly from the cache.</p>
                                    <p><strong>Why Needed:</strong> Prevents bypass attacks by ensuring that the cache stores and retrieves annotations in a consistent manner.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Check if the annotation is set correctly for the given key.</li>
                                            <li>Verify that the annotation's scenario matches the expected value.</li>
                                            <li>Ensure that the annotation's confidence level matches the expected value.</li>
                                            <li>Confirm that the retrieved result has the same scenario and confidence as the original annotation.</li>
                                            <li>Verify that the retrieved result does not contain any null values.</li>
                                            <li>Check if the cache stores annotations in a consistent manner across different runs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        142 output =
                                        428 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 39-41, 53, 55, 58, 60-62, 68-73, 86, 90, 92, 94, 97-101, 103, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">11 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</p>
                                    <p><strong>Why Needed:</strong> The current test does not verify the correct structure of collection errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'assert', 'expected_value': 'nodeid', 'actual_value': 'test_bad.py'}</li>
                                            <li>{'assertion_type': 'assert', 'expected_value': 'message', 'actual_value': 'SyntaxError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        114 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the `get_collection_errors` method returns an empty list when the collection is initially empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert get_collection_errors is a list', 'expected_value': [], 'actual_value': 'collector.get_collection_errors() == []'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        102 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_context_override_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction</p>
                                    <p><strong>Why Needed:</strong> Default llm_context_override should be None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'result.llm_context_override is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        70 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</p>
                                    <p><strong>Why Needed:</strong> Default llm_opt_out should be False.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result.llm_opt_out is False', 'expected_value': False, 'message': 'Expected llm_opt_out to be False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        91 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> The test captures output by default, which can lead to unexpected behavior if not expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.capture_failed_output', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        78 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</p>
                                    <p><strong>Why Needed:</strong> The default value of `capture_output_max_chars` is not sufficient to handle large output files. This test ensures that the default value is set correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert capture_output_max_chars is equal to 4000', 'expected_value': 4000, 'actual_value': 10000}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        109 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</p>
                                    <p><strong>Why Needed:</strong> To ensure that xfail failures are recorded as xfailed in the test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result.outcome', 'expected_value': 'xfailed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        206 input +
                                        81 output =
                                        287 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212, 216, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</p>
                                    <p><strong>Why Needed:</strong> xfail passes should be recorded as xpassed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_name': 'result.outcome', 'expected_value': 'xpassed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        77 output =
                                        282 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212-214)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_create_collector</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `TestCollector` class initializes correctly with an empty collection.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `TestCollector` instance is not initialized properly, leading to incorrect results or behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>collector.results == {}</li>
                                            <li>collector.collection_errors == []</li>
                                            <li>collector.collected_count == 0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        86 output =
                                        291 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_get_results_sorted</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestTestCollector::test_get_results_sorted</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collector correctly sorts the results by nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Results should be sorted by nodeid.', 'expected_result': ['a_test.py::test_a', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        89 output =
                                        316 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_handle_collection_finish</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `handle_collection_finish` method correctly tracks collected and deselected counts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the count of collected items is not updated correctly after the collection finish.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `collected_count` attribute should be set to 3 (the number of collected items).</li>
                                            <li>The `deselected_count` attribute should be set to 1 (the number of deselected items).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        109 output =
                                        365 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 78-79, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</p>
                                    <p><strong>Why Needed:</strong> Capture output via handle_runtest_logreport is disabled for integration test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected_result', 'type': 'assertion', 'message': "Expected `collector.results['t'].captured_stdout` to be None"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        98 output =
                                        309 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals::test_capture_output_stderr</p>
                                    <p><strong>Why Needed:</strong> To test that the collector correctly captures stderr.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected captured stderr to be empty', 'description': 'The collector should not capture any output from stderr.', 'expected_value': '', 'actual_value': 'Some error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        88 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals::test_capture_output_stdout</p>
                                    <p><strong>Why Needed:</strong> To verify that the collector correctly captures stdout and stores it in the TestCaseResult.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stdout', 'expected_value': 'Some output'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        71 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_truncated</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_create_result_with_item_markers</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test `create_result_with_item_markers` verifies that the collector extracts item markers correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the collector does not extract item markers from the item, potentially leading to incorrect report generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>item.get_closest_marker('llm_opt_out') returns MagicMock()</li>
                                            <li>item.get_closest_marker('llm_context') returns MagicMock(args=['complete'])</li>
                                            <li>item.get_closest_marker('requirement') returns MagicMock(args=['REQ-1', 'REQ-2'])</li>
                                            <li>result.param_id is set to 'param1'</li>
                                            <li>result.llm_opt_out is True</li>
                                            <li>result.llm_context_override is set to 'complete'</li>
                                            <li>result.requirements contains ['REQ-1', 'REQ-2']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        382 input +
                                        178 output =
                                        560 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163-164, 167-169, 171, 181-182, 185-189, 198-200, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_repr_crash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_collector_maximal</p>
                                    <p><strong>Why Needed:</strong> To test the `_extract_error` method's ability to return a string representing an error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected output', 'value': 'Some error occurred'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        69 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_extract_skip_reason` method returns `None` when no longrepr is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert collector._extract_skip_reason(report) is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        92 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250, 252)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</p>
                                    <p><strong>Why Needed:</strong> To ensure the `_extract_skip_reason` method returns a string as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert _extract_skip_reason returns 'Just skipped'", 'expected_value': 'Just skipped'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        85 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_tuple</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_collection_report_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `handle_collection_report` method records a collection error and updates the `collection_errors` list with the relevant information.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the collector does not record errors in a collection report, potentially leading to missing important information about the failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `handle_collection_report` method should update the `collection_errors` list with the nodeid and message of the error.</li>
                                            <li>The `collection_errors` list should contain exactly one item with the specified nodeid and message.</li>
                                            <li>The nodeid in the first collection_error should match the value passed to the `report.nodeid` attribute.</li>
                                            <li>The message in the first collection_error should match the value passed to the `report.message` attribute.</li>
                                            <li>The error type (in this case, a 'SyntaxError') should be present in the first collection_error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        196 output =
                                        469 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 58, 60-65, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_rerun</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'handle_runtest_rerun' verifies that the TestCollector handles rerun attribute correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the TestCollector does not handle reruns correctly, potentially leading to incorrect results or failures.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.rerun_count should be equal to 1</li>
                                            <li>res.final_outcome should be 'failed'</li>
                                            <li>collector.results['t::r'] should contain a 'rerun' key with value 1</li>
                                            <li>collector.results['t::r'].final_outcome should be 'failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        132 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140-141, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238, 261, 264-265, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_setup_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'handle_runtest_setup_failure' verifies that a setup error is recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that setup errors are properly reported and handled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.outcome should be set to 'error'</li>
                                            <li>res.phase should be set to 'setup'</li>
                                            <li>res.error_message should match 'Setup failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        300 input +
                                        91 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_teardown_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that handle_runtest_teardown_failure verifies that a teardown failure records an error and prevents the collector from proceeding with the next test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that when a teardown operation fails, it correctly reports an error and stops the collection of results for the current test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `teardown` report should contain an error message indicating 'Cleanup failed'.</li>
                                            <li>The `outcome` of the result for the current test should be set to 'error'.</li>
                                            <li>The `phase` of the result for the current test should be set to 'teardown'.</li>
                                            <li>The `error_message` of the result for the current test should contain 'Cleanup failed'.</li>
                                            <li>If the teardown operation fails, the collector should not proceed with collecting results for the next test.</li>
                                            <li>If the teardown operation succeeds, the collector should still report an error and stop collecting results for the current test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        207 output =
                                        598 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127-128, 130, 132-133, 135-137, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_compression.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_invalid_compression_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid compression mode</p>
                                    <p><strong>Why Needed:</strong> To test that an invalid compression mode fails validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "Context compression should be 'none' or 'gzip'", 'expected_value': 'none|gzip', 'actual_value': 'invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        76 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</p>
                                    <p><strong>Why Needed:</strong> Negative padding is not allowed in context lines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding should be a non-negative integer.', 'expected_type': 'int', 'actual_type': -1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        83 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_valid_compression_modes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To ensure that valid compression modes are validated correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() should return an empty list of errors', 'description': 'The validate method should not return any error messages for valid compression modes.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        76 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</p>
                                    <p><strong>Why Needed:</strong> Zero padding is a valid configuration for the context line padding.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'context_line_padding should be 0 or less.', 'actual': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        77 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> Context compression should be enabled by default ('lines').</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        74 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestContextCompression::test_compression_mode_lines</p>
                                    <p><strong>Why Needed:</strong> Lines compression mode is required for this test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        63 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_line_padding_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_line_padding_default</p>
                                    <p><strong>Why Needed:</strong> To ensure that line padding is set correctly in the default context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_line_padding', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        82 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_contiguous_lines_no_gap</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that contiguous covered lines do not have gap indicators when there is no padding.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where contiguous lines without gaps are incorrectly marked as uncovered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The count of '# ...' should be zero for contiguous lines without gaps.</li>
                                            <li># L3:</li>
                                            <li># L4:</li>
                                            <li># L5:</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        86 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks for an empty coverage scenario, which can occur when no lines are covered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'result == ""', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        83 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 216-217)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_multiple_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Covered Lines: Multiple covered ranges should be extracted with gap indicators.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where multiple covered lines are not correctly identified with gap indicators.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The '# ...' line is present in the result.</li>
                                            <li>The '# L3:' line is present in the result.</li>
                                            <li>The '# L15:' line is present in the result.</li>
                                            <li>Gap indicator between ranges is included in the output.</li>
                                            <li>Multiple covered lines are correctly identified with gap indicators.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        120 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Single covered line should be extracted with padding.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the single covered line is not extracted correctly due to incorrect padding.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert '# L2:' in result</li>
                                            <li>assert '# L3:' in result</li>
                                            <li>assert '# L4:' in result</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        302 input +
                                        81 output =
                                        383 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_padding_boundary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Covered Lines: Padding should not go beyond file boundaries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where padding exceeds the file boundary, potentially causing incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The extracted covered lines should not have negative line numbers (L0 and L4).</li>
                                            <li>The extracted covered lines should only contain lines from the first to third lines (L1, L2, and L3).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        104 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_limits.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_no_truncation_needed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_limits.py::test_no_truncation_needed</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation may truncate context due to performance reasons.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The prompt should contain 'short content'", 'expected_result': 'short content'}</li>
                                            <li>{'assertion': "The prompt should not contain 'truncated'", 'expected_result': 'no-truncation-needed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        158 input +
                                        110 output =
                                        268 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_smart_distribution</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_limits.py::test_smart_distribution verifies the context limits for F1 and F2 to ensure they are allocated fair share of budget without unnecessary truncation.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that could cause F1's content to be truncated unnecessarily when its required tokens exceed available budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>F1 should get full allocation of budget (40 tokens).</li>
                                            <li>F2 should get extra budget beyond required allocation (180 tokens).</li>
                                            <li>F2 content is not fully allocated, with excess characters (>480 tokens) that are truncated.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        773 input +
                                        131 output =
                                        904 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_splitting_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the splitting logic correctly identifies files with large contents and truncates strings while maintaining budget limits.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the splitting logic fails to truncate strings for files with large contents, leading to incorrect results or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file "f1" contains more than 100 tokens (400 characters).</li>
                                            <li>The file "f2" contains more than 100 tokens (400 characters).</li>
                                            <li>The string 'Present' is truncated and appears in the prompt.</li>
                                            <li>The budget per file is approximately 80 tokens, which is within the allowed limit of 200 tokens for both files.</li>
                                            <li>The overhead is small, as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        160 output =
                                        477 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_truncation_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test truncation logic for large context files when limit is exceeded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the context is too long and needs to be truncated due to memory constraints.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The prompt should be truncated to fit within 100 tokens minus system prompt overhead.</li>
                                            <li>Context should be very small or empty if limit is exceeded.</li>
                                            <li>Prompt should contain '[... truncated]' or 'Relevant context' if no budget is left.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        397 input +
                                        109 output =
                                        506 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 243, 245, 264, 266, 270-272, 274-275)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_util.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">28 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing empty lines in a context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\n\nline2', 'actual_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        83 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing empty lines in a multi-line source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The result is equal to 'line1\n\nline2'.", 'expected_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        90 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test if the `collapse_empty_lines` function correctly preserves up to 2 consecutive newlines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The source string has two or fewer consecutive newlines.', 'expected_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        94 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</p>
                                    <p><strong>Why Needed:</strong> Preserve single newlines in collapsed lines</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\nline2\nline3', 'actual_result': 'line1\nline2\nline3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        82 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</p>
                                    <p><strong>Why Needed:</strong> Because empty lines are not being collapsed by the current implementation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '', 'actual': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        137 input +
                                        70 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</p>
                                    <p><strong>Why Needed:</strong> To ensure that the combined optimization process is applied correctly and optimizes the code efficiently.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The optimized source code contains all necessary key assertions.', 'expected_result': 'The optimized source code contains all necessary key assertions.'}</li>
                                            <li>{'assertion': 'The combined optimization process does not introduce any new errors or warnings.', 'expected_result': 'No new errors or warnings were introduced by the combined optimization process.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        134 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</p>
                                    <p><strong>Why Needed:</strong> To ensure that default context stripping only removes docstrings, without affecting comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring removal', 'expected_result': 'True'}</li>
                                            <li>{'name': 'comment presence', 'expected_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        97 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> The function should be able to handle an empty source without raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        69 output =
                                        164 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the source code contains only whitespace characters, such as blank lines or multiple consecutive whitespace characters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'value': '   \n\n   \n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        87 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_both</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_both</p>
                                    <p><strong>Why Needed:</strong> To remove unnecessary documentation from the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'strip_comments', 'expected_output': 'docstring', 'actual_output': 'comment'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        77 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</p>
                                    <p><strong>Why Needed:</strong> To optimize the context by removing unnecessary comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'expected_output', 'expected_output': 'def foo():\n  # This is a comment\n  pass'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        83 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 81-82, 86, 88-90, 93, 108, 124, 126, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_neither</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_neither</p>
                                    <p><strong>Why Needed:</strong> The current implementation of `optimize_context` does not strip unnecessary code, which can lead to unexpected behavior if the user explicitly requests it.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function `foo()` is kept in the optimized context.', 'expected_result': 'def foo():', 'actual_result': 'def foo():'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        108 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `strip_comments` function correctly removes comments from strings containing hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The output of the `strip_comments` function is equal to the expected string.', 'expected_value': '\'url = "http://example.com#anchor"\'', 'actual_value': 'result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        109 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_escaped_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_escaped_quotes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context utility correctly handles escaped quotes in strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'basic behavior', 'expected_result': '# comment', 'actual_result': 'The escaped quote handling is simplified, check basic behavior'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        88 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_mixed_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_mixed_quotes</p>
                                    <p><strong>Why Needed:</strong> To strip quotes from a string containing both single and double quotes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '"don\'t # worry"', 'actual': 'x = "don\'t # worry"  # comment'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        83 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_no_comments</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_no_comments</p>
                                    <p><strong>Why Needed:</strong> To strip comments from the source code, ensuring that only relevant information is exposed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'source_code', 'expected_result': 'def foo():\n  # This line will be stripped\nreturn 1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        91 input +
                                        90 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</p>
                                    <p><strong>Why Needed:</strong> Preserves # inside double-quoted strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'result = \'url = "http://example.com#anchor"\'.split(\''}</li>
                                            <li>expected_result': '</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        104 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `strip_comments` function preserves # inside single-quoted strings, which is essential for maintaining the integrity of the original source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'result == "url = \'http://example.com#anchor\'",', 'expected_result': '"url = \'http://example.com#anchor\'",'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        116 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_simple_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_simple_comment</p>
                                    <p><strong>Why Needed:</strong> To remove simple end-of-line comments from the source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'x = 1', 'actual_result': 'x = 1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        76 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</p>
                                    <p><strong>Why Needed:</strong> To strip standalone comments from the test source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'strip_comments', 'expected_result': 'The line is no longer a comment'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        77 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the function `strip_docstrings` handles syntax errors correctly by returning the original source code when an unclosed parenthesis is found.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'def foo( unclosed paren', 'actual_value': 'def foo( parentheses ', 'message': 'The expected value does not match the actual value.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        115 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 27, 29-31)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</p>
                                    <p><strong>Why Needed:</strong> The function `strip_docstrings` is used to strip unnecessary docstrings from Python code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function should remove all docstrings, not just the first one.', 'expected_result': 'All docstrings in the module should be removed.'}</li>
                                            <li>{'assertion': 'The function should only strip the first occurrence of a docstring.', 'expected_result': 'Only the first docstring should be stripped.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        135 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve multiline data strings in docstrings when stripping context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'strip_context preserves triple-quoted strings', 'expected_value': 'foo()', 'actual_value': 'def foo():\n    """\n    def foo():\n```python\n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        106 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve regular strings in test context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Regular string is preserved', 'expected_value': '\'x = "hello world"\'', 'actual_value': '\'x = "hello world"\''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        88 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 27, 29, 33, 35-36, 38-45, 49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</p>
                                    <p><strong>Why Needed:</strong> Preserve strings in structures is a critical test case for context utilities.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Ensure the function correctly preserves strings in lists/dicts.', 'expected_value': 'Should preserve strings in lists/dicts.'}</li>
                                            <li>{'description': 'Verify the function handles nested quotes correctly.', 'expected_value': 'Should handle nested quotes correctly'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        119 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</p>
                                    <p><strong>Why Needed:</strong> Because of the presence of a multiline docstring, it is causing issues with test coverage and readability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'remove', 'expected_result': 'striped'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        83 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> To remove triple double-quoted docstrings from the test source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "source.strip('"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        99 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> To remove triple single-quoted docstrings from the test source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'source should be modified to not include triple single-quoted docstrings', 'expected_result': 'source = "def foo():\n    # triple single-quoted docstring\n    pass"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        108 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_boosters.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_model_parsing_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the Gemini model parsing edge cases for coverage boosters.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case a new model is added to the preferred list without updating the existing tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function provider._parse_preferred_models() should return ['m1', 'm2'] when the config.model is set to 'm1' or 'm2'.</li>
                                            <li>The function provider._parse_preferred_models() should return an empty list when the config.model is None.</li>
                                            <li>The function provider._parse_preferred_models() should return ['All'] when the config.model is set to 'All'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        144 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 134-135, 137-141, 143-144, 476, 478, 524-531)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_rate_limiter_edge_math</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter prevents over and under token limits for edge cases.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression in the rate limiter's behavior when dealing with edge cases where there are more tokens available than requested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The next_available_in method should return 0 when both limits are exceeded (50+60 > 100).</li>
                                            <li>The next_available_in method should not be able to return a positive value when only one limit is exceeded (10 > 0).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        120 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_models_to_dict_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `to_dict()` method of `SourceCoverageEntry` returns the correct coverage percentage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the coverage percentage is not correctly calculated for certain types of source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `d['coverage_percent']` should be equal to 50.0.</li>
                                            <li>The value of `ann.to_dict()['error']` should be equal to 'timeout'.</li>
                                            <li>The value of `meta.to_dict()['duration']` should be equal to 1.0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        128 output =
                                        446 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 96-103, 130-133, 135, 137-139, 141, 143, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</p>
                                    <p><strong>Why Needed:</strong> Mapper initialization should be tested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mapper.config is equal to config', 'expected_value': 'config', 'actual_value': 'mapper.config'}</li>
                                            <li>{'name': 'mapper.warnings are empty', 'expected_value': [], 'actual_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        103 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</p>
                                    <p><strong>Why Needed:</strong> To ensure the get_warnings method returns a valid list of warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return a list of warnings.', 'expected_type': 'list'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        76 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 44-45, 308)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_map_coverage_no_coverage_file</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `map_coverage` method returns an empty dictionary when no coverage file is present.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails with an incorrect result (empty dict) when there's no coverage file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `map_coverage()` method should return an empty dictionary when no coverage file exists.</li>
                                            <li>The `map_coverage()` method should have at least one warning in this scenario.</li>
                                            <li>The `map_coverage()` method should not throw any exceptions when no coverage file is present.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        277 input +
                                        124 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_all_phases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `CoverageMapper` correctly extracts node IDs for all phases when the `include_phase` parameter is set to 'all'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the coverage map might not include all phases if the `include_phase` parameter is not set to 'all'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The node ID extracted for each phase should be the same as the original node ID.</li>
                                            <li>The node IDs for different phases should be in the same order.</li>
                                            <li>Any additional phase information (e.g., method name) should be ignored when extracting node IDs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        138 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the context is empty or None, allowing for proper coverage extraction.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'assert mapper._extract_nodeid([]) == None', 'expected_result': 'None'}</li>
                                            <li>{'assertion': 'assert mapper._extract_nodeid(None) == None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        118 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage mapping</p>
                                    <p><strong>Why Needed:</strong> To filter out setup phase when include_phase=run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Expected value to be None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        139 input +
                                        63 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 216, 220, 224-225, 228-230)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</p>
                                    <p><strong>Why Needed:</strong> To extract the correct node ID from the run phase context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'test.py::test_foo', 'actual_value': 'test.py::test_foo'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        86 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_contexts_by_lineno_exception</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `contexts_by_lineno` method raises an exception when called with a mocked context that fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in handling unexpected exceptions during context extraction.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_data.contexts_by_lineno.side_effect is set to contexts_side_effect</li>
                                            <li>call_count[0] should be incremented by 1 before raising the exception</li>
                                            <li>the exception raised is an instance of `Exception`</li>
                                            <li>the error message is 'Error accessing contexts'</li>
                                            <li>the context with ID 1 has a key-value pair with value ['test::test_foo|run']</li>
                                            <li>the number of calls to `contexts_by_lineno` is 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        155 output =
                                        487 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152, 156, 160-162, 167-170, 199, 202)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</p>
                                    <p><strong>Why Needed:</strong> To test that the function returns an empty dictionary when there are no measured files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is a dictionary', 'expected_value': {}, 'message': 'The result should be an empty dictionary'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        90 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 44-45, 118, 121-122, 127-128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Contexts</p>
                                    <p><strong>Why Needed:</strong> Skip non-Python files</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Value comparison', 'expected_value': {}, 'actual_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        60 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_coverage_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for coverage when `coverage.py` is not installed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mapper is created successfully', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        166 input +
                                        68 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> To test the scenario when no .coverage file exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'type': 'assertion', 'name': 'result is None', 'description': 'The function _load_coverage_data() should return None when no .coverage file exists.'}</li>
                                            <li>{'type': 'assertion', 'name': "any('W001' in w.code for w in mapper.warnings)", 'description': "The function _load_coverage_data() should have a warning 'W001' in the warnings list."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        139 output =
                                        292 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_analysis_exception_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the exception handling of analysis2 when it raises an exception.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression and ensure that warnings are properly generated when analysis2 raises an exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that no coverage is added to the report when analysis2 raises an exception.</li>
                                            <li>The test verifies that a warning is generated with the message 'COVERAGE_ANALYSIS_FAILED' for each measured file.</li>
                                            <li>The test verifies that all warnings are properly handled and do not prevent further analysis or reporting.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        118 output =
                                        404 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_empty_statements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage</p>
                                    <p><strong>Why Needed:</strong> To test the coverage map when there are no statements in a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return an empty list of lines covered by the code.', 'expected_result': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        178 input +
                                        72 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259-261, 273-274, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_include_test_files_when_not_configured</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that test files are included when omit_tests_from_coverage is False.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage reporting when omitting tests from the coverage report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `mapped_data` attribute of the `result` object should contain a single entry with 'covered' set to 2 and 'missed' set to 1.</li>
                                            <li>The `mapped_data` attribute of the `result` object should not be empty.</li>
                                            <li>The `covered` value in the first test data entry is correct (i.e., it has been measured by the coverage tool).</li>
                                            <li>The `missed` value in the first test data entry is correct (i.e., it does not have any unmeasured files).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        168 output =
                                        490 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Map Source Coverage</p>
                                    <p><strong>Why Needed:</strong> Skip non-Python files</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected to skip non-Python files', 'description': 'The test should skip non-Python files'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        65 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 44-45, 243-244, 246-249, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_test_files_when_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> {'id': 'test_skip_test_files_when_configured', 'description': 'Test that test files are skipped when omit_tests_from_coverage is True.', 'key_assertions': [{'name': 'expected_result', 'type': 'list', 'value': []}]}</p>
                                    <p><strong>Why Needed:</strong> {'id': 'test_skip_test_files_when_configured', 'description': 'Test that test files are skipped when omit_tests_from_coverage is True.', 'key_assertions': [{'name': 'expected_result', 'type': 'list', 'value': []}]}</p>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        182 input +
                                        295 output =
                                        477 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 243-244, 246-248, 250, 252-255, 257, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_all_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all phases are accepted when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where some phases might be missed due to incorrect configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mapper should return the nodeid for any phase in the config.</li>
                                            <li>The mapper should return the same nodeid for different phases (e.g., 'setup', 'run', 'teardown')</li>
                                            <li>All three assertions should pass with the same expected result</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        305 input +
                                        103 output =
                                        408 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the `extract_nodeid` function handles empty strings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert mapper._extract_nodeid returns None for empty string', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        90 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</p>
                                    <p><strong>Why Needed:</strong> None input returns None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        58 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_run_phase_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that run phase is the default filter.</p>
                                    <p><strong>Why Needed:</strong> Prevents unexpected behavior when run phases are not specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>When the 'phase' parameter is missing, it should return the nodeid of the current file.</li>
                                            <li>When the 'phase' parameter does not match 'run', it should return None for that phase.</li>
                                            <li>When the 'phase' parameter does not match 'setup' or 'teardown', it should return None for those phases.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        114 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_setup_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that setup phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the setup phase is incorrectly filtered, leading to false positives in coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        125 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_teardown_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that teardown phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the teardown phase is not properly filtered, potentially leading to false positives in coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        127 output =
                                        423 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233-234, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</p>
                                    <p><strong>Why Needed:</strong> To ensure that the node id is extracted correctly when there are no phase delimiters in the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'test_foo.py::test_bar', 'actual_value': 'test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        94 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 44-45, 216, 220, 224, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_full_logic</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test extracts all contexts for full logic coverage.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage analysis when _extract_contexts is called with a file that has multiple logical contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'file_path': 'test_app.py::test_one', 'line_count': 2}</li>
                                            <li>{'file_path': 'test_app.py::test_two', 'line_count': 3}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        94 output =
                                        507 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152-153, 156, 160-163, 165, 167-168, 173, 176, 178-184, 187-189, 191-194, 196, 199-200, 202, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</p>
                                    <p><strong>Why Needed:</strong> To test the behavior of the _extract_contexts method when there are no test contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result is empty', 'expected_value': {}, 'message': 'Expected result to be an empty dictionary, but got {}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        100 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_nodeid_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test extracting node IDs for maximal coverage in different phases.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `CoverageMapper` correctly extracts node IDs from code paths regardless of phase.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_extract_nodeid` is called with a valid path and returns the expected node ID.</li>
                                            <li>The function `_extract_nodeid` is called with an invalid path (e.g., without a phase) and returns `None` as expected.</li>
                                            <li>The function `_extract_nodeid` is called with a context that does not contain any code paths (e.g., `test.py::test_no_phase`) and returns the expected node ID.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        150 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-234, 236, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_no_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_load_coverage_data_no_files function correctly handles the case when no coverage files exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the test might fail due to missing coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return None for _load_coverage_data() without any .coverage files.</li>
                                            <li>The number of warnings should be 1.</li>
                                            <li>The first warning code should be 'W001'.</li>
                                            <li>The current working directory should remain unchanged after the test.</li>
                                            <li>No coverage file should have been loaded into the mapper.</li>
                                            <li>The mapper's warnings list should contain only one item.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        142 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_read_error</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ensures that the CoverageMapper can handle errors reading coverage files correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the CoverageMapper fails to report coverage data when an error occurs while reading it.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _load_coverage_data() should return None and set warnings to include 'Failed to read coverage data' when an exception is raised by the mock CoverageData.</li>
                                            <li>The function _load_coverage_data() should not raise any exceptions itself, but instead propagate them up the call stack.</li>
                                            <li>The function _load_coverage_data() should log the error message in the warnings list.</li>
                                            <li>The function _load_coverage_data() should set the 'error' level warning to include 'Failed to read coverage data'.</li>
                                            <li>The function _load_coverage_data() should not return any value (i.e., it should be None).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        189 output =
                                        532 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94-96, 107-111, 114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_with_parallel_files</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle parallel coverage files from xdist and verify that the CoverageMapper correctly updates its internal data structures.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling parallel coverage files, ensuring that the CoverageMapper correctly updates its internal data structures when loading coverage data with multiple parallel files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock instances of `CoverageData` are returned by the `_load_coverage_data()` method and updated accordingly.</li>
                                            <li>The `update()` method is called on the `CoverageData` instance for each mock instance.</li>
                                            <li>At least two calls to `update()` are made on the `CoverageData` instance.</li>
                                            <li>The `update()` method is called on the first mock instance (`mock_main_data`), and then on the second mock instance (`mock_parallel_data1`).</li>
                                            <li>The `update()` method is called on the third mock instance (`mock_parallel_data2`) but no call is made to it.</li>
                                            <li>No calls are made to the `update()` method on any other instances of `CoverageData`.</li>
                                            <li>The `update()` method is only called for the first two mock instances, and not for the third one.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        378 input +
                                        248 output =
                                        626 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94, 98, 101-104, 106)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_coverage_no_data</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `map_coverage` method returns an empty dictionary when `_load_coverage_data` returns None.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails if there is no coverage data loaded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_load_coverage_data` method of the `CoverageMapper` instance should return `None` when called with an empty dictionary.</li>
                                            <li>The `map_coverage` method of the `CoverageMapper` instance should return an empty dictionary when passed a non-empty dictionary.</li>
                                            <li>The test should not fail if there is no coverage data loaded, i.e., `_load_coverage_data` returns None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        142 output =
                                        370 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-45, 58-60)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_analysis_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle errors during coverage analysis.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of unexpected errors during analysis, ensuring test coverage is not affected by unhandled exceptions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocked `analysis2` raises an exception when called with error message.</li>
                                            <li>Mocked `get_data` returns mock data but does not raise an exception.</li>
                                            <li>Mocked `map_source_coverage` skips files with errors.</li>
                                            <li>Expected no entries in the list of coverage results.</li>
                                            <li>Asserts that the length of the entries is 0, indicating no skipped files due to error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        136 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_comprehensive</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests coverage of map_source_coverage method with comprehensive test data.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage analysis when testing all paths in map_source_coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The method should return exactly one entry for the given mock data.</li>
                                            <li>The file path of the returned entry should be 'app.py'.</li>
                                            <li>The number of statements in the returned entry should be 3.</li>
                                            <li>The coverage percentage of the returned entry should be 66.67%.</li>
                                            <li>All covered lines should have a count greater than or equal to 1.</li>
                                            <li>No uncovered lines should have a count less than 2.</li>
                                            <li>All missing lines should have a count greater than 0.</li>
                                            <li>The coverage percentage of each line should add up to 100%.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        345 input +
                                        174 output =
                                        519 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_make_warning</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `make_warning` factory function with a valid warning code and message.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where an unknown or invalid warning code is passed to the `make_warning` function, causing it to raise a `ValueError`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The returned object has the correct `code` attribute set to `WarningCode.W001_NO_COVERAGE`.</li>
                                            <li>The message of the returned object contains the expected string 'No .coverage file found'.</li>
                                            <li>The detail of the returned object matches the provided value 'test-detail'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        132 output =
                                        368 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_code_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that warning codes have correct values.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the incorrect value is assigned to a warning code, potentially causing unexpected behavior or errors in downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Assertion failed: WarningCode.W001_NO_COVERAGE.value == "W001"', 'expected': 'WarningCode.W001_NO_COVERAGE', 'actual': 'WarningCode.W001'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W101_LLM_ENABLED.value == "W101"', 'expected': 'WarningCode.W101_LLM_ENABLED', 'actual': 'WarningCode.W101'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W201_OUTPUT_PATH_INVALID.value == "W201"', 'expected': 'WarningCode.W201_OUTPUT_PATH_INVALID', 'actual': 'WarningCode.W201'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W301_INVALID_CONFIG.value == "W301"', 'expected': 'WarningCode.W301_INVALID_CONFIG', 'actual': 'WarningCode.W301'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W401_AGGREGATE_DIR_MISSING.value == "W401"', 'expected': 'WarningCode.W401_AGGREGATE_DIR_MISSING', 'actual': 'WarningCode.W401'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        290 output =
                                        530 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWarning.to_dict() method.</p>
                                    <p><strong>Why Needed:</strong> Prevents a warning about the ReportWarning.to_dict() method being used with warnings that have no detail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'code' key should be present in the dictionary with value 'W001'.</li>
                                            <li>The 'message' key should be present in the dictionary with value 'No coverage'.</li>
                                            <li>The 'detail' key should be present in the dictionary with value 'some/path'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        112 output =
                                        388 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_known_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test creates warning with standard message for known code.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where a known code might not create a warning.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>w.code == WarningCode.W101_LLM_ENABLED</li>
                                            <li>w.message == WARNING_MESSAGES[WarningCode.W101_LLM_ENABLED]</li>
                                            <li>w.detail is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        82 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_make_warning_unknown_code</p>
                                    <p><strong>Why Needed:</strong> To handle unknown code in the typed function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected', 'type': 'assertion', 'message': "The message for missing warning code should be 'Unknown warning.'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        202 input +
                                        75 output =
                                        277 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</p>
                                    <p><strong>Why Needed:</strong> To test the creation of a warning with detail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'w.code == WarningCode.W301_INVALID_CONFIG', 'expected_value': 'WarningCode.W301_INVALID_CONFIG'}</li>
                                            <li>{'name': "w.detail == 'Bad value'", 'expected_value': 'Bad value'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        107 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Error Codes</p>
                                    <p><strong>Why Needed:</strong> The `test_codes_are_strings` test is checking that the WarningCode enum values are strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert isinstance(code.value, str)', 'description': 'Ensure that each code value is a string.'}</li>
                                            <li>{'name': "assert code.value.startswith('W')", 'description': "Ensure that each code starts with 'W', which indicates a warning code."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        112 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_no_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_no_detail</p>
                                    <p><strong>Why Needed:</strong> To ensure that the warning data is correctly serialized without any additional details.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': {'code': 'W001', 'message': 'No coverage'}, 'actual_value': {'code': 'W001_NO_COVERAGE', 'message': 'No coverage'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        120 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_non_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_non_python_file</p>
                                    <p><strong>Why Needed:</strong> Because the test is checking for non-.py files, which are not Python files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Should return False', 'value': False}</li>
                                            <li>{'message': 'for non-.py files', 'value': 'The file does not have a .py extension.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        95 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_python_file</p>
                                    <p><strong>Why Needed:</strong> The function `is_python_file` should be able to identify .py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function is called with a valid .py file path.', 'condition': "assert is_python_file('foo/bar.py') == True"}</li>
                                            <li>{'description': 'The function raises an error when given a non-.py file path.', 'condition': "is_python_file('non_py_file.txt')"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        128 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_makes_path_relative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_makes_path_relative</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function correctly handles path relative paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The file path is absolute after making it relative.', 'expected_result': '/subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        84 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function returns a normalized path when no base is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        78 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_already_normalized</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_already_normalized</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if the `normalize_path` function correctly handles already-normalized paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert normalize_path returns original path for already-normalized paths', 'expected_value': 'foo/bar', 'actual_value': "normalize_path('foo/bar') == 'foo/bar'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        104 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_forward_slashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_forward_slashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly handles paths with forward slashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'foo\\bar', 'expected': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        74 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly removes trailing slashes from file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '/foo/bar/', 'actual': 'foo/bar/'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        77 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> to test the custom exclusion of paths based on patterns</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'should skip a path matching a custom pattern', 'expected_result': True, 'actual_result': 'True'}</li>
                                            <li>{'description': 'should not skip a path not matching any custom pattern', 'expected_result': False, 'actual_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        117 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_normal_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_normal_path</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `should_skip_path` function does not incorrectly skip normal file system paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert should_skip_path('src/module.py') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        67 output =
                                        163 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_git</p>
                                    <p><strong>Why Needed:</strong> The test should be skipped when the path contains a .git directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'path': '.git/objects/foo'}, 'actual': {'should_be': True, 'is_true': False}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        85 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</p>
                                    <p><strong>Why Needed:</strong> The test should be skipped because it's trying to access a __pycache__ directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'foo/__pycache__/bar.pyc', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        83 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_venv</p>
                                    <p><strong>Why Needed:</strong> The test checks if the `should_skip_path` function correctly identifies venv directories as being to be skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Assertion failed', 'expected': True, 'actual': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        80 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Non-.py files should not be considered Python files.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function `is_python_file` incorrectly identifies non-.py files as Python files, leading to incorrect results or unexpected behavior in downstream code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert is_python_file('module.txt') is False</li>
                                            <li>assert is_python_file('module.pyc') is False</li>
                                            <li>assert is_python_file('module') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        210 input +
                                        108 output =
                                        318 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a module file (.py) returns True.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the function `is_python_file` incorrectly identifies non-Python files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert is_python_file('module.py') is True</li>
                                            <li>assert is_python_file('path/to/module.py') is True</li>
                                            <li>assert is_python_file(Path('module.py')) is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        97 output =
                                        309 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_path_not_under_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makes sure `make_relative` returns the correct absolute path when the input path is not relative to the base.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where `make_relative` would incorrectly return an absolute path for paths that are not under the base.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should only include paths that are directly under the base in its result.</li>
                                            <li>The function should exclude any file extensions from being included in the result.</li>
                                            <li>The function should handle cases where the input paths have different levels of nesting (e.g., `project1/subdir/file.py` vs. `/path/to/project2/subdir/file.py`).</li>
                                            <li>The function should not include any redundant or unnecessary information in its output (e.g., file extensions, directory names).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        301 input +
                                        172 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Make Relative</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of making relative paths in the file system.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_output': 'subdir/file.py', 'actual_output': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        66 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_make_relative_with_none_base</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of making a relative path with a None base.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'path/to/file.py', 'actual_value': 'normalized_path'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        68 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that backslashes are correctly converted to forward slashes in file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The normalized path contains a single forward slash.', 'expected_result': '/path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        84 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</p>
                                    <p><strong>Why Needed:</strong> Normalization of a Path object is necessary to ensure consistency and correctness in file system operations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': '/path/to/file.py', 'expected_result': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        81 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure the function correctly handles paths with trailing slashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '/path/to/dir/', 'actual': 'path/to/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        74 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</p>
                                    <p><strong>Why Needed:</strong> Regular paths are not skipped by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should skip regular path', 'expected_result': {'scenario': 'False', 'why_needed': ''}, 'actual_result': {'scenario': 'True', 'why_needed': ''}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        96 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</p>
                                    <p><strong>Why Needed:</strong> Because the test case checks for a specific path (\.git/hooks/pre-commit) and it's not present in the test directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>should be True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        67 output =
                                        169 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly skips paths starting with a skip directory name.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'should be True', 'description': 'The function should return True for paths starting with a skip directory name'}</li>
                                            <li>{'message': '.venv', 'description': 'The function should return True for the path .venv'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        110 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the __pycache__ directory contains a cached Python file that should be skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert should_skip_path('src/__pycache__/module.cpython-312.pyc') is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        77 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_site_packages</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_site_packages</p>
                                    <p><strong>Why Needed:</strong> The test is checking if site-packages directories are skipped by the fs coverage tool.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'type': 'assertion', 'name': 'should_skip_path', 'value': '/usr/lib/python3.12/site-packages/pkg/mod.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        94 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</p>
                                    <p><strong>Why Needed:</strong> The test case checks if venv directories are skipped by the `should_skip_path` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                            <li>{'path': '.venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        112 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> Custom exclude patterns are needed to skip certain files based on their content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should_skip_path', 'expected_result': True}</li>
                                            <li>{'name': 'assert_path', 'expected_result': False, 'message': "Expected 'src/module.py' to be included in the path"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        112 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_gemini_provider.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">25 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotate_loop_daily_limit_hit</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the GeminiProvider class's _annotate_internal method throws an error when it hits the daily limit for a model.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider does not raise an error when exceeding the daily limit for a model.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'Gemini requests-per-day limit reached' in res.error</li>
                                            <li>assert 'Daily limit exceeded' in res.error</li>
                                            <li>assert 'requests per day' in res.error</li>
                                            <li>assert 'limit hit' in res.error</li>
                                            <li>assert 'daily_limit_hit' in provider._rate_limiters['m1']</li>
                                            <li>mock_limiter.next_available_in.return_value == None</li>
                                            <li>provider._models == ['m1']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        164 output =
                                        531 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-227, 232-233, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotation_exceptions_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that _GeminiRateLimitExceeded RPD is raised when rate limit is exceeded</p>
                                    <p><strong>Why Needed:</strong> To prevent the test from passing when rate limit is exceeded, we need to add a check for this scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocking _GeminiRateLimiter with `requests_per_minute=100`</li>
                                            <li>Setting `_call_gemini` to raise `_GeminiRateLimitExceeded` on the mock call</li>
                                            <li>_GeminiRateLimitExceeded should be raised when rate limit is exceeded</li>
                                            <li>The error message should contain 'requests-per-day' or 'rate limits reached'</li>
                                            <li>The model should be marked as exhausted after exceeding the rate limit</li>
                                            <li>No candidate models should remain in the pipeline after exhausting the model</li>
                                            <li>_GeminiRateLimitExceeded RPD should break the loop and mark model exhaustion</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        730 input +
                                        190 output =
                                        920 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-236, 239-244, 263-265, 268, 293, 295, 299-303, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_coverage_gaps</span>
                            <div class="test-meta">
                                <span>209ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Prevents regression in coverage gaps by ensuring proper rate limiting and annotation logic.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the GeminiProvider does not properly handle rate limiting and annotation logic, leading to coverage gaps.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>1. Mock imports to avoid errors</li>
                                            <li>_rate_limiters['m1'] == _GeminiRateLimiter(requests_per_minute=100)</li>
                                            <li>_annotate_internal('TestCaseResult(nodeid=</li>
                                            <li>src</li>
                                            <li>custom)</li>
                                            <li>Context too long: Context too long error</li>
                                            <li>_parse_rate_limits([</li>
                                            <li>requests_per_day</li>
                                            <li>value=100])</li>
                                            <li>_ensure_models_and_limits('token') == ['fallback']</li>
                                            <li>models, limits = provider._fetch_available_models('token')</li>
                                            <li>assert limits['gemini-custom'] == 12345</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        821 input +
                                        185 output =
                                        1006 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">173 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181-182, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 254-255, 259, 340, 343, 346, 348-356, 358-361, 363-364, 366-367, 435, 437-439, 441-442, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-498, 502-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-564, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_parse_preferred_models_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 134-135, 137-141, 143-144, 524-527)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_prune_daily_requests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProvider tests</p>
                                    <p><strong>Why Needed:</strong> To ensure the Gemini provider is correctly pruning daily requests that are older than 24 hours.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Limiter._daily_requests should be an empty list after prune', 'expected_result': [], 'actual_result': {'scenario': 'TestGeminiProvider tests', 'why_needed': 'To ensure the Gemini provider is correctly pruning daily requests that are older than 24 hours.', 'key_assertions': [{'name': 'Limiter._daily_requests should be an empty list after prune', 'expected_result': [], 'actual_result': {}}, {'name': 'assert len(limiter._daily_requests) == 0', 'expected_result': 0, 'actual_result': 0}]}, 'message': 'AssertionError: assert len(limiter._daily_requests) == 0 failed for test tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_prune_daily_requests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        219 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 39-42, 81-82, 84, 87-89)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_tpm_available_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test_tpm_available_fallback function waits for 30 seconds after using all tokens before returning.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the Gemini provider does not wait for 30 seconds after using all tokens, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `remaining` variable decreases by 50 each iteration of the loop.</li>
                                            <li>The loop finishes without returning if `remaining + request_tokens <= limit`.</li>
                                            <li>If `request_tokens` is massive (> 100), it should return 0.0 at line 106/108.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        524 input +
                                        136 output =
                                        660 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39-42)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_import_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a 'google-generativeai' import error is reported when the module is not installed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the GeminiProvider does not report an import error for modules without the required library.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation contains the string 'google-generativeai not installed'.</li>
                                            <li>The annotation includes the key 'error' with the value containing the string 'google-generativeai not installed'.</li>
                                            <li>The annotation includes the key 'message' with the value containing the string 'google-generativeai not installed'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        259 input +
                                        132 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 134-135, 137-141, 143-144, 164-165, 167-169)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_no_token</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotation fails when token is missing from the environment.</p>
                                    <p><strong>Why Needed:</strong> To prevent a test failure due to an unannotated `GEMINI_API_TOKEN` setting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The error message should contain 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The annotation should report that the token is missing.</li>
                                            <li>The annotation should include the key 'GEMINI_API_TOKEN' in its error message.</li>
                                            <li>The annotation should indicate that the token was not found or not set.</li>
                                            <li>The annotation should provide a clear and concise error message.</li>
                                            <li>The annotation should be able to identify the specific environment variable being tested (in this case, `GEMINI_API_TOKEN`).</li>
                                            <li>The annotation should report any other relevant information about the failure (e.g., the test result itself).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        186 output =
                                        499 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_rate_limit_retry</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly annotates a rate limit retry scenario.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of rate limit retries, ensuring that the provider can handle such scenarios without crashing or returning unexpected results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by the `_annotate_internal` method matches the expected scenario.</li>
                                            <li>Mock `mock_post.call_count` is equal to 2 (first call with status code 429 and second call with status code 200).</li>
                                            <li>The `scenario` attribute of the annotation is set to 'Recovered Scenario'.</li>
                                            <li>No other critical checks are performed in this test. Only the scenario, retry status, and post call count assertions are made.</li>
                                            <li>Mock `mock_get.return_value.json.return_value` does not contain any unexpected data or errors.</li>
                                            <li>The `scenario` attribute of the annotation is set to 'Recovered Scenario' even if the provider returns an error.</li>
                                            <li>No other critical checks are performed in this test. Only the scenario, retry status, and post call count assertions are made.</li>
                                            <li>Mock `mock_get.return_value.status_code` is 429 (expected) or 200 (expected).</li>
                                            <li>The `scenario` attribute of the annotation is set to 'Recovered Scenario' even if the provider returns an error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        636 input +
                                        279 output =
                                        915 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">214 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-237, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_success</span>
                            <div class="test-meta">
                                <span>404ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that _annotate_success returns the correct scenario when successful</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in GeminiProvider where it incorrectly assumes a specific response format from _call_gemini.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'scenario' attribute of the annotation returned by _annotate_internal is set to 'Success Scenario'.</li>
                                            <li>The error attribute of the annotation returned by _annotate_internal is None.</li>
                                            <li>The 'error' attribute of the annotation returned by _parse_response is None.</li>
                                            <li>The 'scenario' attribute of the parsed response from _call_gemini matches the expected scenario.</li>
                                            <li>The 'tokens' attribute of the parsed response from _call_gemini is empty.</li>
                                            <li>The 'totalTokenCount' attribute of the parsed response from _call_gemini is 100.</li>
                                            <li>The 'candidates' attribute of the parsed response from _call_gemini contains a single successful candidate with no error message.</li>
                                            <li>The 'types' attribute of the parsed response from _call_gemini matches the expected types for successful scenarios.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        649 input +
                                        224 output =
                                        873 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">208 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-568, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_availability</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the GeminiProvider class correctly checks for availability by setting environment variables and asserting the result.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider does not detect when it has no available data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `provider._check_availability()` method should return False when the GEMINI_API_TOKEN is set but the provider's configuration is 'gemini'.</li>
                                            <li>The `provider._check_availability()` method should return True when the GEMINI_API_TOKEN is not set and the provider's configuration is 'gemini'.</li>
                                            <li>The provider's `_check_availability()` method should raise an exception when the environment variable GEMINI_API_TOKEN is not set.</li>
                                            <li>When setting the GEMINI_API_TOKEN to a valid token, the provider's `_check_availability()` method should return True.</li>
                                            <li>When setting the GEMINI_API_TOKEN to an invalid token or empty string, the provider's `_check_availability()` method should raise an exception.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        235 input +
                                        219 output =
                                        454 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 134-135, 137-141, 143-144, 332-333, 335)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_exceptions</span>
                            <div class="test-meta">
                                <span>60.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider class correctly annotates retry exceptions when using a rate limiter with a daily limit and then again after cleanup.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the provider is not able to handle retry exceptions properly due to rate limiting or other issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the model exhaustion at node 't' for 'm1' is correctly annotated with a ResourceExhausted exception.</li>
                                            <li>Verify that the cooldowns for 'm1' are correctly set after a daily limit has been exceeded.</li>
                                            <li>Verify that the cooldowns for 'm1' can be set to a value greater than the current time after retrying after cleanup.</li>
                                            <li>Verify that the model exhaustion at node 't' for 'm1' is not retried after the cooldown period has expired.</li>
                                            <li>Verify that the provider correctly logs the error and sets the cooldowns for 'm1'.</li>
                                            <li>Verify that the provider correctly updates the _model_exhausted_at dictionary with the correct information.</li>
                                            <li>Verify that the provider correctly returns a valid result even when there are no more retries left.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        651 input +
                                        249 output =
                                        900 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-237, 239-244, 263-265, 268, 272-276, 279-281, 283-286, 288-292, 318-320, 322-323, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_loop_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider's _annotate_internal function clears _model_exhausted_at when models check pass.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the GeminiProvider's _annotate_internal function fails to clear _model_exhausted_at after successful model checks.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of _model_exhausted_at for the given model is not set before calling _annotate_internal.</li>
                                            <li>_model_exhausted_at is cleared when models check pass and their IDs are in provider._models.</li>
                                            <li>The value of _model_exhausted_at is not set after calling _annotate_internal.</li>
                                            <li>The value of _model_exhausted_at for the given model is set to a time in the past (24h ago) after calling _annotate_internal.</li>
                                            <li>_model_exhausted_at is cleared when models check pass and their IDs are in provider._models.</li>
                                            <li>The value of _model_exhausted_at is not set after calling _annotate_internal.</li>
                                            <li>The value of _model_exhausted_at for the given model is set to a time in the past (24h ago) after calling _annotate_internal.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        482 input +
                                        256 output =
                                        738 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-94, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 254, 259, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_ensure_rate_limits_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test GeminiProvider Detailed</p>
                                    <p><strong>Why Needed:</strong> To test the error handling of rate limiting in GeminiProvider</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Equal', 'expected_value': 10, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        69 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 134-135, 137-141, 143-144, 346, 348-356, 358-361, 363-364, 366-367)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test fetch available models with network error</p>
                                    <p><strong>Why Needed:</strong> To test the error handling of GeminiProvider when it encounters a network error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'models are empty', 'description': 'The expected number of models is 0, but the actual result is an empty list.', 'expected_result': [], 'actual_result': []}</li>
                                            <li>{'name': 'limit_map is empty', 'description': 'The expected limit map is {}, but the actual result is an empty dictionary.', 'expected_result': {}, 'actual_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        140 output =
                                        272 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the GeminiProvider fetches available models with invalid JSON data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the GeminiProvider incorrectly assumes valid JSON when fetching available models from an external API.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'm1' model is not included in the list of available models.</li>
                                            <li>The 'm2' model is not included in the list of available models.</li>
                                            <li>The 'm3' model is included in the list of available models.</li>
                                            <li>The 'inputTokenLimit' value for the 'm3' model does not match its supported generation methods.</li>
                                            <li>The 'limit_map' dictionary does not contain the expected key-value pairs for the 'm3' model.</li>
                                            <li>The GeminiProvider incorrectly assumes valid JSON when fetching available models from an external API.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        179 output =
                                        519 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 476-477, 537, 539-543, 547-548, 550-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method of the GeminiProvider class calls the `mock_ensure` function when necessary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked get_max_context_tokens call', 'expected_calls': [1], 'message': 'The `get_max_context_tokens` method should be called once.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        115 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 486, 488-491, 493)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</p>
                                    <p><strong>Why Needed:</strong> To test the parsing of rate limits types and ensure they are correctly converted to Gemini provider configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.requests_per_minute is None', 'expected_value': 'None'}</li>
                                            <li>{'name': 'config.tokens_per_minute == 100', 'expected_value': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        110 output =
                                        266 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 134-135, 137-141, 143-144, 449-457, 459-460, 463-466)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_prune_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the _prune method of the _GeminiRateLimiter class to ensure it prunes requests within a certain time frame.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where requests are not pruned after a certain amount of time, potentially leading to excessive token usage or other problems.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of _request_times should be equal to 1 after calling _prune with the current timestamp.</li>
                                            <li>The length of _token_usage should be equal to 1 after calling _prune with the current timestamp.</li>
                                            <li>The value in _request_times[0] should be equal to the current timestamp minus 10 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        150 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-42, 81-85, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the rate limiter does not handle invalid token counts correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(limiter._token_usage) == 0', 'expected_result': 0, 'actual_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        96 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39-42, 66-67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpd_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the rate limiting feature</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Gemini API does not exceed a certain number of requests per day without being throttled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Limiter should record the request and return None after 100 attempts', 'description': 'The limiter should record the request and return None after 100 attempts, indicating that it has reached its limit.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        101 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 45-46, 48-50, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpm_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter does not block requests for a short period after the first two.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the rate limiter blocks subsequent requests immediately after the initial two requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>limiter.next_available_in(100) == 0.0</li>
                                            <li>limiter.record_request()</li>
                                            <li>limiter.next_available_in(100) == 0.0</li>
                                            <li>limiter.record_request()</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        111 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-97, 100-102)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_seconds_until_tpm_available_branches</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter waits for tokens to expire before returning a 'TPM available' status when no tokens are requested or more than limit are used.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter incorrectly returns 'TPM available' when no tokens are requested, but usage exceeds the limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The time until TPM availability is greater than 0 seconds when no tokens are requested or more than limit are used.</li>
                                            <li>The time until TPM availability does not exceed 60.0 seconds when more than limit are used.</li>
                                            <li>Tokens do not expire before reaching the limit of 100.</li>
                                            <li>Tokens do not expire after exceeding the limit by more than 10%.</li>
                                            <li>Tokens do not expire immediately when usage is within the limit but exceeds it.</li>
                                            <li>The rate limiter waits for tokens to expire before returning 'TPM available' when no tokens are requested or more than limit are used.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        377 input +
                                        210 output =
                                        587 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 100-101, 103-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_daily_limit_exceeded</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `wait_for_slot` method raises a `GeminiRateLimitExceeded` exception when the daily limit is exceeded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter does not raise an exception when the daily limit is exceeded, potentially causing unexpected behavior or errors in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `wait_for_slot` method raises a `GeminiRateLimitExceeded` exception with the correct `limit_type` (in this case, 'requests_per_day')</li>
                                            <li>The error message indicates that the limit was exceeded</li>
                                            <li>The test verifies that the exception is raised only when the daily limit is exceeded</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        151 output =
                                        414 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 32-34, 39-42, 45-46, 48-50, 58-60, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_sleeps</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `wait_for_slot` sleeps for the expected amount of time when waiting for a slot to become available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the rate limiter is not properly implemented or if there are other factors affecting the sleep duration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `next_available_in` method returns a value within the expected range (10.0s) when called with an argument equal to 1.</li>
                                            <li>The `wait_for_slot` method sleeps for at least 10.0 seconds before returning.</li>
                                            <li>The `mock_sleep.assert_called_once_with(10.0)` assertion ensures that the sleep function was called once with a value of 10.0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        157 output =
                                        482 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 58-59, 61-63, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_hashing.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_different_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_different_config</p>
                                    <p><strong>Why Needed:</strong> Different configs should produce different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'different hashes', 'actual': 'same hashes'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        65 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure the computed hash is short and can be stored in a database or used as a unique identifier.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(h) == 16', 'expected_result': 16, 'message': 'Computed hash length should be 16 characters.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        99 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_consistent_with_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> File hash consistency with bytes</p>
                                    <p><strong>Why Needed:</strong> Test that the file hash matches the content hash for consistent results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': "b'test content'", 'actual_value': "compute_file_sha256(path).decode('utf-8') == compute_sha256(content)"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        81 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 32, 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</p>
                                    <p><strong>Why Needed:</strong> To test the correctness of file hashing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The hash should be a 64-byte string.', 'expected_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        74 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_different_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_different_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that different keys produce different signatures.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Different keys should produce different signatures.', 'expected_result': 'different signature'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        72 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_with_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_with_key</p>
                                    <p><strong>Why Needed:</strong> To verify that the HMAC computation is correct and produces the expected signature.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_length': 64, 'actual_length': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        73 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_consistent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_consistent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is consistent and produces the same output for the same input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Same content should produce same hash.', 'expected_result': 'The hash of two identical strings should be equal.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        88 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the hash length is correct and consistent across different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 64, 'actual': 8, 'description': 'The actual length of the hash should be 8 bytes (64 hex chars)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        89 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</span>
                            <div class="test-meta">
                                <span>81ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</p>
                                    <p><strong>Why Needed:</strong> To ensure the 'pytest' package is included in the dependency snapshot.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'value': 'pytest'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        74 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</span>
                            <div class="test-meta">
                                <span>83ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</p>
                                    <p><strong>Why Needed:</strong> To ensure the function correctly returns a dictionary representation of the dependency snapshot.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'snapshot is a dict', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        73 output =
                                        171 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_loads_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_loads_key</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading a HMAC key from a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'hmac_key_file': "tmp_path / 'hmac.key'"}, 'actual': {'hmac_key_file': 'str(key_file)'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        93 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 73, 76-77, 80-81)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Load Hmac Key: Missing Key File</p>
                                    <p><strong>Why Needed:</strong> The test should fail when a key file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'NoneType', 'message': 'Expected the HMAC key to be None, but got <value>'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        76 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 73, 76-78)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</p>
                                    <p><strong>Why Needed:</strong> To test that the function correctly returns None when no key file is configured.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert key is None', 'description': 'The load_hmac_key function should return None if no key file is specified.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        90 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 73-74)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_integration_gate.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">16 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_aggregation_defaults</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the default aggregation configuration.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where aggregation defaults are not set correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.aggregate_dir is None (default aggregation directory should be empty)</li>
                                            <li>config.aggregate_policy == 'latest' (default aggregation policy is 'latest')</li>
                                            <li>config.aggregate_include_history is False (default aggregation include history is False)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        90 output =
                                        291 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</p>
                                    <p><strong>Why Needed:</strong> The test captures failed output by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config', 'type': 'assertion', 'value': 'get_default_config() is not None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        80 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context mode is set to 'minimal' by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.llm_context_mode', 'value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        77 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> The LLM is not enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_llm_enabled', 'expected_result': False, 'actual_result': 'get_default_config().is_llm_enabled() == False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        89 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 123, 171, 284, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the default behavior of omitting tests from coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.omit_tests_from_coverage', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        80 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</p>
                                    <p><strong>Why Needed:</strong> To ensure the provider is set to None by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Provider should be None', 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        71 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the default configuration includes secret files and environment variables by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Excluding secret files and environment variables', 'description': "The function should exclude 'secret' and '.env' files from the list of excluded globs.", 'expected_result': ['exclude_globs']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        108 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_deterministic_output</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the output of a deterministic pipeline is sorted by nodeid.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the order of nodeids in the report changes unexpectedly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>nodeids should be sorted alphabetically and numerically</li>
                                            <li>nodeids should not contain duplicates</li>
                                            <li>nodeids should only include unique values from the input data</li>
                                            <li>nodeid 'z_test.py::test_z' should always come first in the list</li>
                                            <li>nodeid 'a_test.py::test_a' should come second in the list</li>
                                            <li>nodeid 'm_test.py::test_m' should come third in the list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        149 output =
                                        462 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_empty_test_suite</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that an empty test suite produces a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the test suite is empty and still produces a valid report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of tests in the report should be zero.</li>
                                            <li>The 'summary' section of the report should have a 'total' key with a value of zero.</li>
                                            <li>There should be no failed or skipped tests in the report.</li>
                                            <li>All test names and descriptions should be present in the report.</li>
                                            <li>The report format should be valid JSON as expected by the framework.</li>
                                            <li>The test suite should not contain any invalid or missing data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        146 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_html_report_generation</span>
                            <div class="test-meta">
                                <span>44ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the full pipeline generates an HTML report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the HTML report is not generated correctly due to a change in configuration settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path to the generated HTML report exists and can be accessed.</li>
                                            <li>The content of the HTML report contains the string '<html' as expected.</li>
                                            <li>The string 'test_pass' is present in the content of the HTML report as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        107 output =
                                        377 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">118 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_json_report_generation</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a full pipeline generates a valid JSON report with the correct schema version, summary statistics, and number of tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the JSON report generation is not producing a valid output or contains incorrect information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>data['schema_version'] == SCHEMA_VERSION</li>
                                            <li>data['summary']['total'] == 3</li>
                                            <li>data['summary']['passed'] == 1</li>
                                            <li>data['summary']['failed'] == 1</li>
                                            <li>data['summary']['skipped'] == 1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        134 output =
                                        553 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/_git_info.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 2-3)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">138 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_report_root_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the ReportRoot class has required fields when created.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report root is missing required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' field should be present in the data.</li>
                                            <li>The 'run_meta' field should be present in the data.</li>
                                            <li>The 'summary' field should be present in the data.</li>
                                            <li>The 'tests' field should be present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        250 input +
                                        108 output =
                                        358 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_aggregation_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test "RunMeta has run status fields" verifies that the `to_dict()` method returns a dictionary with required status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where `RunMeta` does not have a `to_dict()` method or its output is missing required status fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field should be present in the data.</li>
                                            <li>The 'interrupted' field should be present in the data.</li>
                                            <li>The 'collect_only' field should be present in the data.</li>
                                            <li>The 'collected_count' field should be present in the data.</li>
                                            <li>The 'selected_count' field should be present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        151 output =
                                        388 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</p>
                                    <p><strong>Why Needed:</strong> The schema version is defined, which is necessary for compatibility with older versions of the gate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'SCHEMA_VERSION', 'type': 'string'}</li>
                                            <li>{'name': '.', 'type': 'boolean'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        93 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_test_case_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `TestSchemaCompatibility` class verifies that the `TestCaseResult` object has all required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `TestCaseResult` object is missing one of its required fields, which could lead to incorrect analysis or reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nodeid' key should be present in the data dictionary.</li>
                                            <li>The 'outcome' key should be present in the data dictionary.</li>
                                            <li>The 'duration' key should be present in the data dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        119 output =
                                        342 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_litellm_retry_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_all_retries_exhausted</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all retries are exhausted when API call fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where LiteLLMProvider returns an annotation with no error even when all retries are exhausted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `result` variable is not None.</li>
                                            <li>The `result.error` attribute is not None.</li>
                                            <li>The `provider.annotate()` method raises an exception with the message 'API error'.</li>
                                            <li>The `mock_completion` function is called with a side effect that raises an exception.</li>
                                            <li>The `test_source` is set to a function that does not raise any exceptions.</li>
                                            <li>The `context_files` dictionary is empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        147 output =
                                        493 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_non_401_error_no_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that non-401 errors don't force token refresh.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of non-401 error without forcing token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the annotation returns an annotation with an error status code when a non-401 error is encountered.</li>
                                            <li>The test verifies that the annotation does not force token refresh when a non-401 error is encountered.</li>
                                            <li>The test verifies that the annotation correctly handles an internal server error (500) instead of 401.</li>
                                            <li>The test verifies that the annotation raises an exception with the 'Internal server error' message when a non-401 error is encountered.</li>
                                            <li>The test verifies that the annotation does not raise an exception when a non-401 error is encountered, allowing for token refresh to continue.</li>
                                            <li>The test verifies that the annotation correctly returns None in case of no error.</li>
                                            <li>The test verifies that the annotation correctly sets the 'error' attribute on the result object to None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        215 output =
                                        582 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_retry_succeeds_after_transient_error</span>
                            <div class="test-meta">
                                <span>6.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that retry succeeds after transient error and ensures the test fails with a meaningful error message.</p>
                                    <p><strong>Why Needed:</strong> To prevent the test from succeeding immediately after a transient error, allowing for retries to be attempted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `result.error` attribute is `None` when the test should fail due to a transient error.</li>
                                            <li>The `test.scenario` attribute is set to `'test scenario'` even though an error occurred.</li>
                                            <li>The `test.context_files` dictionary remains empty after the API call fails twice, then succeeds.</li>
                                            <li>The `mock_completion` function raises an exception when the API call fails for the second time.</li>
                                            <li>The `result` object contains a meaningful message indicating that the test failed due to a transient error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        433 input +
                                        170 output =
                                        603 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_token_refresh_on_401</span>
                            <div class="test-meta">
                                <span>6.37s</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 401 error triggers token refresh (test_token_refresh_on_401)</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM token refresh mechanism works correctly for 401 errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the LLM provider calls the `token_refresh_command` with a new token when an API call fails with a 401 status code.</li>
                                            <li>The test checks that the `litellm_token_output_format` is set to 'text' for the output of the `token_refresh_command`.</li>
                                            <li>The test verifies that the `mock_completion` function is called twice, once with a 401 error and once without it.</li>
                                            <li>The test ensures that the `result` variable is not `None` after the token refresh attempt.</li>
                                            <li>The test checks that the `call_count[0] >= 2` condition is met to verify that the LLM provider has retried after token refresh.</li>
                                            <li>The test verifies that the `test_source` and `context_files` are empty for the annotated result.</li>
                                            <li>The test ensures that the `error` variable is raised with a 401 status code when the API call fails.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        252 output =
                                        725 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-188, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the GeminiProvider is correctly instantiated when using the 'gemini' provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected_value': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        83 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLMProvider class is correctly instantiated when a specific provider ('litellm') is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        90 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_none_returns_noop</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_none_returns_noop</p>
                                    <p><strong>Why Needed:</strong> To ensure that the GetProvider function returns a NoopProvider when the provider is set to 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is None', 'expected': 'NoopProvider', 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        90 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the OllamaProvider class is correctly instantiated when a specific provider ('ollama') is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected_value': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        85 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_unknown_raises</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestLlmProviderContract::test_noop_implements_interface</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the implementation of NoopProvider.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where NoopProvider does not implement required interface methods.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'annotate' method should be present in the provider.</li>
                                            <li>The 'is_available' method should be present in the provider.</li>
                                            <li>The 'get_model_name' method should be present in the provider.</li>
                                            <li>The 'config' attribute should be present in the provider.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        105 output =
                                        337 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_annotate_returns_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `annotate` method of a NoopProvider returns an empty annotation when no annotation is provided.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the `annotate` method does not return an annotation if none is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation is always an instance of LlmAnnotation</li>
                                            <li>annotation scenario is an empty string</li>
                                            <li>annotation why_needed is an empty string</li>
                                            <li>annotation key_assertions are an empty list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        249 input +
                                        110 output =
                                        359 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the `get_model_name` method of the `NoopProvider` class does not handle an empty input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected value', 'value': '', 'expected_type': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        91 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_is_available</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_is_available</p>
                                    <p><strong>Why Needed:</strong> The LLM is not available because the NoopProvider is not properly initialized.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_available() should return True', 'expected_value': True, 'actual_value': 'assert provider.is_available() is True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        92 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 59)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_contract.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the schema requires 'scenario' and 'why_needed'.</p>
                                    <p><strong>Why Needed:</strong> The schema requires these fields because they are specified in the ANNOTATION_JSON_SCHEMA.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "The field 'scenario' is required.", 'description': "The field 'scenario' must be present in the annotation."}</li>
                                            <li>{'message': "The field 'why_needed' is required.", 'description': "The field 'why_needed' must be present in the annotation."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        124 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_from_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that AnnotationSchema.from_dict parses a dictionary correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents data corruption or incorrect parsing of user input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'scenario' field is set to the expected value.</li>
                                            <li>The 'why_needed' field is set to the expected value.</li>
                                            <li>The 'key_assertions' list contains the correct number of elements.</li>
                                            <li>The confidence level is set to the expected value (0.95).</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        113 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tested that the AnnotationSchema class correctly returns an empty string when given an empty dictionary.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the AnnotationSchema class should handle empty input and return a valid object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'schema.scenario', 'value': '', 'expected_type': 'str'}</li>
                                            <li>{'name': 'schema.why_needed', 'value': '', 'expected_type': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        111 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_partial</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case for testing AnnotationSchema</p>
                                    <p><strong>Why Needed:</strong> This test is needed to ensure that the AnnotationSchema handles partial input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "schema.scenario should be 'Partial only'", 'expected_value': 'Partial only'}</li>
                                            <li>{'assertion': 'schema.why_needed should be an empty string', 'expected_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        99 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `schema_has_required_fields` function is called with a JSON schema that contains required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `schema_has_required_fields` function is not called with a valid JSON schema.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `schema_has_required_fields` function should be called with a JSON schema that has 'scenario', 'why_needed', and 'key_assertions' properties.</li>
                                            <li>The `schema_has_required_fields` function should validate that the required fields are present in the JSON schema.</li>
                                            <li>The `schema_has_required_fields` function should check for the presence of 'scenario', 'why_needed', and 'key_assertions' keys in the JSON schema.</li>
                                            <li>The `schema_has_required_fields` function should perform checks to ensure these required fields are included in the JSON schema.</li>
                                            <li>The `schema_has_required_fields` function should validate that the required fields meet their respective validation rules.</li>
                                            <li>The `schema_has_required_fields` function should report an error if any of the required fields are missing or invalid.</li>
                                            <li>The `schema_has_required_fields` function should provide detailed information about why a field is required (if applicable).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        259 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> This test verifies that the `AnnotationSchema` class correctly serializes to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `AnnotationSchema` class handles scenario and why needed information properly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assertion 1: The 'scenario' key in the serialized data matches the expected value.</li>
                                            <li>assertion 2: The 'why_needed' key in the serialized data matches the expected value.</li>
                                            <li>assertion 3: The 'key_assertions' list in the serialized data contains all expected assertions.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        127 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 90-92, 94-96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the NoopProvider class does not implement the required interface.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected_value': 'noop', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        85 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the NoopProvider class correctly implements the LlmProvider interface.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'isinstance(provider, LlmProvider)', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        84 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_returns_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> NoopProvider returns empty annotation when no function is annotated with 'noop'</p>
                                    <p><strong>Why Needed:</strong> To prevent a test from failing due to an empty annotation in the NoopProvider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>- result.scenario is an empty string</li>
                                            <li>- result.why_needed is an empty string</li>
                                            <li>-1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        76 output =
                                        329 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_annotate_returns_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the annotate method returns a TestCaseResult object with the correct attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the LlmAnnotation-like object annotation process, ensuring it correctly handles scenarios where annotations are not present or have incorrect attributes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result has an attribute named 'scenario' that contains a string describing the scenario.</li>
                                            <li>The result has an attribute named 'why_needed' that contains a string explaining why this test is necessary.</li>
                                            <li>The result has an attribute named 'key_assertions' that stores the critical checks performed during the test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        134 output =
                                        397 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</p>
                                    <p><strong>Why Needed:</strong> To ensure that the provider handles empty code gracefully and returns a valid result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is not None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        78 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_none_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Provider handles None context gracefully</p>
                                    <p><strong>Why Needed:</strong> The contract should be able to handle a None context without raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is_not_none', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        67 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</p>
                                    <p><strong>Why Needed:</strong> To ensure that all providers have an `annotate` method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'function', 'actual_type': 'callable', 'message': 'Expected annotate to be a callable. Got {0}.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        90 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 65-66, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_providers.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">52 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the `annotate_handles_context` method of the `GeminiProvider` class has a time complexity of O(n), where n is the number of handles. This can cause performance issues when dealing with large numbers of handles.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Test that annotate_handles_context does not raise an exception for small inputs', 'expected_result': 'No exception is raised'}</li>
                                            <li>{'name': 'Test that annotate_handles_context returns the expected result for a small input', 'expected_result': {'scenario': '...', 'why_needed': '...', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        161 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">187 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 263-265, 299, 311-312, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524-525, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider correctly reports a missing dependency when an import error occurs.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider does not report a missing dependency when an import error occurs, potentially masking a dependency issue.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation message includes the correct dependency name and installation instructions.</li>
                                            <li>The annotation message is not empty or null.</li>
                                            <li>The annotation message contains the expected error message.</li>
                                            <li>The annotation message does not contain any other relevant information.</li>
                                            <li>The annotation message is not too long (less than 50 characters).</li>
                                            <li>The annotation message includes the correct dependency name and installation instructions.</li>
                                            <li>The annotation message is a string, not a list or tuple.</li>
                                            <li>The annotation message contains only one line of text.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        175 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-195, 471-473, 497-498, 502-503, 537)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_token</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the 'annotate' method of the GeminiProvider raises an error when the API token is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the 'annotate' method fails to raise an error when the API token is missing, potentially leading to unexpected behavior or errors in downstream code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'error' attribute of the annotation object should be set to 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The 'error' attribute of the annotation object should be set to 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The 'error' attribute of the annotation object should be set to 'GEMINI_API_TOKEN is not set'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        440 input +
                                        157 output =
                                        597 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_records_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `annotate_records_tokens` test prevents regressions by ensuring tokens are recorded correctly.</p>
                                    <p><strong>Why Needed:</strong> To prevent regressions caused by a bug in the `GeminiProvider` class where token usage is not properly recorded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `annotate_records_tokens` test verifies that the provider records token usage correctly.</li>
                                            <li>The provider's `_rate_limiters` dictionary contains an entry for 'gemini-1.5-pro' with a single entry under '_token_usage'.</li>
                                            <li>The value of '_token_usage' is 123, indicating that at least one token was recorded.</li>
                                            <li>The test also verifies that the rate limits logic runs without error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        783 input +
                                        155 output =
                                        938 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-455, 457, 459-460, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_retries_on_rate_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can retry annotating tasks when rate limiting occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Llama model is retried', 'description': 'The Llama model should be retried after a certain number of attempts.'}</li>
                                            <li>{'name': 'Error message is displayed', 'description': 'An error message should be displayed when the rate limit is exceeded.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        116 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM model is rotated on a daily basis and that the annotation process does not interfere with this rotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'model_rotation', 'description': 'The model rotation should be applied every day'}</li>
                                            <li>{'name': 'annotation_process', 'description': 'The annotation process should not interfere with the model rotation'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        125 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">210 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526-527, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> skips on daily limit because it's a performance bottleneck and LLMs are not designed to handle large amounts of data in a single session.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Llama model is not handling large amount of data in a single session efficiently</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        74 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider annotates a valid response with the correct information.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the provider correctly annotates responses from LiteLLM.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        474 input +
                                        64 output =
                                        538 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">209 lines (ranges: 39-42, 45-46, 48-49, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_exhausted_model_recovers_after_24h</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can recover from an exhausted model after 24 hours.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The recovered model's performance is within a reasonable range.</li>
                                            <li>No additional warnings or errors are raised when using the recovered model.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        74 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">222 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To handle the case where there are no available models.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error message', 'value': 'No available models found.'}</li>
                                            <li>{'name': 'Expected error type', 'value': 'LlamaProviderError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        88 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 134-135, 137-141, 143-144, 346, 348-349, 352-356, 358-361, 363-364, 366-367, 435, 437-439, 441-444, 449-452, 463-466, 476, 478, 497-498, 502-508, 511, 514-516, 518-521, 524-525, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_model_list_refreshes_after_interval</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `model_list_refresh` method of the `GeminiProvider` class is called after an interval.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the model list is updated correctly and consistently across different runs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Model list should be refreshed after a certain interval', 'expected_value': 'The model list should be updated with new data after a specific time period.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        99 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">201 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_401_retry_with_token_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the retry mechanism for LiteLLM provider on a 401 error after token refresh.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a regression where the LLM provider does not retry when it encounters a 401 Unauthorized error after refreshing its token.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the LLM provider retries after a 401 Unauthorized error and captures the refreshed token.</li>
                                            <li>Verify that the LLM provider fails with a 401 Unauthorized error on the first attempt to refresh its token.</li>
                                            <li>Verify that the LLM provider succeeds with a new token after refreshing its token.</li>
                                            <li>Verify that the captured keys match the expected tokens for both attempts.</li>
                                            <li>Verify that the retry count is incremented correctly for each attempt.</li>
                                            <li>Verify that the error message is correct and includes the expected reason (401 Unauthorized).</li>
                                            <li>Verify that the LLM provider uses the new token in subsequent requests without any issues.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        580 input +
                                        197 output =
                                        777 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_handles_completion_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider annotates completion errors correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when a completion error occurs during annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'boom' in annotation.error</li>
                                            <li>assert annotation.error is not None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        64 output =
                                        371 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider rejects invalid key_assertions payloads.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression and ensure the correct behavior of the LiteLLMProvider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'response_data' dictionary must contain a list of key_assertion payloads.</li>
                                            <li>The 'response_data' dictionary must not be empty.</li>
                                            <li>The 'response_data' dictionary should have at least one key_assertion payload.</li>
                                            <li>The 'response_data' dictionary should not be None.</li>
                                            <li>The 'response_data' dictionary should have a valid JSON string.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        128 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 206, 211)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a LiteLLMProvider annotates missing dependencies correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider does not report missing dependencies and instead silently installs them.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation error message is set to 'litellm not installed. Install with: pip install litellm' as expected.</li>
                                            <li>The provider correctly reports an import error for the missing dependency.</li>
                                            <li>The test passes even when the mock_import_error function returns a different error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        271 input +
                                        115 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 37-38, 41, 82-86)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider annotates a successful response with the correct information.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions by ensuring the provider correctly handles successful responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                            <li>model gpt-4o</li>
                                            <li>role system</li>
                                            <li>tests/test_auth.py::test_login</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        475 input +
                                        85 output =
                                        560 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider does not override the prompt for custom prompts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `provider._annotate_internal` is called with the correct argument `prompt_override = 'CUSTOM PROMPT'`.</li>
                                            <li>The captured messages from the fake completion are added to the list of expected messages. The message should contain a key named 'content'.</li>
                                            <li>The value of the 'content' key in the captured message matches the expected value 'CUSTOM PROMPT'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        132 output =
                                        505 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LiteLLM provider extracts token usage from response.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug where the provider does not accurately calculate token usage in certain scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `prompt_tokens` attribute of the `token_usage` object is set to the correct value (100).</li>
                                            <li>The `completion_tokens` attribute of the `token_usage` object is set to the correct value (50).</li>
                                            <li>The `total_tokens` attribute of the `token_usage` object is set to the correct value (150).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        129 output =
                                        555 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough verifies that the LiteLLM provider passes `api_base` to the completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the API base is not passed correctly to the completion call, potentially causing issues with downstream integrations or data processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `api_base` attribute of the LiteLLM provider should be set to `https://proxy.corp.com/v1` before calling the completion function.</li>
                                            <li>The `litellm_api_base` configuration parameter should be set to `https://proxy.corp.com/v1` for the test case to pass.</li>
                                            <li>The `api_base` attribute of the LiteLLM provider should not be modified after setting it in the test configuration.</li>
                                            <li>The completion function should return a response with the correct `api_base` value if it is set correctly.</li>
                                            <li>If the `api_base` attribute is not set, the completion function should raise an exception or return an error message indicating that the API base was not provided.</li>
                                            <li>The `litellm_api_base` configuration parameter should be set to a valid URL for the test case to pass.</li>
                                            <li>If the `litellm_api_base` configuration parameter is not set correctly, the test case should fail with an error message indicating that the API base was not provided.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        387 input +
                                        301 output =
                                        688 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182-183, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_key_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `liteellm` provider passes the static API key to the completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the API key is not passed through to the completion function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>- The API key is captured and stored in the `captured` dictionary.</li>
                                            <li>- The API key matches the expected value 'static-key-placeholder' as per the `response_data`.</li>
                                            <li>- The `litellm_api_key` attribute of the `liteellm` object is set to 'static-key-placeholder'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        384 input +
                                        124 output =
                                        508 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_error_without_refresher</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 132-133, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_retry_fails_on_second_attempt</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider does not retry authentication if it fails on the second attempt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider retries authentication even after failing with an auth error, which could lead to unexpected behavior or errors in certain scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test checks that the annotation of the provider contains an 'error' key indicating an authentication failure.</li>
                                            <li>The test verifies that the 'error' value includes the string 'Authentication failed',</li>
                                            <li>The test ensures the 'error' value does not contain any other relevant information, such as the token or refresh command used to authenticate.</li>
                                            <li>The test checks that the provider's annotation is set correctly even after a second authentication attempt fails.</li>
                                            <li>The test verifies that the provider returns an error message indicating that authentication failed when it encounters this scenario.</li>
                                            <li>The test ensures that the provider does not retry authentication if it fails on the first attempt, as intended by the bug being tested.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        221 output =
                                        640 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">51 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 129-130, 132-133, 141-142, 170-174, 176-178, 182, 186-188, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_context_too_long_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider class correctly handles a context too long error when parsing a response.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider fails to handle invalid responses with an error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _parse_response method of the provider should return None for an invalid response.</li>
                                            <li>The _parse_response method of the provider should raise a ValueError for an invalid response.</li>
                                            <li>The error attribute of the annotation returned by _parse_response should be set to 'Context too long for this model'.</li>
                                            <li>The key_assertions in the annotation returned by _parse_response should include 'scenario', 'why_needed', and 'error'.</li>
                                            <li>The value of the 'error' key in the annotation returned by _parse_response should match the expected error message.</li>
                                            <li>The value of the 'key_assertions' list in the annotation returned by _parse_response should be a list containing 'scenario', 'why_needed', and 'error'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        370 input +
                                        218 output =
                                        588 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_dict_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_max_context_tokens_dict_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct dictionary format is returned when getting max context tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 16384, 'actual_value': 16384}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        218 input +
                                        67 output =
                                        285 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227-228, 230-231)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLMProvider can handle errors and return a fallback value for max context tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 16, 'actual_value': 0}</li>
                                            <li>{'name': 'fallback_on_error', 'expected_value': 'Fallback token'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        101 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227, 232-234)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</p>
                                    <p><strong>Why Needed:</strong> To test the LiteLLM provider's ability to get the maximum context tokens from the litellm module.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'type': 'int', 'value': 8192}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        93 output =
                                        306 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 37-38, 41, 221-222, 224, 227-229)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</p>
                                    <p><strong>Why Needed:</strong> To ensure the LiteLLM provider can detect installed modules.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'setitem', 'expected_value': {'litellm': 'fake_litellm'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        160 input +
                                        83 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 37-38, 41, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_token_refresh_integration</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the LiteLLMProvider's token refresh integration.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug where the TokenRefresher is not properly refreshed, causing the LLM to use outdated tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The API key should be 'dynamic-token-789' after token refresh.</li>
                                            <li>The provider should correctly set the API key in the configuration.</li>
                                            <li>The token refresh command and interval should be correctly configured.</li>
                                            <li>The LitellmProvider should properly handle token refresh requests.</li>
                                            <li>The case result should indicate that the test passed successfully.</li>
                                            <li>The captured data from the subprocess call should match the expected response.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        442 input +
                                        145 output =
                                        587 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">41 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_transient_error_retry</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'LiteLLM provider retries on transient errors'.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the LLM provider fails to retry transient errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `fake_completion` raises a `ConnectionError` within 3 calls.</li>
                                            <li>The function `fake_completion` raises a `ConnectionError` within 2 additional calls.</li>
                                            <li>The function `fake_completion` does not raise a `ConnectionError` after the third call.</li>
                                            <li>The LLM provider's retry count is reset to 0 after each call.</li>
                                            <li>The LLM provider retries on transient errors, ensuring it can recover from such events.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        147 output =
                                        573 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_fallbacks_on_context_length_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider correctly handles context length errors during annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Llama model is not properly initialized', 'description': 'The Llama model should be properly initialized before using it for annotation.'}</li>
                                            <li>{'name': 'Context length error is handled correctly', 'description': 'The context length error should be handled correctly by the LLM provider and return a fallback solution.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        122 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">70 lines (ranges: 65-66, 87-89, 97-99, 101, 103, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 243, 245, 264, 266-267, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 85-86, 92, 138, 140, 142-144, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_handles_call_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the annotate function of OllamaProvider correctly handles call errors by checking if the last error message is 'boom'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM provider fails to handle call errors and instead raises an exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should have an error message indicating that the call was unsuccessful with the specified system prompt.</li>
                                            <li>The annotation should indicate that the last error occurred after 2 retries.</li>
                                            <li>The annotation should correctly identify the cause of the failure as 'boom'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        347 input +
                                        126 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 97-98, 100-101, 103-104)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_missing_httpx</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The Ollama provider should report an error when the httpx dependency is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider incorrectly reports a non-existent issue, potentially leading to incorrect usage guidance or downstream errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'httpx not installed. Install with: pip install httpx'</li>
                                            <li>provider.annotate(test, 'def test_case(): assert True')</li>
                                            <li>test_case() should raise an ImportError when httpx is missing</li>
                                            <li>mock_import_error('httpx') should be called before annotating the test</li>
                                            <li>config.provider should be set to 'ollama' before creating the provider instance</li>
                                            <li>OllamaProvider(config) should create a provider instance with the correct config</li>
                                            <li>test should pass when httpx is installed correctly</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        268 input +
                                        182 output =
                                        450 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 42-46)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> The test is likely to fail because the annotation of runtime errors by Ollama Provider is not implemented yet.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'OllamaProvider.annotate_runtime_error_immediate_fail returns correct result', 'description': 'The function should return a specific JSON object with certain key-value pairs.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        95 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 96)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_success_full_flow</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the annotate method correctly annotates a full flow with mocked HTTP responses.</p>
                                    <p><strong>Why Needed:</strong> Prevents authentication issues caused by unverified HTTP requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>check status of response after successful login</li>
                                            <li>validate token sent in response</li>
                                            <li>assert that no exception is raised during annotation process</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        414 input +
                                        80 output =
                                        494 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided with a custom prompt.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider uses the custom prompt when it is provided, rather than using the default one.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by _annotate_internal method of LiteLLMProvider should not contain any error.</li>
                                            <li>The content of the captured messages should match 'CUSTOM PROMPT'.</li>
                                            <li>The key assertion 'a' in the captured message should be present and have a valid type.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        121 output =
                                        494 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52-53, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LiteLLM provider annotates with token usage.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token usage calculation when annotating responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total tokens should be equal to the sum of prompt and completion tokens.</li>
                                            <li>The prompt tokens should not exceed 100.</li>
                                            <li>The completion tokens should not exceed 50.</li>
                                            <li>The total tokens should be greater than or equal to 150.</li>
                                            <li>The token usage is not None.</li>
                                            <li>The token usage is correctly calculated based on the provided data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        123 output =
                                        549 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71, 74-80, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider makes correct API call for successful response.</p>
                                    <p><strong>Why Needed:</strong> Prevents bug where OllamaProvider returns incorrect or incomplete responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The response from the Ollama model is as expected and matches the provided prompt.</li>
                                            <li>The URL of the generated text is correctly set to the specified host and port.</li>
                                            <li>The JSON payload sent by the Ollama provider includes the required 'model', 'prompt', 'system', and 'stream' fields.</li>
                                            <li>The timeout value is correctly set to 60 seconds as expected.</li>
                                            <li>The response from the Ollama model does not exceed the maximum allowed length of 2048 characters.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        470 input +
                                        154 output =
                                        624 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_uses_default_model</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the Ollama provider uses the default model when not specified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the model is not set to 'llama3.2' even if it's not provided in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The captured response from the Ollama provider contains the expected model.</li>
                                            <li>The value of `model` in the captured response matches the default model ('llama3.2').</li>
                                            <li>The absence of a specified model in the configuration does not prevent the provider from using the default model.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        344 input +
                                        129 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test OLLAMA Provider: Check Availability Failure</p>
                                    <p><strong>Why Needed:</strong> The test checks if the OLLAMA provider returns False when the server is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Provider is not set up to return a response', 'expected': 'False', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        183 input +
                                        83 output =
                                        266 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 113-114, 116-117, 119-120)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</p>
                                    <p><strong>Why Needed:</strong> To test that the Ollama provider returns False for non-200 status codes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() is False', 'expected_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        197 input +
                                        87 output =
                                        284 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the Ollama provider checks availability successfully by returning a 200 status code for the /api/tags endpoint.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider returns an error or exception when checking availability, causing the application to fail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The '/api/tags' URL is present in the request.</li>
                                            <li>The response from the server has a status code of 200.</li>
                                            <li>The provider's check_availability method does not raise any exceptions when called with a valid configuration.</li>
                                            <li>The provider's check_availability method returns True for a successful check.</li>
                                            <li>The provider's check_availability method does not return False for an unsuccessful check.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        155 output =
                                        451 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_context_length_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_max_context_tokens` method returns the correct context length key for a given scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context_length_key', 'expected_value': 'max_context_tokens'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        75 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns a fallback value when an error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected `get_max_context_tokens` to return a fallback value', 'description': 'When an error occurs, `get_max_context_tokens` should return a fallback value'}</li>
                                            <li>{'name': 'Fallback value is returned for non-LLM errors', 'description': 'The fallback value should be returned for all types of errors (not just LLM errors)'}</li>
                                            <li>{'name': 'Fallback value is returned for LLM errors', 'description': 'The fallback value should be returned when an error occurs with the LLM provider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        162 output =
                                        263 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 138, 140, 142-147, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_model_info</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns the correct maximum context tokens for a given model info.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 512, 'actual_value': 0}</li>
                                            <li>{'name': 'context_token_count', 'expected_value': 8, 'actual_value': 4}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        112 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_parameters</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for OLLAMA provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct number of context tokens is returned from the parameters</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context token count', 'expected_value': 8, 'actual_value': 5}</li>
                                            <li>{'name': 'Token type distribution', 'expected_value': "{'B': 55.0, 'I': 30.0, 'O': 15.0}", 'actual_value': "{'B': 55.0, 'I': 31.0, 'O': 14.0}"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        135 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 138, 140, 142-147, 149-150, 156, 158, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_non_200_status</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for LLM providers</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM provider returns a valid response when the maximum context tokens is not 200.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Response status code should be 400', 'expected_value': 400, 'actual_value': 0}</li>
                                            <li>{'name': 'Response body should contain an error message', 'expected_value': 'Error: max_context_tokens must be at least 200', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        123 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 138, 140, 142-147, 149, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider always returns `is_local=True`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of OllamaProvider', 'expected_value': 'True'}</li>
                                            <li>{'name': 'provider is configured with a valid provider name', 'expected_value': 'ollama'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        112 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider reports invalid JSON responses</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider correctly handles and reports invalid JSON responses in its tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotation.error', 'value': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        76 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 65-66, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_parse_response_invalid_key_assertions</p>
                                    <p><strong>Why Needed:</strong> to test Ollama provider's behavior when receiving invalid key_assertions payloads</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Invalid response: key_assertions must be a list'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        95 output =
                                        269 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</p>
                                    <p><strong>Why Needed:</strong> To test that the LLM provider correctly extracts JSON from markdown code fences.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected JSON format', 'value': '{"scenario": "tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence", "why_needed": "To test that the LLM provider correctly extracts JSON from markdown code fences."}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        124 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of extracting JSON from plain markdown fences (no language).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected response is a dictionary', 'description': 'The extracted JSON should be in a dictionary format.'}</li>
                                            <li>{'name': 'Expected keys are correct', 'description': 'The keys in the extracted JSON should match the expected ones.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        122 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider parses valid JSON responses.</p>
                                    <p><strong>Why Needed:</strong> Prevents bugs in the LLM providers by ensuring correct parsing of responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert a is not None</li>
                                            <li>assert b is not None</li>
                                            <li>assert 'scenario' in annotation.scenario</li>
                                            <li>assert 'why_needed' in annotation.why_needed</li>
                                            <li>assert 'key_assertions' in annotation.key_assertions</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        292 input +
                                        102 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_utils.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_constrained</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify water-fill algorithm satisfies smaller files first.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where larger files are prioritized over smaller ones, potentially leading to incorrect token distribution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total allocated tokens for small.py should be exactly 10.</li>
                                            <li>The total allocated tokens for large.py should be between 30 and 45 (inclusive).</li>
                                            <li>The allocation of tokens to small.py is sufficient to cover its content, leaving some wiggle room for overhead estimation changes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        396 input +
                                        114 output =
                                        510 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_empty</p>
                                    <p><strong>Why Needed:</strong> Verify that the function handles empty input or no budget correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': {'message': 'Expected an empty dictionary to be returned when {} is passed with 100 as the token budget.'}, 'expected_result': {}}</li>
                                            <li>{'assertion': {'message': "Expected an empty dictionary to be returned when {'f1': 'c'} is passed with 0 as the token budget."}, 'expected_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        131 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 42-43)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_fair_share</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify fair sharing when neither fits.</p>
                                    <p><strong>Why Needed:</strong> Prevents bug where one model gets significantly more tokens than the other, leading to unfair distribution of token budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The expected range for allocations of `l1.py` is between 35 and 50 tokens.</li>
                                            <li>The expected range for allocations of `l2.py` is also between 35 and 50 tokens.</li>
                                            <li>The absolute difference in allocations should be less than or equal to 1 token.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        116 output =
                                        443 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_max_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_max_files</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM Utils library handles token budget allocation correctly when dealing with a large number of files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(allocations) == 3', 'expected_result': 3, 'actual_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        94 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_sufficient</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that all files receive sufficient token allocation when the budget is sufficient.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where files with larger content are not allocated enough tokens, leading to incomplete or corrupted code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of allocations for each file matches the required amount (10 tokens).</li>
                                            <li>Each allocation is within the estimated overhead range (6-16 tokens per file).</li>
                                            <li>All files receive full content as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        108 output =
                                        440 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_estimate_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the minimum token estimation for an empty string.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function does not return a valid estimate for an empty string, potentially leading to incorrect results or errors in downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert estimate_tokens('') == 1</li>
                                            <li># Expected minimum token estimation of 1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        85 output =
                                        302 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">29 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestArtifactEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `CoverageEntry` class to ensure it correctly serializes its attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `CoverageEntry` object is not properly serialized, potentially causing issues with data transfer or storage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' attribute of the `CoverageEntry` object should match the expected value.</li>
                                            <li>The 'line_ranges' attribute of the `CoverageEntry` object should match the expected format.</li>
                                            <li>The 'line_count' attribute of the `CoverageEntry` object should be equal to the expected value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        130 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 263-266)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCollectionError::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` correctly serializes a CoverageEntry object.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the serialized data does not match the expected format, potentially causing issues with downstream processing or debugging.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the serialized dictionary should be equal to 'src/foo.py'.</li>
                                            <li>The 'line_ranges' key in the serialized dictionary should be equal to '1-3, 5, 10-15'.</li>
                                            <li>The 'line_count' key in the serialized dictionary should be equal to 10.</li>
                                            <li>The 'file_path' value in the expected dictionary should match the actual value in the test data.</li>
                                            <li>The 'line_ranges' value in the expected dictionary should match the actual value in the test data.</li>
                                            <li>The 'line_count' value in the expected dictionary should match the actual value in the test data.</li>
                                            <li>All keys and values in the serialized dictionary should be present in the expected dictionary.</li>
                                            <li>Any missing keys or values in the serialized dictionary should raise an AssertionError.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        236 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 241-243)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests CoverageEntry to_dict method.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the coverage entry serialization fails or is incorrect when dealing with complex line ranges.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the d dictionary should match the expected value.</li>
                                            <li>The 'line_ranges' key in the d dictionary should contain the correct range values.</li>
                                            <li>The 'line_count' key in the d dictionary should be equal to the expected value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        109 output =
                                        364 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 65-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> An empty annotation should be created with default values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where an empty annotation does not have any default values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation.scenario == "" (empty string)</li>
                                            <li>annotation.why_needed == "Empty annotation does not have any default values."</li>
                                            <li>annotation.key_assertions == [] (no key assertions are performed in this test)</li>
                                            <li>assert annotation.confidence is None (checks if confidence is set to None)</li>
                                            <li>assert annotation.error is None (checks if error is set to None)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        131 output =
                                        343 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `to_dict` method of `LlmAnnotation` returns a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the minimal annotation is missing some required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Required keys: 'scenario', 'why_needed', and 'confidence'</li>
                                            <li>Optional key: 'key_assertions' (does not need to be present)</li>
                                            <li>Missing field: 'confidence' (should be excluded when None)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        230 input +
                                        112 output =
                                        342 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 130-133, 135, 137, 139, 141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_with_all_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the full annotation is included in the dictionary.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where only some fields are included in the output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Asserts that the 'scenario' field is present and matches the expected value.</li>
                                            <li>Asserts that the 'confidence' field is present and matches the expected value.</li>
                                            <li>Asserts that the 'context_summary' field has the correct mode and byte count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        284 input +
                                        104 output =
                                        388 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 130-133, 135-137, 139-141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_default_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Default Report</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the default report is missing required schema version and empty test lists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert d['schema_version'] == SCHEMA_VERSION</li>
                                            <li>assert d['tests'] == []</li>
                                            <li>assert 'warnings' not in d</li>
                                            <li>assert 'collection_errors' not in d</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        93 output =
                                        324 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Report Root test with collection errors to ensure it includes them.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report does not include all collection errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report should contain at least one collection error.</li>
                                            <li>Each collection error should have a unique nodeid.</li>
                                            <li>The first collection error should be for the specified nodeid 'test_bad.py'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        94 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestReportRoot::test_report_with_warnings</p>
                                    <p><strong>Why Needed:</strong> To test that the ReportRoot class correctly identifies warnings in a report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "Expected length of 'warnings' key to be 1", 'description': 'The number of warnings in the report should be exactly one.'}</li>
                                            <li>{'name': "Expected value of 'code' in first warning to match 'W001'", 'description': "The code of the first warning should match 'W001'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        126 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_tests_sorted_by_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: tests/test_models.py::TestReportRoot::test_tests_sorted_by_nodeid</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the output of ReportRoot is sorted by nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "nodeids == ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']", 'expected_result': ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        123 output =
                                        338 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `to_dict` method of the `ReportWarning` class is being tested.</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if the `detail` key is included in the dictionary returned by the `to_dict` method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert detail is correct', 'expected_value': '/path/to/file', 'actual_value': "assert d['detail'] == '/path/to/file'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        128 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_without_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to dictionary without detail should exclude it.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a warning that could indicate a missing or misleading detail in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'detail' key is present and contains the actual detailed message.</li>
                                            <li>The 'code' key matches the expected code.</li>
                                            <li>The 'message' key matches the expected message.</li>
                                            <li>The 'warning_type' key (currently set to 'ReportWarning') is not included in the dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        112 output =
                                        335 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_aggregation_fields_present</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that RunMeta has aggregation fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in aggregation feature where run_id, run_group_id and run_count are expected to be present.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'run_id' key is present in the output dictionary.</li>
                                            <li>The 'run_group_id' key is present in the output dictionary.</li>
                                            <li>The 'is_aggregated' key is True.</li>
                                            <li>The 'aggregation_policy' key is set to 'merge'.</li>
                                            <li>The 'run_count' key is equal to 3.</li>
                                            <li>The length of 'source_reports' list is 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        140 output =
                                        483 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 286-288, 290-292, 376-392, 394, 397, 399, 402, 405, 407, 409, 411-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_fields_excluded_when_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LLM fields are excluded when annotations not enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where LLM fields are included despite annotation being disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_annotations_enabled' key is present in the data.</li>
                                            <li>The 'llm_provider' key is present in the data.</li>
                                            <li>The 'llm_model' key is present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        94 output =
                                        326 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_traceability_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LLM traceability fields are included when enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case llm_annotations_enabled is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert data['llm_annotations_enabled'] is True</li>
                                            <li>assert data['llm_provider'] == 'ollama'</li>
                                            <li>assert data['llm_model'] == 'llama3.2:1b'</li>
                                            <li>assert data['llm_context_mode'] == 'complete'</li>
                                            <li>assert data['llm_annotations_count'] == 10</li>
                                            <li>assert data['llm_annotations_errors'] == 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        135 output =
                                        462 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419-431, 433, 435, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</p>
                                    <p><strong>Why Needed:</strong> To ensure that non-aggregated reports do not include source_reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Non-aggregated report should not include source_reports', 'expected_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        81 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_meta_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test RunMeta to dict with all optional fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing or outdated plugin version, which could lead to incorrect aggregation policy.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'git_sha' field is set to 'abc1234'.</li>
                                            <li>The 'git_dirty' field is set to True.</li>
                                            <li>The 'repo_version' field is set to '1.0.0'.</li>
                                            <li>The 'repo_git_sha' field is set to 'abc1234'.</li>
                                            <li>The 'repo_git_dirty' field is set to True.</li>
                                            <li>The 'plugin_git_sha' field is set to 'def5678'.</li>
                                            <li>The 'plugin_git_dirty' field is set to False.</li>
                                            <li>The 'config_hash' field is set to 'def5678'.</li>
                                            <li>The length of the 'source_reports' list is 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        483 input +
                                        198 output =
                                        681 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">49 lines (ranges: 286-288, 290-292, 376-392, 394-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestRunMeta::test_run_status_fields verifies that the RunMeta class includes run status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the RunMeta class does not include all necessary run status fields, potentially causing incorrect interpretation of the results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field should be set to 1.</li>
                                            <li>The 'interrupted' field should be set to True.</li>
                                            <li>The 'collect_only' field should be set to True.</li>
                                            <li>The 'collected_count' field should match the number of runs collected (10).</li>
                                            <li>The 'selected_count' field should match the number of selected runs (8).</li>
                                            <li>The 'deselected_count' field should match the number of deselected runs (2).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        173 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_format</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the schema version is formatted correctly as semver.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'schema_version should be semver format', 'expected_output': {'format': 'semver'}, 'actual_output': {'format': 'string'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        91 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the ReportRoot class includes the schema version in its JSON representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'ReportRoot.schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                            <li>{'name': 'report.to_dict().schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        106 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a CoverageEntry object can be serialized correctly into a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the coverage data is not properly encoded in the JSON representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key should contain the expected value.</li>
                                            <li>The 'line_ranges' key should contain the expected string representation.</li>
                                            <li>The 'line_count' key should contain the expected integer value.</li>
                                            <li>Each assertion should be true for a CoverageEntry object.</li>
                                            <li>The dictionary structure should match the expected format.</li>
                                            <li>Any additional keys or values in the dictionary should not affect the test result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        143 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-103)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `to_dict` method of `LlmAnnotation` returns a dictionary with required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the minimal annotation is missing some required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The dictionary should contain 'scenario' key</li>
                                            <li>The dictionary should contain 'why_needed' key</li>
                                            <li>The dictionary should contain 'key_assertions' key</li>
                                            <li>The dictionary should not contain 'confidence' key when it's None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        229 input +
                                        114 output =
                                        343 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 286-288, 290, 292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestSourceReport::test_to_dict_with_run_id</p>
                                    <p><strong>Why Needed:</strong> To ensure SourceReport objects have a 'run_id' attribute in their dictionary representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "Expected value for 'run_id'", 'value': 'run-1', 'type': 'string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        77 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 286-288, 290-292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSummary::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test `test_to_dict` verifies that a CoverageEntry object is correctly serialized to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage entry serialization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the actual file path of the CoverageEntry.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the expected line ranges.</li>
                                            <li>The 'line_count' key in the dictionary should match the actual number of lines in the CoverageEntry.</li>
                                            <li>All values in the dictionary should be strings, as they represent file paths, line ranges, and line counts.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        254 input +
                                        138 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_minimal_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `TestTestCaseResult` class should be able to create a minimal result with the required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where only the 'nodeid', 'outcome', and 'duration' are known.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `d['nodeid']` is equal to `'test_foo.py::test_bar'`.</li>
                                            <li>The value of `d['outcome']` is equal to `'passed'`.</li>
                                            <li>The value of `d['duration']` is equal to `0.0`.</li>
                                            <li>The value of `d['phase']` is equal to `'call'`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        244 input +
                                        150 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `TestCaseResult` includes a coverage list.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the coverage is not included in the result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The coverage list should contain exactly one entry.</li>
                                            <li>The file path of the first coverage entry should match 'src/foo.py'.</li>
                                            <li>All line ranges and counts in the coverage entry should be present.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        96 output =
                                        352 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 65-68, 190, 194-199, 201, 203, 205, 207, 210-212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM opt-out flag is correctly set in the result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert llm_opt_out is True', 'expected_value': True, 'message': 'Expected llm_opt_out to be True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        94 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_rerun</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_rerun</p>
                                    <p><strong>Why Needed:</strong> The test result should include rerun fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'rerun_count', 'expected_value': 2, 'message': 'Expected rerun count to be 2'}</li>
                                            <li>{'name': 'final_outcome', 'expected_value': 'passed', 'message': "Expected final outcome to be 'passed'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        117 output =
                                        279 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203, 205, 207-210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if the result of a test case does not include fields that indicate reruns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result should be an empty dictionary', 'description': 'The result of the test case should be an empty dictionary.'}</li>
                                            <li>{'name': 'rerun_count should be None', 'description': 'The rerun count should be None.'}</li>
                                            <li>{'name': 'final_outcome should be passed', 'description': "The final outcome of the test case should be 'passed'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        161 output =
                                        313 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_to_dict_with_all_optional_fields verifies that the `to_dict` method includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `to_dict` method handles optional parameters correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result['param_id'] == 'a-b-c',</li>
                                            <li>assert result['param_summary'] == 'a=1, b=2, c=3',</li>
                                            <li>assert result['captured_stdout'] == 'stdout content',</li>
                                            <li>assert result['captured_stderr'] == 'stderr content',</li>
                                            <li>assert result['requirements'] == ['REQ-100'],</li>
                                            <li>assert result['llm_opt_out'] is True,</li>
                                            <li>assert result['llm_context_override'] == 'complete',</li>
                                            <li>assert len(result['coverage']) == 1,</li>
                                            <li>assert result['llm_annotation']['scenario'] == 'Tests foo'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        203 output =
                                        657 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 96-103, 241-243, 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_artifacts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes artifacts when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report is not properly formatted with artifacts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `result['artifacts']` should be 2.</li>
                                            <li>The path of `result['artifacts'][0]` should be `report.html`.</li>
                                            <li>All artifact entries in `result['artifacts']` should have a 'path' key.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        105 output =
                                        369 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530-532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes collection_errors when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test reports collection errors without including them in the dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `result['collection_errors']` is 1 and it contains only one item with key `nodeid` equal to `broken_test.py`.</li>
                                            <li>The value of `result['collection_errors'][0]` has a valid node id `broken_test.py`.</li>
                                            <li>The value of `result['collection_errors'][0]['message']` is `SyntaxError` which is the expected error message for `CollectionError` type.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        243 input +
                                        144 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_custom_metadata</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes custom_metadata when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the custom metadata is not included in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'custom_metadata' key should be present in the result dictionary.</li>
                                            <li>The 'custom_metadata' key should contain the expected project, environment, and build_number values.</li>
                                            <li>The 'build_number' value should match the provided value of 123.</li>
                                            <li>The custom metadata should override any default values set by the ReportRoot class.</li>
                                            <li>The custom metadata should be included in the report even if it's empty or None.</li>
                                            <li>The custom metadata should not be overwritten by other metadata attributes (e.g., 'project' and 'environment').</li>
                                            <li>The custom metadata should be preserved across different test runs with the same configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        179 output =
                                        443 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534-536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</p>
                                    <p><strong>Why Needed:</strong> HMAC signature is included in the report for security purposes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'signature123', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        76 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes sha256 when set.</p>
                                    <p><strong>Why Needed:</strong> Because the ReportRoot class has a SHA-256 hash stored in its instance variable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'expected_value': 'abcdef1234567890'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        97 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536-538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes source_coverage when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test does not verify that the report includes source coverage, potentially leading to incorrect reporting or missing important information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'source_coverage' key in the result dictionary should contain exactly one SourceCoverageEntry.</li>
                                            <li>The 'file_path' of the first SourceCoverageEntry in the 'source_coverage' list should match the specified file path.</li>
                                            <li>All other keys and values in the 'source_coverage' list should be present and have the expected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        282 input +
                                        130 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 96-103, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532-534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of `report.to_dict()` when warnings are present.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "len(result['warnings']) == 1", 'description': "The length of the 'warnings' key in the result dictionary should be 1.", 'expected_value': 1, 'message': 'Expected length of warnings to be 1.'}</li>
                                            <li>{'name': "result['warnings'][0]['code'] == 'W001'", 'description': "The code of the first warning in the 'warnings' list should be 'W001'.", 'expected_value': 'W001', 'message': "Expected code of the first warning to be 'W001'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        196 output =
                                        347 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_with_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test should include the coverage_total_percent key in the result dictionary.</p>
                                    <p><strong>Why Needed:</strong> Because of the following reason: The `to_dict()` method is expected to return a dictionary with all the assertions, including the `coverage_total_percent` value. Without it, the assertion would fail because the key is missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The coverage_total_percent value should be equal to 85.5', 'expected_value': 85.5}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        161 output =
                                        314 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 467-475, 477-479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_without_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                            <li>...</li>
                                            <li>...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        83 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_to_dict_with_all_optional_fields verifies that the `to_dict` method includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case where `llm_opt_out=True` and `llm_context_override='complete'`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'param_id' field is present and matches 'a-b-c'.</li>
                                            <li>The 'param_summary' field is present and matches 'a=1, b=2, c=3'.</li>
                                            <li>The 'captured_stdout' field is present and matches 'stdout content'.</li>
                                            <li>The 'captured_stderr' field is present and matches 'stderr content'.</li>
                                            <li>All required parameters ('REQ-100') are included in the result.</li>
                                            <li>Optional fields (e.g. `llm_opt_out`, `llm_context_override`) are excluded from the result.</li>
                                            <li>The length of the coverage entry is 1, which is expected for a single test case.</li>
                                            <li>The 'llm_annotation' field contains the correct scenario name.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        228 output =
                                        682 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 65-68, 130-133, 135, 137, 139, 141, 143, 190, 194-199, 201-207, 210-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</p>
                                    <p><strong>Why Needed:</strong> Because the `to_dict` method includes captured stderr in the test case results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The captured stderr is correctly included in the result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        67 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220-222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</p>
                                    <p><strong>Why Needed:</strong> Captured stdout is necessary for accurate coverage analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 'Debug output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        74 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218-220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_param_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203-207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the `to_dict` method includes requirements when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': ['REQ-001', 'REQ-002'], 'actual_value': ['REQ-001', 'REQ-002']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        102 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">21 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the default exclude globs for LLM context.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default exclude globs are not correctly set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `llm_context_exclude_globs` returns a list of excluded files.</li>
                                            <li>The file `*.pyc` is included in the default exclude globs.</li>
                                            <li>The directory `__pycache__/*` is also included in the default exclude globs.</li>
                                            <li>The string `*secret*` is not included in the default exclude globs.</li>
                                            <li>The string `*password*` is correctly excluded as a file extension.</li>
                                            <li>The function `llm_context_exclude_globs` returns an empty list when no files or directories are specified.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        169 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies the default redact patterns used by the Config class.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential security vulnerability where sensitive information like passwords and tokens are not properly redacted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `--password` pattern should match any string containing '--password' in its contents.</li>
                                            <li>The `--token` pattern should match any string containing '--token' in its contents.</li>
                                            <li>The `--api[_-]?key` pattern should match any string containing '--api[_-]?key' in its contents, where `_` is a non-alphanumeric character and `key` is the actual key being redacted.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        144 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that default values are set correctly for the TestConfig class.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the default values of the TestConfig class are not set correctly, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.provider == 'none'</li>
                                            <li>cfg.llm_context_mode == 'minimal'</li>
                                            <li>cfg.llm_max_tests == 0</li>
                                            <li>cfg.llm_max_retries == 10</li>
                                            <li>cfg.llm_context_bytes == 32000</li>
                                            <li>cfg.llm_context_file_limit == 10</li>
                                            <li>cfg.llm_requests_per_minute == 5</li>
                                            <li>cfg.llm_timeout_seconds == 30</li>
                                            <li>cfg.llm_cache_ttl_seconds == 86400</li>
                                            <li>cfg.include_phase == 'run'</li>
                                            <li>cfg.aggregate_policy == 'latest'</li>
                                            <li>cfg.is_llm_enabled() is False</li>
                                            <li>cfg.omit_tests_from_coverage is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        205 output =
                                        523 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_get_default_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_get_default_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the default configuration is properly initialized and provides a 'provider' key with value 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'expected_type': 'Config'}</li>
                                            <li>{'name': "cfg.provider == 'none'", 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        105 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_is_llm_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `is_llm_enabled` check returns False for providers without a specified LLM provider.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case the `provider` is set to 'none' and the test relies on it returning True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return False when the `provider` is not explicitly set or defaults to `'none'`.</li>
                                            <li>The function should return True for providers with a specified LLM provider, such as `'ollama'`.</li>
                                            <li>The function should return True for providers with a default LLM provider, such as `'litellm'`.</li>
                                            <li>The function should not return False when the `provider` is set to `'gemini'`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        163 output =
                                        426 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_aggregate_policy</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_aggregate_policy</p>
                                    <p><strong>Why Needed:</strong> To test the validation of an invalid aggregation policy.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The error message should contain the string 'Invalid aggregate_policy ''", 'expected_value': "'Invalid aggregate_policy '''"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        73 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-221, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_context_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_context_mode</p>
                                    <p><strong>Why Needed:</strong> To test the validation of an invalid context mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected number of errors', 'value': 1, 'description': 'The function should return exactly one error message.'}</li>
                                            <li>{'name': 'Expected error message content', 'value': "Invalid llm_context_mode 'mega_max'", 'description': 'The error message should contain the invalid context mode string.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        126 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-213, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_phase` parameter is valid and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The length of errors is 1', 'expected_result': 1}</li>
                                            <li>{'assertion': "The string 'Invalid include_phase ' is in errors[0]", 'expected_result': "Invalid include_phase 'lunch_break'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        112 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-229, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To test the validation of an invalid provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Invalid provider 'invalid_provider'", 'type': 'assertion'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        68 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_numeric_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of numeric constraints for TestConfig.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the default values for llm_context_bytes, llm_max_tests, llm_requests_per_minute, llm_timeout_seconds, and llm_max_retries are not validated correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>llm_context_bytes must be at least 1000</li>
                                            <li>llm_max_tests must be 0 (no limit) or positive</li>
                                            <li>llm_requests_per_minute must be at least 1</li>
                                            <li>llm_timeout_seconds must be at least 1</li>
                                            <li>llm_max_retries must be 0 or positive</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        329 input +
                                        145 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245-254, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_valid_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_valid_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `validate` method returns an empty list of errors when a valid configuration is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'errors should be empty', 'expected': [], 'actual': {'scenario': 'tests/test_options.py::TestConfig::test_validate_valid_config', 'why_needed': 'To ensure that the `validate` method returns an empty list of errors when a valid configuration is provided.', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        131 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_aggregation_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ability to load aggregation options correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where aggregation options are not loaded correctly, potentially causing issues with downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate_dir` option is set to 'aggr_dir'.</li>
                                            <li>The `aggregate_policy` option is set to 'merge'.</li>
                                            <li>The `aggregate_run_id` option is set to 'run-123'.</li>
                                            <li>The `aggregate_group_id` option is set to 'group-abc'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        120 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</p>
                                    <p><strong>Why Needed:</strong> To test that the disabled batch flag works correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        70 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_config_missing_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when pyproject.toml doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the LLM report generation fails with an error due to missing pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `load_config` should be able to handle the case when pyproject.toml is not present.</li>
                                            <li>The default value for `llm_max_retries` should be used in this scenario.</li>
                                            <li>The test should fail with a meaningful error message indicating that the LLM report generation failed due to missing pyproject.toml file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        130 output =
                                        543 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_coverage_source</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_coverage_source</p>
                                    <p><strong>Why Needed:</strong> To test the coverage source option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'cov_dir', 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        64 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607-608, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_defaults</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_defaults</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading configuration with no options set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg.provider == "none"', 'expected_value': 'None'}</li>
                                            <li>{'name': 'cfg.report_html is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        94 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Load configuration from CLI overrides in PyProject</p>
                                    <p><strong>Why Needed:</strong> To ensure that CLI options override PyProject settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'CLI options override PyProject.toml', 'expected_value': {'override': True}}</li>
                                            <li>{'name': 'PyProject.toml values not overridden by CLI options', 'expected_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        95 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">132 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492-494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_provider_override</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Load configuration from CLI provider override</p>
                                    <p><strong>Why Needed:</strong> To test that CLI provider option overrides pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'CLI provider option overrides pyproject.toml', 'expected_value': 'pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        71 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">133 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading retries from CLI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'llm_max_retries': 2}, 'actual': {'llm_max_retries': 2}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        81 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494-495, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_pyproject</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading values from pyproject.toml.</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of the `load_config` method in the Options class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'True', 'actual': 'True'}</li>
                                            <li>{'name': 'pyproject.toml contents are correct', 'expected': "{'...'}", 'actual': {'scenario': '...', 'why_needed': '...', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        127 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">134 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386-388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_token_optimization_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loads token optimization options from CLI and verifies the expected configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `llm_prompt_tier` option is set to 'minimal' but the `batch_parametrized_tests` option is still enabled, leading to unexpected behavior in the test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `prompt_tier` of the configuration should be 'minimal'.</li>
                                            <li>The `batch_parametrized_tests` flag should be False.</li>
                                            <li>The `context_compression` of the configuration should be 'none'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        129 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">88 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470-474, 476-477, 479, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">47 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_dependency_snapshot</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the `test_cli_dependency_snapshot` test function to verify that it correctly sets the `llm_dependency_snapshot` option to 'deps.json' when a CLI override is used.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the `llm_dependency_snapshot` option is not set to 'deps.json' when a CLI override is applied, which could lead to unexpected behavior or errors in dependency snapshot reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_dependency_snapshot` option is correctly set to 'deps.json' after applying a CLI override.</li>
                                            <li>The `report_dependency_snapshot` configuration value matches the expected value of 'deps.json'.</li>
                                            <li>A mock configuration object is created with the correct `llm_dependency_snapshot` option value.</li>
                                            <li>The `load_config` function successfully loads the mock configuration object.</li>
                                            <li>The `cfg.report_dependency_snapshot` attribute is set to the expected value of 'deps.json' after applying a CLI override.</li>
                                            <li>A critical check is performed: the `llm_dependency_snapshot` option is present and has the correct value in the configuration.</li>
                                            <li>A test case is executed with mock configuration data, ensuring that the `llm_dependency_snapshot` option is correctly set.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        261 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488, 490-492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_evidence_bundle</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `report_evidence_bundle` option is correctly set to 'bundle.zip' when CLI override is enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `report_evidence_bundle` option is not updated correctly when CLI overrides are applied.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `cfg.report_evidence_bundle` should be set to 'bundle.zip'.</li>
                                            <li>The value of `mock.option.llm_evidence_bundle` should match 'bundle.zip'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        114 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488-490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_json</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test CLI overrides the default report format to 'output.json'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default report format is not set correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_report_json` option is set to 'output.json' in the mock configuration.</li>
                                            <li>The value of `report_json` in the loaded configuration matches 'output.json'.</li>
                                            <li>The `llm_report_json` option is present and has a value of 'output.json' in the loaded configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        122 output =
                                        334 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484-486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_pdf</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the 'test_cli_report_pdf' test function to verify that it sets the 'report_pdf' option correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the 'report_pdf' option is not set correctly for CLI overrides.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'report_pdf' option should be set to 'output.pdf'.</li>
                                            <li>Mocking the config object with a mock configuration and verifying it sets the 'report_pdf' option correctly.</li>
                                            <li>Verifying that the assert statement passes when the 'report_pdf' option is set correctly.</li>
                                            <li>Testing the error case where the 'report_pdf' option is not set at all.</li>
                                            <li>Mocking the config object without setting the 'report_pdf' option and verifying it does not affect the test.</li>
                                            <li>Verifying that the mock configuration overrides any default value for the 'report_pdf' option.</li>
                                            <li>Testing the case where the 'llm_report_pdf' option is also overridden by a custom value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        211 output =
                                        423 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486-488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_invalid_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of invalid token output format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the token output format is always valid and consistent with the expected format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "litellm_token_output_format should be one of ['json', 'xml']", 'description': 'The token output format should be either json or xml.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        91 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-237, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_token_refresh_interval_too_short</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation when token refresh interval is too short</p>
                                    <p><strong>Why Needed:</strong> Because the token refresh interval is set to 30 seconds, which is too short and may cause issues with authentication.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The token refresh interval must be at least 60 seconds', 'expected_value': 60, 'actual_value': 30}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        93 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241-242, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_valid_litellm_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_valid_litellm_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM configuration is valid and does not raise any validation errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is_not_empty', 'expected_value': 'litellm_token_output_format', 'actual_value': 'text'}</li>
                                            <li>{'assertion_type': 'not_equal_to', 'expected_value': 3600, 'actual_value': 3600}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        118 output =
                                        260 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate_include_history feature is properly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'include_history = True\naggregate_include_history = True', 'actual': 'include_history = True\naggregate_include_history = True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        108 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438-440, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate policy is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has an aggregate_policy section', 'expected': 'pyproject.toml should exist and have an aggregate_policy section'}</li>
                                            <li>{'name': 'aggregate_policy is present in pyproject.toml', 'expected': 'aggregate_policy should be present in pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        135 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436-438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</p>
                                    <p><strong>Why Needed:</strong> To ensure that all config keys are loaded when loading the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected': {'status': 0, 'message': ''}, 'actual': {'status': 0, 'message': ''}}</li>
                                            <li>{'name': 'pyproject.toml file has all config keys', 'expected': {'status': 1, 'message': 'Missing required config key'}, 'actual': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        150 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">150 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340-346, 348-350, 352-354, 356-357, 360-369, 372-375, 378-392, 396, 400, 402, 404, 408-410, 412-413, 416-422, 426-428, 430-432, 436-440, 444-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache directory is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "pyproject.toml exists and has a 'cache_dir' key", 'expected_value': 'True'}</li>
                                            <li>{'name': "pyproject.toml contains a valid 'cache_dir' value", 'expected_value': "The 'cache_dir' value in the pyproject.toml file is correct."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        132 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390-392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache TTL seconds is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and has ttl_seconds setting', 'value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml file content contains ttl_seconds setting', 'value': {'ttl_seconds': 3600}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        120 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388-390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_failed_output` feature flag is correctly set when loading a PyProject file with an empty 'build' section.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'empty build section', 'actual': 'not empty build section'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        103 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418-420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_output_max_chars` option in `pyproject.toml` is correctly loaded and used to set the maximum number of characters for capturing output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected value for capture_output_max_chars', 'value': 100, 'expected_type': 'int'}</li>
                                            <li>{'name': 'Expected error message for invalid capture_output_max_chars value', 'value': 'Invalid capture_output_max_chars value. It should be an integer between 1 and 999.', 'expected_type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        160 output =
                                        279 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420-422, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context_bytes functionality in Pytest is working correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context bytes are loaded from pyproject.toml', 'expected_value': 'context_bytes', 'actual_value': 'pyproject.toml'}</li>
                                            <li>{'name': 'Context bytes are not loaded from other files', 'expected_value': 'other_files', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        128 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362-364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'context_exclude_globs' setting in the PyProject is properly loaded and excluded from the test coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'exclude globs from pyproject.toml', 'actual': 'include globs from pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        110 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368-369, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context file limit is properly set in the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context file limit is correctly set to 1000', 'expected_value': 1000, 'actual_value': '1234'}</li>
                                            <li>{'name': 'Context file limit is not exceeded by default settings', 'expected_value': 1000}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        125 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364-366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for `tests/test_options_coverage.py`</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_include_globs` option is correctly loaded from `pyproject.toml`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context include globs are correctly loaded', 'expected_value': 'True'}</li>
                                            <li>{'name': 'Context include globs are not empty', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        105 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366-368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hmac key file is loaded correctly and used for signing requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "hmac_key_file = 'path/to/hmac/key.txt'", 'actual': 'pyproject.toml contents'}</li>
                                            <li>{'name': 'hmac key file path', 'expected': '/path/to/hmac/key.txt', 'actual': 'pyproject.toml contents'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        140 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The include_param_values option should be present in the pyproject.toml file', 'expected_value': {'scenario': 'tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values', 'why_needed': 'To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.'}}</li>
                                            <li>{'name': 'The include_param_values option should be a boolean value', 'expected_value': {'scenario': 'tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values', 'why_needed': 'To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.'}}</li>
                                            <li>{'name': 'The include_param_values option should be set to True', 'expected_value': {'scenario': 'tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values', 'why_needed': 'To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        297 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372-374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the include phase is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "include_phase = ['main', 'util']", 'actual': "include_phase = ['main', 'test']"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        102 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</p>
                                    <p><strong>Why Needed:</strong> To ensure that the include_pytest_invocation option is properly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'include_pytest_invocation = ["path/to/pytestInvocation.py"]', 'actual': 'include_pytest_invocation = []'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        114 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426-428, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_invocation_redact_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_invocation_redact_patterns</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'invocation_redact_patterns' key in pyproject.toml is correctly loaded and redacted for sensitive information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'Redacted invocation_redact_patterns key from pyproject.toml contents', 'actual': 'Redacted invocation_redact_patterns key in pyproject.toml contents'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        111 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430-432, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_litellm_api_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_api_base` module is loaded correctly from the PyPI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'The contents of pyproject.toml should be a valid Python project file with the following structure:\n\n[tool.pyproject.toml]\n\t[tool.litellm_api_base]\n\t"litellm_api_base": "path/to/litellm_api_base"\n', 'actual': 'The contents of pyproject.toml should be a valid Python project file with the following structure:\n\n[tool.pyproject.toml]\n\t[tool.litellm_api_base]\n\t"litellm_api_base": "path/to/litellm_api_base"\n', 'error_code': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        204 output =
                                        326 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340-342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm API key is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'api-key = "..."', 'actual': 'api-key = "..."'}</li>
                                            <li>{'name': 'litellm_api_key loaded', 'expected': 'True', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        131 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342-344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading litellm_token_json_key from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure the coverage of litellm token JSON key is properly loaded in the project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "pyproject.toml exists and has a 'litellm_token_json_key' section", 'expected_value': 'True'}</li>
                                            <li>{'name': "pyproject.toml has a 'litellm_token_json_key' section with the correct key", 'expected_value': {'key': 'litellm_token_json_key', 'value': 'some_value'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        142 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356-357, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm token output format is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The contents of the pyproject.toml file should contain a section named 'tool' with a sub-section named 'litellm' and a key named 'token_output_format'."}</li>
                                            <li>{'name': 'litellm token output format', 'expected': "The value of the 'token_output_format' key in the pyproject.toml file should be a string representing the expected output format."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        170 output =
                                        295 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352-354, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm_token_refresh_command is loaded correctly from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has the correct content', 'expected_content': '```\ntoml version 0.13.2\n[tool.pyproject.toml]\nversion = "0.13.2"\n\tpy_requires = ["python >= 3.8"]\n\tpython_requires = {exact: "py>=3.7,upper-exact"}\n\ntoctreatesource = False\n\ttoctree = []\n\thelprootsync = True\n[tool.pyproject.toml]\nversion = "0.13.2"\n\tpy_requires = ["python >= 3.8"]\n\tpython_requires = {exact: "py>=3.7,upper-exact"}\n\ttoctreatesource = False\n\ttoctree = []\n\thelprootsync = True\n```\n', 'actual_content': '```\ntoml version 0.13.2\n[tool.pyproject.toml]\nversion = "0.13.2"\n\tpy_requires = ["python >= 3.8"]\n\tpython_requires = {exact: "py>=3.7,upper-exact"}\n\ntoctreatesource = False\n\ttoctree = []\n\thelprootsync = True\n[tool.pyproject.toml]\nversion = "0.13.2"\n\tpy_requires = ["python >= 3.8"]\n\tpython_requires = {exact: "py>=3.7,upper-exact"}\n\ttoctreatesource = False\n\ttoctree = []\n\thelprootsync = True\n```\n', 'error_message': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        457 output =
                                        582 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344-346, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm_token_refresh_interval option is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "refresh_interval = '1h'", 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        101 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348-350, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_malformed_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 123, 171, 308, 311-312, 320-325, 449, 451, 453-456, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_concurrency` option is correctly loaded from the `pyproject.toml` file and used to configure the concurrency settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected max_concurrency value in pyproject.toml', 'value': 4, 'expected_type': 'int'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        106 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380-382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_tests` setting in `pyproject.toml` is correctly loaded and used to determine the number of tests to run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'pyproject.toml should exist'}</li>
                                            <li>{'name': 'pyproject.toml file content', 'expected': 'pyproject.toml should contain the correct setting for max_tests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        132 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378-380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the metadata file is loaded correctly and provides accurate information about the project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected_result': 'True'}</li>
                                            <li>{'name': 'pyproject.toml is a file', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        105 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444-446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ollama_host configuration is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "{'ollama_host': 'host_name'}", 'actual': "{'ollama_host': 'host_name'}"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        107 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336-337, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that omit_tests_from_coverage is correctly loaded from pyproject.toml when coverage is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'omitted tests are not included in the coverage report', 'actual': 'included tests are included in the coverage report'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        108 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_chars` parameter in `pyproject.toml` is correctly loaded and validated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected value for max_chars', 'value': 100, 'expected_type': 'int'}</li>
                                            <li>{'name': 'Error message for invalid max_chars value', 'value': 'max_chars must be an integer between 1 and 9999', 'expected_type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        138 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374-375, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `report_collect_only` option is correctly loaded from the PyProject file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'Collect only files', 'actual': 'Collect all files'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        93 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416-418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the timeout_seconds feature is properly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has a correct timeout_seconds setting', 'value': 'True'}</li>
                                            <li>{'name': 'timeout_seconds value in pyproject.toml is within the expected range', 'value': 60}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        117 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `batch_max_tests` feature is correctly loaded from the PyProject file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'file existence', 'expected_result': 'pyproject.toml exists in the test directory'}</li>
                                            <li>{'assertion_type': 'file content', 'expected_result': 'The contents of pyproject.toml match the expected format'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        123 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400-402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_parametrized_tests</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Load batch parametrized tests</p>
                                    <p><strong>Why Needed:</strong> Optimize Pytest configuration by reducing unnecessary test loading</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'File existence and content', 'condition': 'pyproject.toml exists and contains the expected file structure'}</li>
                                            <li>{'assertion_type': 'JSON structure consistency', 'condition': 'the JSON object in pyproject.toml is consistent with the expected structure'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        109 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">131 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396-398, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression feature is properly loaded and enabled in the PyPI token optimization process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context compression is enabled', 'value': 'True'}</li>
                                            <li>{'name': 'Context compression is disabled', 'value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        104 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402-404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_line_padding` option in the PyProject is correctly loaded and applied to context lines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context line padding is applied correctly', 'expected_value': '\n# This is a test\n# with line padding', 'actual_value': '```python\nThis is a test\nwith line padding\n```'}</li>
                                            <li>{'name': 'Context line padding is not applied when using the default value', 'expected_value': '\nThis is a test\n', 'actual_value': '```python\nThis is a test\n\n```'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        170 output =
                                        287 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404-405, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` option is correctly loaded from the PyProject file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The 'prompt_tier' key in the PyProject file should be present and contain a list of tier names."}</li>
                                            <li>{'name': 'prompt_tier value', 'expected': "The value of the 'prompt_tier' option should be a list of tier names."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        141 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392-393, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because it checks if the `batch_max_tests` configuration option allows for too few tests to be validated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert errors are not empty', 'message': "Expected no error messages, but got 'batch_max_tests must be at least 1'", 'type': 'error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        113 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context line padding is correctly validated and raises an error when it's negative.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding must be 0 or positive', 'type': 'assertionError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        88 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</p>
                                    <p><strong>Why Needed:</strong> To test the validation of a scenario with an invalid context_compression setting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Invalid context_compression', 'type': 'AssertionError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        78 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the validation of invalid `prompt_tier` values does not produce any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': 'Invalid prompt_tier', 'value': "['Invalid prompt_tier']"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        95 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_integration.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</p>
                                    <p><strong>Why Needed:</strong> To ensure the config has safe defaults.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'description': 'The function should check if cfg is indeed an instance of Config.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        80 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">124 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378-380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603-605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</p>
                                    <p><strong>Why Needed:</strong> The test requires that markers exist in the plugin configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytestconfig is not None', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        74 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_both_json_and_html_outputs</span>
                            <div class="test-meta">
                                <span>97ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test generates both JSON and HTML reports for a test function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the plugin is used to generate both JSON and HTML outputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should exist after running the test.</li>
                                            <li>The `report.html` file should exist after running the test.</li>
                                            <li>Both files should have the expected contents before running the test.</li>
                                            <li>The `report.json` file should contain the correct data.</li>
                                            <li>The `report.html` file should not be empty or contain unexpected content.</li>
                                            <li>The plugin should correctly generate both JSON and HTML reports for the test function.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        146 output =
                                        425 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</p>
                                    <p><strong>Why Needed:</strong> pytest_collection_finish counts items (line 378)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert data['run_meta']['collected_count'] == 3", 'expected_value': 3, 'message': 'Expected collected count to be 3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        198 input +
                                        96 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_creates_nested_directory</span>
                            <div class="test-meta">
                                <span>59ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that output directories are created if missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the plugin might not create nested directory structure for reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `nested` directory should be created in the report.json file.</li>
                                            <li>The `report.json` file should exist in the specified directory path.</li>
                                            <li>The `nested` directory should have been created recursively if it does not already exist.</li>
                                            <li>The plugin should create a nested directory structure for reports even when output directories are missing.</li>
                                            <li>The test should fail if the report.json file is not created or exists outside of the specified directory path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        142 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 70-71, 73-75, 77, 79, 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_fixture_error_captured</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fixture errors are captured in report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the error from a failed plugin hook is not properly reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'error' key in the report should be set to 1 when there is an error.</li>
                                            <li>The 'summary' section of the report should contain an 'error' key with value 1.</li>
                                            <li>The 'error' value should match the number of times the test was run (in this case, once).</li>
                                            <li>The 'summary' section of the report should not be empty.</li>
                                            <li>The 'report.json' file should exist in the expected location.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        149 output =
                                        435 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 78-79, 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330, 332, 334-335, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_makereport_captures_all_outcomes</span>
                            <div class="test-meta">
                                <span>174ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_runtest_makereport captures all outcomes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the report does not capture all outcomes of the tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the report includes 'passed', 'failed', and 'skipped' outcomes.</li>
                                            <li>The test asserts that there are at least three types of outcomes in the report.</li>
                                            <li>The test checks if the report has a valid JSON structure with 'tests' and 'outcome' keys.</li>
                                            <li>The test ensures that the report does not contain any missing or invalid data.</li>
                                            <li>The test verifies that the report includes all test names (i.e., 'test_pass', 'test_fail', and 'test_skip').</li>
                                            <li>The test checks if the report has a correct order of outcomes (i.e., 'passed' before 'failed' and 'skipped').</li>
                                            <li>The test verifies that the report does not contain any duplicate outcomes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        209 output =
                                        544 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">114 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the generated report exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'report_path.exists()', 'expected': {'status': 0, 'message': ''}, 'actual': {'status': 1, 'message': 'Report file not found'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        150 input +
                                        100 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">250 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403-404, 558-559, 562-563, 566-568, 579, 583, 602-603, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_pdf_option_enables_plugin</span>
                            <div class="test-meta">
                                <span>617ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that --llm-pdf option enables the plugin.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where the plugin is not enabled due to an error in Playwright.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test should run without any errors or warnings indicating that the plugin was disabled.</li>
                                            <li>The test should exit with code 0 (success) if the plugin was successfully enabled.</li>
                                            <li>The test should verify that the JSON output is generated even when not asked for a report.</li>
                                            <li>The test should verify that passing only --llm-pdf works to trigger the plugin logic.</li>
                                            <li>The test should verify that the plugin key validation passes without any issues.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        435 input +
                                        146 output =
                                        581 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_session_start_records_time</span>
                            <div class="test-meta">
                                <span>60ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the pytest_sessionstart records start time is recorded correctly when running Pytest with --llm-report-json.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the start time of the session might not be recorded correctly if the report is generated without it.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'start_time' key should exist in the run_meta dictionary.</li>
                                            <li>The value of the 'start_time' key should be present in the run_meta dictionary.</li>
                                            <li>The 'start_time' value should match the current time when the test runs.</li>
                                            <li>The start time should be recorded correctly even if the test is not executed successfully.</li>
                                            <li>The report path should contain a 'start_time' key with a non-empty string value.</li>
                                            <li>The 'run_meta' dictionary should have a 'start_time' key with a datetime object value.</li>
                                            <li>The 'start_time' value should be in seconds since the epoch.</li>
                                            <li>The start time should not be affected by the test's execution status (e.g., failed, skipped).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        225 output =
                                        501 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_context_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the requirement marker does not cause any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The requirement marker is used correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        46 output =
                                        136 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestReportGeneration::test_report_writer_integration</span>
                            <div class="test-meta">
                                <span>46ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the integration of report writer with pytest_llm_report models and ReportWriter.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report generation flow fails due to missing or corrupted JSON report files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the report.json file exists at the specified path.</li>
                                            <li>Check if the summary section of the report.json file contains the correct total and passed counts.</li>
                                            <li>Assert that the test_a.py nodeid is present in the HTML report.</li>
                                            <li>Verify that the test_b.py nodeid is also present in the HTML report.</li>
                                            <li>Check if the duration of each test case is correctly reported.</li>
                                            <li>Assert that the error message associated with test_b.py's failed outcome is 'AssertionError'.</li>
                                            <li>Verify that the total count of passed tests is 1, and the individual counts are correct.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        417 input +
                                        184 output =
                                        601 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">26 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_disabled</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the collectreport plugin behaves correctly when it is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytest_collectreport', 'expected_result': 'Mock object session.config.stash.get was not called'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        90 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 579-580, 586-587)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collecting reports when pytest_collectreport is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_report.called_once_with(mock_report)', 'description': 'The handle_collection_report method should be called once with mock_report as an argument.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        204 input +
                                        98 output =
                                        302 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 558-559, 562, 566-568, 579-580, 586, 590-592)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</p>
                                    <p><strong>Why Needed:</strong> Because the plugin requires a valid session to function correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'Exception', 'message': 'pytest_collectreport is not available in this environment.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        81 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</p>
                                    <p><strong>Why Needed:</strong> Because the test is checking if collectreport skips when session is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytest_collectreport', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        78 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</p>
                                    <p><strong>Why Needed:</strong> LLM is currently disabled by default. This test checks if the warning is raised when LLM is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM is not disabled', 'value': 'True'}</li>
                                            <li>{'name': 'LLM is enabled', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        108 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</p>
                                    <p><strong>Why Needed:</strong> Validation errors are raised when the plugin is configured with invalid values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected a UsageError to be raised', 'expected': 'UsageError', 'actual': 'pytest_llm_report.plugin'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        90 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">135 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-358, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</p>
                                    <p><strong>Why Needed:</strong> To ensure that the configure function skips on xdist workers and does not attempt to add markers for them.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_config.addinivalue_line.called', 'expected': 1, 'message': 'Expected mock_config.addinivalue_line to be called once'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        105 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 328-330, 332-334, 336-338, 342-343, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigureFallback::test_pytest_configure_fallback_load</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test fallback to load_config if Config.load is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the plugin would attempt to load configuration from an empty Config object, causing an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_cfg.validate.asserts.return_value == []</li>
                                            <li># Verify that validate() method returns an empty list when Config.load is missing</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        747 input +
                                        317 output =
                                        1064 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> CLI options override in pyproject.toml is necessary for plugin functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'pyproject.toml contents with CLI options overridden'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        88 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</span>
                            <div class="test-meta">
                                <span>116ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Load configuration from PyProject.toml</p>
                                    <p><strong>Why Needed:</strong> To test the plugin's ability to load configuration from a specific file format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'File extension', 'value': '.pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        68 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that terminal summary skips when plugin is disabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case the plugin is disabled and terminal summary is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mocked stash.get() with _enabled_key set to False</li>
                                            <li>mocked stash.get() with _enabled_key set to True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        78 output =
                                        359 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 399, 403-404, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 399-400, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::testload_config</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test config loading from pytest objects (CLI) for maximal plugin functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the maximal plugin's ability to load configuration files correctly, ensuring that the plugin can properly use pytest objects (CLI).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        639 input +
                                        383 output =
                                        1022 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `pytest_runtest_makereport` hookwrapper is not properly handling the generator when makereport is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Mocking', 'expected_mock': ['mock_item', 'mock_call'], 'actual_result': {'config': {'stash': {}}}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        115 output =
                                        335 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 558-559, 562-563, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makereport calls collector when enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the collector is not called when makereport is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `mock_collector` should be called with the provided `mock_report` when `pytest_runtest_makereport` is called.</li>
                                            <li>The `mock_item.config.stash.get(_enabled_key)` method should return `True` when `_enabled_key` is present in the stash.</li>
                                            <li>The `mock_item.config.stash.get(_collector_key)` method should return `mock_collector` when `_collector_key` is present in the stash.</li>
                                            <li>The `mock_call.send(mock_outcome)` call should not raise an exception if `mock_outcome.get_result.return_value` is `None`.</li>
                                            <li>The `mock_collector.handle_runtest_logreport` method should be called with the provided `mock_report` and `mock_item` when `pytest_runtest_makereport` is called.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        371 input +
                                        220 output =
                                        591 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 602-603)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginSessionHooks</p>
                                    <p><strong>Why Needed:</strong> To test that collection_finish calls collector when enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_finish was called once with correct arguments', 'expected_args': ['[MagicMock(), MagicMock()]'], 'actual_args': [], 'assertion_type': 'method_call'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        219 input +
                                        90 output =
                                        309 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 602, 606-608)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the pytest_sessionstart hook is properly disabled in the stash configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_session.get.call_count', 'expected_value': 1, 'message': 'Expected mock_session.get to be called once.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        95 output =
                                        252 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that sessionstart initializes collector when enabled and the collector is properly created.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the collector might not be initialized or created correctly if pytest_sessionstart is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The key '_collector_key' should exist in the mock stash.</li>
                                            <li>The key '_start_time_key' should exist in the mock stash.</li>
                                            <li>A MagicMock instance with config.stash set to a MockStash instance should be created and assigned to pytest_sessionstart's config.</li>
                                            <li>The _collector_key and _start_time_key should both be present in the mock stash.</li>
                                            <li>The collector should have been successfully initialized when pytest_sessionstart is called on a session with enabled collectives.</li>
                                            <li>A KeyError or other exception should not be raised if pytest_sessionstart is called on a session without enable_collectives set to True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        191 output =
                                        526 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 558-559, 562, 566-568, 619, 623, 626, 628-629)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_addoption adds expected arguments to the parser.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where pytest_addoption does not add required arguments to the parser, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>parser.getgroup.assert_called_with('llm-report', 'LLM-enhanced test reports')</li>
                                            <li>group.addoption.call_args_list[0][0].startswith('--llm-report')</li>
                                            <li>group.addoption.call_args_list[1][0].startswith('--llm-coverage-source')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        123 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption no longer adds INI options</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'parser.addini was not called', 'expected_result': [], 'actual_result': 'parser.addini.called'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        86 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_coverage_calculation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage percentage calculation logic for terminal summary.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage reporting when terminal summaries are generated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option is set to 'out.html'.</li>
                                            <li>The `stash` dictionary contains the correct stash data.</li>
                                            <li>The `Coverage` class is mocked correctly with a valid coverage report.</li>
                                            <li>The `MockStash` class is created and its `load` method is called.</li>
                                            <li>The `report` method of the `Coverage` class is called once.</li>
                                            <li>The `patched_pathlib.Path.exists` function returns True when it should return False.</li>
                                            <li>The `patched_coverage.Coverage.report` method is called once with a valid coverage report.</li>
                                            <li>The `pytest_llm_report.coverage_map.CoverageMapper` class is patched correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        189 output =
                                        584 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">53 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_llm_enabled</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that terminal summary with LLM enabled runs annotations correctly when provider is 'ollama'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the plugin does not run annotations when LLM is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that `pytest_terminal_summary` is called once with correct configuration.</li>
                                            <li>Verify that `pytest_terminal_summary` passes a valid configuration to `llm.annotator.annotate_tests`.</li>
                                            <li>Verify that `pytest_llm_report.llm.annotator.annotate_tests` returns True for the provided configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        121 output =
                                        598 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">66 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-486, 491-494, 497, 499, 502-504, 512-514, 516, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_no_collector</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary creates collector if missing.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where terminal summary is not collecting metrics.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The stash object passed to pytest_terminal_summary() does not contain any _enabled_key or _config_key.</li>
                                            <li>The stash object passed to pytest_terminal_summary() contains True for _enabled_key but False for _config_key.</li>
                                            <li>The stash object passed to pytest_terminal_summary() is empty.</li>
                                            <li>_enabled_key is present in the stash object, but its value is False.</li>
                                            <li>The stash object passed to pytest_terminal_summary() does not contain any coverage mapper.</li>
                                            <li>The stash object passed to pytest_terminal_summary() contains a CoverageMapper object with an empty map.</li>
                                            <li>The stash object passed to pytest_terminal_summary() has no _enabled_key or _config_key.</li>
                                            <li>_enabled_key is present in the stash object, but its value is False and _config_key is not present.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        204 output =
                                        595 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_with_aggregation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with aggregation enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in aggregation functionality when terminal summary is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate_dir` option should be set to `/agg` for aggregation to work correctly.</li>
                                            <li>The `get()` method of the stash should return a report when aggregation is enabled.</li>
                                            <li>The `[]` index should also return a report when aggregation is enabled.</li>
                                            <li>The `ReportWriter` class should write JSON and HTML files when aggregation is enabled.</li>
                                            <li>The `Aggregator` class should aggregate reports correctly when aggregation is enabled.</li>
                                            <li>The `aggregate()` method of the Aggregator class should be called once with no arguments when aggregation is enabled.</li>
                                            <li>The `get()` method of the stash should return a report when aggregation is enabled and the stash has both `_enabled_key` and `_config_key` set to True.</li>
                                            <li>The `write_json()` and `write_html()` methods of the ReportWriter class should be called once with no arguments when aggregation is enabled.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        441 input +
                                        225 output =
                                        666 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 399, 403, 407, 410-411, 413-414, 417-418, 420, 422-426, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummaryErrors::test_terminal_summary_coverage_error</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage calculation error when loading coverage map during terminal summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the plugin fails to calculate coverage percentages due to an OSError during load.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `load` method of `CoverageMapper` raises an `OSError` with message 'Disk full'.</li>
                                            <li>A warning is raised when trying to compute coverage percentage without loading the coverage map.</li>
                                            <li>The `report_writer` does not raise any warnings or errors during execution.</li>
                                            <li>The `pytest_terminal_summary` function returns a mock object that matches the expected behavior.</li>
                                            <li>The `MagicMock()` instance passed as an argument to `pytest_terminal_summary` is not modified by the test.</li>
                                            <li>The `mock_config.stash` dictionary contains the correct key-value pairs for the plugin configuration.</li>
                                            <li>The `mock_cov_cls.return_value` attribute of the mock object returns a new instance of `CoverageMapper` with the expected behavior.</li>
                                            <li>The `mock_cov.load.side_effect` attribute is set to an instance of `OSError` with the specified message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        389 input +
                                        235 output =
                                        624 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">52 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 476-479, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_balanced_context</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the ContextAssembler with a balanced context configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regressions where the ContextAssembler is used with an unbalanced context configuration, which can lead to incorrect coverage metrics.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'utils.py' file should be present in the assembled source code.</li>
                                            <li>The 'def util()' function should be found in the 'utils.py' file within the assembled source code.</li>
                                            <li>The ContextAssembler should assemble a balanced context configuration for the given test result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        117 output =
                                        448 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</p>
                                    <p><strong>Why Needed:</strong> To assemble a complete context for the test 'test_a.py::test_1' and verify that it contains the expected code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'def test_1():\n    pass\n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        176 input +
                                        95 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139-140, 268-272)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_minimal_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the ContextAssembler can assemble a minimal context for a test file with a single test function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using the 'minimal' llm_context_mode, as it ensures that only necessary code is included in the assembly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The source of the assembled context should contain only the specified test function.</li>
                                            <li>The context object should be empty (i.e., no additional code or variables are present).</li>
                                            <li>The 'test_1' assertion should be present in the source code of the assembled context.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        267 input +
                                        130 output =
                                        397 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_balanced_context_limits</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the ContextAssembler does not exceed the specified context limits when assembling a test file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential issues where the ContextAssembler exceeds the specified context limit, causing unexpected behavior or errors in the assembly process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' file is present in the assembled context.</li>
                                            <li>The length of the 'f1.py' file does not exceed 40 bytes (20 bytes + truncation message).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        109 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_complete_context_limits_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'complete' mode does not truncate long files despite a small context size limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the ContextAssembler truncates long files when the context size is too small, potentially leading to incorrect results or data loss.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file content is preserved and can be accessed through the assembled context.</li>
                                            <li>The 'truncated' key in the context does not exist.</li>
                                            <li>The file path of the content is correct (i.e., 'f1.py')</li>
                                            <li>The length of the content matches its original value (20 bytes)</li>
                                            <li>The coverage report includes all lines and counts as expected</li>
                                            <li>The test result indicates that the assembly was successful (outcome='passed')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        361 input +
                                        166 output =
                                        527 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_get_test_source_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the function `_get_test_source` returns an empty string when given a non-existent file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function `_get_test_source` throws a `ValueError` or raises an exception when given a non-existent file path.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_get_test_source` returns an empty string for the given input.</li>
                                            <li>The function `_get_test_source` does not raise any exceptions for the given input.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        275 input +
                                        111 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 33, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_should_exclude</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the ContextAssembler should exclude certain files from the llm context.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler incorrectly excludes files that are not actually present in the llm context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert assembler._should_exclude('test.pyc') is True</li>
                                            <li>assert assembler._should_exclude('secret/key.txt') is True</li>
                                            <li>assert assembler._should_exclude('public/readme.md') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        110 output =
                                        337 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 33, 284-287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_minimal_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble in minimal mode returns no context files.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the assemble function does not generate any context files when run in minimal mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context_files == {}</li>
                                            <li>def test_foo() in test_source</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        71 output =
                                        369 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_with_context_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble respects llm_context_override from test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that occurs when llm_context_override is set to 'balanced' but the assembly process overrides it with a different mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the assembler uses the specified context override.</li>
                                            <li>Check if the module file is included in the context files.</li>
                                            <li>Ensure that the coverage entry points are correct for the module file.</li>
                                            <li>Verify that the llm_context_override is respected and not overridden by other factors.</li>
                                            <li>Test that the assembly process correctly overrides the default mode with the specified override.</li>
                                            <li>Confirm that the test passes even when the llm_context_override is set to 'balanced' but the assembly process overrides it with a different mode.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        362 input +
                                        168 output =
                                        530 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_excludes_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test balanced context excludes files matching exclude patterns.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM context mode 'balanced' would include files that match the specified exclude patterns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'secret_config.py' should not be included in the balanced context.</li>
                                            <li>No files should be matched against the exclude pattern '*secret*'.</li>
                                            <li>The coverage entry for 'secret_config.py' should have a line count of 1, indicating it is only executed once.</li>
                                            <li>The LLM context mode 'balanced' should exclude all files matching the specified exclude patterns.</li>
                                            <li>No files should match any glob patterns in the LLM context mode 'balanced'.</li>
                                            <li>The coverage entry for the test file should not have any line ranges or line counts.</li>
                                            <li>The LLM context mode 'balanced' should only include files that do not match any exclude patterns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        197 output =
                                        528 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163-164, 201, 284-286)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler correctly handles cases where a balanced context file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context is empty', 'expected': {}, 'actual': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        85 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-161, 201)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_max_bytes_limit</span>
                            <div class="test-meta">
                                <span>14ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that balanced context respects max bytes limit.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential memory leak or unexpected behavior due to the large module size exceeding the allocated bytes limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The content of the source file is truncated to prevent excessive memory usage.</li>
                                            <li>A message indicating truncation ('truncated') is included in the context.</li>
                                            <li>The total length of the content does not exceed the specified limit (120 bytes).</li>
                                            <li>The 'large_module.py' file itself contains a message indicating truncation ('truncated').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        405 input +
                                        126 output =
                                        531 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler can correctly assemble a balanced context with no coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context is empty', 'expected': {}, 'actual': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        82 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 139-140)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_reaches_max_bytes_before_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that loop exits when max bytes is reached before processing file and the context is truncated.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler exceeds the maximum allowed bytes in the LLM context without encountering any errors, potentially leading to incorrect coverage metrics or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context should be either empty (truncated) or contain only one file (non-truncated).</li>
                                            <li>context should not exceed the specified max_bytes limit.</li>
                                            <li>context should not contain more than llm_context_file_limit files. If it does, the test should fail with an appropriate error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        409 input +
                                        139 output =
                                        548 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-157, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</p>
                                    <p><strong>Why Needed:</strong> Complete context delegates to balanced because it requires a full context for all node assertions, which can be complex and error-prone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'includes', 'expression': 'module.py', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        98 output =
                                        309 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_empty_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _get_test_source with empty nodeid returns empty string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly handles an empty nodeid and returns an empty string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The result of the test should be an empty string.', 'expected_result': '', 'type': 'assertion'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        87 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 33, 78-79, 82-83, 86-89)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</p>
                                    <p><strong>Why Needed:</strong> To ensure that source extraction stops at the next function definition, even if it's not immediately following a test function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected source extraction to stop at next function definition', 'description': 'The code should contain a `def` statement immediately after a test function.', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        117 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for the _get_test_source method</p>
                                    <p><strong>Why Needed:</strong> To ensure that the _get_test_source method handles cases where a test source file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The result of _get_test_source is an empty string when the input file does not exist.', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        87 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 33, 78-79, 82-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the _get_test_source function correctly extracts functions with proper indentation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'indentation': 4, 'expected_lines': ['def foo(): pass']}, 'actual': {'indentation': 1, 'expected_lines': []}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        106 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_ranges.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that consecutive lines are compressed correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': ['1-3'], 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        69 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_duplicates</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_duplicates</p>
                                    <p><strong>Why Needed:</strong> To handle duplicate ranges in the input data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        68 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_empty_list</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_empty_list</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation of `compress_ranges` does not handle an empty input list correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'the function should return an empty string for an empty list', 'expected_result': '', 'message': 'Expected the function to return an empty string, but got [insert actual result here]'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        109 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 29-30)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</p>
                                    <p><strong>Why Needed:</strong> To test the ability of the `compress_ranges` function to handle mixed ranges and singles.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5, 10-12, 15', 'actual': '1-3, 5, 10-12, 15'}</li>
                                            <li>{'expected': 'True', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        108 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> Non-consecutive lines should be comma-separated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': '1, 3, 5', 'actual_result': '1, 3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        80 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_single_line</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `compress_ranges` function does not attempt to compress a single line of numbers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '5', 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        78 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 29, 33, 35-37, 39, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_two_consecutive</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_two_consecutive</p>
                                    <p><strong>Why Needed:</strong> To test that two consecutive lines are compressed to a single range.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert compress_ranges([1, 2]) == '1-2'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        65 output =
                                        168 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_unsorted_input</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_unsorted_input</p>
                                    <p><strong>Why Needed:</strong> To ensure the function correctly handles unsorted input ranges.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5', 'actual': '1-3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        77 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_empty_string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `expand_ranges` function handles empty strings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert expand_ranges returns an empty list for an empty string', 'description': 'The output of the `expand_ranges` function should be an empty list when given an empty string as input.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        98 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 81-82)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_mixed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_mixed</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of `expand_ranges` only handles ranges and does not handle singles correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3, 5, 10, 11, 12], 'actual': ['1', '2', '3', '5', '10', '11', '12']}</li>
                                            <li>{'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        119 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_range</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_range</p>
                                    <p><strong>Why Needed:</strong> The range function should expand to a list of integers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3], 'actual': '1-3'}</li>
                                            <li>{'expected': ['1', '2', '3'], 'actual': '[1, 2, 3]'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        93 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 81, 84-91, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_roundtrip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_roundtrip</p>
                                    <p><strong>Why Needed:</strong> To ensure that `compress_ranges` and `expand_ranges` are inverses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'original and compressed should be equal', 'expected_value': [1, 2, 3, 5, 10, 11, 12, 15], 'actual_value': [1, 2, 3, 5, 10, 11, 12, 15]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        128 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67, 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_single_number</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_single_number</p>
                                    <p><strong>Why Needed:</strong> The function `expand_ranges` is expected to handle a single input, producing a single output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': [5], 'actual_value': ['5']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        75 output =
                                        170 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81, 84-87, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_render.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the format_duration function for milliseconds when input is less than 1 second.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the function does not correctly format durations in milliseconds when input is less than 1 second.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return '500ms' when input is 0.5 seconds.</li>
                                            <li>The function should return '1ms' when input is 0.001 seconds.</li>
                                            <li>The function should return '0ms' when input is 0.0 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        120 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestFormatDuration::test_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations in seconds for values greater than or equal to 1 second.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert format duration of 1.23s returns '1.23s'", 'expected': '1.23s', 'actual': 'format_duration(1.23)'}</li>
                                            <li>{'name': "assert format duration of 60.0s returns '60.00s'", 'expected': '60.00s', 'actual': 'format_duration(60.0)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        153 output =
                                        269 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all outcomes map to CSS classes.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in rendering CSS classes for different outcomes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>outcome-to-css-class mapping is correct for each outcome.</li>
                                            <li>outcome-to-css-class mapping preserves the original outcome value.</li>
                                            <li>outcome-to-css-class mapping handles skipped outcomes correctly.</li>
                                            <li>outcome-to-css-class mapping handles xfailed and xpassed outcomes correctly.</li>
                                            <li>outcome-to-css-class mapping handles error outcome correctly.</li>
                                            <li>outcome-to-css-class mapping preserves the correct CSS class for passed, failed, and skipped outcomes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        130 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</p>
                                    <p><strong>Why Needed:</strong> Unknown outcomes are not handled correctly and may cause unexpected styling.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'outcome-unknown', 'actual': 'outcome-unknown'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        73 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_basic_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders basic report with fallback HTML.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a rendering issue where the full HTML document is not rendered correctly due to plugin or repository version issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert '<!DOCTYPE html>' in html</li>
                                            <li>assert 'Test Report' in html</li>
                                            <li>assert 'test::passed' in html</li>
                                            <li>assert 'test::failed' in html</li>
                                            <li>assert 'PASSED' in html</li>
                                            <li>assert 'FAILED' in html</li>
                                            <li>assert 'Plugin:</strong> v0.1.0' in html</li>
                                            <li>assert 'Repo:</strong> v1.2.3' in html</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        153 output =
                                        579 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65-67, 79-85, 87, 121-124, 126-127, 131-132, 155-157, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders coverage for fallback HTML test.</p>
                                    <p><strong>Why Needed:</strong> Prevents rendering of non-coverage files and ensures accurate coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report includes the file "src/foo.py" which is part of the test.</li>
                                            <li>The assertion checks that there are exactly 5 lines in the rendered HTML.</li>
                                            <li>The assertion verifies that the file name 'src/foo.py' is present in the rendered HTML.</li>
                                            <li>The assertion ensures that the number of lines in the rendered HTML matches the coverage report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        121 output =
                                        409 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-129, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</p>
                                    <p><strong>Why Needed:</strong> This test prevents LLM annotation rendering from failing due to missing confidence scores.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Tests login flow</li>
                                            <li>Prevents auth bypass</li>
                                            <li>Confidence: 85%</li>
                                            <li>Expected HTML content includes the following strings: 'Tests login flow', 'Prevents auth bypass', and 'Confidence: 85%'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        110 output =
                                        427 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">64 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-134, 136-137, 140-142, 144, 147, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the source coverage summary is included in the rendered HTML.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the source coverage information is not displayed in the rendered HTML.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Source Coverage summary should be present in the rendered HTML.</li>
                                            <li>Source code file path should be included in the HTML.</li>
                                            <li>Percentage of covered statements should be displayed in the HTML.</li>
                                            <li>Percentage of missed statements should be displayed in the HTML.</li>
                                            <li>Covered ranges should be correctly formatted in the HTML.</li>
                                            <li>Missed ranges should be correctly formatted in the HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        134 output =
                                        465 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-178, 180-186, 191, 206, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_xpass_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the 'XFailed' and 'XPassed' summary entries are included in the rendered HTML.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the xfailed/xpassed summary is missing from the rendered HTML, potentially misleading users about the test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The string 'XFailed' should be present in the rendered HTML.</li>
                                            <li>The string 'XPassed' should be present in the rendered HTML.</li>
                                            <li>Both 'XFailed' and 'XPassed' summary entries should be included in the rendered HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        127 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">19 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_different_content</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_different_content</p>
                                    <p><strong>Why Needed:</strong> To ensure that different content produces different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Hashes should be different', 'expected': {'hash1': '...'}}</li>
                                            <li>{'name': 'Hashes should be different', 'expected': {'hash2': '...'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        100 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the compute_sha256 function produces consistent hashes for empty byte sequences.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected hash to be equal', 'expected_value': '', 'actual_value': ''}</li>
                                            <li>{'message': 'Expected length of hash to be 64', 'expected_value': 64, 'actual_value': 64}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        104 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_run_meta</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_build_run_meta verifies that the build run meta includes version info.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not include version information in the build run meta.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert meta.duration == 60.0: The duration of the build should be 60 seconds.</li>
                                            <li>assert meta.pytest_version: The pytest version should have a value.</li>
                                            <li>assert meta.plugin_version == __version__: The plugin version should match the current version.</li>
                                            <li>assert meta.python_version: The python version should have a value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        132 output =
                                        450 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `build_summary` method correctly counts all outcome types and their corresponding tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a test might be skipped or ignored due to an incorrect count of outcome types.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of outcomes should match the sum of passed, failed, skipped, xfailed, xpassed, error outcome types.</li>
                                            <li>Each outcome type (passed, failed, skipped, xfailed, xpassed, error) should be correctly counted in the summary.</li>
                                            <li>The `x` prefix for each outcome type indicates that it has an unknown number of tests.</li>
                                            <li>If a test is not included in any outcome type, its result should still be reported as 'error'.</li>
                                            <li>If all tests are skipped or ignored, the total count should remain 0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        336 input +
                                        182 output =
                                        518 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 156-158, 319, 321-322, 324-335, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_counts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `build_summary_counts` method counts outcomes correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the total count of passed, failed, and skipped tests is not accurate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of tests should be equal to 4 (tests1, tests2, tests3, and tests4).</li>
                                            <li>The number of passed tests should be 2 (tests1 and tests3).</li>
                                            <li>The number of failed tests should be 1 (test3).</li>
                                            <li>The number of skipped tests should be 1 (test4).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        137 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 319, 321-322, 324-329, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_create_writer</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a new ReportWriter instance initializes correctly with its configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the writer's configuration is not properly initialized.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `config` attribute of the `ReportWriter` instance should be set to the provided `Config` object.</li>
                                            <li>The `warnings` attribute of the `ReportWriter` instance should be an empty list.</li>
                                            <li>The `artifacts` attribute of the `ReportWriter` instance should be an empty list.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        199 input +
                                        118 output =
                                        317 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 156-158)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_assembles_tests</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test writes a report that includes all tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring the ReportWriter can write reports with at least two tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the report.tests list should be equal to 2.</li>
                                            <li>The value of report.summary.total should be equal to 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        81 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the ReportWriter class correctly includes the total coverage percentage in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'report.summary.coverage_total_percent == 85.5', 'description': 'The total coverage percentage of the report should be equal to 85.5%'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        105 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-199, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_source_coverage</span>
                            <div class="test-meta">
                                <span>9ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_includes_source_coverage verifies that the report includes source coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report does not include source coverage information, which is crucial for understanding the code's quality and maintainability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `report.source_coverage` should be 1.</li>
                                            <li>The file path of the first `source_coverage` entry in `report.source_coverage` should match `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        291 input +
                                        237 output =
                                        528 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_merges_coverage</span>
                            <div class="test-meta">
                                <span>9ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_merges_coverage verifies that the report writer merges coverage into tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report writer does not merge coverage from individual tests to the overall report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report should have at least one coverage entry for the first test.</li>
                                            <li>The file path of the first coverage entry should match the file path of the first test.</li>
                                            <li>Each coverage entry in the report should be a single object with 'file_path' and 'coverage' attributes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        125 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">99 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186-189, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the ReportWriterWithFiles class falls back to direct write if atomic write fails and writes warnings.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a regression where the atomic write operation fails, causing the report writer to fall back to direct write and potentially writing unnecessary or misleading warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file `report.json` should exist at the specified path.</li>
                                            <li>Any warning messages written by the ReportWriterWithFiles class should have code 'W203'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        110 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513-514, 516-519, 522-523)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case 'tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing'</p>
                                    <p><strong>Why Needed:</strong> The test writer should create an output directory if it does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Directory exists after writing report', 'expected': True, 'actual': 'exists'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        171 input +
                                        87 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">128 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_ensure_dir_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_ensure_dir_failure` test captures a warning when creating a non-existent directory.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report writer fails to capture warnings for directories that cannot be created.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer.warnings` list contains any warnings with code 'W201' (indicating permission denied error).</li>
                                            <li>The `writer.warnings` list does not contain any warnings with code 'W100' (indicating directory creation failure).</li>
                                            <li>The `writer.warnings` list is empty if the directory cannot be created.</li>
                                            <li>The `writer.warnings` list contains at least one warning with code 'W201'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        158 output =
                                        436 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 156-158, 477-480, 487-491)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_git_info_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'Should handle git command failures gracefully.'</p>
                                    <p><strong>Why Needed:</strong> To prevent a test failure when the `git` command fails and no Git repository information can be retrieved.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_git_info()` should return an empty string for SHA and dirty flags if the `git` command fails.</li>
                                            <li>The function `get_git_info()` should not raise an exception if the `git` command is successful but returns no Git repository information.</li>
                                            <li>The function `get_git_info()` should handle the case where the `git` command fails with a specific error message ('Git not found') and return None for SHA and dirty flags.</li>
                                            <li>The function `get_git_info()` should handle the case where the `git` command fails but returns an empty string for SHA and dirty flags (e.g., when running on a system without Git installed).</li>
                                            <li>The function `get_git_info()` should not raise an exception if the `git` command is successful but returns no Git repository information, indicating that it cannot retrieve any information.</li>
                                            <li>The function `get_git_info()` should be able to handle different types of errors raised by the `git` command (e.g., permission issues, invalid options).</li>
                                            <li>The test should be able to pass even if the `git` command fails and no Git repository information can be retrieved due to external system limitations.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        297 output =
                                        528 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_creates_file</span>
                            <div class="test-meta">
                                <span>46ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the report writer creates an HTML file with expected content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report writer fails to create an HTML file even when there are tests that fail or skip.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report.html file should exist.</li>
                                            <li>The report.html file should contain the expected content (test1, test2, PASSED, FAILED, Skipped, XFailed, XPassed, Errors).</li>
                                            <li>Test1 and Test2 should be present in the HTML content.</li>
                                            <li>PASSED and FAILED should be present in the HTML content.</li>
                                            <li>Skipped and XFailed/XPassed should be present in the HTML content.</li>
                                            <li>Errors should be present in the HTML content.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        366 input +
                                        164 output =
                                        530 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">120 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_includes_xfail_summary</span>
                            <div class="test-meta">
                                <span>45ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_write_html_includes_xfail_summary' verifies that the report writer includes xfail outcomes in the HTML summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression of the issue where xfail outcomes are not included in the HTML summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test should find the string 'XFAILED' and 'XFailed' in the HTML content.</li>
                                            <li>The test should find the string 'XPASSED' and 'XPassed' in the HTML content.</li>
                                            <li>The test should assert that both 'XFAILED' and 'XFailed' are present in the HTML content.</li>
                                            <li>The test should assert that both 'XPASSED' and 'XPassed' are present in the HTML content.</li>
                                            <li>The test should verify that the report writer correctly includes xfail outcomes in the HTML summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        181 output =
                                        489 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-333, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_json_creates_file</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `ReportWriter` creates a JSON file with the specified configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `ReportWriter` fails to create a JSON file even when the report has an artifact.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file should exist at the expected path.</li>
                                            <li>At least one artifact should be tracked in the JSON file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        89 output =
                                        354 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_creates_file</span>
                            <div class="test-meta">
                                <span>49ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `write_pdf` creates a PDF file when Playwright is available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not create a PDF file even if Playwright is available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.pdf` path should be created in the temporary directory.</li>
                                            <li>Any artifacts written to the `report.pdf` path should match its original path.</li>
                                            <li>The `report.pdf` path should exist after the test completes.</li>
                                            <li>The `report.pdf` path should not be empty or None.</li>
                                            <li>The `writer.artifacts` list should contain any artifact with a matching path.</li>
                                            <li>Any artifacts written to the temporary directory should have a matching path in the `report.pdf` path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        478 input +
                                        164 output =
                                        642 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-430, 441-442, 444-450, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_missing_playwright_warns</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a warning is raised when Playwright is missing for PDF output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report writer does not warn users about missing Playwright for PDF output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pdf_path` should exist after writing the report.</li>
                                            <li>At least one warning with code `W204_PDF_PLAYWRIGHT_MISSING` should be present in the `writer.warnings` list.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        311 input +
                                        105 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</p>
                                    <p><strong>Why Needed:</strong> To ensure that the report writer can handle cases where git info is not available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function should return None for a nonexistent path.', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        87 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_git_info` function returns a valid Git SHA or an error message when running in a non-Git repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None or isinstance(sha, str)', 'expected_result': {'type': 'NoneType', 'message': 'Expected `get_git_info` to return None or a string'}, 'actual_result': {'type': 'AssertionError'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        159 input +
                                        130 output =
                                        289 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 67-74, 76-81, 83-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests that a fallback occurs when `_git_info` import fails and the plugin's `get_plugin_git_info()` function returns an empty string or a string representation of a Git hash.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a fallback is not executed correctly when `_git_info` import fails, potentially causing unexpected behavior in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `sha` variable will be either None (if the fallback succeeds) or an empty string (if the fallback fails).</li>
                                            <li>The `dirty` variable will always be False because it is not modified during the test.</li>
                                            <li>The `get_plugin_git_info()` function will return a string representation of a Git hash if `_git_info` import fails and the plugin's `get_plugin_git_info()` function returns an empty string or a string representation of a Git hash.</li>
                                            <li>The `sha` variable will be None after calling `get_plugin_git_info()` because it is not modified during this test.</li>
                                            <li>The `dirty` variable will always be False because it is not modified during the test.</li>
                                            <li>The `get_plugin_git_info()` function will return an empty string or a string representation of a Git hash if `_git_info` import fails and the plugin's `get_plugin_git_info()` function returns None.</li>
                                            <li>The `sha` variable will be either None (if the fallback succeeds) or an empty string (if the fallback fails).</li>
                                            <li>The `dirty` variable will always be False because it is not modified during the test.</li>
                                            <li>The `get_plugin_git_info()` function will return a string representation of a Git hash if `_git_info` import fails and the plugin's `get_plugin_git_info()` function returns an empty string or a string representation of a Git hash.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        373 output =
                                        626 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_returns_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_plugin_git_info</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin's Git info returns some values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'returning a non-empty string for sha', 'description': 'The function should return either None or a non-empty string for the sha value.', 'expected_value': 'None'}</li>
                                            <li>{'name': 'returning a valid string for dirty', 'description': 'The function should return a valid string for the dirty value.', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        141 input +
                                        133 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterAtomicWrite::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test atomic write fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure the report writer can handle errors and still produce a valid report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The report file exists after writing', 'expected_result': 'True'}</li>
                                            <li>{'name': 'The report file is not empty after writing', 'expected_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        181 input +
                                        93 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_exception</span>
                            <div class="test-meta">
                                <span>122ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright raises exception (lines 424-432) and expected a warning about PDF failure</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where PDF generation fails due to playwright exception without raising a warning</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer.warnings` list should contain a warning with code 'W201'</li>
                                            <li>The `writer.warnings` list should contain a warning with code 'W202'</li>
                                            <li>The `writer.warnings` list should contain a warning with code 'W203'</li>
                                            <li>The `writer.warnings` list should contain a warning with code 'W204'</li>
                                            <li>The `writer.warnings` list should contain a warning with code 'W205'</li>
                                            <li>The `writer.warnings` list should contain a warning with code 'W206'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        356 input +
                                        175 output =
                                        531 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 156-158, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that when playwright is not installed, a warning is generated about missing playwright and the report does not get created.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the PDF generation fails due to playwright not being installed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test should have a warning indicating that playwright is not installed.</li>
                                            <li>Any of the warnings in the report should contain 'W204'.</li>
                                            <li>The report should not be created because playwright is missing.</li>
                                            <li>The file 'report.pdf' should not exist at the expected location.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        123 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 156-158, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_creates_temp</span>
                            <div class="test-meta">
                                <span>35ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source creates temp file when no HTML source is provided.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential issue where the report writer does not create a temporary PDF file if there are no HTML sources to resolve.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path created by the _resolve_pdf_html_source method exists and has the correct suffix (.html).</li>
                                            <li>The path is not empty.</li>
                                            <li>The suffix of the path is correctly set to .html.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        109 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 156-158, 455, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_missing_html_file</span>
                            <div class="test-meta">
                                <span>36ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source when configured HTML doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the test fails due to an incorrect assumption about the existence of a missing HTML file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path to the resolved PDF report is not None and exists.</li>
                                            <li>The path to the resolved PDF report is not in the same directory as the temporary file.</li>
                                            <li>The resolved PDF report has the correct filename.</li>
                                            <li>The resolved PDF report does not contain any HTML content.</li>
                                            <li>The resolved PDF report is a valid PDF file with the correct metadata.</li>
                                            <li>The resolved PDF report is not corrupted or damaged.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        145 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 455-457, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_uses_existing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source uses existing HTML file.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the report writer does not use an existing HTML file when resolving the PDF source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path to the existing HTML file is correctly set to `html_path`.</li>
                                            <li>The report writer correctly resolves the PDF source using `report`.</li>
                                            <li>The resolved path matches the expected value of `html_path`.</li>
                                            <li>The report is not created as a temporary file (`is_temp` is False).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        266 input +
                                        123 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 156-158, 455-458)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_schemas.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_from_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `AnnotationSchema.from_dict` correctly creates an annotation from a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing or malformed input data, ensuring the application can handle invalid inputs without crashing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert schema.scenario == 'Verify login'</li>
                                            <li>assert schema.why_needed == 'Catch auth bugs'</li>
                                            <li>assert schema.key_assertions == ['assert 200', 'assert token']</li>
                                            <li>assert schema.confidence == 0.95</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        119 output =
                                        395 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Should convert to dictionary with all fields.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression in schema validation when using to_dict method for complex schemas.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'scenario' in data</li>
                                            <li>assert 'why_needed' in data</li>
                                            <li>assert 'key_assertions' in data</li>
                                            <li>assert isinstance(data['scenario'], str)</li>
                                            <li>assert isinstance(data['why_needed'], str)</li>
                                            <li>assert all(isinstance(x, str) for x in data['key_assertions'])</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        112 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 90-92, 94-98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_smoke_pytester.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_report_created</span>
                            <div class="test-meta">
                                <span>95ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The HTML report is created and exists as expected.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the HTML report might not be generated correctly or exist even after running the tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file path for the report is correct and exists.</li>
                                            <li>The content of the report contains the expected string '<html'.</li>
                                            <li>The name 'test_simple' is present in the report content.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        99 output =
                                        363 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_summary_counts_all_statuses</span>
                            <div class="test-meta">
                                <span>135ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_html_summary_counts_all_statuses verifies that the HTML summary counts include all statuses.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the HTML summary does not include all statuses, potentially leading to incorrect reporting or misleading results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `assert_summary(labels: list[str], expected: int)` checks if each label in the `labels` list matches the corresponding count in the HTML report.</li>
                                            <li>It also checks for any missing summary labels and raises an assertion error with a descriptive message.</li>
                                            <li>For example, it will check if 'Total Tests' is present in the HTML report and its count matches the expected value of 6.</li>
                                            <li>Similarly, it will verify that each label (e.g., 'Passed', 'Failed', etc.) has a corresponding count in the HTML report.</li>
                                            <li>If any label is missing or does not match its expected count, it raises an assertion error with a message indicating which labels are missing and why.</li>
                                            <li>The test ensures that all statuses (including 'XFailed' and 'XPassed') are included in the summary counts.</li>
                                            <li>It also checks for any errors or exceptions raised during the execution of the `test_error` function.</li>
                                            <li>In case of an error, it raises an assertion error with a descriptive message indicating where the error occurred.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        621 input +
                                        280 output =
                                        901 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 78-79, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212-214, 216, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-335, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_json_report_created</span>
                            <div class="test-meta">
                                <span>70ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The JSON report is created successfully.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report generation fails due to missing or incorrect configuration files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report path exists and contains the expected data.</li>
                                            <li>The schema version of the report matches the expected value.</li>
                                            <li>The total number of tests passed is correct (2 in this case).</li>
                                            <li>At least one test failed, which is correctly reported as such.</li>
                                            <li>All test names are included in the summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        117 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_annotations_in_report</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM annotations are included in the report when a provider is enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevent regressions by ensuring LLM annotations are present in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_pass()` returns True.</li>
                                            <li>The 'why_needed' assertion checks if the annotation is present and prevents regressions.</li>
                                            <li>The 'key_assertions' list includes assertions related to the annotation presence.</li>
                                            <li>The 'choices' attribute of the mock completion function contains a message that matches the expected annotation content.</li>
                                            <li>The 'content' attribute of the chosen message in the mock completion function matches the expected annotation content.</li>
                                            <li>The 'message' attribute of the chosen message in the mock completion function is set to the expected annotation content.</li>
                                            <li>The 'choices' attribute of the mock completion function returns a list that includes an instance with the expected annotation content.</li>
                                            <li>The test passes if all assertions pass, preventing regressions.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        385 input +
                                        208 output =
                                        593 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 130-133, 135-137, 139, 141, 143, 190, 194-199, 201, 203, 205, 207, 210, 212-214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419-437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-506, 509, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_error_is_reported</span>
                            <div class="test-meta">
                                <span>98ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM errors are surfaced in HTML output.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression where LLM errors are not reported correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test case `test_llm_error_is_reported` verifies that the LLM error is reported in the HTML output.</li>
                                            <li>The `pytester.makepyfile` function creates a test function with an assertion.</li>
                                            <li>The `pytester.makeconftest` function patches the `litellm.completion` module to raise an error.</li>
                                            <li>The `pytester.makefile` function creates a pyproject.toml file with the `[tool.pytest_llm_report]` configuration.</li>
                                            <li>The test function `test_pass()` is called within the `makepyfile` function.</li>
                                            <li>The `pytester.makepyfile` function includes the `mock_completion` function in the test code.</li>
                                            <li>The `pytester.makeconftest` function sets the `litellm.completion` module to `mock_completion` before running the tests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        224 output =
                                        537 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-507, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>61ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the LLM opt-out marker.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in LLM opt-out functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the LLM opt-out marker is correctly recorded.</li>
                                            <li>The test asserts that the LLM opt-out marker is enabled for a single test.</li>
                                            <li>The test checks if the 'llm_opt_out' attribute of the first test in the report is set to True.</li>
                                            <li>The test verifies that the LLM opt-out marker is not present in the tests list.</li>
                                            <li>The test asserts that the number of tests in the report is 1.</li>
                                            <li>The test checks if the 'llm_opt_out' attribute of each test is set to False.</li>
                                            <li>The test verifies that the 'llm_opt_out' attribute of the first test matches the expected value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        184 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181-182, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>58ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the requirement marker functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the requirement marker is not recorded for tests with multiple requirements.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest.mark.requirement` decorator should be applied to each test function that requires specific requirements.</li>
                                            <li>The `pytester.makepyfile()` method should create a file with the required pytest configuration.</li>
                                            <li>The `report_path` variable should be created and populated with the correct report path.</li>
                                            <li>The JSON data from the report path should contain a single test with the specified requirements.</li>
                                            <li>The 'requirements' key in the test's metadata should contain the expected requirements.</li>
                                            <li>The 'REQ-001' and 'REQ-002' strings should be present in the list of required requirements for each test.</li>
                                            <li>The `json.loads()` method should correctly parse the JSON data from the report path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        193 output =
                                        500 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-200, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_multiple_xfail_outcomes</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that multiple xfailed tests are recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression of a scenario where multiple xfailed tests are not recorded in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Multiple xfailed tests are recorded in the report.</li>
                                            <li>Each xfailed test is counted only once.</li>
                                            <li>The count of xfailed tests matches the number of tests with xfailed outcomes.</li>
                                            <li>No xfailed tests are missed due to missing test outcomes.</li>
                                            <li>The test verifies that each xfailed test contributes to the total count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        127 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_skip_outcome</span>
                            <div class="test-meta">
                                <span>59ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that skipped tests are recorded and their count is accurate.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the number of skipped tests might not be correctly reported in the LLM report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key under 'skipped' should contain an integer value equal to 1.</li>
                                            <li>The 'summary' key under 'skipped' should not contain any other values or strings.</li>
                                            <li>The number of skipped tests should be exactly 1 as per the pytester's configuration.</li>
                                            <li>The test skip reason is correctly set to 'test skip'.</li>
                                            <li>The test file name and path are correctly recorded in the report.json file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        152 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_xfail_outcome</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that xfailed tests are recorded and counted correctly in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where xfailed tests are not properly reported in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key in the JSON report should contain the correct number of xfailed tests (1).</li>
                                            <li>The value of the 'xfailed' key under the 'summary' section should be equal to 1.</li>
                                            <li>If no xfailed tests are recorded, the 'summary' section should not have a 'xfailed' key or its value should be 0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        134 output =
                                        398 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestParametrization::test_parametrized_tests</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test parameterized tests are recorded separately.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in parametrized tests where the same input can produce different outputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'test_param' function is called with the correct argument 'x'.</li>
                                            <li>The assert statement inside the function checks if x is greater than 0.</li>
                                            <li>The total number of test cases is 3 as expected.</li>
                                            <li>The number of passed tests is also 3 as expected.</li>
                                            <li>The report.json file contains a summary with total and passed counts.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        127 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203-205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the CLI help text includes usage examples for the plugin registration feature.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result.stdout.fnmatch_lines', 'expected_result': ['*Example:*--llm-report*'], 'actual_result': [1, 2, 3]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        105 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_markers_registered</span>
                            <div class="test-meta">
                                <span>47ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginRegistration test</p>
                                    <p><strong>Why Needed:</strong> To ensure that LLM markers are registered correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "Markers should be registered with pytester.runpytest('--markers')", 'expected_result': 'Markers should be registered'}</li>
                                            <li>{'description': 'Markers should match the expected lines in stdout.fnmatch_lines', 'expected_result': ['*llm_opt_out*', '*llm_context*', '*requirement*']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        114 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</span>
                            <div class="test-meta">
                                <span>53ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</p>
                                    <p><strong>Why Needed:</strong> To verify that the plugin is registered correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'plugin registration', 'expected_result': 'The plugin was successfully registered.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        72 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestSpecialCharacters::test_special_chars_in_nodeid</span>
                            <div class="test-meta">
                                <span>99ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that special characters in nodeid are handled correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where special characters in the nodeid field cause the Pytest reporter to crash or produce invalid HTML reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The string '<html' should be present in the report HTML.</li>
                                            <li>The report path should exist and contain an 'html' substring.</li>
                                            <li>The content of the report path should contain the string 'html'.</li>
                                            <li>The nodeid field should not cause the Pytest reporter to crash or produce invalid reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        127 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_time.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_boundary_one_minute</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_boundary_one_minute</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function can correctly format a duration of exactly one minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'value': '1m 0.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        80 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_microseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_microseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-millisecond durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The result should contain 'Œºs' to indicate microsecond format.", 'expected_value': 'Œºs'}</li>
                                            <li>{'description': 'The result should be equal to the expected value.', 'expected_result': '500Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        116 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_milliseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_milliseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-second durations as milliseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "result == '500.0ms'", 'expected_result': '500.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        83 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_minutes_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_minutes_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations over a minute, including minutes and seconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "result contains 'm'", 'expected': '1m 30.5s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        83 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_multiple_minutes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_multiple_minutes</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats multiple minutes into a human-readable string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '3m 5.0s', 'actual': '3m 5.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        84 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_one_second</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_one_second</p>
                                    <p><strong>Why Needed:</strong> The function `format_duration` should return a string representation of exactly one second in the format 'X.Xss'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '1.00s', 'actual_value': '1.0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        85 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_seconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_seconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the seconds function correctly formats numbers under a minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert 's' in result", 'expected_result': "'s'", 'actual_result': '5.50s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        84 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_small_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_small_milliseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats small millisecond durations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '1.0ms', 'actual_value': '1.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        78 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_very_small_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_very_small_microseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly handles very small durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': '1Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        77 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_datetime_with_utc</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ISO Format with UTC</p>
                                    <p><strong>Why Needed:</strong> To test the correct formatting of datetime objects with UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The formatted string should be in the format 'YYYY-MM-DDTHH:MM:SS+HH:MM:SS'", 'expected_value': '2024-01-15T10:30:45+00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        98 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</p>
                                    <p><strong>Why Needed:</strong> To ensure that the naive datetime (no timezone) is correctly formatted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '2024-06-20T14:00:00', 'actual': '2024-06-20T14:00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        92 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_with_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests time module</p>
                                    <p><strong>Why Needed:</strong> To test the format of datetime objects with microseconds</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Result contains 12 digits', 'expected': '12345678901234567890', 'actual': '123456'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        73 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_has_utc_timezone</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_has_utc_timezone</p>
                                    <p><strong>Why Needed:</strong> To ensure the datetime object has a valid UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result.tzinfo is not None', 'expected': 'True'}</li>
                                            <li>{'name': 'result.tzinfo == UTC', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        95 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_is_current_time</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests that the `is_current_time` function returns a valid JSON response when called with an empty input.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `utc_now()` function does not return a valid datetime object if no UTC time has been set. This can cause issues in tests that rely on this function returning a specific value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'type': 'assertion', 'value': 'datetime.datetime(2023, 1, 1, 0, 0, tzinfo=TimezoneInfo.get_default())'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        139 output =
                                        255 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_returns_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_returns_datetime</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `utc_now()` function returns a datetime object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Type of result', 'expected': 'datetime', 'actual': 'isinstance(result, datetime)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        81 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_command_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When TokenRefresher raises an error on command failure, it should return a TokenRefreshError with the correct message.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where TokenRefresher does not handle command failures correctly and may silently fail or produce incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` in `TokenRefresher` raises a `TokenRefreshError` with the correct message 'Authentication failed'.</li>
                                            <li>The error message returned by `get_token()` includes the string 'exit 1', which is expected for command failure.</li>
                                            <li>The test asserts that the error message contains the string 'Authentication failed' to verify its correctness.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        310 input +
                                        150 output =
                                        460 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_empty_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher raises an error when given an empty output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not raise an error for an empty output, potentially masking a regression.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'empty output' in str(exc_info.value).lower()</li>
                                            <li>assert exc_info.value.value == 'empty output'</li>
                                            <li>assert isinstance(exc_info.value.value, str)</li>
                                            <li>assert len(exc_info.value.value) == 0</li>
                                            <li># Check if the string is empty</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        127 output =
                                        424 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-109, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'force_refresh' bypasses cache and returns a new token when called with the same command.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the TokenRefresher does not return a new token when force_refresh is called with the same command.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` instance returns a new token after force refresh.</li>
                                            <li>The output of the `get_token()` method contains the expected token value.</li>
                                            <li>The number of calls to the `get_token()` method increases by one after force refresh.</li>
                                            <li>The `call_count` variable is updated correctly with each call to `get_token()`.</li>
                                            <li>The `token1` and `token2` variables are assigned the correct values based on the output of `get_token()`.</li>
                                            <li>The `force=True` parameter does not affect the return value of `get_token()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        199 output =
                                        545 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_custom_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `TokenRefresher` class with a custom JSON key.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `TokenRefresher` class does not properly handle custom JSON keys in the `get_token()` method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token` variable should be equal to 'custom-key-token'.</li>
                                            <li>The `json_key` parameter passed to `TokenRefresher.get_token()` should match the expected value.</li>
                                            <li>The `subprocess.run()` function returns a CompletedProcess object with the correct JSON output.</li>
                                            <li>The `stdout` attribute of the `CompletedProcess` object is set to 'custom-key-token'.</li>
                                            <li>The `stderr` attribute of the `CompletedProcess` object is empty.</li>
                                            <li>The `json.dumps()` function correctly converts the expected JSON string to a Python dictionary.</li>
                                            <li>The `returncode` attribute of the `CompletedProcess` object is 0 (indicating successful execution).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        303 input +
                                        209 output =
                                        512 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `TokenRefresher` extracts a JSON token from the expected output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `get-token` command returns an incorrect or malformed JSON response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token` key in the JSON output is set to 'json-token-value'.</li>
                                            <li>The `expires_in` value in the JSON output is set to 3600 (1 hour).</li>
                                            <li>The `output_format` parameter is set to 'json'.</li>
                                            <li>The `json_key` parameter is set to 'token'.</li>
                                            <li>The extracted token matches the expected string 'json-token-value'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        149 output =
                                        457 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_text_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `TokenRefresher` extracts the correct token from the provided text output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the token is not extracted correctly due to an incorrect or incomplete text output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>token == 'my-secret-token'</li>
                                            <li>stdout contains 'INFO: Processing...' and 'my-secret-token'</li>
                                            <li>stderr does not contain any relevant information</li>
                                            <li>the `get_token()` method returns the expected token value</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        114 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when receiving invalid JSON from the command.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher class does not handle invalid input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method of the `TokenRefresher` instance should raise a `TokenRefreshError` exception when receiving an invalid JSON string.</li>
                                            <li>The error message returned by the `get_token` method should contain the word 'json' in lowercase.</li>
                                            <li>A non-empty string containing only whitespace characters or special characters (except for quotes) should be considered as an invalid JSON input.</li>
                                            <li>The `subprocess.CompletedProcess` result should include a returncode of 1, indicating that the command failed with a non-zero exit status.</li>
                                            <li>The `stdout` and `stderr` attributes of the `subprocess.CompletedProcess` result should contain strings containing 'not valid json' and '', respectively.</li>
                                            <li>The `TokenRefreshError` exception raised by the `get_token` method should be an instance of the `Exception` class.</li>
                                            <li>The error message returned by the `get_token` method should not be empty (i.e., it should contain at least one non-whitespace character).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        272 output =
                                        571 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-134, 149-150)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalidate</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher.invalidate() clears cache and verifies it is invalidated after refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not invalidate its cache after a successful refresh, leading to stale token values being returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `invalidate()` of the `TokenRefresher` class clears the cache.</li>
                                            <li>A new token is generated and stored in the cache after calling `invalidate()`.</li>
                                            <li>The number of tokens in the cache increases by one after calling `invalidate()`.</li>
                                            <li>The cached token values are different from the actual token values obtained using `get_token()`.</li>
                                            <li>The function `invalidate()` does not return an error or exception when called with invalid arguments (e.g., no command, refresh interval, or output format).</li>
                                            <li>The function `invalidate()` clears the cache after a successful refresh, even if there are still tokens in the cache.</li>
                                            <li>The cached token values are different from the actual token values obtained using `get_token()` even after calling `invalidate()` multiple times.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        230 output =
                                        570 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_missing_json_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when the JSON key is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the TokenRefresher does not raise an error when the required JSON key is missing, allowing the test to fail with a meaningful error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'token' key should be present in the output of the get_token() method.</li>
                                            <li>The 'not found' string should be present in the error message.</li>
                                            <li>The error message should include the required JSON key ('token').</li>
                                            <li>The error message should not contain any other keys or values that are relevant to the test case.</li>
                                            <li>The 'token' key should be present in the output of the get_token() method even if it is missing from the input data.</li>
                                            <li>The 'not found' string should be present in the output of the get_token() method even if the required JSON key ('token') is not present in the input data.</li>
                                            <li>The error message should include a clear indication that the 'token' key was not found, without including any other relevant information.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        244 output =
                                        569 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139-141, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_thread_safety</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher thread safety by verifying that all threads receive the same token after concurrent execution.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where multiple threads may acquire the lock and access different tokens, leading to inconsistent results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>All threads should acquire the lock before accessing the token.</li>
                                            <li>The first thread to acquire the lock should receive the same token as all other threads.</li>
                                            <li>If any thread acquires the lock after the initial call to get_token(), it should not affect the result of get_token() for subsequent calls.</li>
                                            <li>The output of get_token() should be consistent across all threads, with no variation in the token string.</li>
                                            <li>Subsequent calls to get_token() should return the same token as the first call made by any thread.</li>
                                            <li>If a thread acquires the lock before calling get_token(), it should not affect the results of subsequent calls to get_token().</li>
                                            <li>The output of subprocess.CompletedProcess() should be consistent across all threads, with no variation in the command string or return code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        427 input +
                                        229 output =
                                        656 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_timeout_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher handles command timeout correctly by raising a TokenRefreshError when the 'get-token' command takes longer than 30 seconds to complete.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not handle command timeouts properly, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'get_token()' method of the TokenRefresher instance raises a TokenRefreshError with the message 'timed out' when the 'get-token' command takes longer than 30 seconds to complete.</li>
                                            <li>The 'get_token()' method does not raise a TokenRefreshError when the 'get-token' command completes within the specified timeout period (30 seconds in this case).</li>
                                            <li>The 'get_token()' method correctly raises a TokenRefreshError with the message 'timed out' when the 'get-token' command takes longer than 30 seconds to complete.</li>
                                            <li>The 'refresh_interval' attribute of the TokenRefresher instance is set to 3600 seconds (1 hour), which allows the 'get-token' command to timeout within this interval.</li>
                                            <li>The 'output_format' attribute of the TokenRefresher instance is set to 'text', which does not affect the timeout handling behavior of the 'get-token' command.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        275 output =
                                        554 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_token_caching</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Token Refreshing with Caching to verify that the function does not call the command again after caching.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `TokenRefresher` calls the `get-token` command multiple times if it is cached, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get-token` command should be the same for both `token1` and `token2` after caching.</li>
                                            <li>The `call_count` variable should only increment once when the function is called with a cached token.</li>
                                            <li>Both `token1` and `token2` should have the same value after caching, indicating that they are the same token.</li>
                                            <li>The output of the `get-token` command for both calls should be identical to prevent multiple calls to the command.</li>
                                            <li>If the function is called again with a different cached token, it should not call the command again and return an empty string or a specific error message.</li>
                                            <li>The `subprocess.CompletedProcess` object returned by the fake run function should have an `stdout` field that contains the expected output for both calls to the `get-token` command.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        353 input +
                                        254 output =
                                        607 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_command_failure_no_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a command failure results in an exception being raised and the expected error message is printed to stderr.</p>
                                    <p><strong>Why Needed:</strong> To ensure that TokenRefresher correctly handles command failures with no stderr output, preventing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` when executed with a non-zero return code.</li>
                                            <li>The error message 'exit 1' should be printed to stderr.</li>
                                            <li>The string 'No error output' should be present in the error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        123 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_empty_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TokenRefresherEdgeCases</p>
                                    <p><strong>Why Needed:</strong> Test handling of empty command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Expected a TokenRefreshError to be raised with the message 'empty' when the command string is empty.", 'type': 'assertion_error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        75 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_invalid_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_invalid_command_string function to verify it handles an invalid command string (shlex parse error).</p>
                                    <p><strong>Why Needed:</strong> Prevent a TokenRefreshError due to shlex parse errors when handling invalid shell syntax in the command.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `TokenRefresher` instance is not created with an invalid command string.</li>
                                            <li>The `refresh_interval` parameter is set to 3600 seconds.</li>
                                            <li>The `output_format` parameter is set to 'text'.</li>
                                            <li>An exception of type `TokenRefreshError` is raised when calling `get_token()` on the `refresher` instance.</li>
                                            <li>The error message contains the string 'Invalid command string'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        251 input +
                                        156 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-88, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_not_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that TokenRefresher raises a TokenRefreshError when the output is not a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the function does not raise an error for non-dict JSON outputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'output' argument of the get_token method should be a dict.</li>
                                            <li>The 'expected' key in the output should contain 'list'.</li>
                                            <li>The 'token' key in the expected dictionary should also be present and equal to 'array'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        328 input +
                                        117 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-137, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when token value is an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents potential TokenRefreshError due to invalid input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `json.dumps({</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        324 input +
                                        120 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_not_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifying that the `get_token` method raises a `TokenRefreshError` when the token value is not a string.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `get_token` method incorrectly handles non-string token values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `json.dumps()` function is called with an integer argument instead of a string.</li>
                                            <li>The `stdout` attribute contains an empty string.</li>
                                            <li>The `stderr` attribute is empty.</li>
                                            <li>An exception is raised with the message 'empty or not a string'.</li>
                                            <li>The `TokenRefreshError` is correctly raised.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        326 input +
                                        136 output =
                                        462 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_oserror_on_execution</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TokenRefresher's handling of OSError when executing a command.</p>
                                    <p><strong>Why Needed:</strong> Prevent regressions where the TokenRefresher fails to handle OSError during execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method raises a `TokenRefreshError` with the message 'Failed to execute'.</li>
                                            <li>The `refresh_interval` parameter has no effect on the behavior of the `get_token()` method when an OSError occurs.</li>
                                            <li>The `output_format` parameter does not affect the handling of OSError during execution.</li>
                                            <li>The `fake_run()` function raises an `OSError` with a message 'Command not found'.</li>
                                            <li>The `TokenRefresher` instance is created with a command that returns an error.</li>
                                            <li>The `get_token()` method attempts to execute the command and raise an exception if it fails.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        184 output =
                                        464 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113, 115-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_text_only_whitespace_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a TokenRefresher fails when the output has only blank lines after initial strip, but still contains non-whitespace wrapper lines.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where a TokenRefresher incorrectly handles text output with only whitespace lines after an initial strip, potentially leading to incorrect token refresh results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output should be empty after stripping blank lines.</li>
                                            <li>The output should contain non-whitespace wrapper lines but no whitespace content lines.</li>
                                            <li>The error message should indicate that there are no non-empty lines in the output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        376 input +
                                        128 output =
                                        504 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 132, 153-155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_whitespace_only_command</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_whitespace_only_command to ensure it raises a TokenRefreshError when given an empty whitespace-only command string.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression by ensuring the test covers the case where the input command is empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` with the message 'empty' when passed an empty whitespace-only command string.</li>
                                            <li>The error message should contain the word 'empty'.</li>
                                            <li>The test should fail when running on a system where the input command is empty.</li>
                                            <li>The test should not pass when running on a system where the input command contains non-whitespace characters.</li>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` with a specific error message even if the input command is empty.</li>
                                            <li>The error message should contain the word 'empty'.</li>
                                            <li>The test should fail when running on a system where the input command does not contain any whitespace characters.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        211 output =
                                        447 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_usage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_usage.py::test_token_usage_aggregation</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test token usage aggregation for multiple test cases</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token usage reporting when aggregating results from multiple tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total input tokens should be 30 and the total output tokens should be 15.</li>
                                            <li>The number of annotations should be 2.</li>
                                            <li>The total tokens should be 45.</li>
                                            <li>The annotation count should match the number of test cases.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        775 input +
                                        101 output =
                                        876 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-487, 491-494, 497, 499, 502-506, 509, 512-514, 516-521, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
        </div>
        </section>
    </div>
</body>
</html>