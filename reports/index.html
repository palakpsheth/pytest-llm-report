<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Report &bull; 623 tests</title>
    <!-- Optional: Inter font from rsms.me CDN. Falls back to system fonts if unavailable. -->
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <style>
/* Modern Color Palette */
:root {
    --bg-color: #f8fafc;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --border-color: #e2e8f0;
    --card-bg: #ffffff;
    --surface-muted: #f1f5f9;
    --primary-color: #3b82f6;
    color-scheme: light dark;

    /* Status Colors */
    --passed-bg: #dcfce7;
    --passed-text: #166534;
    --failed-bg: #fee2e2;
    --failed-text: #991b1b;
    --skipped-bg: #fef9c3;
    --skipped-text: #854d0e;
    --xfailed-bg: #ffedd5;
    --xfailed-text: #9a3412;
    --xpassed-bg: #f3e8ff;
    --xpassed-text: #6b21a8;
    --error-bg: #fee2e2;
    --error-text: #991b1b;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background-color: var(--bg-color);
    color: var(--text-primary);
    line-height: 1.5;
    margin: 0;
    padding: 0;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
}

/* Header */
header {
    margin-bottom: 2rem;
    border-bottom: 1px solid var(--border-color);
    padding-bottom: 1rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

h1 {
    font-size: 1.875rem;
    font-weight: 700;
    color: var(--text-primary);
    margin: 0;
}

.meta {
    font-size: 0.875rem;
    color: var(--text-secondary);
}

/* Summary Grid */
.summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 1rem;
    margin-bottom: 2rem;
}

.summary-card {
    background: var(--card-bg);
    border-radius: 0.5rem;
    padding: 1.5rem;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
    text-align: center;
    border: 1px solid var(--border-color);
    transition: transform 0.2s;
}

.summary-card:hover {
    transform: translateY(-2px);
}

.summary-card .count {
    font-size: 2.25rem;
    font-weight: 700;
    line-height: 1;
    margin-bottom: 0.5rem;
}

.summary-card .label {
    text-transform: uppercase;
    font-size: 0.75rem;
    font-weight: 600;
    letter-spacing: 0.05em;
    color: var(--text-secondary);
}

/* Status Colors for Summary */
.summary-card.passed .count {
    color: var(--passed-text);
}

.summary-card.failed .count {
    color: var(--failed-text);
}

.summary-card.skipped .count {
    color: var(--skipped-text);
}

.summary-card.xfailed .count {
    color: var(--xfailed-text);
}

.summary-card.xpassed .count {
    color: var(--xpassed-text);
}

.summary-card.coverage .count {
    color: var(--primary-color);
}

/* Filters */
.filters {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid var(--border-color);
    margin-bottom: 1.5rem;
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.filter-input {
    flex: 1;
    padding: 0.5rem 1rem;
    border: 1px solid var(--border-color);
    border-radius: 0.375rem;
    font-size: 0.875rem;
    background: var(--card-bg);
    color: var(--text-primary);
}

.filter-input::placeholder {
    color: var(--text-secondary);
}

.filter-statuses {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
}

.filter-chip {
    display: inline-flex;
    align-items: center;
    gap: 0.35rem;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    border: 1px solid var(--border-color);
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.04em;
}

.filter-chip input {
    margin: 0;
}

.filter-chip.passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.filter-chip.failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.filter-chip.skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.filter-chip.xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.filter-chip.xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.filter-chip.error {
    background: var(--error-bg);
    color: var(--error-text);
}

/* Test List */
.test-list {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.test-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
    overflow: hidden;
}

.test-header {
    padding: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    cursor: pointer;
    background: var(--card-bg);
}

.test-header:hover {
    background: var(--surface-muted);
}

.status-badge {
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
}

.status-passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.status-failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.status-skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.status-xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.status-xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.status-error {
    background: var(--error-bg);
    color: var(--error-text);
}

.test-name {
    flex: 1;
    font-family: monospace;
    font-size: 0.9rem;
    color: var(--text-primary);
    word-break: break-all;
}

.test-meta {
    display: flex;
    gap: 1rem;
    align-items: center;
    color: var(--text-secondary);
    font-size: 0.875rem;
}

/* Details Section */
.test-details {
    padding: 0 1rem 1rem 1rem;
    border-top: 1px solid var(--border-color);
    background: var(--surface-muted);
}

.detail-section {
    margin-top: 1rem;
}

.detail-title {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    color: var(--text-secondary);
    margin-bottom: 0.5rem;
}

.coverage-item {
    font-family: monospace;
    font-size: 0.85rem;
    padding: 0.25rem 0;
    border-bottom: 1px solid var(--border-color);
    display: grid;
    grid-template-columns: minmax(200px, 2fr) minmax(120px, 1fr);
    gap: 1rem;
}

.coverage-list {
    background: var(--card-bg);
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
    overflow: hidden;
}

.source-coverage {
    margin-top: 2rem;
}

.source-coverage h2 {
    margin: 0 0 1rem;
    font-size: 1.5rem;
}

.source-coverage-table {
    display: grid;
    gap: 0.35rem;
}

.source-coverage-header,
.source-coverage-row {
    display: grid;
    grid-template-columns: minmax(200px, 2fr) repeat(4, minmax(60px, 0.5fr)) minmax(
            140px,
            1fr
        ) minmax(140px, 1fr);
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
}

.source-coverage-header {
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.04em;
    color: var(--text-secondary);
}

.source-coverage-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    font-size: 0.85rem;
}

.source-path {
    font-family: monospace;
    word-break: break-word;
}

.source-lines {
    font-family: monospace;
    color: var(--text-secondary);
    word-break: break-word;
}

.llm-annotation {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
}

.llm-annotation p {
    margin: 0 0 0.5rem 0;
}

.llm-annotation p:last-child {
    margin-bottom: 0;
}

.llm-annotation ul {
    margin: 0.5rem 0 0;
    padding-left: 1.25rem;
}

.llm-annotation li {
    margin-bottom: 0.25rem;
}

.error-message {
    font-family: monospace;
    color: var(--failed-text);
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--failed-bg);
    white-space: pre-wrap;
    overflow-x: auto;
}

/* HTML5 Progress Bar for Coverage */
progress {
    width: 60px;
}

/* Utility: Hidden state for filtering */
.hidden {
    display: none !important;
}

/* Dark Mode Support */
@media (prefers-color-scheme: dark) {
    :root {
        --bg-color: #0f172a;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
        --border-color: #334155;
        --card-bg: #1e293b;
        --surface-muted: #0b1220;
        --primary-color: #60a5fa;

        /* Status Colors - Adjusted for dark mode */
        --passed-bg: #14532d;
        --passed-text: #86efac;
        --failed-bg: #7f1d1d;
        --failed-text: #fca5a5;
        --skipped-bg: #713f12;
        --skipped-text: #fde047;
        --xfailed-bg: #7c2d12;
        --xfailed-text: #fdba74;
        --error-bg: #7f1d1d;
        --error-text: #fca5a5;
    }

    /* Adjust box shadows for dark mode */
    .summary-card {
        box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.3), 0 1px 2px -1px rgb(0 0 0 / 0.3);
    }
}

@media print {
    body {
        background: #ffffff;
        color: #0f172a;
    }

    .container {
        max-width: none;
        padding: 1rem 1.5rem;
    }

    header {
        border-bottom: 2px solid var(--border-color);
    }

    .filters {
        display: none;
    }

    .summary-card,
    .test-row {
        box-shadow: none;
    }

    .test-header {
        background: #ffffff;
    }

    .test-row {
        page-break-inside: avoid;
        break-inside: avoid;
    }

    .test-details {
        background: #ffffff;
    }

    .llm-annotation {
        background: var(--surface-muted);
    }

    progress {
        width: 80px;
    }
}

body.pdf-mode .filters {
    display: none;
}

body.pdf-mode .test-row {
    page-break-inside: avoid;
    break-inside: avoid;
}

/* TOC Styling */
.toc {
    margin-bottom: 2rem;
    padding: 1rem;
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
}
.toc ul {
    list-style: none;
    padding: 0;
    margin: 0;
    display: flex;
    gap: 1.5rem;
    flex-wrap: wrap;
}
.toc a {
    color: var(--primary-color);
    text-decoration: none;
    font-weight: 600;
    cursor: pointer;
}
.toc a:hover {
    text-decoration: underline;
}

/* File Group Styling */
.test-file-group {
    margin-bottom: 2rem;
}
.test-file-header {
    font-size: 1.1rem;
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid var(--border-color);
    display: flex;
    justify-content: space-between;
    align-items: center;
}    </style>
    <script>
// pytest-llm-report interactive features

// Global state for filters
const activeStatuses = new Set(['passed', 'failed', 'skipped', 'xfailed', 'xpassed', 'error']);

// Filter tests based on search input and outcome filters
function filterTests() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    document.querySelectorAll('.test-row').forEach(row => {
        const nodeid = row.querySelector('.test-name').textContent.toLowerCase();
        const statusMatch = row.dataset.status ? activeStatuses.has(row.dataset.status) : false;
        const matchesSearch = nodeid.includes(query);
        row.classList.toggle('hidden', !matchesSearch || !statusMatch);
    });
}

// Show only failures and scroll to list
function showFailuresOnly() {
    document.querySelectorAll('.filter-chip input').forEach(cb => {
        const s = cb.dataset.status;
        if (s === 'failed' || s === 'error') {
            cb.checked = true;
            activeStatuses.add(s);
        } else {
            cb.checked = false;
            activeStatuses.delete(s);
        }
    });
    filterTests();
    const testList = document.getElementById('test-list');
    if (testList) {
        testList.scrollIntoView({ behavior: 'smooth' });
    }
}

// Toggle visibility of status filters
function toggleStatus(checkbox) {
    const status = checkbox.dataset.status;
    if (checkbox.checked) {
        activeStatuses.add(status);
    } else {
        activeStatuses.delete(status);
    }
    filterTests();
}

// Initialize interactive features after DOM is ready
document.addEventListener('DOMContentLoaded', function () {
    'use strict';

    // Toggle dark mode on preference
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.documentElement.dataset.theme = 'dark';
    }

    // Default: expand all details
    document.querySelectorAll('details').forEach(details => {
        details.setAttribute('open', '');
    });

    const params = new URLSearchParams(window.location.search);
    if (params.get('pdf') === '1') {
        document.body.classList.add('pdf-mode');
    }
});    </script>
</head>
<body>
    <div class="container">
        <header>
            <div>
                <h1>Test Report</h1>
                <div class="meta">
                    Run ID: 21201087766-py3.12 &bull;
                    Generated: 2026-01-21 07:36:48 &bull;
                    Duration: 119.30s<br>
                    <strong>Plugin:</strong> v0.2.1
                        (a03dbe622cdc018f89b74731aed91adf1a582867)
[dirty]<br>
                    <strong>Repo:</strong> v0.2.0
                        (b1f3c49618f01bb762e8fa4ff37082e2ac4ba601)
<br>
                    <strong>LLM:</strong> ollama / llama3.2:1b
                        (minimal context,
                         621 annotated, 1 errors)
                        <br><strong>Token Usage:</strong>
                        135999 input,
                        73657 output
                        (Total: 209656)
                </div>
            </div>
            <div style="text-align: right">
                <div style="font-size: 2rem; font-weight: 700; color: var(--primary-color)">
                    93.04%
                </div>
                <div class="meta">Total Coverage</div>
            </div>
        </header>

        <!-- Summary Cards -->
        <div class="summary">
            <div class="summary-card">
                <div class="count">623</div>
                <div class="label">Total Tests</div>
            </div>
            <div class="summary-card passed">
                <div class="count">623</div>
                <div class="label">Passed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Failed</div>
            </div>
            <div class="summary-card skipped">
                <div class="count">0</div>
                <div class="label">Skipped</div>
            </div>
            <div class="summary-card xfailed">
                <div class="count">0</div>
                <div class="label">XFailed</div>
            </div>
            <div class="summary-card xpassed">
                <div class="count">0</div>
                <div class="label">XPassed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Errors</div>
            </div>
        </div>

        <!-- Table of Contents -->
        <nav class="toc">
            <ul>
                <li><a href="#source-coverage">Source Coverage</a></li>
                <li><a href="#test-list">Per Test Details</a></li>
                <li><a onclick="showFailuresOnly()">Failures Only</a></li>
            </ul>
        </nav>

        <section class="source-coverage" id="source-coverage">
            <h2>Source Coverage</h2>
            <div class="source-coverage-table">
                <div class="source-coverage-header">
                    <span>File</span>
                    <span>Stmts</span>
                    <span>Miss</span>
                    <span>Cover</span>
                    <span>%</span>
                    <span>Covered Lines</span>
                    <span>Missed Lines</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/_git_info.py</span>
                    <span>2</span>
                    <span>0</span>
                    <span>2</span>
                    <span>100.0%</span>
                    <span class="source-lines">2-3</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/aggregation.py</span>
                    <span>121</span>
                    <span>6</span>
                    <span>115</span>
                    <span>95.04%</span>
                    <span class="source-lines">13, 15-19, 21, 36, 39, 45, 47, 53-54, 56-58, 60, 62-65, 70, 74-75, 78-81, 85, 88-90, 94, 104, 110, 113-115, 117-121, 123-124, 129, 131-132, 134-135, 138-139, 145-147, 149, 152, 155, 158, 160, 162, 176, 178, 182, 184, 186, 196, 198-202, 204-205, 208, 210, 219, 231, 233-247, 249, 251, 259-260, 262-263, 265, 267-269, 273, 276-277, 279-280, 283, 285-286, 288, 290-291, 295</span>
                    <span class="source-lines">67, 91-92, 111, 206, 217</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/cache.py</span>
                    <span>47</span>
                    <span>3</span>
                    <span>44</span>
                    <span>93.62%</span>
                    <span class="source-lines">13, 15-19, 21, 27, 33, 39-41, 43, 53, 55-56, 58, 60-62, 68-69, 78, 86, 88, 90, 92, 94, 97, 103, 107, 118-119, 121, 123, 129, 132-136, 141, 144, 153</span>
                    <span class="source-lines">64-65, 130</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/collector.py</span>
                    <span>111</span>
                    <span>1</span>
                    <span>110</span>
                    <span>99.1%</span>
                    <span class="source-lines">19, 21-22, 24, 26-27, 33-34, 45-50, 52, 58, 60-62, 69, 78-79, 81, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127-128, 130, 132-133, 135-137, 140-141, 143, 155, 163-164, 167-169, 171, 173, 181-182, 185-189, 191, 198-200, 202, 209-210, 212-214, 216, 218, 227-228, 230-236, 238, 241, 250-252, 254, 261, 264-265, 268-269, 271, 277, 279, 285</span>
                    <span class="source-lines">239</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/context_util.py</span>
                    <span>53</span>
                    <span>3</span>
                    <span>50</span>
                    <span>94.34%</span>
                    <span class="source-lines">13-15, 18, 27, 29-31, 33, 35-36, 38-41, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 72, 81-82, 86, 88-90, 93, 96, 108, 111, 124, 126-127, 129-130, 133, 135</span>
                    <span class="source-lines">53, 83-84</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/coverage_map.py</span>
                    <span>135</span>
                    <span>6</span>
                    <span>129</span>
                    <span>95.56%</span>
                    <span class="source-lines">13, 15-17, 19-22, 30, 38, 44-45, 47, 58-60, 64, 72-73, 83, 86, 88-90, 92, 94-96, 98, 101-104, 106-108, 114, 116, 118, 121-122, 127-128, 131-135, 137-140, 144-146, 148, 150, 152-153, 156, 160-162, 165, 167-168, 173, 176, 178-184, 187-189, 191, 196, 199-200, 202, 204, 216-217, 220, 224-225, 228-234, 236, 239, 241, 243-244, 246-250, 252-254, 257, 259-260, 263-264, 271, 273-274, 276-279, 281-283, 285, 299-300, 302, 308</span>
                    <span class="source-lines">62, 123, 125, 157, 221, 251</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/errors.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">8-9, 12, 25-28, 31-36, 39-42, 45-46, 49-51, 54-55, 64-66, 68, 70, 73, 77-79, 83, 132, 142</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/__init__.py</span>
                    <span>3</span>
                    <span>0</span>
                    <span>3</span>
                    <span>100.0%</span>
                    <span class="source-lines">4-5, 7</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/annotator.py</span>
                    <span>154</span>
                    <span>21</span>
                    <span>133</span>
                    <span>86.36%</span>
                    <span class="source-lines">4, 6-10, 12-15, 21-22, 25-30, 33, 47-48, 50-52, 56, 58-59, 65, 67-68, 70, 73-74, 76, 84, 86-90, 95-96, 98-99, 106-107, 112-113, 116, 121-126, 130, 132, 134, 137, 144, 156, 181-182, 184, 186, 188-189, 199, 211, 213-216, 221-223, 226, 249-252, 254-255, 260, 262, 264-267, 269-270, 277-279, 281, 283-284, 289-290, 292-293, 298-301, 303, 306, 329-332, 334, 336, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381</span>
                    <span class="source-lines">77-81, 160-168, 173, 286-287, 345, 364-365, 371</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/base.py</span>
                    <span>131</span>
                    <span>6</span>
                    <span>125</span>
                    <span>95.42%</span>
                    <span class="source-lines">13, 15-18, 20, 30, 33, 47, 50, 53, 59, 65-66, 68, 87-88, 96, 101, 103, 105, 128, 134-135, 137-138, 149, 155, 157, 163, 165, 174, 176, 185-186, 188, 191-198, 200, 202, 212, 214-217, 219-222, 224, 232, 243, 245, 247, 264, 266-267, 270-272, 274-275, 277, 279, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314, 316, 325-326, 329-331, 333-334, 337-339, 342-347, 351, 353, 359-360, 363-364, 367-369, 372, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404, 406</span>
                    <span class="source-lines">91-92, 230, 284, 292, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/batching.py</span>
                    <span>90</span>
                    <span>4</span>
                    <span>86</span>
                    <span>95.56%</span>
                    <span class="source-lines">8, 10-13, 20, 23-24, 27-29, 31-32, 34, 36-37, 39, 44, 53-55, 58, 67-68, 70, 73, 92-93, 95, 97, 103-106, 108-110, 112, 122-123, 126-128, 136, 139, 156-157, 160, 162, 164-167, 170-176, 181-185, 187-188, 190, 192-194, 196-197, 203-206, 209-210, 213-214, 216-218, 222, 224</span>
                    <span class="source-lines">158, 207, 211, 220</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/gemini.py</span>
                    <span>325</span>
                    <span>7</span>
                    <span>318</span>
                    <span>97.85%</span>
                    <span class="source-lines">7, 9-13, 15-16, 23-27, 30-34, 37-42, 44-46, 48-50, 52, 57-63, 65-70, 72-73, 75-78, 80-85, 87-89, 91-97, 99-114, 121-122, 125, 128, 134-135, 137-141, 143-144, 146, 164-166, 173-175, 178, 181-182, 184, 186-189, 191-192, 198-206, 208-210, 212-213, 215, 218, 221-230, 232-233, 235-237, 239-243, 246-247, 249-252, 254-255, 259, 261, 263, 268, 272-276, 279-281, 283, 288-293, 295, 299-305, 308-309, 311-312, 318-319, 322, 326, 332-333, 335, 339-343, 345-349, 352-353, 358-359, 366-367, 369, 383, 385-386, 390, 410, 413-415, 418-422, 424-427, 432, 434-435, 437, 441-444, 446, 449-463, 469, 471-473, 475-478, 480, 486, 488-491, 493, 495, 497-498, 502-508, 511, 514-516, 518-521, 523-528, 534, 537, 539-543, 547-548, 550-559, 562-564, 567-570, 574</span>
                    <span class="source-lines">115-117, 298, 310, 313-314</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/litellm_provider.py</span>
                    <span>77</span>
                    <span>1</span>
                    <span>76</span>
                    <span>98.7%</span>
                    <span class="source-lines">8, 10, 12-13, 21, 31, 37-38, 41-42, 44, 51, 60-62, 64, 82-83, 89, 92, 95-96, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 122, 124-126, 129-130, 132, 135, 137, 139, 141-142, 144, 148, 170, 182-183, 186-188, 190, 192-193, 196-198, 204, 206, 211, 213, 215, 221-222, 224, 227-231, 234, 236, 242-243, 245</span>
                    <span class="source-lines">207</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/noop.py</span>
                    <span>13</span>
                    <span>0</span>
                    <span>13</span>
                    <span>100.0%</span>
                    <span class="source-lines">8, 10, 12-13, 20, 26, 32, 34, 51, 53, 59, 61, 67</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/ollama.py</span>
                    <span>72</span>
                    <span>1</span>
                    <span>71</span>
                    <span>98.61%</span>
                    <span class="source-lines">7, 9, 11-12, 18, 24, 42-43, 49, 52-53, 55, 58, 60-61, 63-67, 70, 74-77, 83, 85-86, 92, 94, 96-98, 100-101, 103, 107, 113-114, 116-118, 122, 128, 130, 138, 140, 142-144, 149-150, 156, 158, 160-162, 165-167, 172-173, 178, 180, 190, 192-193, 204, 209, 211-212</span>
                    <span class="source-lines">90</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/schemas.py</span>
                    <span>36</span>
                    <span>1</span>
                    <span>35</span>
                    <span>97.22%</span>
                    <span class="source-lines">8, 10-12, 16, 22, 38, 42-44, 46-47, 50-53, 55, 58-59, 62-65, 67-68, 77, 84, 90, 94-98, 102, 130</span>
                    <span class="source-lines">39</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/token_refresh.py</span>
                    <span>71</span>
                    <span>0</span>
                    <span>71</span>
                    <span>100.0%</span>
                    <span class="source-lines">7, 9-14, 17, 20, 23-24, 36-39, 41-43, 47, 59-60, 63-66, 69-72, 74, 83, 85-88, 90-91, 93, 101-103, 107-109, 111, 113-116, 120, 132-136, 139-140, 143-145, 148-150, 153-156, 158, 160-162</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/utils.py</span>
                    <span>33</span>
                    <span>2</span>
                    <span>31</span>
                    <span>93.94%</span>
                    <span class="source-lines">4, 6, 9, 20, 23, 42-43, 46-47, 51-53, 55-56, 66, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90, 93-94, 96, 98</span>
                    <span class="source-lines">48, 78</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/models.py</span>
                    <span>253</span>
                    <span>0</span>
                    <span>253</span>
                    <span>100.0%</span>
                    <span class="source-lines">17-18, 20, 23, 26-27, 36-38, 40, 42, 49-50, 59-61, 63, 65, 72-73, 86-92, 94, 96, 107-108, 120-126, 128, 130, 135-143, 146-147, 169-185, 187-188, 190, 192, 194, 201-224, 227-228, 236-237, 239, 241, 247-248, 257-259, 261, 263, 270-271, 280-282, 284, 286, 290-292, 295-296, 333-362, 364-372, 374, 376, 394-417, 419-437, 440-441, 455-463, 465, 467, 477-479, 482-483, 500-510, 512, 518, 520, 526-540</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/options.py</span>
                    <span>268</span>
                    <span>57</span>
                    <span>211</span>
                    <span>78.73%</span>
                    <span class="source-lines">122, 170, 199, 202-204, 209-211, 217-219, 225-227, 233-235, 241-242, 245-254, 257-259, 265-267, 271-274, 276, 284, 293, 308, 311-312, 320-325, 327, 332-337, 340-345, 348-349, 352-353, 356-357, 360-369, 372-375, 378-393, 396-397, 400-405, 408-409, 412-413, 416-421, 426-427, 430-431, 436-439, 444-447, 449, 451, 453, 460-461, 463-464, 466-467, 470-475, 479, 482-495, 498, 502-503, 507, 510, 514-515, 519-520, 524, 527, 531, 534-536, 540-541, 545-546, 550, 553, 557, 560, 564-565, 569, 572-574, 578, 581-584, 587, 591-592, 596, 599-608, 611, 613</span>
                    <span class="source-lines">13-15, 21-22, 98-102, 105-107, 110-115, 118-121, 138-139, 142-149, 152-155, 158-160, 163-166, 169, 180-184, 187-188, 191, 193, 278, 287, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/plugin.py</span>
                    <span>182</span>
                    <span>24</span>
                    <span>158</span>
                    <span>86.81%</span>
                    <span class="source-lines">41, 44, 50, 56, 62, 68, 74, 81, 90, 96, 102, 108, 114, 122, 128, 134, 142, 148, 155, 161, 169, 176, 185, 192, 199, 208, 215, 223, 229, 235, 241, 247, 254, 260, 268, 274, 283, 289, 297, 304, 311, 328, 332, 336, 342-343, 346-347, 349, 351, 354-356, 362-363, 371-372, 399-400, 403-404, 407, 410-411, 413-414, 417-418, 420, 422-426, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 476-477, 485-487, 491-494, 497, 499, 502-507, 509, 512-514, 516-521, 523, 534-535, 558-559, 562-563, 566-568, 579-580, 583, 586-587, 590-592, 602-603, 606-608, 619-620, 623, 626, 628-629</span>
                    <span class="source-lines">13, 15-18, 20-21, 23, 29-32, 35, 319, 377, 481-482, 488, 548-549, 571, 595, 611-612</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/prompts.py</span>
                    <span>110</span>
                    <span>3</span>
                    <span>107</span>
                    <span>97.27%</span>
                    <span class="source-lines">13, 15-17, 24, 27, 33, 35, 49, 52, 55, 58-61, 63, 65, 67, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 114, 116, 118, 139-140, 142-144, 147, 152-153, 155-157, 159-161, 163-164, 166-167, 170-171, 173, 177, 180, 189, 192-194, 196-197, 201, 203, 216-217, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249, 251, 268, 275, 284-287</span>
                    <span class="source-lines">80, 185, 233</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/render.py</span>
                    <span>65</span>
                    <span>6</span>
                    <span>59</span>
                    <span>90.77%</span>
                    <span class="source-lines">13, 15-16, 18, 24, 30-31, 34, 40, 42, 50-51, 53, 56, 65-67, 70, 79, 87, 90, 99, 101-102, 107, 110, 121-124, 126-129, 131-134, 140-142, 147, 155-157, 159, 172-177, 191, 210-211, 224, 267, 269, 285</span>
                    <span class="source-lines">148-149, 212, 217-218, 222</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/report_writer.py</span>
                    <span>167</span>
                    <span>3</span>
                    <span>164</span>
                    <span>98.2%</span>
                    <span class="source-lines">13, 15-25, 27-29, 46, 55, 58, 67-68, 76, 83-84, 89, 98-100, 102, 105-108, 110, 113, 116, 127-128, 130, 142, 150, 156-158, 160, 186-189, 192, 197-199, 202-203, 211, 222-223, 226-227, 230-231, 233, 235, 254, 256-259, 262-264, 266, 268, 310, 319, 321-322, 324-335, 337, 339, 347, 350-352, 355-356, 359-361, 364, 367, 375, 383, 385-386, 389, 392, 395, 398, 406, 408-409, 415, 417, 419, 421-432, 439, 441-442, 444-446, 454-458, 460, 462, 465, 468-469, 471, 477-481, 487-488, 495, 502, 504, 506-508, 510, 513-514, 516, 522-523</span>
                    <span class="source-lines">135-137</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/fs.py</span>
                    <span>34</span>
                    <span>1</span>
                    <span>33</span>
                    <span>97.06%</span>
                    <span class="source-lines">11, 13-14, 17, 30, 33, 36, 39, 42, 45, 55-56, 58-60, 63-65, 67, 70, 79, 82, 100, 103, 111-113, 116-117, 119-121, 123</span>
                    <span class="source-lines">40</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/hashing.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 14-17, 23, 32, 35, 44-48, 51, 61, 64, 73-74, 76-78, 80-81, 86, 96, 103-104, 107, 113-114, 116-121</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/ranges.py</span>
                    <span>33</span>
                    <span>0</span>
                    <span>33</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 15, 29-30, 33, 35-37, 39-40, 42, 45-47, 50, 52, 55, 65-67, 70, 81-82, 84-91, 93, 95</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/time.py</span>
                    <span>16</span>
                    <span>0</span>
                    <span>16</span>
                    <span>100.0%</span>
                    <span class="source-lines">4, 6, 9, 15, 18, 27, 30, 39-44, 46-48</span>
                    <span class="source-lines">-</span>
                </div>
            </div>
        </section>

        <section class="per-test-details" id="test-list">
            <h2>Per Test Details</h2>

        <!-- Filters -->
        <div class="filters">
            <input type="text" id="searchInput" class="filter-input" placeholder="Search tests..." onkeyup="filterTests()">
            <div class="filter-statuses" aria-label="Filter by status">
                <label class="filter-chip passed">
                    <input type="checkbox" data-status="passed" checked onchange="toggleStatus(this)">
                    Passed
                </label>
                <label class="filter-chip failed">
                    <input type="checkbox" data-status="failed" checked onchange="toggleStatus(this)">
                    Failed
                </label>
                <label class="filter-chip skipped">
                    <input type="checkbox" data-status="skipped" checked onchange="toggleStatus(this)">
                    Skipped
                </label>
                <label class="filter-chip xfailed">
                    <input type="checkbox" data-status="xfailed" checked onchange="toggleStatus(this)">
                    XFailed
                </label>
                <label class="filter-chip xpassed">
                    <input type="checkbox" data-status="xpassed" checked onchange="toggleStatus(this)">
                    XPassed
                </label>
                <label class="filter-chip error">
                    <input type="checkbox" data-status="error" checked onchange="toggleStatus(this)">
                    Error
                </label>
            </div>
        </div>

        <!-- Test List -->
        <div class="test-list">
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_adaptive_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        25 output =
                                        143 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of the `Config` class when given an empty source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert provider._estimate_test_complexity returns 0 for an empty string', 'expected': 0, 'got': 0}</li>
                                            <li>{'name': 'assert provider._estimate_test_complexity returns 0 for None', 'expected': 0, 'got': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        139 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 185-186, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the complexity estimation algorithm can accurately handle simple tests with low complexity.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'complexity score', 'value': 'low'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        84 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestConfigValidation::test_invalid_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the prompt tier is valid and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "The prompt tier should be one of [None, 'standard', 'advanced']", 'expected_value': 'invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        92 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_valid_prompt_tiers</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Valid prompt tiers should pass validation</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` field in the configuration is correctly validated and does not cause any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error count for minimal tier', 'expected_value': 0, 'actual_value': 1}</li>
                                            <li>{'name': 'Expected error count for standard tier', 'expected_value': 0, 'actual_value': 1}</li>
                                            <li>{'name': 'Expected error count for auto tier', 'expected_value': 0, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        149 output =
                                        291 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        25 output =
                                        147 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-220, 222, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</p>
                                    <p><strong>Why Needed:</strong> To ensure that the auto-tier feature can use minimal prompts for simple tests, which reduces the overhead of prompt generation and improves test performance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'selected_prompt_type', 'expected_value': 'MINIMAL_SYSTEM_PROMPT'}</li>
                                            <li>{'name': 'minimal_system_prompt', 'expected_value': {'prompt_type': 'minimal', 'prompt_text': 'def test_simple(): assert 1 == 1'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        155 input +
                                        136 output =
                                        291 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</p>
                                    <p><strong>Why Needed:</strong> To ensure that the minimal prompt is always used when possible, even in cases where a more advanced tier is required.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config', 'value': 'Config override to minimal should always use minimal prompt.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        92 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 212, 214-215, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_standard_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Config override to standard should always use standard prompt.</p>
                                    <p><strong>Why Needed:</strong> Because the config override is not necessary in this case, as the standard prompt is already used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'STANDARD_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        77 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 212, 214, 216-217, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_all_policy</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the aggregate function correctly handles all policy for multiple test cases.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using 'all' aggregation policy, which may cause duplicate tests to be included in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregated report should contain both retained tests.</li>
                                            <li>The number of tests in the aggregated report should match the expected number (2).</li>
                                            <li>Each retained test should have a unique ID.</li>
                                            <li>No duplicate tests should be included in the aggregated report.</li>
                                            <li>All test cases should be included in the aggregated report, even if they are not retained.</li>
                                            <li>The aggregate function should correctly handle all policy for multiple test cases.</li>
                                            <li>The aggregate function should not include any redundant or duplicate data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        164 output =
                                        528 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">71 lines (ranges: 53, 56-57, 60, 62-64, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</p>
                                    <p><strong>Why Needed:</strong> To test that the aggregate function correctly handles a directory that does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert aggregator is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        77 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 53, 56-58, 110, 113-115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_latest_policy</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the latest policy is selected when aggregating reports with different times.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the latest policy might not be chosen for aggregated reports with different times.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The outcome of the aggregate should match the outcome of the report with the latest timestamp.</li>
                                            <li>There should only be one test in the result.</li>
                                            <li>The outcome of the test should be 'passed'.</li>
                                            <li>The run meta should indicate that the aggregation was performed on multiple runs.</li>
                                            <li>The number of passed tests should equal the total number of runs.</li>
                                            <li>The summary should contain exactly one passed test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        144 output =
                                        621 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">79 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 204-205, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py</p>
                                    <p><strong>Why Needed:</strong> The test ensures that an aggregator can be created without a specified directory configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'agg is None after aggregate call', 'expected': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        67 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 45, 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `aggregate` returns `None` when no reports exist and there are no files to aggregate.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the function `aggregate` throws an error or raises an exception due to missing reports or empty file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate()` method should return `None` when called with an aggregator that has no reports and no files to aggregate.</li>
                                            <li>The `aggregate()` method should not throw any errors or raise exceptions in this scenario.</li>
                                            <li>The `aggregate()` method should behave as expected without throwing any errors or raising exceptions due to missing reports or empty file paths.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        144 output =
                                        345 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 53, 56-58, 110, 113-114, 117-118, 184)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_coverage_and_llm_annotations</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that coverage and LLM annotations are properly deserialized and can be re-serialized.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in core functionality</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>coverage: Verify coverage was properly deserialized from JSON.</li>
                                            <li>llm_annotation: Verify LLM annotation was properly deserialized from JSON.</li>
                                            <li>token_usage: Verify token usage serialization is correct (this was the CI bug fix).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        1002 input +
                                        98 output =
                                        1100 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">87 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138-141, 145-147, 149-150, 152-153, 155, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-45, 65-68, 130-133, 135-137, 139, 141-143, 190, 194-199, 201, 203, 205, 207, 210-214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_source_coverage</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Source coverage summary should be deserialized.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the source coverage is not correctly deserialized from the aggregated report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'source_coverage' key in the aggregated report contains a list of SourceCoverageEntry objects.</li>
                                            <li>Each SourceCoverageEntry object has the required attributes: 'file_path', 'statements', 'missed', 'covered', 'coverage_percent', 'covered_ranges', and 'missed_ranges'.</li>
                                            <li>The 'file_path' attribute is set to the correct file path in the report.</li>
                                            <li>The 'statements', 'missed', 'covered', 'coverage_percent', 'covered_ranges', and 'missed_ranges' attributes are correctly populated with values from the report.</li>
                                            <li>The 'coverage_percent' value is a valid percentage between 0 and 100.</li>
                                            <li>The 'covered_ranges' attribute contains ranges in the correct format (e.g., '1-5, 7-11').</li>
                                            <li>The 'missed_ranges' attribute also contains ranges in the correct format (e.g., '6, 12').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        243 output =
                                        638 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">67 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 162-169, 171-173, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_load_coverage_from_source</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading coverage from configured source file when option is not set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the aggregator fails to load coverage data when the `llm_coverage_source` option is not provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_load_coverage_from_source()` method should return `None` when `llm_coverage_source` is `None`.</li>
                                            <li>The `_load_coverage_from_source()` method should raise a `UserWarning` when trying to load coverage data from an invalid source file.</li>
                                            <li>The `_load_coverage_from_source()` method should mock the `coverage.Coverage` class and its methods to return the expected values.</li>
                                            <li>The `_load_coverage_from_source()` method should verify that it calls the correct functions with the expected arguments.</li>
                                            <li>The `_load_coverage_from_source()` method should verify that the coverage data is correctly loaded into the aggregator's internal state.</li>
                                            <li>The `_load_coverage_from_source()` method should return a valid `SourceCoverageEntry` object when successful loading occurs.</li>
                                            <li>The `SourceCoverageEntry` class should be mocked to return the correct values for its attributes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        584 input +
                                        242 output =
                                        826 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 259-260, 262-263, 265, 267-271, 273, 276-277, 279-280, 283, 285-286, 288)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_recalculate_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the recalculate_summary function correctly updates the latest summary with test results.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the recalculate_summary function fails to update the latest summary even after adding new tests or removing skipped tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of passed, failed, and skipped tests should match the actual counts in the latest summary.</li>
                                            <li>The number of xfailed and xpassed tests should be equal to their actual counts in the latest summary.</li>
                                            <li>The error status should remain unchanged even after adding new tests or removing skipped tests.</li>
                                            <li>The coverage percentage should be preserved from the latest summary.</li>
                                            <li>The total duration of all tests should increase by 5 seconds (1.0 + 4.0 = 5.0) to reflect the updated count in the latest summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        181 output =
                                        654 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 231, 233-247, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_skips_invalid_json</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping an invalid JSON file prevents the aggregation from counting it as a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test verifies that the `aggregate` function correctly handles cases where the input is not a valid JSON report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate` function should skip the 'invalid.json' file and only count the 'valid.json' file in the aggregation result.</li>
                                            <li>The `aggregate` function should raise a warning when it encounters an invalid JSON file, indicating that it's being skipped.</li>
                                            <li>The `aggregate` function should not include any reports from files with missing fields (e.g., 'missing_fields.json') in its final count of valid reports.</li>
                                            <li>The test should be able to reproduce the issue by creating a temporary directory and writing both an invalid JSON file and a valid JSON file inside it.</li>
                                            <li>The `aggregate` function should correctly handle cases where the input is not a valid JSON report, without raising any errors or unexpected behavior.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        352 input +
                                        212 output =
                                        564 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123-124, 129, 131-132, 162-167, 169, 171-173, 176, 178-180, 182, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation_maximal.py::TestAggregationMaximal::test_recalculate_summary_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the aggregator correctly recalculates the summary when new tests are added and the latest summary is provided.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage calculation when new tests with different durations are added to the aggregation process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total duration of all passed tests should be equal to the latest summary's total duration.</li>
                                            <li>The number of passed tests should match the latest summary's passed count.</li>
                                            <li>The total duration of failed tests should remain unchanged.</li>
                                            <li>The coverage total percent should still reflect the latest summary's coverage.</li>
                                            <li>The total duration of all tests should increase by 1 second (3.0 seconds) compared to the previous test result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        157 output =
                                        456 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 45, 231, 233-239, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_annotator.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</p>
                                    <p><strong>Why Needed:</strong> To test the batch optimization message generation and verification.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_type': 'MockProvider'}</li>
                                            <li>{'name': 'mock_cache', 'expected_type': 'MockCache'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_type': 'MockAssembler'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        116 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-91, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the progress reporting is cached correctly and not lost in case of a provider or assembler failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_cache.get_cached_progress_reporting_result().should_return_json', 'description': 'Mocked cache should return the expected JSON result when the annotator has completed the task.'}</li>
                                            <li>{'name': 'mock_provider.get_progress_reporting_status().should_return_success', 'description': 'Mocked provider should return a successful status when the annotator completes the task.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        147 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-128, 130, 134, 156, 181-182, 184, 211, 213-219, 221, 223)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</p>
                                    <p><strong>Why Needed:</strong> To ensure that cached tests are skipped correctly and not executed unnecessarily.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'Mocked provider is used', 'actual_value': 'Mocked provider is used'}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 'Mocked cache is used', 'actual_value': 'Mocked cache is used'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_value': 'Mocked assembler is used', 'actual_value': 'Mocked assembler is used'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        165 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">95 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-124, 130, 132, 134, 137-141, 144-151, 156, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotators can be annotated concurrently without causing any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should not raise an exception when called concurrently', 'expected_result': 'None'}</li>
                                            <li>{'name': 'Mock cache should not raise an exception when accessed concurrently', 'expected_result': 'None'}</li>
                                            <li>{'name': 'Mock assembler should not raise an exception when called concurrently', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        128 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221, 223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</p>
                                    <p><strong>Why Needed:</strong> To test that concurrent annotation handles failures correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'pytest-capsys', 'expected_output': 'Capture the output of the annotation process and verify it contains an error message.', 'actual_output': 'Capture the output of the annotation process and verify it contains an error message.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        111 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221-223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator correctly reports progress during the annotation process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should be called with a valid task ID', 'expected_result': 1, 'actual_result': 0}</li>
                                            <li>{'name': 'Mock cache should not raise an exception when getting a valid task ID', 'expected_result': 1, 'actual_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        129 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator correctly displays progress messages during reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider is called with correct arguments', 'expected_calls': [], 'asserted_calls': [], 'message': 'Expected mock provider to be called with correct arguments, but got unexpected ones.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        106 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the annotator respects the opt-out and limit settings when performing annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'mocking', 'expected_mocking': ['mock_provider', 'mock_cache', 'mock_assembler']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        95 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 47, 50-51, 58-59, 65, 67-68, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</p>
                                    <p><strong>Why Needed:</strong> Respects rate limit for annotating test data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider.get_rate_limit() returns a valid rate limit value', 'expected_value': 10, 'actual_value': 5}</li>
                                            <li>{'name': 'mock_cache.get_result() does not raise an exception when the result is already cached', 'expected_exception': 'Cache miss', 'actual_exception': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        133 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-257, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation</span>
                            <div class="test-meta">
                                <span>12.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that sequential annotation works correctly and produces the expected output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected_output', 'description': 'The expected output of the sequential annotation process.'}</li>
                                            <li>{'name': 'output_length', 'description': 'The length of the output string after sequential annotation.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        107 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</span>
                            <div class="test-meta">
                                <span>24.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</p>
                                    <p><strong>Why Needed:</strong> Error tracking for sequential annotation is needed to ensure that errors are properly reported and handled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocking the provider', 'expected_output': 'Mocked provider object'}</li>
                                            <li>{'name': 'Mocking the cache', 'expected_output': 'Mocked cache object'}</li>
                                            <li>{'name': 'Mocking the assembler', 'expected_output': 'Mocked assembler object'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        135 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</p>
                                    <p><strong>Why Needed:</strong> The test should be skipped when the LLM (Language Model) is not enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'bool', 'actual_type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        79 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 47-48)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</p>
                                    <p><strong>Why Needed:</strong> The annotator should skip the annotation process if the provider is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'MockProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        79 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 47, 50-54, 56)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_coverage_v2.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_malformed_json_after_extract</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Base Parse Response Malformed JSON After Extract</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `extract_json_from_response` function handles malformed JSON correctly and raises a meaningful error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'JSONDecodeError', 'expected_error_message': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        85 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 325-326, 329-330, 333-334, 359-360)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_non_string_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `test_base_parse_response_non_string_fields` function handles non-string fields correctly, specifically verifying if it correctly identifies the expected key assertion.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function incorrectly assumes all fields are strings and fails to identify the correct list of keys.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.scenario == "123"</li>
                                            <li>assert annotation.why_needed == "['list']"</li>
                                            <li>assert annotation.key_assertions == ['a']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        117 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342-346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_gemini_provider` function returns an instance of `GeminiProvider` when a Gemini provider is requested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider_type', 'expected_value': 'GeminiProvider'}</li>
                                            <li>{'name': 'provider_class', 'expected_value': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        111 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To test that a ValueError is raised when an unknown LLM provider is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected exception message', 'value': 'Unknown LLM provider: invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        80 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_litellm_provider` function returns a valid instance of `LiteLLMProvider`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider_type', 'expected': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        86 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of getting a provider without any configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of NoopProvider', 'expected_result': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        80 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider can be retrieved and used correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of OllamaProvider', 'expected_type': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        85 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_available_caches_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `is_available()` method returns a boolean indicating availability.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the `is_available()` method does not return a boolean value when it should.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `is_available()` method of the provider is called and its result is checked to be `True`.</li>
                                            <li>The `is_available()` method of the provider is called again with the same arguments and its result is checked to be `True`.</li>
                                            <li>The value of `provider.checks` after calling `_check_availability()` is checked to be 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        137 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 134-135, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_model_name_defaults_to_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the model name defaults to the configuration if no custom value is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "provider.get_model_name() == 'test-model'", 'expected_value': 'test-model'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        81 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_rate_limits_defaults_to_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider defaults to using rate limits when they are not explicitly set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.get_rate_limits() should return None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        75 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_is_local_defaults_to_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM default settings are correctly set to false when using a non-local configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_local() is False', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        74 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 174)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_batching.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_context_files_included</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that context files are included in the batch prompt for a given function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where context files are not added to the prompt, potentially causing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'src/module.py' file is present in the prompt.</li>
                                            <li>The 'def helper()' function is included in the prompt.</li>
                                            <li>Context files should be added to the prompt for a given function.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        261 input +
                                        103 output =
                                        364 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 192-194, 196-200, 203-206, 209-210, 213-214, 216-218, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_parametrized_batch_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the parametrized batch prompt functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that all variants of a test are included in a parametrized batch prompt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'Test Group: test.py::test_add[*]' assertion should be present in the prompt.</li>
                                            <li>The 'Parameterizations (2 variants)' assertion should be present in the prompt.</li>
                                            <li>The '[1+1=2]' assertion should be present in the prompt.</li>
                                            <li>The '[0+0=0]' assertion should be present in the prompt.</li>
                                            <li>The 'ONE annotation' assertion should be present in the prompt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        330 input +
                                        145 output =
                                        475 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 34, 39-40, 156-157, 160, 162, 164-168, 170-177, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_single_test_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The single_test_prompt test verifies that a normal batched request can be generated.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the test prompt is not correctly formatted or does not include necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Test: test.py::test_foo should appear in the prompt.</li>
                                            <li>```python should appear in the prompt.</li>
                                            <li>source should be included in the prompt.</li>
                                            <li>Parameterizations should not appear in the prompt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        107 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the same source code produces the same hash value.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where different versions of the test function produce different hashes, potentially leading to inconsistent results or incorrect analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `source` variable is assigned a string containing test function code.</li>
                                            <li>Two calls to `_compute_source_hash(source)` return the same hash value.</li>
                                            <li>The length of the returned hash value is 32 bytes (as expected).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        110 output =
                                        330 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that different sources produce different hashes, which is a requirement for batching to work correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'hash1 != hash2', 'description': 'The first computed source hash should be different from the second one'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        92 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> The current implementation of compute_source_hash() does not handle an empty source correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _compute_source_hash() returns an empty string for an empty input', 'expected_result': '', 'actual_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        90 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `batch_max_tests` configuration option must be at least 1 to ensure that the batch size can be set correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() returns an error', 'description': 'The `validate()` method of the config object should return a list of errors.'}</li>
                                            <li>{'name': "any('batch_max_tests' in e for e in errors)", 'description': "At least one 'batch_max_tests' key-value pair should be present in the error messages."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        152 output =
                                        278 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</p>
                                    <p><strong>Why Needed:</strong> Context line padding must be non-negative.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'context_line_padding', 'actual_value': -1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        79 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation test_invalid_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_compression` parameter is validated correctly and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config validation errors', 'description': 'The `validate()` method should return a list of error messages for the given configuration.'}</li>
                                            <li>{'name': 'invalid context compression mode', 'description': 'The `context_compression` parameter should be an invalid value and raise an error.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        125 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_valid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To ensure that valid context compression modes pass validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "Context compression mode should be None or 'lines'", 'expected_value': "None|'lines'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        67 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_nested_params</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_nested_params</p>
                                    <p><strong>Why Needed:</strong> This test ensures that complex params are fully stripped from the base node id.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'striped base node id', 'expected': 'test.py::test', 'actual': '_get_base_nodeid('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        90 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `parametrized_nodeid` function correctly strips parameters from node IDs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'node_id assertion', 'expected_value': 'tests/test_foo.py::test_add', 'actual_value': '_get_base_nodeid('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        101 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `_get_base_nodeid` function does not handle nodeids without parameters correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeid is unchanged', 'expected_value': 'tests/test_foo.py::test_bar', 'actual_value': '_get_base_nodeid('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        103 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batch_max_size_respected</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Large groups of tests should be split into batches with a maximum size.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when the batch size is set to a value that would result in too many tests being processed at once.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of each batch should match the expected number of tests (2, 2, 1).</li>
                                            <li>Each batch should contain exactly two tests.</li>
                                            <li>A batch with only one test is not considered a valid batch.</li>
                                            <li>The total number of tests across all batches should be equal to the specified maximum size (3).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        133 output =
                                        497 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 53-54, 67-68, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batching_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Group Tests For Batching</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the batching parameterized tests are disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Number of batches should be equal to number of tests', 'expected_value': 2, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        79 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 92-93, 95, 97-99)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_parametrized_tests_grouped</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test parametrized tests should be grouped together.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression due to the lack of grouping of parametrized tests, which can lead to unexpected behavior when running tests in parallel.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of batches is equal to 1.</li>
                                            <li>Each batch contains exactly 3 tests.</li>
                                            <li>Each batch is a parameterized test.</li>
                                            <li>The base node ID of each batch is 'test.py::test_add'.</li>
                                            <li>All tests in the first batch are parametrized.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        124 output =
                                        470 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 34, 39-40, 53-54, 67, 70, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_single_tests_no_grouping</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_single_tests_no_grouping' verifies that single tests are batched individually without grouping.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where multiple tests are grouped together and their individual tests are not batched separately.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Each test is assigned to a separate batch with no grouping.</li>
                                            <li>There are two batches in total, each containing one test.</li>
                                            <li>The first batch contains only one test ('test_a') and the second batch also contains only one test ('test_b').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        118 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_cache.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_consistent_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache is consistent across multiple tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'same source produces same hash', 'expected': 'hash_source(source)', 'actual': 'hash_source(source)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        81 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache is working correctly when using different source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'different hash', 'expected': 'different hash', 'actual': 'same hash'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        80 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_hash_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_hash_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the hash length is correct and consistent across different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 16, 'actual_value': {'hash': '486d8f5e4b2ae6c99a9c43d3a1f29f44'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        96 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_clear</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `clear` method of LlmCache to ensure it removes all existing entries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the cache might not be cleared properly, leading to unexpected behavior or incorrect results in subsequent tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the `clear` method correctly removes all cache entries.</li>
                                            <li>Ensure that after clearing the cache, no existing entries are still present.</li>
                                            <li>Test that the `get` method returns `None` for any non-existent keys.</li>
                                            <li>Verify that the cache size is updated correctly before and after clearing.</li>
                                            <li>Check if the test raises an error when trying to access a non-existent key.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        150 output =
                                        433 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 129, 132-136, 141)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that LLMCache does not cache errors in annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cache should be empty when annotation has error', 'expected_value': [], 'actual_value': ['abc123']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        74 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_get_missing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_get_missing</p>
                                    <p><strong>Why Needed:</strong> To test that the get method returns None for missing entries in the cache.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None', 'actual_value': 'result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        72 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 39-41, 53, 55-56, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_set_and_get</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotations can be set and retrieved from the cache.</p>
                                    <p><strong>Why Needed:</strong> Prevents bypass attacks by ensuring that LLMCache stores and retrieves annotations in a consistent manner.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Check that the annotation is stored correctly in the cache.</li>
                                            <li>Verify that the annotation's confidence value is preserved during retrieval.</li>
                                            <li>Ensure that the retrieved annotation matches the original annotation.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        93 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 39-41, 53, 55, 58, 60-62, 68-73, 86, 90, 92, 94, 97-101, 103, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">11 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the collection errors have a correct structure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeid', 'expected_value': 'test_bad.py'}</li>
                                            <li>{'name': 'message', 'expected_value': 'SyntaxError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        94 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</p>
                                    <p><strong>Why Needed:</strong> To ensure that the get_collection_errors method returns an empty list when the collection is initially empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert get_collection_errors is a list', 'expected_value': [], 'actual_value': 'get_collection_errors'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        94 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_context_override_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction</p>
                                    <p><strong>Why Needed:</strong> Default llm_context_override should be None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'llm_context_override', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        66 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</p>
                                    <p><strong>Why Needed:</strong> The default value of llm_opt_out should be False.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'llm_opt_out is not equal to False', 'expected_value': False, 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        90 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> The output capture feature is not disabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.capture_failed_output', 'expected_value': True, 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        79 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</p>
                                    <p><strong>Why Needed:</strong> The default value of `capture_output_max_chars` is 4000. This is necessary to ensure that the output does not exceed this limit, which could cause issues with downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert capture_output_max_chars is equal to 4000', 'expected_value': 4000, 'message': 'The default value of `capture_output_max_chars` is 4000.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        127 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</p>
                                    <p><strong>Why Needed:</strong> To ensure that xfail failures are correctly recorded as xfailed in the test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected failure', 'value': 'xfail'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        206 input +
                                        80 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212, 216, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</p>
                                    <p><strong>Why Needed:</strong> xfail passes should be recorded as xpassed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_name': "result.outcome == 'xpassed'", 'expected_value': 'xpassed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        81 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212-214)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_create_collector</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `TestCollector` class initializes correctly and returns default values for results, collection errors, and collected count.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the collector does not initialize with empty results, leading to incorrect assertions in subsequent tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `results` attribute of the `collector` object is set to an empty dictionary.</li>
                                            <li>The `collection_errors` attribute of the `collector` object is an empty list.</li>
                                            <li>The `collected_count` attribute of the `collector` object is set to 0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        131 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_get_results_sorted</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestTestCollector::test_get_results_sorted</p>
                                    <p><strong>Why Needed:</strong> To ensure that the results are sorted by nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeids are in expected order', 'expected': ['a_test.py::test_a', 'z_test.py::test_z'], 'actual': [False]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        94 output =
                                        321 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_handle_collection_finish</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `handle_collection_finish` method correctly tracks collected and deselected items.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the count of collected items is not updated correctly after calling `handle_collection_finish`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `collected_count` attribute should be set to 3 (number of collected items).</li>
                                            <li>The `deselected_count` attribute should be set to 1 (number of deselected items).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        110 output =
                                        366 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 78-79, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_internals.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</p>
                                    <p><strong>Why Needed:</strong> To ensure that the test does not capture output when `config.capture_failed_output=False` and the integration is via handle_runtest_logreport.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result captured_stdout is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        95 output =
                                        306 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for Collector Internals</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collector correctly captures stderr output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'collector._capture_output', 'expected_result': 'Some error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        62 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals::test_capture_output_stdout</p>
                                    <p><strong>Why Needed:</strong> To test that the collector captures stdout correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stdout', 'expected_value': 'Some output'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        64 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_truncated</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_create_result_with_item_markers</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test creates a result with item markers.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of item markers being used as requirements or context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>item.callspec.id = 'param1' is called and its value is set to 'param1'.</li>
                                            <li>get_closest_marker('llm_opt_out') returns a mock object with the expected behavior.</li>
                                            <li>get_closest_marker('llm_context') returns a mock object with the correct arguments.</li>
                                            <li>get_closest_marker('requirement') returns a mock object with the expected requirements.</li>
                                            <li>item.get_closest_marker('llm_opt_out') is called and its value is set to True.</li>
                                            <li>item.get_closest_marker('llm_context_override') is called and its value is set to 'complete'.</li>
                                            <li>item.get_closest_marker('requirement') returns a mock object with the expected requirements.</li>
                                            <li>result.param_id matches the expected value of 'param1'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        382 input +
                                        213 output =
                                        595 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163-164, 167-169, 171, 181-182, 185-189, 198-200, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_repr_crash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_internals.py::TestCollectorInternals::test_extract_error_string</p>
                                    <p><strong>Why Needed:</strong> To ensure the `extract_error` method returns a string that can be used to reconstruct the original error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert extract error is correct', 'description': 'The extracted error string should match the expected value'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        93 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_collector_maximal</p>
                                    <p><strong>Why Needed:</strong> To ensure the `_extract_skip_reason` method returns None when no longrepr is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _extract_skip_reason returns None for None longrepr', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        76 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250, 252)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_extract_skip_reason` method returns a string as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert _extract_skip_reason returns 'Just skipped'", 'expected_value': 'Just skipped'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        86 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_tuple</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_collection_report_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When the `handle_collection_report` method is called with a collection report that fails, it should record this failure.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where a collection report fails and does not trigger any error messages or warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `collection_errors` list should contain exactly one item.</li>
                                            <li>The first item in the `collection_errors` list should have a 'nodeid' of 'test_broken.py'.</li>
                                            <li>The first item in the `collection_errors` list should have a 'message' that matches 'SyntaxError'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        133 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 58, 60-65, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_rerun</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TestCollector's handle_runtest_rerun method to ensure it correctly handles reruns and updates the report accordingly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the TestCollector does not update the report when a rerun is requested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'rerun' attribute of the report should be set to 1 after handling a runtest_rerun event.</li>
                                            <li>The final outcome of the runtest_rerun event should be updated to 'failed'.</li>
                                            <li>The 'rerun_count' and 'final_outcome' attributes of the results dictionary should contain the expected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        143 output =
                                        424 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140-141, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238, 261, 264-265, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_setup_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When the `handle_runtest_setup_failure` test is executed, it should record an error setup in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the collector might not correctly handle setup failures and instead incorrectly reports a success or no action.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.outcome == 'error'</li>
                                            <li>res.phase == 'setup'</li>
                                            <li>res.error_message == 'Setup failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        300 input +
                                        98 output =
                                        398 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_teardown_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should record error if teardown fails after pass.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression in case of teardown failure, where the collector logs an error instead of a success result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert res.outcome == 'error'</li>
                                            <li>assert res.phase == 'teardown'</li>
                                            <li>assert res.error_message == 'Cleanup failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        85 output =
                                        476 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127-128, 130, 132-133, 135-137, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_compression.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_invalid_compression_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid context compression mode</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression mode is valid and does not cause any issues during testing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "context_compression must be one of 'none', 'gzip', or 'lz4'", 'expected': ['context_compression', 'invalid']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        86 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</p>
                                    <p><strong>Why Needed:</strong> Negative padding should fail validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding is not a valid value for this configuration provider.', 'expected_value': -1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        75 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_valid_compression_modes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To ensure that valid compression modes are correctly validated and do not raise any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Context compression should be None or 'lines'", 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        69 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</p>
                                    <p><strong>Why Needed:</strong> Zero padding is a valid configuration option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() returns no errors', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        71 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> The context compression should be enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        71 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</p>
                                    <p><strong>Why Needed:</strong> Lines compression mode is needed to ensure that the test suite can run without any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        79 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_line_padding_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_line_padding_default</p>
                                    <p><strong>Why Needed:</strong> To ensure that line padding is set to a default value of 2, which is the expected behavior according to the documentation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_line_padding', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        94 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_contiguous_lines_no_gap</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that contiguous covered lines do not have gap indicators.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where contiguous lines are marked with a gap indicator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The count of '#' characters should be zero for contiguous lines.</li>
                                            <li># L3:</li>
                                            <li># L4:</li>
                                            <li># L5:</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        77 output =
                                        370 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</p>
                                    <p><strong>Why Needed:</strong> Empty coverage should return empty string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        70 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 216-217)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_multiple_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Covered Lines: Multiple covered ranges should be extracted with gap indicators.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where multiple covered lines are not correctly identified with gap indicators.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result contains the expected gap indicator between the two covered lines (# ...).</li>
                                            <li>The result contains the expected range indicator for line L3: # L3:...</li>
                                            <li>The result contains the expected range indicator for line L15: # L15:...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        111 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a single covered line is extracted with the correct number of lines padded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where a single line is not extracted due to insufficient padding.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result should contain '# L2:' and '# L3:' and '# L4:'</li>
                                            <li>The result should include lines 2, 3, and 4 with the correct number of lines padded (1)</li>
                                            <li>The line numbers in the result should match the original covered lines</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        302 input +
                                        120 output =
                                        422 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_padding_boundary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Covered Lines: Padding should not go beyond file boundaries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where padding exceeds the file boundary, potentially causing incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert '# L1:' in result</li>
                                            <li>assert '# L2:' in result</li>
                                            <li>assert '# L3:' in result</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        86 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_limits.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_no_truncation_needed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_smart_distribution</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_limits.py::test_smart_distribution verifies that the smart distribution algorithm does not waste tokens when F1 and F2 have different needs.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the smart distribution logic, where F1 gets more budget than F2 if their needs are unequal.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>F1 should be full with ~536 chars (134 tokens).</li>
                                            <li>F2 got the extra budget of ~400 chars (480 tokens) instead of ~100 tokens (110 tokens).</li>
                                            <li>F2's content is truncated to ~800 chars (720 tokens) instead of ~440 tokens (110 tokens).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        773 input +
                                        145 output =
                                        918 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_splitting_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the splitting logic correctly truncates strings and meets budget requirements.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the splitting logic does not truncate strings, leading to excessive output or incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>f1 contains 'truncated' in its prompt</li>
                                            <li>f2 contains 'truncated' in its prompt</li>
                                            <li>prompt includes 'Present'</li>
                                            <li>prompt is within budget (~200 tokens total)</li>
                                            <li>prompt has overhead small (<80 tokens per file)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        118 output =
                                        435 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_truncation_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test truncation logic when creating large context files.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test passes even though the context is too long, causing unnecessary computation and potentially incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The prompt should be truncated to fit within 100 tokens minus system prompt overhead (~40-50 tokens) minus header overhead (~20 tokens)</li>
                                            <li>Context should be very small or empty</li>
                                            <li>Prompt contains '[... truncated]' or 'Relevant context' indicating truncation</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        397 input +
                                        116 output =
                                        513 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 243, 245, 264, 266, 270-272, 274-275)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_util.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">28 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</p>
                                    <p><strong>Why Needed:</strong> Because the current implementation does not handle three or more empty lines correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The result of collapsing three+ empty lines is 2.', 'expected_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        90 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing many empty lines to one blank line.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\n\nline2', 'actual_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        83 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</p>
                                    <p><strong>Why Needed:</strong> Preserves up to 2 consecutive newlines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\n\nline2', 'actual_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        81 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</p>
                                    <p><strong>Why Needed:</strong> Preserve single newlines in collapsed context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 'line1\nline2\nline3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        74 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation does not correctly handle empty lines in the input source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'line1\nline2', 'actual_value': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        137 input +
                                        90 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</p>
                                    <p><strong>Why Needed:</strong> To ensure that the combined optimization process works as expected and does not introduce any unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected Optimizations to be applied', 'value': 'All optimizations should be applied'}</li>
                                            <li>{'name': 'Optimization Order', 'value': 'The combined optimization process should apply all optimizations in the expected order.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        115 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</p>
                                    <p><strong>Why Needed:</strong> The default behavior of `optimize_context` is to strip all code, including docstrings and comments. However, this can be problematic when working with complex codebases where docstrings provide important context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring stripping', 'expected': '', 'actual': 'def foo():'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        107 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> The function `optimize_context()` should be able to handle an empty source without raising an exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        71 output =
                                        166 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of optimize_context does not handle source code with only whitespace correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the optimize_context function should be a string containing only whitespace characters.</li>
                                            <li>The input to the optimize_context function should be a string containing only whitespace characters.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        95 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_both</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_both</p>
                                    <p><strong>Why Needed:</strong> To optimize the context by removing unnecessary documentation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'source: def foo():\n# ...', 'expected': 'def foo():\n# ...'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        80 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</p>
                                    <p><strong>Why Needed:</strong> To optimize the context by removing unnecessary comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'string', 'expected_value': 'def foo():\n  # This is a comment\n  pass', 'actual_value': {'scenario': 'tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only', 'why_needed': 'To optimize the context by removing unnecessary comments.', 'key_assertions': ['def foo():\n  # This is a comment\n  pass']}, 'reason': "The docstring 'This is a comment' should be removed."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        161 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 81-82, 86, 88-90, 93, 108, 124, 126, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_neither</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_neither</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the optimizer strips out unnecessary code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'source_code', 'expected': 'def foo():\n  pass', 'actual': 'def foo():\n  # This line will be stripped by the optimizer'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        97 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that comments are stripped from strings containing hash symbols (#) after they appear within string literals.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': '\'url = "http://example.com#anchor"\'', 'actual_result': 'url = "http://example.com#anchor",'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        100 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_escaped_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_escaped_quotes</p>
                                    <p><strong>Why Needed:</strong> To handle escaped quotes in strings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return the original string without any escaped quotes.', 'expected_result': 's = "escaped \\'}</li>
                                            <li>actual_result": {u's': u'\u201c'}  # The actual result is a Unicode escape sequence for a double quote character, not just a literal double quote.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        120 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_mixed_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_mixed_quotes</p>
                                    <p><strong>Why Needed:</strong> To strip quotes from a string containing both single and double quotes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '"don\'t # worry"', 'actual': '"don\'t\\# worry"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        77 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_no_comments</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_no_comments</p>
                                    <p><strong>Why Needed:</strong> To strip comments from the source code to ensure correct context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'source_code', 'expected_result': 'def foo():\n  # This is a comment\n    pass'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        91 input +
                                        84 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</p>
                                    <p><strong>Why Needed:</strong> To preserve '#' inside double-quoted strings in the context of strip_comments() function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': '\'url = "http://example.com#anchor"\'', 'actual_result': '\'url = "http://example.com#anchor"\''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        99 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</p>
                                    <p><strong>Why Needed:</strong> To preserve the hash (#) inside single-quoted strings when stripping comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '# is preserved in single-quoted string', 'actual': "url = 'http://example.com#anchor'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        90 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_simple_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_simple_comment</p>
                                    <p><strong>Why Needed:</strong> To remove simple end-of-line comments from the source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'x = 1', 'actual_result': 'x = 1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        76 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</p>
                                    <p><strong>Why Needed:</strong> To strip standalone comments from the test source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'line': 1, 'column': 4}, 'actual': {'line': 2, 'column': 0}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        85 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the function correctly handles syntax errors in the input source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'strip_docstrings() returns the original source on syntax error.', 'expected_result': 'def foo( unclosed paren', 'actual_result': 'def foo( unclosed paren'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        107 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 27, 29-31)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation of context_util.strip_docstrings() does not handle multiple docstrings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function should remove all docstrings from the source code.', 'expected_output': 'No docstring remains in the source code.'}</li>
                                            <li>{'assertion': 'The function should return an empty string if there are no docstrings to strip.', 'expected_output': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        131 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve multiline data strings in docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring triple quotes are preserved', 'expected_value': 'def foo():\n    """\n    This is a triple quoted string.\n"""', 'actual_value': 'def foo():\n    This is a triple quoted string.', 'message': 'Expected docstring triple quotes to be preserved, but were not.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        133 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve regular strings in test output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'strip_docstrings', 'expected_value': 'x = "hello world"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        74 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 27, 29, 33, 35-36, 38-45, 49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</p>
                                    <p><strong>Why Needed:</strong> Preserving strings in structures is a crucial aspect of the context utility.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The string 'string 1' is preserved in the output.", 'expected_output': '\'"string 1"\'', 'actual_output': "'''string 1'''"}</li>
                                            <li>{'assertion': "The string '"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        117 output =
                                        263 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `strip_multiline_docstring` function correctly removes multiline docstrings from Python code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring removal', 'expected': 'The function should remove all docstrings, including those with multiple lines.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        95 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> To ensure that context managers are properly stripped of triple double-quoted docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring removal', 'expected': 'def foo():'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        82 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation does not correctly strip triple single-quoted docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'striped source code contains a triple single-quoted docstring', 'expected_result': 'source = """\ndef foo():\n>>> foo()""\\'}</li>
                                            <li>actual_result</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        151 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_boosters.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_model_parsing_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the GeminiProvider's _parse_preferred_models method with edge cases.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the method returns incorrect results when given an empty or invalid model configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return an empty list when the `model` parameter is None.</li>
                                            <li>The function should return an empty list when the `model` parameter is set to 'All'.</li>
                                            <li>The function should not return any models when the `model` parameter is an invalid string (e.g., 'abc').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        126 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 134-135, 137-141, 143-144, 476, 478, 524-531)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_rate_limiter_edge_math</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter correctly handles edge cases where there are more tokens than available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter fails to handle situations with excessive token usage, leading to incorrect behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `next_available_in` method should return an error when there are more tokens than available.</li>
                                            <li>The `next_available_in` method should return 0 when both limits have been exceeded.</li>
                                            <li>The rate limiter should not attempt to process requests beyond the available token limit.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        127 output =
                                        400 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_models_to_dict_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `models_to_dict` method returns accurate coverage percentages for SourceCoverageEntry objects.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the `models_to_dict` method by ensuring it accurately calculates coverage percentages for SourceCoverageEntry objects.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'coverage_percent' key of the dictionary returned by `to_dict()` contains the correct value.</li>
                                            <li>The 'error' key of the dictionary returned by `to_dict()` contains the expected error message.</li>
                                            <li>The 'duration' key of the dictionary returned by `to_dict()` contains the correct duration value.</li>
                                            <li>The 'start_time', 'end_time', and 'duration' keys are present in the dictionary with their respective values.</li>
                                            <li>The coverage percentage is calculated correctly based on the number of statements, covered, missed, and coverage percent.</li>
                                            <li>The LLM annotation error message is correctly extracted from the annotation object.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        198 output =
                                        516 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 96-103, 130-133, 135, 137-139, 141, 143, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</p>
                                    <p><strong>Why Needed:</strong> Mapper initialization should be tested to ensure it creates a new instance with the correct configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mapper is an instance of CoverageMapper', 'expected_type': 'CoverageMapper', 'actual_type': 'type'}</li>
                                            <li>{'name': 'config is initialized correctly', 'expected_value': 'Config', 'actual_value': 'type'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        118 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_warnings` method returns a list of warnings as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert isinstance(warnings, list)', 'expected_result': 'list'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        78 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 44-45, 308)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_map_coverage_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `map_coverage` method returns an empty dictionary when no coverage file is present.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails due to missing coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `map_coverage()` method should return an empty dictionary when no coverage file exists.</li>
                                            <li>The `map_coverage()` method should not have any warnings when no coverage file is present.</li>
                                            <li>The `map_coverage()` method should correctly handle the absence of a coverage file by returning an empty dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        277 input +
                                        119 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_all_phases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `CoverageMapper` extracts all phases when the `include_phase` parameter is set to 'all'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage map does not include all phases when `include_phase=all`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class correctly extracts node IDs from the given path.</li>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class returns the expected node ID for each phase.</li>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class handles cases where the input path is empty or contains only one phase.</li>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class correctly handles cases where the input path starts with a phase name (e.g., 'test.py::test_foo|')</li>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class does not modify any node IDs.</li>
                                            <li>The function `_extract_nodeid` of the `CoverageMapper` class raises an AssertionError if the input path is invalid or malformed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        243 output =
                                        522 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the context is empty or None, and return None as per the expected result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'None', 'actual_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        83 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</p>
                                    <p><strong>Why Needed:</strong> To filter out setup phase when include_phase=run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeid is None', 'expected_value': '', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        139 input +
                                        82 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 216, 220, 224-225, 228-230)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</p>
                                    <p><strong>Why Needed:</strong> To extract the correct node ID from run phase context in coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'node ID extraction', 'expected_value': 'test.py::test_foo', 'actual_value': 'test.py::test_foo'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        99 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_contexts_by_lineno_exception</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the coverage mapper's behavior when encountering an exception while extracting contexts by line number.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the test fails due to an unexpected exception being raised during context extraction.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_data.contexts_by_lineno.side_effect is set to contexts_side_effect with the correct side effect.</li>
                                            <li>call_count[0] is incremented correctly before raising the exception.</li>
                                            <li>the exception is not raised within the first call to contexts_by_lineno</li>
                                            <li>the exception raises an Exception object with the correct message and context number</li>
                                            <li>the exception does not cause any other tests to fail</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        141 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152, 156, 160-162, 167-170, 199, 202)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</p>
                                    <p><strong>Why Needed:</strong> To test the case where coverage data has no measured files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is an empty dictionary', 'expected_result': '{}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        75 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 44-45, 118, 121-122, 127-128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Contexts</p>
                                    <p><strong>Why Needed:</strong> To skip non-Python files from coverage report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "mocked mock_data.measured_files.return_value is equal to ['file.txt', 'data.json']", 'expected_result': ['file.txt', 'data.json']}</li>
                                            <li>{'assertion': 'mocked mock_data.contexts_by_lineno.return_value is empty', 'expected_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        111 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_coverage_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> To test that coverage.py is installed and properly loaded into the environment.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'coverage.py is imported correctly', 'expected_result': 'coverage.py should be imported from the Python path.'}</li>
                                            <li>{'name': 'CoverageMapper is created successfully', 'expected_result': 'CoverageMapper should be created with a Config object.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        166 input +
                                        104 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> To test that the function returns None when no .coverage file exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The result of _load_coverage_data() is not None.', 'expected_value': 'None'}</li>
                                            <li>{'description': 'Any warnings are present in the mapper.warnings list.', 'expected_value': ['W001']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        100 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_analysis_exception_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that analysis exception handling prevents adding an empty coverage report.</p>
                                    <p><strong>Why Needed:</strong> To prevent adding an empty coverage report when analysis2 raises an exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the `map_source_coverage` function returns an empty list of warnings.</li>
                                            <li>The test verifies that any warning messages contain 'COVERAGE_ANALYSIS_FAILED'.</li>
                                            <li>The test verifies that the `map_source_coverage` function sets the expected warnings to be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        108 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_empty_statements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestMapSourceCoverage test_empty_statements</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly handles a case where there are no statements in the file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_cov.get_data.return_value is empty list', 'expected': [], 'actual': []}</li>
                                            <li>{'name': 'mock_cov.analysis2.return_value is correct', 'expected': ['empty.py', [], [], [], []], 'actual': ['empty.py', [], [], [], []]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        178 input +
                                        123 output =
                                        301 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259-261, 273-274, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_include_test_files_when_not_configured</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that test files are included when omit_tests_from_coverage is False.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage map does not include all test files when omitting tests from coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `covered` count for each file should be greater than or equal to 1.</li>
                                            <li>The `missed` count for each file should be less than or equal to 0.</li>
                                            <li>All test files (`/project/tests/test_foo.py`) should be included in the coverage map.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        122 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Map Source Coverage</p>
                                    <p><strong>Why Needed:</strong> This test is needed to ensure that non-Python files are skipped from coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'mock_data.measured_files.return_value should be an empty list', 'expected_result': [], 'message': 'Expected mock_data.measured_files.return_value to be an empty list'}</li>
                                            <li>{'assertion': 'mock_data.contexts_by_lineno.return_value should be an empty dictionary', 'expected_result': {}, 'message': 'Expected mock_data.contexts_by_lineno.return_value to be an empty dictionary'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        143 output =
                                        297 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 44-45, 243-244, 246-249, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_test_files_when_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Map Source Coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that test files are skipped when omit_tests_from_coverage is True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Test case 1: Test file should be skipped', 'description': 'The test file should not be included in the coverage report.', 'expected_result': [], 'actual_result': []}</li>
                                            <li>{'name': 'Test case 2: Test file is included in the coverage report', 'description': 'The test file should be included in the coverage report.', 'expected_result': ['Expected result'], 'actual_result': ['Actual result']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        182 input +
                                        149 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 243-244, 246-248, 250, 252-255, 257, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_all_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all phases are accepted when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage mapping for 'all' phase configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mapper should return the same nodeid for any phase.</li>
                                            <li>The mapper should match the expected nodeids for each phase.</li>
                                            <li>No unexpected nodeids are returned for phases other than 'setup', 'run', and 'teardown'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        305 input +
                                        97 output =
                                        402 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</p>
                                    <p><strong>Why Needed:</strong> The test extracts node ID from an empty string, which should return None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None', 'actual_value': 'assert mapper._extract_nodeid("") is None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        86 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</p>
                                    <p><strong>Why Needed:</strong> None input returns None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        66 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_run_phase_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that run phase is the default filter.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where `run` phase is not included in coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_extract_nodeid` should return the node ID when the phase matches.</li>
                                            <li>The function `_extract_nodeid` should return None when the phase does not match.</li>
                                            <li>The function `_extract_nodeid` should not throw an error or raise an exception when the phase is setup or teardown.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        110 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_setup_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that setup phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test would incorrectly filter out nodes in the setup phase due to missing configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _extract_nodeid should return the nodeid of the specified module and phase.</li>
                                            <li>If the phase does not match 'setup', the function should return None for that phase.</li>
                                            <li>If the phase is neither 'setup' nor 'run' (or 'teardown'), the function should return None for those phases as well.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        126 output =
                                        419 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_teardown_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that teardown phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the teardown phase configuration does not filter out nodeids for certain phases.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        125 output =
                                        421 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233-234, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</p>
                                    <p><strong>Why Needed:</strong> To ensure that the node id is extracted correctly when there are no phase delimiters in the import statement.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'test_foo.py::test_bar', 'actual': 'test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        93 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 44-45, 216, 220, 224, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_full_logic</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_extract_contexts_full_logic function exercises all paths in _extract_contexts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a file's coverage is not fully included in the extracted contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'test_app.py::test_one' in result</li>
                                            <li>assert 'test_app.py::test_two' in result</li>
                                            <li>assert len(result['test_app.py::test_one']) == 1</li>
                                            <li>assert one_cov[0].line_count == 2</li>
                                            <li># lines 1 and 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        128 output =
                                        541 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152-153, 156, 160-163, 165, 167-168, 173, 176, 178-184, 187-189, 191-194, 196, 199-200, 202, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_nodeid_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the coverage mapper's ability to extract node IDs for different phases and contexts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the coverage mapper correctly identifies missing lines in the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _extract_nodeid should return 'test.py::test' when called with a valid context (e.g., 'test.py::test|setup').</li>
                                            <li>The function _extract_nodeid should return None when called with an invalid context (e.g., 'test.py::test_no_phase').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        122 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-234, 236, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_no_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the case where no coverage files exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function does not raise an exception when no coverage files are found, but instead returns None or other unexpected values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `mapper._load_coverage_data()` should return `None` when there are no .coverage files.</li>
                                            <li>The function `mapper.warnings` should contain exactly one warning with code 'W001'.</li>
                                            <li>The current implementation of the test does not raise an exception when no coverage files exist, but instead returns None or other unexpected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        135 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_read_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `CoverageMapper` raises an error when trying to load corrupted coverage data.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where the test fails due to a corrupt coverage file being loaded, which would cause the `CoverageMapper` to incorrectly report no coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_load_coverage_data()` should raise an exception when it encounters a corrupted coverage file.</li>
                                            <li>Any warnings generated by the `CoverageMapper` should contain the message 'Failed to read coverage data'.</li>
                                            <li>The test should fail if any warnings are generated, indicating that the coverage data is corrupt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        137 output =
                                        480 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94-96, 107-111, 114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_with_parallel_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle parallel coverage files from xdist and verify that it correctly updates the CoverageData instances.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling parallel coverage files, which can lead to incorrect coverage data being reported if not properly updated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock instances of `CoverageData` should have been called with at least two times.</li>
                                            <li>The `update` method of the mock instances should be called.</li>
                                            <li>The number of calls to `update` for each mock instance should be greater than or equal to 1.</li>
                                            <li>Each mock instance's `update` method should be called before any other method is called on it.</li>
                                            <li>The `update` method should not be called multiple times with the same arguments if it was already called once.</li>
                                            <li>If a mock instance's `update` method is called, it should only be called once per test.</li>
                                            <li>If a mock instance's `update` method is called multiple times, it should raise an AssertionError.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        378 input +
                                        217 output =
                                        595 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94, 98, 101-104, 106)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_coverage_no_data</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_map_coverage_no_data function returns an empty dictionary when _load_coverage_data returns None.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the mapper does not handle the case of no coverage data being loaded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mapper should return an empty dictionary when _load_coverage_data returns None.</li>
                                            <li>_load_coverage_data() was called with argument None</li>
                                            <li>No coverage data is available for mapping</li>
                                            <li>mapper._load_coverage_data() did not return a non-None value</li>
                                            <li>mapper.map_coverage() should have been called with an empty dictionary</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        135 output =
                                        363 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-45, 58-60)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_analysis_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `map_source_coverage` method skips files with errors during analysis.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where an error in analysis results in incorrect skipping of source code files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_cov.analysis2.assert_called_once_with(mock_data)</li>
                                            <li>mock_cov.get_data.return_value.measured_files.return_value == ['app.py']</li>
                                            <li>entries == []</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        98 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_comprehensive</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should exercise all paths in map_source_coverage to ensure comprehensive coverage of source files.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the CoverageMapper is correctly analyzing all possible paths from the map_source_coverage configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function mapper.map_source_coverage() returns a list containing one entry with file_path='app.py', statements=3, covered=2, missed=1, and coverage_percent=66.67.</li>
                                            <li>The entries in the returned list should include all possible paths from map_source_coverage configuration.</li>
                                            <li>All files in the source directory should be included in the analysis.</li>
                                            <li>Statements should be counted correctly based on their actual values.</li>
                                            <li>Covered statements should match the number of statements in the file.</li>
                                            <li>Missed statements should be zero or less, not greater than the total number of statements.</li>
                                            <li>Coverage percentage should be between 0 and 100, inclusive.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        345 input +
                                        202 output =
                                        547 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_make_warning</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `make_warning` factory function to ensure it correctly returns a WarningCode.W001_NO_COVERAGE instance with the expected message and detail.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where an invalid or unknown code is passed to the `make_warning` function, resulting in unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The returned warning has the correct `code` attribute set to `WarningCode.W001_NO_COVERAGE`.</li>
                                            <li>The message of the warning contains the expected string 'No .coverage file found'.</li>
                                            <li>The detail of the warning matches the provided string 'test-detail'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        139 output =
                                        375 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_code_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that warning codes have correct values.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the warning code for W001_NO_COVERAGE is set to an incorrect value, potentially leading to unexpected behavior or errors in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'assert WarningCode.W001_NO_COVERAGE.value == "W001"', 'description': "Checks that the assertion correctly sets the warning code to 'W001'"}</li>
                                            <li>{'message': 'assert WarningCode.W101_LLM_ENABLED.value == "W101"', 'description': "Checks that the assertion correctly sets the warning code to 'W101'"}</li>
                                            <li>{'message': 'assert WarningCode.W201_OUTPUT_PATH_INVALID.value == "W201"', 'description': "Checks that the assertion correctly sets the warning code to 'W201'"}</li>
                                            <li>{'message': 'assert WarningCode.W301_INVALID_CONFIG.value == "W301"', 'description': "Checks that the assertion correctly sets the warning code to 'W301'"}</li>
                                            <li>{'message': 'assert WarningCode.W401_AGGREGATE_DIR_MISSING.value == "W401"', 'description': "Checks that the assertion correctly sets the warning code to 'W401'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        256 output =
                                        496 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWarning.to_dict() method to ensure it returns the correct warning code and detail.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the 'to_dict()' method of ReportWarning class does not return the expected warning details for certain warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return a dictionary with the correct warning code and detail.</li>
                                            <li>The function should return the same warning details even when no detail is provided.</li>
                                            <li>The function should handle WarningCode.W001_NO_COVERAGE correctly.</li>
                                            <li>The function should handle WarningCode.W101_LLM_ENABLED correctly.</li>
                                            <li>The function should not raise any errors for valid warnings with missing detail.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        148 output =
                                        424 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_known_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Verify creation of warning with known code.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case unknown code is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function make_warning() returns a Warning object with the correct code and message.</li>
                                            <li>The detail attribute of the Warning object is None, indicating no additional information about the warning.</li>
                                            <li>The assertion that w.code == WarningCode.W101_LLM_ENABLED checks if the created warning has the correct code.</li>
                                            <li>The assertions that w.message == WARNING_MESSAGES[WarningCode.W101_LLM_ENABLED] and w.detail is None check if the created warning has the expected message and no additional information.</li>
                                            <li>If unknown code was used, make_warning() should raise an exception or return a Warning object with incorrect attributes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        167 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</p>
                                    <p><strong>Why Needed:</strong> To test the behavior of `make_warning` when it encounters an unknown warning code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'missing_message_for_valid_code', 'expected': 'Unknown warning.', 'actual': 'Unknown warning.'}</li>
                                            <li>{'name': 'restoring_original_message', 'expected': 'WARNING_MESSAGES[missing_code] = old_message', 'actual': 'WARNING_MESSAGES[missing_code] = old_message'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        202 input +
                                        132 output =
                                        334 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</p>
                                    <p><strong>Why Needed:</strong> The test is needed to ensure that the `make_warning` function creates a warning with detail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'code', 'value': 'WarningCode.W301_INVALID_CONFIG'}</li>
                                            <li>{'name': 'detail', 'value': 'Bad value'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        91 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</p>
                                    <p><strong>Why Needed:</strong> Because the `code.value` attribute is expected to be a string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert isinstance(code.value, str)', 'expected_result': 'True'}</li>
                                            <li>{'name': "assert code.value.startswith('W')", 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        102 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_no_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for errors maximal</p>
                                    <p><strong>Why Needed:</strong> To test the warning_to_dict method of ReportWarning class without including detail in the dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "data == {'code': 'W001', 'message': 'No coverage'}", 'expected_result': {'code': 'W001', 'message': 'No coverage'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        92 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_non_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_non_python_file</p>
                                    <p><strong>Why Needed:</strong> The test should return False for non-.py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_python_file() should return False for non-.py files', 'expected_result': False, 'actual_result': 'foo/bar.txt'}</li>
                                            <li>{'name': 'is_python_file() should return False for non-.py files (2)', 'expected_result': False, 'actual_result': 'foo/bar.pyc'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        130 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_python_file</p>
                                    <p><strong>Why Needed:</strong> The function `is_python_file` should be able to identify .py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'type', 'expected': 'str', 'actual': 'bool'}</li>
                                            <li>{'name': 'extension', 'expected': '.py', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        103 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_makes_path_relative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_makes_path_relative</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function correctly makes a path relative to the test directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': '/tmp/test_dir/subdir/file.py', 'expected_result': '/tmp/test_dir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        86 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function returns a normalized path when no base is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 'foo/bar', 'message': "Expected result to be 'foo/bar'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        91 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_already_normalized</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_already_normalized</p>
                                    <p><strong>Why Needed:</strong> The function should be able to handle already-normalized paths without raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'foo/bar', 'actual': 'normalize_path('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        73 output =
                                        169 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_forward_slashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_forward_slashes</p>
                                    <p><strong>Why Needed:</strong> Converts backslashes in path strings to forward slashes for correct behavior in Windows.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '/foo/bar', 'actual': 'foo\\bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        74 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly removes trailing slashes from file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert normalize path returns correct result', 'expected_result': 'foo/bar', 'actual_result': 'foo/bar/'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        91 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> To ensure that custom patterns are correctly excluded from the test directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'should skip path', 'condition': "assert should_skip_path('tests/conftest.py', exclude_patterns=['test*']) is True"}</li>
                                            <li>{'message': 'should not skip path', 'condition': "assert should_skip_path('src/module.py', exclude_patterns=['test*']) is False"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        126 output =
                                        252 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_normal_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_normal_path</p>
                                    <p><strong>Why Needed:</strong> The test should not be skipped for normal paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should not skip normal path', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        70 output =
                                        166 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_git</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the `should_skip_path` function correctly identifies .git directories as requiring skipping.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path returns True for .git/objects/foo', 'value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        87 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the file is a .pyc file, which is cached by Python and should not be included in the test output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert should_skip_path('foo/__pycache__/bar.pyc') is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        80 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_venv</p>
                                    <p><strong>Why Needed:</strong> Because the test case is checking if venv directories are skipped, which can cause issues with testing and environment setup.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': True, 'actual': 'True'}</li>
                                            <li>{'expected': '.venv/lib/python/site.py', 'actual': '.venv/lib/python/site.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        108 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that a non-.py file does not match the expected criteria.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in cases where a user might mistakenly assume a non-.py file is Python code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert is_python_file('module.txt') is False</li>
                                            <li>assert is_python_file('module.pyc') is False</li>
                                            <li>assert is_python_file('module') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        210 input +
                                        97 output =
                                        307 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing if a file is a Python file.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test might incorrectly identify non-Python files as such.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `is_python_file` correctly identifies .py files and returns True.</li>
                                            <li>It handles paths with spaces in them by converting them to a single space.</li>
                                            <li>It supports relative paths by resolving them to absolute paths.</li>
                                            <li>It ignores non-existent files, returning False for those.</li>
                                            <li>It does not incorrectly identify non-Python file extensions (e.g., .txt).</li>
                                            <li>It correctly identifies Python modules with different casing (e.g., `module.py` and `Module.py`).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        155 output =
                                        367 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_path_not_under_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makes sure make_relative function returns a normalized absolute path when the input paths are not relative to each other.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where make_relative function fails to return a normalized absolute path when the input paths are not relative to each other.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'project1' should be included in the result.</li>
                                            <li>The 'file.py' should also be included in the result.</li>
                                            <li>The result should be an absolute path (i.e., it should start with a slash).</li>
                                            <li>The relative_to parameter should fail and return None.</li>
                                            <li>The make_relative function should correctly handle cases where the input paths are not relative to each other.</li>
                                            <li>The test should pass even if the input paths have different names or extensions.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        301 input +
                                        171 output =
                                        472 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Make Relative - Success</p>
                                    <p><strong>Why Needed:</strong> To test that the `make_relative` function correctly resolves relative paths to file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '/subdir/file.py', 'actual': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        70 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_make_relative_with_none_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function correctly handles cases where the base path is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result is equal to expected result', 'expected_result': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        77 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that backslashes are correctly converted to forward slashes in file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '/path/to/file.py', 'actual': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        78 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</p>
                                    <p><strong>Why Needed:</strong> To ensure the `normalize_path` function correctly normalizes path objects, including those with nested directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'path/to/file.py', 'actual_value': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        85 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `pathlib` module correctly handles paths with trailing slashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The normalized path has no trailing slash.', 'expected_result': 'path/to/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        85 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</p>
                                    <p><strong>Why Needed:</strong> To ensure that regular paths are not skipped and should be included in the coverage report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Regular path is included in the coverage report', 'expected_result': True}</li>
                                            <li>{'description': 'Regular path should be excluded from the coverage report', 'expected_result': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        109 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</p>
                                    <p><strong>Why Needed:</strong> The test should skip the .git directory because it contains Git hooks that are not necessary for the current scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should be True', 'description': 'The function should return True when the path is a .git directory.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        93 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that paths starting with a skip directory name are properly skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should be True', 'description': 'The function should return True for the given path.'}</li>
                                            <li>{'name': '.venv', 'description': '.venv is a file that starts with a skip directory name.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        116 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the '__pycache__' directory contains a cached Python file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should skip __pycache__ directory', 'description': 'The test should return True indicating that the path is skipped.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        90 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_site_packages</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> /usr/lib/python3.12/site-packages/pkg/mod.py</p>
                                    <p><strong>Why Needed:</strong> Because it's a site-package directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>should be skipped</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        45 output =
                                        156 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</p>
                                    <p><strong>Why Needed:</strong> Because the 'venv' directory contains a Python package, which should be skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'venv/lib/python3.12/site.py', 'expected': True}</li>
                                            <li>{'path': '.venv/lib/python3.12/site.py', 'expected': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        108 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> Custom exclude patterns are used to skip certain files or directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should be true', 'description': 'The function should return True when the path is excluded.', 'expected_value': 'True'}</li>
                                            <li>{'name': 'should be false', 'description': 'The function should return False when the path is not excluded.', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        128 output =
                                        260 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_gemini_provider.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">25 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotate_loop_daily_limit_hit</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the 'Gemini requests-per-day limit reached' error is thrown when the daily limit for a model is hit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the Gemini provider does not correctly handle daily limits being exceeded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'Gemini requests-per-day limit reached' in res.error</li>
                                            <li>assert 'requests per day' in res.error</li>
                                            <li>assert 'limit exceeded' in res.error</li>
                                            <li>assert 'daily limit hit' in res.error</li>
                                            <li>assert 'requests per day exceeded' in res.error</li>
                                            <li>assert 'limit exceeded daily' in res.error</li>
                                            <li>assert 'requests per day limit reached' in res.error</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        157 output =
                                        524 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-227, 232-233, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotation_exceptions_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'GenerationFailure' exception is raised when Gemini generation fails</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where 'GenerationFailure' exception is not raised due to internal model exhaustion.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>MockGenFailure (Line 293)</li>
                                            <li>MockResExhausted (Lines 300, 301)</li>
                                            <li>_GeminiRateLimitExceeded (Lines 300, 301)</li>
                                            <li>assert 'Gemini requests-per-day' in res.error or 'rate limits reached' in res.error</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        730 input +
                                        119 output =
                                        849 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-236, 239-244, 263-265, 268, 293, 295, 299-303, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_coverage_gaps</span>
                            <div class="test-meta">
                                <span>161ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Prevents bug in coverage gaps test by ensuring proper rate limiting and annotation logic for various scenarios.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that could cause coverage gaps due to improper rate limiting or annotation logic.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>1. Mock imports are set up correctly without causing errors.</li>
                                            <li>2. Context too long error is raised with the correct error message.</li>
                                            <li>3. RPD (Rate Limiting and Parsing) function returns the expected value for requests_per_day.</li>
                                            <li>4. Fallback models are properly fetched and added to the list of available models.</li>
                                            <li>5. Input limits logic works correctly, providing the expected input token limit.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        821 input +
                                        149 output =
                                        970 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">173 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181-182, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 254-255, 259, 340, 343, 346, 348-356, 358-361, 363-364, 366-367, 435, 437-439, 441-442, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-498, 502-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-564, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_parse_preferred_models_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test parsing preferred models coverage</p>
                                    <p><strong>Why Needed:</strong> To test the behavior of GeminiProvider when no model is specified in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected _parse_preferred_models to return an empty list', 'expected_value': [], 'message': 'The function should not parse any preferred models.'}</li>
                                            <li>{'name': 'Expected mock_config.model to be None after setting it to "ALL"', 'expected_value': 'None', 'message': 'mock_config.model should be set to None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        131 output =
                                        287 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 134-135, 137-141, 143-144, 524-527)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_prune_daily_requests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_prune_daily_requests</p>
                                    <p><strong>Why Needed:</strong> To test the behavior of the GeminiRateLimiter when a daily request is pruned after being older than 24 hours.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The length of _daily_requests should be 0 after pruning', 'expected_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        85 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 39-42, 81-82, 84, 87-89)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_tpm_available_fallback</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the test_tpm_available_fallback function behaves correctly when a token is requested.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the function does not wait for the TPM to become available after requesting tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The loop should finish without returning if `remaining` decreases and `request_tokens <= limit`.</li>
                                            <li>If `request_tokens` is massive, the function should return 0.0 at line 106/108.</li>
                                            <li>The `tokens_used` value should be equal to `limit` when all tokens are used up.</li>
                                            <li>The `remaining` value should decrease by `request_tokens` for each iteration of the loop.</li>
                                            <li>If `remaining + request_tokens <= limit`, the function should not return and wait for the TPM to become available.</li>
                                            <li>The `time.monotonic()` difference between the start and end times of the loop should be less than or equal to 30 seconds.</li>
                                            <li>The total number of tokens used by the function should be equal to `limit` when all tokens are used up.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        524 input +
                                        233 output =
                                        757 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39-42)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_import_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test annotation when google-generativeai is not installed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential import error that could occur when trying to annotate an annotation with a module that does not exist (i.e., `google.generativeai` is not installed).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation contains the string 'google-generativeai not installed' in its error message.</li>
                                            <li>The annotation includes the key-value pair 'module': 'google.generativeai'.</li>
                                            <li>The annotation includes the key-value pair 'outcome': 'passed'.</li>
                                            <li>The annotation includes the nodeid 't'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        259 input +
                                        139 output =
                                        398 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 134-135, 137-141, 143-144, 164-165, 167-169)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_no_token</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotation fails when token is missing and GEMINI_API_TOKEN is not set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test annotates an empty result without checking for the presence of a GEMINI_API_TOKEN environment variable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The error message should contain 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The annotation should fail when GEMINI_API_TOKEN is missing.</li>
                                            <li>The annotation should report an error indicating that GEMINI_API_TOKEN is not set.</li>
                                            <li>The test should verify the presence of a GEMINI_API_TOKEN environment variable before annotating the result.</li>
                                            <li>The test should check for the absence of a GEMINI_API_TOKEN environment variable in the annotation string.</li>
                                            <li>The test should report an error when trying to annotate without setting GEMINI_API_TOKEN.</li>
                                            <li>The test should verify that the annotation is not successful with missing GEMINI_API_TOKEN.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        207 output =
                                        520 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_rate_limit_retry</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly annotates a rate limit retry scenario.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the case where the GeminiProvider is called with a 429 status code due to rate limiting, and then receives a successful response after a retry.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation's `scenario` field matches the expected value 'Recovered Scenario'.</li>
                                            <li>The mock `mock_post.call_count` is set to 2 when the test call fails with a 429 status code, indicating that the provider retries the request.</li>
                                            <li>The mock `mock_get.return_value.json.return_value` is set to a valid JSON response for a successful rate limit retry scenario.</li>
                                            <li>The `test_result` nodeid matches the expected value 'test1'.</li>
                                            <li>The annotation's `error` field is None when the test call succeeds with a 200 status code, indicating that no error occurred.</li>
                                            <li>The mock `_parse_response` returns a valid response for a successful rate limit retry scenario.</li>
                                            <li>The `mock_get.return_value.status_code` matches the expected value '429' when the test call fails with a 429 status code.</li>
                                            <li>The `mock_get.return_value.headers` set to `{</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        636 input +
                                        264 output =
                                        900 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">214 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-237, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_success</span>
                            <div class="test-meta">
                                <span>412ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the _annotate_internal method returns a successful annotation with no error when the response from _call_gemini is in the expected format.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the GeminiProvider does not correctly handle responses from _call_gemini with the expected format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The scenario 'Success Scenario' should be returned by _annotate_internal.</li>
                                            <li>_parse_response returns a Mock object with the correct scenario and no error.</li>
                                            <li>The annotation does not contain any error information.</li>
                                            <li>The annotation's scenario matches the expected value.</li>
                                            <li>_build_prompt is called before _parse_response to avoid complex dependencies, but this test does not require it.</li>
                                            <li>The response from _call_gemini has the correct format (text and tokens).</li>
                                            <li>The annotation correctly handles a successful response from _call_gemini with no error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        649 input +
                                        188 output =
                                        837 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">208 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-568, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_availability</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the availability of a Gemini provider is checked correctly when environment variables are set.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the availability of a Gemini provider is not checked in certain environments, such as when environment variables like GEMINI_API_TOKEN are set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _check_availability() returns False when environment variable GEMINI_API_TOKEN is set.</li>
                                            <li>The function _check_availability() returns True when environment variable GEMINI_API_TOKEN is not set.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        235 input +
                                        119 output =
                                        354 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 134-135, 137-141, 143-144, 332-333, 335)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_exceptions</span>
                            <div class="test-meta">
                                <span>60.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the GeminiProvider class correctly annotates retry exceptions for models with high request rates.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the GeminiProvider class fails to annotate retry exceptions for models with high request rates, potentially leading to incorrect model exhaustion tracking.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'm1' model should be marked as exhausted after a daily limit is exceeded.</li>
                                            <li>The 'm1' model should be marked as available again after a retry-after cleanup is triggered.</li>
                                            <li>The cooldown for the 'm1' model should exceed the time it took to reach the daily limit.</li>
                                            <li>The cooldown for the 'm1' model should not be reset immediately after a retry-after cleanup is triggered.</li>
                                            <li>Mock calls to '_ensure_models_and_limits' and '_call_gemini' should result in the correct side effects being simulated.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        651 input +
                                        187 output =
                                        838 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-237, 239-244, 263-265, 268, 272-276, 279-281, 283-286, 288-292, 318-320, 322-323, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_loop_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly clears the `_model_exhausted_at` dictionary after a successful annotation.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `GeminiProvider` fails to clear the `_model_exhausted_at` dictionary after a successful annotation, potentially leading to inconsistent model exhaustion checks.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `_model_exhausted_at[model]` is set to None before the annotation process starts.</li>
                                            <li>After calling `provider._annotate_internal`, the value of `_model_exhausted_at[model]` becomes False.</li>
                                            <li>If a successful annotation occurs, then the value of `_model_exhausted_at[model]` should be cleared to avoid inconsistent model exhaustion checks.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        482 input +
                                        160 output =
                                        642 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-94, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 254, 259, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_ensure_rate_limits_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed::test_ensure_rate_limits_error</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the GeminiProvider raises an error when rate limiting is attempted with a non-integer value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Rate limits should be enforced', 'description': 'The function should return a valid rate limit configuration.', 'expected_value': 10, 'actual_value': 10}</li>
                                            <li>{'name': 'Exception is raised when rate limiting is attempted with non-integer value', 'description': 'The function should raise an exception when rate limiting is attempted with a non-integer value.', 'expected_exception': 'RateLimitError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        160 output =
                                        316 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 134-135, 137-141, 143-144, 346, 348-356, 358-361, 363-364, 366-367)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed::test_fetch_available_models_error</p>
                                    <p><strong>Why Needed:</strong> To test that an exception is raised when fetching available models fails due to a network error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'models are empty', 'expected_value': [], 'actual_value': '[]'}</li>
                                            <li>{'name': 'limit_map is empty', 'expected_value': {}, 'actual_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        106 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_invalid_json</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fetching available models with invalid JSON data prevents a bug.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential issue where the GeminiProvider fetches models from an invalid JSON response, which could lead to incorrect model availability information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'm1' model should not be included in the list of available models.</li>
                                            <li>The 'm2' model should not be included in the list of available models.</li>
                                            <li>The 'm3' model should be included in the list of available models.</li>
                                            <li>The 'inputTokenLimit' value for the 'm3' model should match its supported generation methods.</li>
                                            <li>The 'limit_map' dictionary should contain only valid keys ('m1', 'm2', and 'm3').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        169 output =
                                        509 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 476-477, 537, 539-543, 547-548, 550-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method calls the `mock_ensure` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock Ensure Function', 'expected_calls': [1], 'message': 'The `mock_ensure` function was called once.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        86 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 486, 488-491, 493)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Gemini provider can correctly parse rate limits and return the expected configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'requests_per_minute', 'expected_value': 'None'}</li>
                                            <li>{'name': 'tokens_per_minute', 'expected_value': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        101 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 134-135, 137-141, 143-144, 449-457, 459-460, 463-466)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_prune_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the prune logic of the GeminiRateLimiter to ensure it removes old requests within a specified time window.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where old requests are not removed from the limiter's cache, leading to performance degradation or incorrect rate limiting behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of _request_times should be 1 after pruning.</li>
                                            <li>The length of _token_usage should be 1 after pruning.</li>
                                            <li>The first element in _request_times should be equal to the current time minus 10 seconds.</li>
                                            <li>_request_times[0] should be equal to now - 10.0</li>
                                            <li>The first element in _token_usage should be equal to (now - 10.0, 10).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        168 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-42, 81-85, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that record tokens with a negative value returns an empty list of token usage.</p>
                                    <p><strong>Why Needed:</strong> To ensure the rate limiter correctly handles invalid input values, specifically negative token counts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected len(limiter._token_usage) to be 0'}</li>
                                            <li>{'message': 'Actual: {len(limiter._token_usage)}', 'value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        96 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39-42, 66-67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpd_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the rate limiting mechanism</p>
                                    <p><strong>Why Needed:</strong> The test ensures that the rate limiting mechanism correctly limits the number of requests to a resource within a certain time frame.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'limiter.next_available_in(100) is None', 'description': 'The next available in time should be None after 100 requests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        91 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 45-46, 48-50, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpm_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the RPM limit is correctly enforced for the first two requests and that it resets after the third request.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter does not reset properly after the third request, leading to unexpected behavior in subsequent requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The next_available_in method returns 0.0 for the first two requests and 60.0 for the third request.</li>
                                            <li>The limit is correctly reset after the third request.</li>
                                            <li>The rate limiter does not wait for more than 1 minute between requests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        130 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-97, 100-102)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_seconds_until_tpm_available_branches</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter correctly returns seconds until TPM available when no tokens are requested or more than limit is exceeded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the rate limiter does not return a correct value for seconds_until_tpm_available when no tokens are requested, and also ensures that it returns a correct value even when more than the limit of tokens is requested but usage is still within the limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert limiter._seconds_until_tpm_available(now, 0) == 0.0</li>
                                            <li>assert limiter._seconds_until_tpm_available(now, 150) == 0.0</li>
                                            <li>assert wait > 0 and wait <= 60.0 + 1e-9</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        377 input +
                                        168 output =
                                        545 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 100-101, 103-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_daily_limit_exceeded</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `wait_for_slot` method raises a `GeminiRateLimitExceeded` exception when the daily limit is exceeded.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential rate limiter error where the daily limit is exceeded and the user does not receive an error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `limit_type` attribute of the raised exception is set to 'requests_per_day'.</li>
                                            <li>The `value` attribute of the raised exception contains the string 'requests_per_day'.</li>
                                            <li>The `exc.value.limit_type` attribute matches the expected value 'requests_per_day'.</li>
                                            <li>The `exc.value.limit_type` attribute matches the expected value 'requests_per_day'.</li>
                                            <li>The `exc.value.limit_type` attribute is set to 'requests_per_day' and its value is a string.</li>
                                            <li>The `exc.value.limit_type` attribute is set to 'requests_per_day' and its value is a string.</li>
                                            <li>The `exc.value.limit_type` attribute matches the expected value 'requests_per_day'.</li>
                                            <li>The `exc.value.limit_type` attribute matches the expected value 'requests_per_day'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        245 output =
                                        508 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 32-34, 39-42, 45-46, 48-50, 58-60, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_sleeps</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the wait_for_slot function waits for a sufficient amount of time before returning.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter does not wait long enough for subsequent requests to be processed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The next_available_in method is called with an argument greater than or equal to 10.0 seconds.</li>
                                            <li>The mock_sleep function is called once with an argument of 10.0 seconds.</li>
                                            <li>The time.monotonic value returned by the mock_next_available_in function is greater than or equal to 10.0 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        133 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 58-59, 61-63, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_hashing.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_different_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_different_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that different configurations of the same provider produce different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config1 and config2 should have different hashes', 'expected_value': 'different hashes'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        79 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure the computed hash is short and can be easily stored in a database or used for other purposes where storage space is limited.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'hash length', 'expected': 16, 'actual': {'type': 'int', 'value': 16}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        100 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_consistent_with_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeFileSha256::test_consistent_with_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the computed SHA-256 hash of a file matches its content hash.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'content_hash', 'actual': 'file_hash'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        78 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 32, 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `compute_file_sha256` function correctly hashes file contents.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected length of hash to be 64 bytes', 'expected': 64, 'actual': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        88 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_different_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_different_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that different keys produce different signatures.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Different keys should produce different signatures.', 'description': 'The HMAC signature for a given input content and key should be unique.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        78 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_with_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_with_key</p>
                                    <p><strong>Why Needed:</strong> To test the computation of HMAC with a key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_length': 64, 'actual_length': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        68 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_consistent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_consistent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is consistent and produces the same output for the same input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'h1': 'hash1', 'h2': 'hash2'}, 'actual': {'h1': 'hash1', 'h2': 'hash1'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        100 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_length</p>
                                    <p><strong>Why Needed:</strong> The length of the hash is expected to be 64 characters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected hash length to be 64. Actual: %r'}</li>
                                            <li>expected_value</li>
                                            <li>actual_value</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        82 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</span>
                            <div class="test-meta">
                                <span>77ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'pytest' package is included in the dependency snapshot.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'includes pytest package', 'description': "The 'pytest' package should be present in the dependency snapshot."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        86 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</span>
                            <div class="test-meta">
                                <span>79ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_dependency_snapshot` function returns a dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'snapshot is a dict', 'expected': 'dict', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        80 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_loads_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_loads_key</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading a HMAC key from a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': "b'my-secret-key\n'", 'actual_value': "b'...'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        80 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 73, 76-77, 80-81)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</p>
                                    <p><strong>Why Needed:</strong> The test should return None if the key file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected to return None when missing key file exists'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        72 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 73, 76-78)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</p>
                                    <p><strong>Why Needed:</strong> To test that the function returns None when no key file is configured.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'type': 'NoneType', 'message': 'The function should return None.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        85 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 73-74)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_integration_gate.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">16 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_aggregation_defaults</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test aggregation defaults with no aggregate directory specified.</p>
                                    <p><strong>Why Needed:</strong> Without an aggregate directory, aggregation may not work as expected or may result in unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.aggregate_dir should be None</li>
                                            <li>config.aggregate_policy should be 'latest'</li>
                                            <li>config.aggregate_include_history should be False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        79 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</p>
                                    <p><strong>Why Needed:</strong> The test captures failed output by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.capture_failed_output', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        70 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context mode is set to 'minimal' by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.llm_context_mode', 'expected_value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        78 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> The LLM (Language Model) is not enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM is not enabled by default', 'description': 'The LLM should be disabled by default.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        85 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 123, 171, 284, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</p>
                                    <p><strong>Why Needed:</strong> The test omits all tests from the coverage report by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.omit_tests_from_coverage', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        76 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the provider is set to 'none' by default when no other value is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "config.provider == 'none'", 'expected_result': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        81 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the default configuration includes secret files and environment variables, which are not intended to be exposed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Excluding secret files', 'expected': ['llm_context_exclude_globs'], 'actual': ['secret']}</li>
                                            <li>{'name': 'Excluding .env files', 'expected': ['llm_context_exclude_globs'], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        127 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_deterministic_output</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the deterministic output of the integration gate.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that could cause non-deterministic output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `nodeid` values in the report are sorted by nodeid.</li>
                                            <li>All `nodeid` values are present in the report.</li>
                                            <li>No duplicates are present in the `nodeid` values.</li>
                                            <li>All `outcome` values are either 'passed' or 'failed'.</li>
                                            <li>The `tests` list contains exactly one test for each `nodeid`.</li>
                                            <li>Each `test_z`, `test_a`, and `test_m` is a valid test function.</li>
                                            <li>The output of the integration gate is deterministic (sorted by nodeid).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        164 output =
                                        477 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_empty_test_suite</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that an empty test suite produces a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the test suite is empty, ensuring the report is always valid and accurate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of tests in the report should be zero.</li>
                                            <li>The summary section of the report should contain no data.</li>
                                            <li>The 'total' key in the summary section should have a value of zero.</li>
                                            <li>The test counts are not affected by an empty test suite.</li>
                                            <li>The report does not contain any duplicate test names or IDs.</li>
                                            <li>There are no missing test results in the report.</li>
                                            <li>The test suite is correctly identified as empty in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        153 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_html_report_generation</span>
                            <div class="test-meta">
                                <span>37ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the full pipeline generates an HTML report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the HTML report is not generated correctly due to a change in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file "report.html" exists at the specified path.</li>
                                            <li>The string '<html' is present in the content of 'report.html'.</li>
                                            <li>The string 'test_pass' is present in the content of 'report.html'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        107 output =
                                        377 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">118 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_json_report_generation</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the full pipeline generates a valid JSON report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the pipeline where JSON reports are not generated correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_json` and `report_html` paths should exist in the temporary directory.</li>
                                            <li>The schema version of the report data should match the expected value.</li>
                                            <li>The summary statistics (total, passed, failed, skipped) should be correct.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        102 output =
                                        521 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/_git_info.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 2-3)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">138 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_report_root_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the ReportRoot object has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the report root is missing required fields, making it invalid to use as a schema.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' field is present in the data.</li>
                                            <li>The 'run_meta' field is present in the data.</li>
                                            <li>The 'summary' field is present in the data.</li>
                                            <li>The 'tests' field is present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        250 input +
                                        111 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_aggregation_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_aggregation_fields</p>
                                    <p><strong>Why Needed:</strong> To ensure that the RunMeta object has an 'is_aggregated' key and a 'run_count' value when it is used in aggregation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_aggregated', 'expected_value': 'True'}</li>
                                            <li>{'name': 'run_count', 'expected_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        111 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'RunMeta has run status fields' verifies that the RunMeta object contains the required status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the RunMeta object is missing certain status fields, potentially leading to incorrect analysis results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field should be present in the data.</li>
                                            <li>The 'interrupted' field should be present in the data.</li>
                                            <li>The 'collect_only' field should be present in the data.</li>
                                            <li>The 'collected_count' field should be present in the data.</li>
                                            <li>The 'selected_count' field should be present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        144 output =
                                        381 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</p>
                                    <p><strong>Why Needed:</strong> The schema version is needed to ensure compatibility with the gate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'SCHEMA_VERSION', 'value': '1.2.3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        75 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_test_case_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `TestCaseResult` object has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `TestCaseResult` object is missing some of its required fields, potentially causing incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>nodeid</li>
                                            <li>outcome</li>
                                            <li>duration</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        77 output =
                                        300 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_litellm_retry_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_all_retries_exhausted</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that all retries are exhausted when API call fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where LLMTokenRefreshRetry may not retry if all retries are exhausted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `provider.annotate` method should raise an exception with the error message.</li>
                                            <li>The `result.error` attribute should be set to a non-None value indicating an error.</li>
                                            <li>The `result` object should contain a `message` key with the error message.</li>
                                            <li>The `error` attribute of the `result.message` string should match the expected error message.</li>
                                            <li>The `provider.annotate` method should not return any result when all retries are exhausted.</li>
                                            <li>The `provider.annotate` method should raise an exception when all retries are exhausted and no result is returned.</li>
                                            <li>The `provider.annotate` method should set the `error` attribute of the `result` object to a non-None value indicating an error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        205 output =
                                        551 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_non_401_error_no_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that non-401 errors don't force token refresh.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of non-401 error, where the LLMTokenRefreshRetry test would fail due to a forced refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should not return an error with status code 500 (Internal server error).</li>
                                            <li>The annotation should have an error attribute set to the exception object.</li>
                                            <li>The annotation should not call the completion function with any arguments.</li>
                                            <li>The annotation should not raise an exception.</li>
                                            <li>The annotation should be None if the API call fails without raising an exception.</li>
                                            <li>The annotation's status code should match the expected 500 status code.</li>
                                            <li>The annotation's error attribute should have a non-None value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        169 output =
                                        536 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_retry_succeeds_after_transient_error</span>
                            <div class="test-meta">
                                <span>6.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that retry succeeds after transient error.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression in case of transient errors where the API call fails and needs to be retried.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the retry mechanism works correctly even when the initial API call fails.</li>
                                            <li>The test ensures that the retry process does not get stuck in an infinite loop due to transient errors.</li>
                                            <li>The test verifies that the scenario is updated correctly after a transient error occurs.</li>
                                            <li>The test checks if the error message is properly set and matches the expected format.</li>
                                            <li>The test verifies that the key assertions are met, including 'assert true' as required.</li>
                                            <li>The test ensures that the result object has an 'error' attribute that is None when no error occurred.</li>
                                            <li>The test verifies that the scenario is updated correctly after a transient error occurs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        433 input +
                                        187 output =
                                        620 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_token_refresh_on_401</span>
                            <div class="test-meta">
                                <span>5.96s</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 401 error triggers token refresh (lines 123-126).</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLMTokenRefreshRetry test case covers a scenario where the API call to refresh the token fails with a 401 status code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `provider.annotate` should be called twice with an error status code of 401.</li>
                                            <li>The second call to `provider.annotate` should have a valid response containing a new token.</li>
                                            <li>The third check in the test case should not trigger due to successful API call.</li>
                                            <li>The LLMTokenRefreshRetry test case should fail when the API call to refresh the token fails with a 401 status code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        157 output =
                                        630 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-188, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the GeminiProvider class is correctly instantiated when the 'gemini' provider is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected_value': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        89 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLMProvider class is correctly instantiated when a specific provider ('litellm') is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected_value': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        91 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_none_returns_noop</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_none_returns_noop</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the LLM returns a `NoopProvider` when the provider is set to 'none'. This is not a realistic scenario, as it would indicate that the LLM has no knowledge of the input data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected': 'None', 'got': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        113 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the OllamaProvider is correctly instantiated when a specific provider ('ollama') is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected_value': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        89 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_unknown_raises</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestLlmProviderContract::test_noop_implements_interface</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the NoopProvider class implements all required interface methods.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the NoopProvider class is not implemented correctly and may cause unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'annotate' method should be present on the provider.</li>
                                            <li>The 'is_available' method should be present on the provider.</li>
                                            <li>The 'get_model_name' method should be present on the provider.</li>
                                            <li>The 'config' attribute should be present on the provider.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        119 output =
                                        351 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_annotate_returns_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that NoopProvider returns an empty annotation when no nodes are annotated.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the annotate method of NoopProvider returns an annotation even if no nodes are annotated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation is an instance of LlmAnnotation</li>
                                            <li>annotation scenario is an empty string</li>
                                            <li>annotation why_needed is an empty string</li>
                                            <li>annotation key_assertions is an empty list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        249 input +
                                        102 output =
                                        351 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the model name returned by the NoopProvider is not empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert provider.get_model_name() == ""', 'expected_value': '', 'message': 'Expected get_model_name to return an empty string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        97 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_is_available</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_is_available</p>
                                    <p><strong>Why Needed:</strong> The NoopProvider class should always be available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_available() should return True', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        72 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 59)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_contract.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the schema requirements</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the LLM contract's annotation schema requires 'scenario' and 'why_needed' fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'field_name': 'required', 'expected_value': ['scenario', 'why_needed'], 'actual_value': [0, 1]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        85 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_from_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `AnnotationSchema.from_dict` method correctly parses a dictionary into an AnnotationSchema instance.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential issues where the `AnnotationSchema.from_dict` method fails to parse a dictionary with required keys, potentially leading to incorrect schema creation or other errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>checks password</li>
                                            <li>checks username</li>
                                            <li>correctly parses the 'scenario' key</li>
                                            <li>correctly parses the 'why_needed' key</li>
                                            <li>correctly parses the 'confidence' key</li>
                                            <li>has exactly two assertions for the 'key_assertions' list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        137 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestAnnotationSchema.test_schema_handles_empty</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the AnnotationSchema class correctly handles empty input scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'schema.scenario', 'value': '', 'expected_type': 'str'}</li>
                                            <li>{'name': 'schema.why_needed', 'value': '', 'expected_type': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        96 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_partial</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the schema has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the schema is not properly defined with required fields, potentially leading to invalid or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'scenario' in ANNOTATION_JSON_SCHEMA['properties'],</li>
                                            <li>assert 'why_needed' in ANNOTATION_JSON_SCHEMA['properties'],</li>
                                            <li>assert 'key_assertions' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        109 output =
                                        324 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test AnnotationSchema::test_schema_to_dict verifies that the `AnnotationSchema` instance is correctly serialized to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `AnnotationSchema` instance can be successfully converted to a dictionary, which is necessary for proper data storage and retrieval.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assertion 1</li>
                                            <li>assertion 2</li>
                                            <li># Ensure 'key_assertions' key exists in the dictionary</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        105 output =
                                        352 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 90-92, 94-96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the NoopProvider class can be instantiated correctly when a provider is set to 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected_type': 'NoopProvider', 'actual_type': 'get_provider(config)', 'message': 'Expected get_provider(config) to return NoopProvider, but got '}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        117 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `isinstance` function checks if an object is of a certain type. In this case, we want to ensure that the `provider` variable is actually an instance of `LLMProvider`, which is the expected implementation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The provider is an instance of LLMProvider', 'description': 'We expect the `provider` variable to be an instance of `LLMProvider`. This can be verified by checking if it has a certain attribute or method.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        150 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_returns_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that NoopProvider returns an empty annotation when the test function does not return any value.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM contract incorrectly returns an annotation for a non-executable test function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by NoopProvider is expected to be empty.</li>
                                            <li>No assertion was made in the provided code, indicating that it should return an empty annotation.</li>
                                            <li>The `annotate` method of the `NoopProvider` class is expected to return a `TestCaseResult` object with an empty string as its scenario.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        134 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_annotate_returns_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `annotate` method returns a valid LlmAnnotation-like object with the correct attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `annotate` method does not return an expected LlmAnnotation-like object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result has the expected 'scenario' attribute.</li>
                                            <li>The result has the expected 'why_needed' attribute.</li>
                                            <li>The result has the expected 'key_assertions' attribute.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        103 output =
                                        366 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</p>
                                    <p><strong>Why Needed:</strong> To ensure the contract handles empty code gracefully and returns a valid result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Expected the provider to return a non-empty result for an empty test code.', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        85 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_none_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Provider handles None context gracefully</p>
                                    <p><strong>Why Needed:</strong> To ensure the provider can handle cases where `None` is passed as a context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is_not_none', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        69 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</p>
                                    <p><strong>Why Needed:</strong> To ensure that all providers have an annotate method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'All providers should have an annotate method.', 'expected_result': 'True'}</li>
                                            <li>{'message': 'Each provider should have a callable annotate method.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        102 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 65-66, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_providers.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">52 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> The current implementation of annotate_handles_context may lead to a MemoryError when dealing with large contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotate_handles_context', 'description': 'This function is expected to handle the context correctly and not raise an exception.'}</li>
                                            <li>{'name': 'context_size', 'description': 'The size of the context should be within a reasonable limit (e.g., 1024 bytes).'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        121 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">187 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 263-265, 299, 311-312, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524-525, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider annotates a missing dependency correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the provider from reporting an error when a required library is not installed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation message includes the correct error message for installing the required library.</li>
                                            <li>The annotation message does not include any misleading information about the installation process.</li>
                                            <li>The annotation message provides a clear and concise explanation of what needs to be done to resolve the issue.</li>
                                            <li>The test passes with an empty annotation object if no errors are found during the annotation process.</li>
                                            <li>The test fails with a non-empty annotation object if an error is found during the annotation process.</li>
                                            <li>The annotation object contains the correct information about the required library and its installation instructions.</li>
                                            <li>The annotation object does not contain any unnecessary or misleading information.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        181 output =
                                        451 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-195, 471-473, 497-498, 502-503, 537)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_token</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `annotate` method of the `GeminiProvider` class throws an error when an API token is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `annotate` method fails to recognize the absence of an API token, potentially leading to incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation does not throw an error when the `GEMINI_API_TOKEN` environment variable is not set.</li>
                                            <li>The annotation throws an error with a message indicating that the `GEMINI_API_TOKEN` environment variable is not set.</li>
                                            <li>The annotation correctly identifies the absence of an API token and returns it as the error message.</li>
                                            <li>The annotation does not throw any errors when the `GEMINI_API_TOKEN` environment variable is explicitly unset using `unsetenv` or other methods.</li>
                                            <li>The annotation throws a `ResourceExhausted` exception with a mock `GenerationFailure` instance, which is consistent with the expected behavior of the `annotate` method.</li>
                                            <li>The annotation correctly handles cases where the `GEMINI_API_TOKEN` environment variable is not set and returns an appropriate error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        440 input +
                                        244 output =
                                        684 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_records_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `annotate` method records tokens on the limiter and rate limits correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions where token usage is not recorded or reported accurately.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'json' key in the captured dictionary contains a valid JSON payload with the correct response data.</li>
                                            <li>The 'totalTokenCount' key in the captured dictionary matches the expected value of 123.</li>
                                            <li>The 'candidates' list in the captured dictionary contains at least one record with the correct content and metadata.</li>
                                            <li>The 'usageMetadata' object in the captured dictionary has a valid total token count.</li>
                                            <li>No exceptions are raised when calling `fake_get` or `fake_post` functions.</li>
                                            <li>The rate limits logic is correctly implemented and does not raise any exceptions.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        783 input +
                                        175 output =
                                        958 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-455, 457, 459-460, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_retries_on_rate_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for Gemini provider</p>
                                    <p><strong>Why Needed:</strong> To handle retries on rate limit errors</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked requests should be retried', 'description': 'Verify that the LLM is retried when a request exceeds the rate limit'}</li>
                                            <li>{'name': 'Llama model should not be skipped due to rate limit error', 'description': "Verify that the Llama model is not skipped if it's already been used to generate an answer"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        121 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM models are rotated on a daily basis and not cached for an extended period, which could lead to performance issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'model rotation', 'expected_result': 'models are rotated daily'}</li>
                                            <li>{'assertion_type': 'cache invalidation', 'expected_result': 'cache is invalidated daily'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        125 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">210 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526-527, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> Skips daily limit due to excessive annotation requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mocks', 'expected': ['mocks']}</li>
                                            <li>{'name': 'requests', 'expected': ['annotation_requests']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        94 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider annotates a valid response with the correct information.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the provider correctly annotates responses from liteLLM.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        474 input +
                                        64 output =
                                        538 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">209 lines (ranges: 39-42, 45-46, 48-49, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_exhausted_model_recovers_after_24h</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> The LLM provider's model is exhausted after 24 hours. This test ensures the provider can recover and continue serving requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Provider should be able to recover from exhaustion', 'description': 'After 24 hours, the provider should still be able to serve requests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        94 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">222 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `fetch_available_models` method returns an error when there are no available models.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "The response should contain a 'no_available_models' key", 'value': "{'scenario': ..., 'why_needed': ..., 'key_assertions': [...]}", 'expected_value': "{'scenario': ..., 'why_needed': ..., 'key_assertions': [...]"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        126 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 134-135, 137-141, 143-144, 346, 348-349, 352-356, 358-361, 363-364, 366-367, 435, 437-439, 441-444, 449-452, 463-466, 476, 478, 497-498, 502-508, 511, 514-516, 518-521, 524-525, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_model_list_refreshes_after_interval</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The model list is refreshed after an interval.</p>
                                    <p><strong>Why Needed:</strong> To ensure the model list is updated correctly and consistently across tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Model list should be empty before refresh', 'value': [], 'expected_value': []}</li>
                                            <li>{'name': 'Model list should contain expected models after refresh', 'value': ['...'], 'expected_value': ['...']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        106 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">201 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_401_retry_with_token_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider retries on 401 after refreshing token.</p>
                                    <p><strong>Why Needed:</strong> Reason for retrying on 401 error</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the provider retries with a new token.</li>
                                            <li>Verify that the provider throws an exception for 401 error.</li>
                                            <li>Verify that the provider captures the captured keys.</li>
                                            <li>Verify that the provider increments call count correctly.</li>
                                            <li>Verify that the provider increments token count correctly.</li>
                                            <li>Verify that the provider returns a successful response after retrying with new token.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        580 input +
                                        126 output =
                                        706 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_handles_completion_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider annotates completion errors correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider does not surface completion errors in annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The error message is 'boom' which indicates a completion error.</li>
                                            <li>The annotation has an 'error' key with the value 'boom'.</li>
                                            <li>The annotation's error contains the string 'boom'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        98 output =
                                        405 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider rejects invalid key_assertions payloads.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the provider from silently failing when receiving an invalid key_assertions payload, making it easier to detect and diagnose issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'response_data' dictionary must be a valid JSON object.</li>
                                            <li>The 'json.dumps(response_data)' expression should return a valid JSON string.</li>
                                            <li>The 'response_data' dictionary must contain exactly one key_assertion value.</li>
                                            <li>The 'key_assertion' value must be a list of strings or a single string.</li>
                                            <li>The 'key_assertions' value must not be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        145 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 206, 211)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The LiteLLMProvider should report a missing dependency when trying to annotate a case that depends on it.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider does not handle cases that depend on missing dependencies correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation.error == 'litellm not installed. Install with: pip install litellm'</li>
                                            <li>provider.annotate(test, 'def test_case(): assert True')</li>
                                            <li>test_case()</li>
                                            <li>assert True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        271 input +
                                        111 output =
                                        382 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 37-38, 41, 82-86)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider annotates a successful response with the correct key assertions and confidence level.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by verifying that the provider correctly handles successful responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        475 input +
                                        65 output =
                                        540 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider uses prompt_override when provided.</p>
                                    <p><strong>Why Needed:</strong> To prevent a bug where the provider does not override prompts correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The `prompt_override` parameter is present in the config.', 'content': 'CUSTOM PROMPT'}</li>
                                            <li>{'message': 'The `prompt_override` value matches the expected custom prompt.', 'content': 'CUSTOM PROMPT'}</li>
                                            <li>{'message': 'The `messages` attribute of the fake completion function contains the correct key assertion.', 'content': 'a'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        125 output =
                                        498 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the LiteLLMProvider's annotate method with token usage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling token usage data from LiteLLM providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verifies that the annotation object has a 'token_usage' attribute.</li>
                                            <li>Checks if the 'prompt_tokens', 'completion_tokens', and 'total_tokens' attributes are correctly set.</li>
                                            <li>Asserts that the 'token_usage' attribute is not None.</li>
                                            <li>Ensures that the values of 'prompt_tokens', 'completion_tokens', and 'total_tokens' match the expected values.</li>
                                            <li>Verifies that the total tokens count matches the sum of prompt and completion tokens.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        149 output =
                                        575 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The LiteLLM provider passes the `litellm_api_base` attribute to the completion call of its API.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider does not set the `litellm_api_base` attribute correctly, causing unexpected behavior in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `litellm_api_base` is set to `https://proxy.corp.com/v1`.</li>
                                            <li>The `litellm_api_base` attribute is present in the response data.</li>
                                            <li>The `api_base` key is present in the captured dictionary.</li>
                                            <li>The value of `api_base` is equal to `https://proxy.corp.com/v1`.</li>
                                            <li>The `litellm_api_base` attribute is set correctly for the given configuration.</li>
                                            <li>No exception is raised when calling the completion function with the provided arguments.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        387 input +
                                        192 output =
                                        579 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182-183, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_key_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLM provider passes a static API key to the completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the API key is not passed through correctly, potentially causing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>- The API key is set to 'static-key-placeholder' in the captured dictionary.</li>
                                            <li>- The API key matches the expected value of 'static-key-placeholder'.</li>
                                            <li>- The API key is present in the captured dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        384 input +
                                        108 output =
                                        492 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_error_without_refresher</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider returns an auth error when no refresher is configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the provider does not return an authentication error for cases without token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `fake_completion` raises a `FakeAuthError` with message '401 Unauthorized'.</li>
                                            <li>The `LiteLLMProvider` instance is configured to use the 'gpt-4o' model, but no token refresh is provided.</li>
                                            <li>The provider returns an authentication error in its annotation.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        338 input +
                                        125 output =
                                        463 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 132-133, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_retry_fails_on_second_attempt</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider reports an authentication error when retrying after a second failure.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider fails to report an authentication error on subsequent retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'error' attribute of the annotation is not None.</li>
                                            <li>The value of 'Authentication failed' in the 'error' attribute contains the string '401 Unauthorized'.</li>
                                            <li>The 'error' attribute contains a string that indicates an authentication failure, such as '401 Unauthorized'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        121 output =
                                        540 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">51 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 129-130, 132-133, 141-142, 170-174, 176-178, 182, 186-188, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_context_too_long_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider class correctly handles a context too long error in its _parse_response method.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider incorrectly raises an AuthenticationError when encountering a response with an invalid JSON structure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error is not None</li>
                                            <li>assert 'Context too long for this model' in str(annotation)</li>
                                            <li>assert annotation.json is not None</li>
                                            <li>assert 'scenario' in annotation.json</li>
                                            <li>assert 'why_needed' in annotation.json</li>
                                            <li>assert 'key_assertions' in annotation.json</li>
                                            <li>assert 'error' in annotation.json</li>
                                            <li>assert 'Context too long for this model' in str(annotation.json)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        370 input +
                                        161 output =
                                        531 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_dict_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_max_context_tokens_dict_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns a dictionary in the expected format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is a dictionary', 'expected_value': {'max_tokens': 16384}, 'actual_value': '16384'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        218 input +
                                        86 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227-228, 230-231)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider returns a JSON response with the expected structure when an error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'JSON structure', 'expected': {'scenario': '...', 'why_needed': '...', 'key_assertions': ['...']}, 'actual': {'scenario': '...', 'why_needed': '...', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        110 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227, 232-234)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider correctly returns the maximum number of context tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 8192, 'actual_value': 0}</li>
                                            <li>{'name': 'provider', 'expected_value': 'LiteLLMProvider', 'actual_value': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        124 output =
                                        337 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 37-38, 41, 221-222, 224, 227-229)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</p>
                                    <p><strong>Why Needed:</strong> To ensure the liteLLM provider can detect installed modules.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'module_name': 'litellm'}, 'actual': '__import__('}</li>
                                            <li>message_type_error_message_id_or_key_not_found_0_1: module not found</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        160 input +
                                        102 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 37-38, 41, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_token_refresh_integration</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: LiteLLM provider uses TokenRefresher for dynamic tokens.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a scenario where the LLM provider fails to refresh its token due to an interval setting that is too short, causing it to run out of tokens before the next refresh cycle.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert captured['api_key'] == 'dynamic-token-789',</li>
                                            <li>assert captured['provider'] == 'litellm',</li>
                                            <li>assert captured['model'] == 'gpt-4o',</li>
                                            <li>assert captured['token_refresh_command'] == 'get-token',</li>
                                            <li>assert captured['token_refresh_interval'] == 3600,</li>
                                            <li>assert captured['expected_token'] == None,</li>
                                            <li>assert captured['actual_token'] == 'dynamic-token-789',</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        442 input +
                                        180 output =
                                        622 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">41 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_transient_error_retry</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider retries on transient errors.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider fails to retry transient errors, causing the test to fail intermittently.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The provider should not raise an exception when it encounters a transient error.</li>
                                            <li>The provider should retry the operation after a transient error.</li>
                                            <li>The number of retries should be limited to 5.</li>
                                            <li>The provider should only retry if the network error is transient (i.e., not due to other issues).</li>
                                            <li>The provider should not retry indefinitely when it encounters a transient error.</li>
                                            <li>The test should pass even if the provider fails to retry transient errors occasionally.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        155 output =
                                        581 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_fallbacks_on_context_length_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider correctly handles context length errors during annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected_exception', 'type': 'Exception'}</li>
                                            <li>{'name': 'message', 'type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        83 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">70 lines (ranges: 65-66, 87-89, 97-99, 101, 103, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 243, 245, 264, 266-267, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 85-86, 92, 138, 140, 142-144, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_handles_call_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the annotate method of OllamaProvider returns an error message when a call to the annotated function fails.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case where the annotation fails due to a timeout or other unforeseen reason during the retry process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The error message returned by the annotate method is 'Failed after 2 retries. Last error: boom'.</li>
                                            <li>The function `test_case` was not executed successfully.</li>
                                            <li>The last error raised during the annotation attempt is 'boom'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        347 input +
                                        124 output =
                                        471 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 97-98, 100-101, 103-104)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_missing_httpx</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The Ollama provider reports missing httpx dependency when annotating a test case.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider incorrectly assumes that httpx is installed and fails to report an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'httpx not installed. Install with: pip install httpx'</li>
                                            <li>provider.annotate(test, "def test_case(): assert True")</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        268 input +
                                        97 output =
                                        365 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 42-46)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</p>
                                    <p><strong>Why Needed:</strong> To test the immediate failure of annotating runtime errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected_exception', 'type': 'Exception'}</li>
                                            <li>{'name': 'expected_message', 'type': 'RuntimeError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        96 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 96)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_success_full_flow</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotating a full flow of an Ollama provider with mocked HTTP returns the expected annotations.</p>
                                    <p><strong>Why Needed:</strong> Prevents auth bugs by ensuring the correct status and token are returned in case of errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>check status</li>
                                            <li>validate token</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        414 input +
                                        68 output =
                                        482 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided with a custom prompt.</p>
                                    <p><strong>Why Needed:</strong> To prevent bugs where LiteLLM provider does not override the prompt and instead uses the default one.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should have no error.</li>
                                            <li>The captured messages should contain the custom prompt.</li>
                                            <li>The content of the captured message should be 'CUSTOM PROMPT'.</li>
                                            <li>The key assertion 'a' should match the expected value in the captured message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        113 output =
                                        486 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52-53, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LiteLLM provider annotates token usage for a case with a specific configuration and test result.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that would occur if the LiteLLMProvider's annotate method does not correctly handle cases where there is no response or incomplete response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation object contains the correct number of prompt tokens, completion tokens, and total tokens.</li>
                                            <li>The token usage is not None.</li>
                                            <li>The prompt tokens are equal to 100.</li>
                                            <li>The completion tokens are equal to 50.</li>
                                            <li>The total tokens are equal to 150.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        135 output =
                                        561 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71, 74-80, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider makes correct API call to generate response with specified model, prompt, and system prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the Ollama provider fails to make a successful API call to generate a response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'response' key in the result dictionary should be equal to 'test response'.</li>
                                            <li>The 'url' key in the captured dictionary should contain the string 'http://localhost:11434/api/generate'.</li>
                                            <li>The 'json' key in the captured dictionary should have a 'model' value of 'llama3.2:1b'.</li>
                                            <li>The 'json' key in the captured dictionary should have a 'prompt' value of 'test prompt'.</li>
                                            <li>The 'json' key in the captured dictionary should have a 'system' value of 'system prompt'.</li>
                                            <li>The 'stream' key in the captured dictionary should be False.</li>
                                            <li>The 'timeout' key in the captured dictionary should be equal to 60 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        470 input +
                                        226 output =
                                        696 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_uses_default_model</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the Ollama provider uses the default model when not specified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the default model is used instead of the provided model.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `model` in the captured JSON response should be 'llama3.2'.</li>
                                            <li>The value of `model` in the captured JSON response should not be empty.</li>
                                            <li>The value of `model` in the captured JSON response is a string, not None or an empty string.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        344 input +
                                        120 output =
                                        464 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama Provider</p>
                                    <p><strong>Why Needed:</strong> To test the failure case when the server is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() should return False', 'description': "The provider's check_availability method should return False when the server is not available."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        183 input +
                                        81 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 113-114, 116-117, 119-120)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</p>
                                    <p><strong>Why Needed:</strong> To test the Ollama provider's check_availability method with a non-200 status code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected False', 'expected_value': False, 'type': 'assertion'}</li>
                                            <li>{'message': 'OllamaProvider._check_availability() returned True instead of False.', 'expected_value': True, 'type': 'exception'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        197 input +
                                        118 output =
                                        315 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test checks availability of Ollama provider when it returns a successful response.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider fails to return a successful response when available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The method _check_availability() of the OllamaProvider instance should return True.</li>
                                            <li>The status code of the /api/tags endpoint should be 200.</li>
                                            <li>The URL '/api/tags' is present in the request.</li>
                                            <li>No exception is raised when making a GET request to the /api/tags endpoint.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        123 output =
                                        419 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_context_length_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct behavior of the Ollama provider when retrieving context length from the LLM.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context length should be an integer', 'expected_value': 100, 'actual_value': 123}</li>
                                            <li>{'name': 'Context length should not exceed the maximum allowed value', 'expected_value': 100, 'actual_value': 150}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        106 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for OLLAMA provider</p>
                                    <p><strong>Why Needed:</strong> To handle errors that may occur during the execution of the model</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected a fallback to use max_context_tokens', 'description': 'The maximum context tokens should be used when an error occurs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        78 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 138, 140, 142-147, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_model_info</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns the correct maximum context tokens for a given model info.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 1024, 'actual_value': 0}</li>
                                            <li>{'name': 'context_token_count', 'expected_value': 512, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        113 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_parameters</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider can correctly retrieve the maximum context tokens from its parameters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 32, 'actual_value': 16}</li>
                                            <li>{'name': 'parameter_count', 'expected_value': 2, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        106 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 138, 140, 142-147, 149-150, 156, 158, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_non_200_status</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider returns a valid response when the API call to get max context tokens fails with a non-200 status code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The response from the API call is not an object.</li>
                                            <li>The 'max_context_tokens' key in the response is not present or its value is empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        91 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 138, 140, 142-147, 149, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Ollama provider always returns `is_local=True`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of OllamaProvider', 'expected_value': 'True'}</li>
                                            <li>{'name': 'is_local() method returns True for OllamaProvider instances', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        116 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider reports invalid JSON responses</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider correctly handles and reports invalid JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotation.error', 'value': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        73 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 65-66, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> {'id': 1, 'description': 'Test case for Ollama provider with invalid key assertions'}</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure the Ollama provider rejects invalid key assertions in its responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Invalid response', 'message': "The provided 'key_assertions' value is not a list."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        143 output =
                                        317 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Ollama provider correctly extracts JSON from markdown code fences.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected JSON format', 'description': 'The extracted JSON should be in the expected format.'}</li>
                                            <li>{'name': 'Expected key assertion', 'description': 'The provider should assert that it has found a specific key in the JSON object.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        123 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of extracting JSON from plain markdown fences (no language).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected response type to be dict', 'value': 'expected response type is a dictionary'}</li>
                                            <li>{'name': 'Expected keys in response', 'value': "keys in the response should include 'scenario', 'why_needed', and 'key_assertions'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        127 output =
                                        255 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider parses valid JSON responses and verifies correct key assertions.</p>
                                    <p><strong>Why Needed:</strong> Prevents bugs that may occur when parsing invalid or malformed JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert a</li>
                                            <li>assert b</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        292 input +
                                        57 output =
                                        349 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_utils.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_constrained</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify water-fill algorithm satisfies smaller files first.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the algorithm does not satisfy the constraint of smaller files first, leading to inefficient allocation of tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `distribute_token_budget` should return an allocation dictionary with 'small.py' as the key and 10 as its value.</li>
                                            <li>The function `distribute_token_budget` should return an allocation dictionary with 'large.py' as the key and between 30 and 45 (inclusive) as its value.</li>
                                            <li>The total allocated tokens for both files should be less than or equal to the total budget of 60.</li>
                                            <li>The remaining tokens after allocating to 'small.py' should be greater than or equal to the remaining budget of 44.</li>
                                            <li>The allocation of 'large.py' should not exceed the remaining budget of 44.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        396 input +
                                        193 output =
                                        589 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_empty</p>
                                    <p><strong>Why Needed:</strong> Verify behavior with empty input or no budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert an empty dictionary is returned when {} is passed to distribute_token_budget(100)', 'expected_output': {}, 'actual_output': 'tests/test_llm_utils.py::test_distribute_token_budget_empty'}</li>
                                            <li>{'name': "assert an empty dictionary is returned when {'f1': 'c'} is passed to distribute_token_budget(0)", 'expected_output': {}, 'actual_output': 'tests/test_llm_utils.py::test_distribute_token_budget_empty'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        156 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 42-43)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_fair_share</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify fair sharing when neither fits.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case where both files are too large to fit within the budget, causing unfair distribution of token budgets.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The allocation for `l1.py` should be between 35 and 50 tokens.</li>
                                            <li>The allocation for `l2.py` should also be between 35 and 50 tokens.</li>
                                            <li>The absolute difference in allocations for `l1.py` and `l2.py` should not exceed 1 token.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        121 output =
                                        448 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_max_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_max_files</p>
                                    <p><strong>Why Needed:</strong> Verify the limit of max_files in token budget distribution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'length of allocations is equal to 3', 'expected_value': 3, 'actual_value': 0}</li>
                                            <li>{'name': 'number of files allocated is less than or equal to max_files', 'expected_value': 3, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        121 output =
                                        254 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_sufficient</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that all files get full content when the token budget is sufficient.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the LLM might not be able to handle large budgets without running out of tokens or headers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of allocations should match the total needed for each file (32 tokens per file).</li>
                                            <li>Each allocation should contain exactly 10 tokens (40 characters in 'f1.py' and 40 characters in 'f2.py').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        114 output =
                                        446 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_estimate_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the rough token estimation (chars / 4) for an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential division by zero error when estimating tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert estimate_tokens('') == 1</li>
                                            <li>assert estimate_tokens('a') == 1</li>
                                            <li>assert estimate_tokens('aaaa') == 1</li>
                                            <li>assert estimate_tokens('aaaa' * 10) == 10</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        103 output =
                                        320 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">29 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestArtifactEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a CoverageEntry object can be successfully converted to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the regression of coverage data not being properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert d['file_path'] == 'src/foo.py'</li>
                                            <li>assert d['line_ranges'] == '1-3, 5, 10-15'</li>
                                            <li>assert d['line_count'] == 10</li>
                                            <li>The file path is correctly serialized as 'src/foo.py'.</li>
                                            <li>The line ranges are correctly serialized as '1-3, 5, 10-15'.</li>
                                            <li>The line count is correctly serialized as 10.</li>
                                            <li>CoverageEntry object has been successfully converted to a dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        165 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 263-266)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCollectionError::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` returns the expected dictionary structure for a CoverageEntry object.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `to_dict()` method of `CoverageEntry` does not return the correct dictionary structure, potentially causing unexpected behavior or errors in downstream code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key should contain the string 'src/foo.py'.</li>
                                            <li>The 'line_ranges' key should contain a comma-separated list of strings representing the range of lines covered by the entry. The expected format is '1-3, 5, 10-15'.</li>
                                            <li>The 'line_count' key should contain an integer value equal to the number of lines in the coverage entry.</li>
                                            <li>Each assertion checks that the values returned by `to_dict()` match the expected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        183 output =
                                        438 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 241-243)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `CoverageEntry` class should serialize correctly to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the serialization of `CoverageEntry` objects is not accurate, potentially leading to incorrect coverage data being reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the serialized dictionary matches the expected value.</li>
                                            <li>The 'line_ranges' key in the serialized dictionary matches the expected format.</li>
                                            <li>The 'line_count' key in the serialized dictionary matches the expected value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        115 output =
                                        370 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 65-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> An empty annotation should be created with default values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where an empty annotation is not properly initialized with default values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation.scenario == "" (empty string)</li>
                                            <li>annotation.why_needed == "" (empty string) (default value for LlmAnnotation)</li>
                                            <li>annotation.key_assertions == [] (no key assertions are performed on an empty annotation)</li>
                                            <li>assert annotation.confidence is None (expected confidence to be None for an empty annotation)</li>
                                            <li>assert annotation.error is None (expected error to be None for an empty annotation)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        139 output =
                                        351 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `LlmAnnotation` object can be serialized into a dictionary with required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the minimal annotation is properly serialized and includes all necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'scenario' key should be present in the dictionary.</li>
                                            <li>The 'why_needed' key should be present in the dictionary.</li>
                                            <li>The 'key_assertions' key should be present in the dictionary.</li>
                                            <li>The 'confidence' key should not be present in the dictionary when it is None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        230 input +
                                        127 output =
                                        357 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 130-133, 135, 137, 139, 141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_with_all_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `to_dict` method returns all required fields for a full annotation.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in LLMAnnotation class, where some fields are missing or incomplete.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Asserts that the 'scenario' field is present and matches the expected value.</li>
                                            <li>Asserts that the 'confidence' field has a value within the expected range (0.0 to 1.0).</li>
                                            <li>Asserts that the 'context_summary' field contains the expected keys ('mode' and 'bytes') with correct values.</li>
                                            <li>Asserts that all required fields are present in the resulting dictionary.</li>
                                            <li>Asserts that the 'error' field is absent or None, as per the test's expectation.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        284 input +
                                        166 output =
                                        450 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 130-133, 135-137, 139-141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_default_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Default Report</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the default report is missing required schema version and empty test lists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' key should be present in the dictionary with value equal to SCHEMA_VERSION.</li>
                                            <li>The 'tests' key should be an empty list.</li>
                                            <li>The 'warnings' key should not be present in the dictionary.</li>
                                            <li>The 'collection_errors' key should not be present in the dictionary.</li>
                                            <li>If the schema version is missing, a KeyError should be raised when trying to access it.</li>
                                            <li>If the tests are missing, a KeyError should be raised when trying to access them.</li>
                                            <li>If the warnings or collection errors lists are non-empty, an AssertionError should be raised.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        170 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportRoot::test_report_with_collection_errors verifies that the test reports collection errors properly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where collection errors are not reported correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report should contain exactly one collection error.</li>
                                            <li>The first collection error should be for the file "test_bad.py".</li>
                                            <li>The node ID of the collection error should match the provided node ID in the ReportRoot constructor.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        103 output =
                                        340 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestReportRoot::test_report_with_warnings</p>
                                    <p><strong>Why Needed:</strong> The test is needed to ensure that the ReportRoot class correctly handles warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Length of warnings list', 'expected': 1, 'actual': 0}</li>
                                            <li>{'name': 'Code in first warning', 'expected': 'W001', 'actual': 'No coverage'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        105 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_tests_sorted_by_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests should be sorted by nodeid in output.</p>
                                    <p><strong>Why Needed:</strong> Because the current implementation does not sort tests by nodeid, which can lead to incorrect test results if multiple tests have the same nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'a_test.py::test_a', 'actual_value': 'z_test.py::test_z'}</li>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'm_test.py::test_m', 'actual_value': 'z_test.py::test_z'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        139 output =
                                        354 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_without_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_to_dict_without_detail' verifies that a ReportWarning object is created without detail.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the creation of a ReportWarning object with detail, which could lead to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The warning should be excluded from the dictionary.</li>
                                            <li>The warning message should not contain any details.</li>
                                            <li>The 'detail' key should not exist in the warning dictionary.</li>
                                            <li>The warning code should still match the expected value.</li>
                                            <li>The warning message should remain unchanged.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        122 output =
                                        345 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_aggregation_fields_present</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that RunMeta has aggregation fields.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression where RunMeta is missing aggregation fields, potentially leading to incorrect aggregation results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert d['run_id'] == 'run-123'</li>
                                            <li>assert d['run_group_id'] == 'group-456'</li>
                                            <li>assert d['is_aggregated'] is True</li>
                                            <li>assert d['aggregation_policy'] == 'merge'</li>
                                            <li>assert d['run_count'] == 3</li>
                                            <li>assert len(d['source_reports']) == 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        128 output =
                                        471 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 286-288, 290-292, 376-392, 394, 397, 399, 402, 405, 407, 409, 411-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_fields_excluded_when_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LLM fields are excluded when annotations are disabled.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression and ensure consistent behavior when annotations are disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_annotations_enabled' key is present in the data dictionary.</li>
                                            <li>The 'llm_provider' key is not present in the data dictionary.</li>
                                            <li>The 'llm_model' key is not present in the data dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        97 output =
                                        329 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_traceability_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM traceability fields are included when enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the LLM traceability fields are properly set when running with llm_provider='ollama' and llm_model='llama3.2:1b'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>data['llm_annotations_enabled'] is True</li>
                                            <li>data['llm_provider'] == 'ollama'</li>
                                            <li>data['llm_model'] == 'llama3.2:1b'</li>
                                            <li>data['llm_context_mode'] == 'complete'</li>
                                            <li>data['llm_annotations_count'] == 10</li>
                                            <li>data['llm_annotations_errors'] == 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        160 output =
                                        487 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419-431, 433, 435, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks if a non-aggregated report excludes source reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Non-aggregated report should not include source_reports', 'expected_result': {'source_reports': [], 'is_aggregated': False}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        94 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_meta_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test RunMeta to dict with all optional fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where RunMeta's optional fields are not properly populated in the dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that 'git_sha' is set to 'abc1234'.</li>
                                            <li>Verify that 'git_dirty' is True.</li>
                                            <li>Verify that 'repo_version' is set to '1.0.0'.</li>
                                            <li>Verify that 'repo_git_sha' is set to 'abc1234'.</li>
                                            <li>Verify that 'repo_git_dirty' is False.</li>
                                            <li>Verify that 'plugin_git_sha' is set to 'def5678'.</li>
                                            <li>Verify that 'plugin_git_dirty' is False.</li>
                                            <li>Verify that 'config_hash' is set to 'def5678'.</li>
                                            <li>Verify the length of 'source_reports' is 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        483 input +
                                        188 output =
                                        671 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">49 lines (ranges: 286-288, 290-292, 376-392, 394-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the 'RunMeta' object's run status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the 'RunMeta' object is not properly initialized with all required fields, leading to incorrect or missing data in its attributes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' attribute of the 'RunMeta' object should be equal to 1.</li>
                                            <li>The 'interrupted' attribute of the 'RunMeta' object should be True.</li>
                                            <li>The 'collect_only' attribute of the 'RunMeta' object should be True.</li>
                                            <li>The 'collected_count' attribute of the 'RunMeta' object should be equal to 10.</li>
                                            <li>The 'selected_count' attribute of the 'RunMeta' object should be equal to 8.</li>
                                            <li>The 'deselected_count' attribute of the 'RunMeta' object should be equal to 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        196 output =
                                        481 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the schema version is in semver format, which is a standard way of expressing software compatibility and change history.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "schema_version.split('.').should.have.length.equal.to(3)", 'message': "The schema version should have exactly 3 parts (e.g., '1.2.3')", 'type': 'assertion'}</li>
                                            <li>{'name': 'each part.should.be.a.digit', 'message': 'Each part of the schema version should be a digit (0-9)', 'type': 'assertion'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        162 output =
                                        277 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ReportRoot includes the schema version in its JSON representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'ReportRoot.schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                            <li>{'name': 'report.to_dict().schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        104 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage entry serialization.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `CoverageEntry` object is not correctly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key should be present and contain the expected value.</li>
                                            <li>The 'line_ranges' key should be present and contain the expected string.</li>
                                            <li>The 'line_count' key should be present and contain the expected integer value.</li>
                                            <li>All assertions should pass for the `CoverageEntry` object to be considered valid.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        117 output =
                                        373 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-103)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `to_dict` method of `LlmAnnotation` returns a dictionary with required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the minimal annotation is missing some required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'scenario' in d: The expected field is present in the output dictionary.</li>
                                            <li>assert 'why_needed' in d: The expected field is present in the output dictionary.</li>
                                            <li>assert 'key_assertions' in d: The expected field is present in the output dictionary.</li>
                                            <li>assert 'confidence' not in d: The unexpected field is not present in the output dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        229 input +
                                        143 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 286-288, 290, 292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestSourceReport to_dict_with_run_id</p>
                                    <p><strong>Why Needed:</strong> To ensure SourceReport objects are properly serialized and can be easily converted back into a dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "Expected 'run_id' key in source object", 'value': 'run-1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        78 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 286-288, 290-292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSummary::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `to_dict` method of `CoverageEntry` class.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `to_dict` method does not correctly serialize the coverage entry data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should be equal to 'src/foo.py'.</li>
                                            <li>The 'line_ranges' key in the dictionary should be equal to '1-3, 5, 10-15'.</li>
                                            <li>The 'line_count' key in the dictionary should be equal to 10.</li>
                                            <li>The 'coverage_data' key (if present) should not be missing from the dictionary.</li>
                                            <li>Any additional keys or values in the dictionary should match the expected format.</li>
                                            <li>The 'file_path' value should start with a forward slash '/' and end with a backslash '\'.</li>
                                            <li>The 'line_ranges' value should contain valid ranges separated by commas (e.g., '1-3, 5, 10-15').</li>
                                            <li>The 'line_count' value should be an integer.</li>
                                            <li>Any other unexpected values in the dictionary should raise an AssertionError.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        254 input +
                                        247 output =
                                        501 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_minimal_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_minimal_result</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the minimal result is missing required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nodeid' field should be present in the result dictionary.</li>
                                            <li>The 'outcome' field should be present in the result dictionary.</li>
                                            <li>The 'duration' field should be present in the result dictionary.</li>
                                            <li>The 'phase' field should be present in the result dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        244 input +
                                        112 output =
                                        356 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test `test_result_with_coverage` verifies that the `TestCaseResult` object includes a coverage list.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regressions where the coverage is not included in the result, potentially leading to incorrect reporting of code coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `coverage` key should be present and contain exactly one entry.</li>
                                            <li>The `file_path` attribute of the first coverage entry should match the nodeid of the test.</li>
                                            <li>All file paths in the coverage list should be relative to the source directory.</li>
                                            <li>Each coverage entry should have a `line_ranges` attribute with values '1-5' and a `line_count` attribute equal to 5.</li>
                                            <li>The total number of lines covered by code in the coverage list should match the total number of lines in the test file.</li>
                                            <li>All line ranges in the coverage list should be contiguous (i.e., no gaps between them).</li>
                                            <li>No coverage entries should have a `line_ranges` attribute with values that are not '1-5'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        226 output =
                                        482 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 65-68, 190, 194-199, 201, 203, 205, 207, 210-212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `llm_opt_out` flag is correctly set for test results with LLM opt-out.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert llm_opt_out is True in result dictionary', 'expected': True, 'actual': 'is True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        97 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_rerun</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_rerun</p>
                                    <p><strong>Why Needed:</strong> The test case result should include rerun fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'field_name': 'rerun_count', 'expected_value': 2, 'actual_value': "assert d['rerun_count'] == 2"}</li>
                                            <li>{'field_name': 'final_outcome', 'expected_value': 'passed', 'actual_value': "assert d['final_outcome'] == 'passed'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        127 output =
                                        289 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203, 205, 207-210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `result` object contains fields that are specific to reruns (e.g. 'rerun_count', 'rerun_message') which should be excluded in a result without reruns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Result without reruns excludes rerun fields', 'description': 'The `result` object should not contain the following fields: rerun_count, rerun_message'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        128 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</p>
                                    <p><strong>Why Needed:</strong> Prevents bar because llm_opt_out is True and llm_context_override is set to 'complete'. Without these, the test would fail due to missing coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result['llm_opt_out'] == True</li>
                                            <li>assert len(result['coverage']) == 1</li>
                                            <li>assert result['llm_annotation']['scenario'] == 'Tests foo'</li>
                                            <li>assert result['captured_stdout'] == 'stdout content'</li>
                                            <li>assert result['captured_stderr'] == 'stderr content'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        145 output =
                                        599 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 96-103, 241-243, 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_artifacts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes artifacts when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the 'to_dict' method does not include all required artifacts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of 'artifacts' in the result should be 2.</li>
                                            <li>The path of the first artifact ('report.html') should match its expected value.</li>
                                            <li>All artifacts should have their paths included in the result dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        99 output =
                                        363 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530-532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes collection_errors when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test reports collection errors without checking if they are actually present in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `result['collection_errors']` is 1 and its first element's 'nodeid' is `broken_test.py`.</li>
                                            <li>The value of `result['collection_errors'][0]` is an instance of `CollectionError` with a non-empty `nodeid` attribute.</li>
                                            <li>The value of `result['collection_errors'][0]['nodeid']` matches the expected value `broken_test.py`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        243 input +
                                        144 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_custom_metadata</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes custom_metadata when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the custom metadata is not included in the report even though it was provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'custom_metadata' key should be present in the result dictionary with the correct values.</li>
                                            <li>The 'project' value of 'custom_metadata' should match the provided value.</li>
                                            <li>The 'environment' value of 'custom_metadata' should match the provided value.</li>
                                            <li>The 'build_number' value of 'custom_metadata' should match the provided value.</li>
                                            <li>The custom metadata dictionary should not be empty after calling to_dict.</li>
                                            <li>The report root object passed to to_dict() should have a 'custom_metadata' attribute with the correct values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        167 output =
                                        431 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534-536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes hmac_signature when set.</p>
                                    <p><strong>Why Needed:</strong> HMAC signature is required for the report to be considered valid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'signature123'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        93 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ReportRoot class correctly includes a sha256 value in its dictionary representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': 'abcdef1234567890'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        83 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536-538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes source_coverage when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents test failure due to missing source coverage information in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'source_coverage' key is present in the result dictionary.</li>
                                            <li>The value of 'source_coverage' is a list containing exactly one element.</li>
                                            <li>The first element of 'source_coverage' has the correct 'file_path' attribute.</li>
                                            <li>The 'file_path' attribute matches the expected value 'src/mod.py'.</li>
                                            <li>The coverage percentage and ranges are correctly calculated.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        282 input +
                                        126 output =
                                        408 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 96-103, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532-534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `to_dict` method of ReportRoot includes warnings when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "len(result['warnings']) == 1", 'expected': 1, 'actual': 0}</li>
                                            <li>{'name': "result['warnings'][0]['code'] == 'W001'", 'expected': 'W001', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        127 output =
                                        278 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_with_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes coverage_total_percent when set</p>
                                    <p><strong>Why Needed:</strong> The test is needed because it checks if the `to_dict` method of `Summary` class correctly returns the total coverage percentage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'coverage_total_percent', 'expected_value': 85.5, 'actual_value': 85.5}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        116 output =
                                        269 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 467-475, 477-479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_without_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict excludes coverage_total_percent when None.</p>
                                    <p><strong>Why Needed:</strong> The test is needed because it checks the behavior of `summary.to_dict()` when `coverage_total_percent` is `None`. Without this test, the test might fail due to unexpected behavior in other tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': {'coverage_total_percent': None}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        121 output =
                                        252 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents bar regression in coverage analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>param_id should be 'a-b-c',</li>
                                            <li>param_summary should contain 'a=1, b=2, c=3',</li>
                                            <li>captured_stdout and captured_stderr should match 'stdout content' and 'stderr content respectively',</li>
                                            <li>requirements list should include 'REQ-100',</li>
                                            <li>llm_opt_out should be True,</li>
                                            <li>llm_context_override should be 'complete',</li>
                                            <li>coverage length should be 1 (only one entry),</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        143 output =
                                        597 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 65-68, 130-133, 135, 137, 139, 141, 143, 190, 194-199, 201-207, 210-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</p>
                                    <p><strong>Why Needed:</strong> to include captured_stderr in the result dictionary when it is set to True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected': 'captured_stderr', 'actual': 'Error output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        87 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220-222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</p>
                                    <p><strong>Why Needed:</strong> to cover the scenario where captured stdout is needed for accurate test results</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': {'captured_stdout': 'Debug output here'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        83 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218-220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_param_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203-207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because it checks if the `to_dict` method of `TestCaseResult` includes requirements when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "result['requirements'] == ['REQ-001', 'REQ-002]", 'expected_value': ['REQ-001', 'REQ-002']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        105 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">21 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the default exclude globs for LLMContext.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where default exclude globs are not correctly identified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `llm_context_exclude_globs` is called and its return value is checked.</li>
                                            <li>The string `*.pyc` is found in the returned list of default exclude globs.</li>
                                            <li>The string `__pycache__/*` is found in the returned list of default exclude globs.</li>
                                            <li>The string `*secret*` is found in the returned list of default exclude globs.</li>
                                            <li>The string `*password*` is found in the returned list of default exclude globs.</li>
                                            <li>The function returns a list with all expected strings.</li>
                                            <li>The function does not return an empty list when no exclude globs are specified.</li>
                                            <li>The function does not raise any exceptions when encountering unknown files or directories.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        202 output =
                                        424 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that default redact patterns include sensitive information.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential security vulnerability where sensitive information like passwords and tokens are not properly redacted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The pattern '--password' is present in the default redact patterns.</li>
                                            <li>The pattern '--token' is present in the default redact patterns.</li>
                                            <li>The pattern '--api[_-]?key' is present in the default redact patterns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        105 output =
                                        333 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that default values are set correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the default values of Config are not properly initialized.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.provider == 'none'</li>
                                            <li>cfg.llm_context_mode == 'minimal'</li>
                                            <li>cfg.llm_max_tests == 0</li>
                                            <li>cfg.llm_max_retries == 10</li>
                                            <li>cfg.llm_context_bytes == 32000</li>
                                            <li>cfg.llm_context_file_limit == 10</li>
                                            <li>cfg.llm_requests_per_minute == 5</li>
                                            <li>cfg.llm_timeout_seconds == 30</li>
                                            <li>cfg.llm_cache_ttl_seconds == 86400</li>
                                            <li>cfg.include_phase == 'run'</li>
                                            <li>cfg.aggregate_policy == 'latest'</li>
                                            <li>not cfg.is_llm_enabled() is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        180 output =
                                        498 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_get_default_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_default_config</p>
                                    <p><strong>Why Needed:</strong> to ensure that the default configuration is created correctly without any external dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'expected': 'True'}</li>
                                            <li>{'name': "cfg.provider == 'none'", 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        87 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_is_llm_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the `is_llm_enabled` check returns False for a provider without an LLM.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case the LLM provider is changed to 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `Config.is_llm_enabled()` should return `False` when the provider is set to `'none'`.</li>
                                            <li>The function `Config.is_llm_enabled()` should return `True` when the provider is set to `'ollama'` or `'litellm'`.</li>
                                            <li>The function `Config.is_llm_enabled()` should return `True` when the provider is set to `'gemini'`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        150 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_aggregate_policy</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_aggregate_policy</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `aggregate_policy` parameter is validated correctly and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The number of errors returned by the validate() method should be 1.', 'expected_value': 1, 'actual_value': 0}</li>
                                            <li>{'description': "The first error message should contain 'Invalid aggregate_policy 'random'.", 'expected_value': "'Invalid aggregate_policy 'random'", 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        140 output =
                                        268 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-221, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_context_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_context_mode</p>
                                    <p><strong>Why Needed:</strong> to test the validation of an invalid context mode</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': "Invalid llm_context_mode 'mega_max'", 'expected_value': "Invalid llm_context_mode 'mega_max'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        81 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-213, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_include_phase</p>
                                    <p><strong>Why Needed:</strong> To test the validation of an invalid include phase.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error message', 'value': "Invalid include_phase 'lunch_break'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        73 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-229, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To test the validation of an invalid provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'condition': "Invalid provider 'invalid_provider'", 'expected_value': "Invalid provider 'invalid_provider'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        81 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_numeric_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of numeric constraints.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the llm_context_bytes is set to a value less than 1000, potentially causing issues with LLM context creation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.validate() returns an error message indicating that llm_context_bytes must be at least 1000</li>
                                            <li>llm_context_bytes in errors contains the expected string 'llm_context_bytes must be at least 1000'</li>
                                            <li>The number of errors is greater than or equal to 5</li>
                                            <li>llm_context_bytes must be at least 1000 is found in the list of errors</li>
                                            <li>llm_max_tests must be 0 (no limit) or positive is found in the list of errors</li>
                                            <li>llm_requests_per_minute must be at least 1 is found in the list of errors</li>
                                            <li>llm_timeout_seconds must be at least 1 is found in the list of errors</li>
                                            <li>llm_max_retries must be 0 or positive is found in the list of errors</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        329 input +
                                        228 output =
                                        557 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245-254, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_valid_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_valid_config</p>
                                    <p><strong>Why Needed:</strong> To ensure the config is correctly validated and no errors are returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config is empty', 'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        72 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_aggregation_options</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `load_aggregation_options` function to ensure it correctly loads aggregation options.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the aggregation options are not loaded correctly, potentially causing issues with downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate_dir` attribute of the configuration object is set to `aggr_dir`.</li>
                                            <li>The `aggregate_policy` attribute of the configuration object is set to `merge`.</li>
                                            <li>The `aggregate_run_id` attribute of the configuration object is set to `run-123`.</li>
                                            <li>The `aggregate_group_id` attribute of the configuration object is set to `group-abc`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        145 output =
                                        440 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig</p>
                                    <p><strong>Why Needed:</strong> To ensure that the batch parameter in LLMs is correctly set to False when it's disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg.batch_parametrized_tests', 'expected_value': {'scenario': 'False', 'why_needed': 'disabled batch flag works'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        89 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_config_missing_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when pyproject.toml doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM configuration is not properly loaded due to the absence of pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_max_retries' attribute in the config should be set to 10 by default.</li>
                                            <li>The 'llm_provider' attribute in the config should be None.</li>
                                            <li>The 'llm_model' attribute in the config should be None.</li>
                                            <li>The 'llm_context_mode' attribute in the config should be None.</li>
                                            <li>The 'llm_prompt_tier' attribute in the config should be None.</li>
                                            <li>The 'llm_batch_parametrized' attribute in the config should be False.</li>
                                            <li>The 'llm_context_compression' attribute in the config should be None.</li>
                                            <li>The 'llm_aggregate_dir' attribute in the config should not exist.</li>
                                            <li>The 'llm_coverage_source' attribute in the config should not exist.</li>
                                            <li>The 'llm_evidence_bundle' attribute in the config should not exist.</li>
                                            <li>The 'llm_report_html', 'llm_report_json', and 'llm_report_pdf' attributes in the config should be None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        268 output =
                                        681 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_coverage_source</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_coverage_source</p>
                                    <p><strong>Why Needed:</strong> To test the coverage source option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'id': 'assert_cfg_llm_coverage_source', 'expected_value': 'cov_dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        69 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607-608, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_defaults</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_defaults</p>
                                    <p><strong>Why Needed:</strong> To test the default configuration of the Pytest plugin.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "cfg.provider == 'none'", 'expected': 'None', 'message': 'Expected cfg.provider to be None'}</li>
                                            <li>{'name': 'cfg.report_html is None', 'expected': 'None', 'message': 'Expected cfg.report_html to be None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        116 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_from_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test that CLI options override pyproject.toml options.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'CLI options should override pyproject.toml options', 'expected_value': {'option1': 'value1', 'option2': 'value2'}, 'actual_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        90 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">132 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492-494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_provider_override</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that CLI provider option overrides pyproject.toml.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the correct configuration is loaded based on the provided CLI provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml', 'expected_content': '```toml\n[tool.pytest.ini]\nversion = 6.2.0\ndirectories = [\'tests\', \'docs\']\npytest.ini\n``"', 'actual_content': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        112 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">133 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading retries from CLI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_pytest_config.option.llm_max_retries', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        85 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494-495, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_pyproject</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of the `load_config` function in the `LoadConfig` class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is not empty', 'expected': {'status': 0, 'message': ''}, 'actual': {'status': 0, 'message': ''}}</li>
                                            <li>{'name': 'pyproject.toml file has the correct structure', 'expected': {'status': 1, 'message': "The pyproject.toml file should have a 'tool' section with the required keys"}, 'actual': {'status': 0, 'message': ''}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        162 output =
                                        281 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">134 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386-388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_token_optimization_options</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading token optimization options from CLI.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `llm_prompt_tier` and `batch_parametrized_tests` options are not correctly set for token optimization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.prompt_tier should be 'minimal'</li>
                                            <li>cfg.batch_parametrized_tests should be False</li>
                                            <li>cfg.context_compression should be 'none'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        97 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">88 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470-474, 476-477, 479, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">47 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_dependency_snapshot</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the CLI override for dependency snapshot configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `llm_dependency_snapshot` option is not correctly set to 'deps.json' when running the CLI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_dependency_snapshot` option in the configuration file should be set to 'deps.json'.</li>
                                            <li>The value of `llm_dependency_snapshot` in the configuration file should match 'deps.json'.</li>
                                            <li>The `llm_dependency_snapshot` option should have a valid value.</li>
                                            <li>The configuration file should contain the correct dependency snapshot path.</li>
                                            <li>The CLI output should display the expected dependency snapshot path.</li>
                                            <li>The `report_dependency_snapshot` option should be enabled in the CLI configuration.</li>
                                            <li>The `llm_dependency_snapshot` option should be set to 'deps.json' in the CLI configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        187 output =
                                        400 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488, 490-492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_evidence_bundle</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test CLI override for evidence bundle sets the correct value.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the CLI override is not set to the expected evidence bundle.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_evidence_bundle` option in the configuration file should be set to 'bundle.zip'.</li>
                                            <li>The `report_evidence_bundle` value in the configuration file should match 'bundle.zip'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        101 output =
                                        318 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488-490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_json</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_cli_report_json` test case sets the `report_json` option to 'output.json' in the mock configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the `llm_report_json` option is not set correctly for CLI override reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `cfg.report_json` should be 'output.json'.</li>
                                            <li>The `llm_report_json` option in the mock configuration should match the value specified by the test.</li>
                                            <li>The expected value of `cfg.report_json` is not being set correctly in the mock configuration.</li>
                                            <li>The `test_cli_report_json` test case does not prevent a regression where the `llm_report_json` option is not set for CLI override reports.</li>
                                            <li>The `report_json` option in the mock configuration should be updated to 'output.json' after setting it by the test.</li>
                                            <li>The expected value of `cfg.report_json` is being set correctly in the mock configuration.</li>
                                            <li>The `test_cli_report_json` test case prevents a regression where the `llm_report_json` option is not set for CLI override reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        246 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484-486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_pdf</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `llm_report_pdf` option is correctly overridden to point to a PDF file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default report location is not updated when CLI overrides are applied.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `llm_report_pdf` in the configuration is set to `output.pdf` after applying the override.</li>
                                            <li>The expected value of `report_pdf` in the configuration is `output.pdf`.</li>
                                            <li>No other values for `llm_report_pdf` are present in the configuration.</li>
                                            <li>The configuration file does not contain any other overrides that would affect the default report location.</li>
                                            <li>The `llm_report_pdf` option is correctly overridden to point to a PDF file.</li>
                                            <li>The test passes without raising an assertion error if no override is applied.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        181 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486-488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_invalid_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the token output format is valid and not causing coverage issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "litellm_token_output_format should be either 'json', 'xml' or 'yaml'", 'expected_value': ['json', 'xml', 'yaml'], 'message': 'Invalid token output format'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        98 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-237, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_token_refresh_interval_too_short</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation when token refresh interval is too short</p>
                                    <p><strong>Why Needed:</strong> Token refresh intervals that are too short may cause issues with the application's security and functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The token refresh interval must be at least 60 seconds.', 'expected_value': 60, 'actual_value': 30}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        88 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241-242, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_valid_litellm_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of valid LiteLLM config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM configuration is correctly validated and no errors are returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is None', 'expected_value': [], 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        77 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate_include_history feature is properly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'aggregate_include_history = ["...", "..."]', 'actual': 'aggregate_include_history = [...]'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        104 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438-440, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate policy is loaded correctly from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml contains the correct keys', 'expected_value': {'aggregate_policy': 'some_value'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        119 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436-438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'all' configuration key is loaded in a single pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml should contain all config keys', 'expected': True, 'actual': 'all'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        94 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">150 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340-346, 348-350, 352-354, 356-357, 360-369, 372-375, 378-392, 396, 400, 402, 404, 408-410, 412-413, 416-422, 426-428, 430-432, 436-440, 444-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache directory is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True'}</li>
                                            <li>{'name': 'cache_dir exists in pyproject.toml', 'expected': '/path/to/cache/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        107 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390-392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the cache TTL seconds are correctly loaded from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'cache_ttl_seconds key exists in pyproject.toml', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        112 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388-390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_failed_output` option in the `pyproject.toml` file is correctly loaded and used when running tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'pyproject.toml was created successfully'}</li>
                                            <li>{'name': 'pyproject.toml content', 'expected': 'The pyproject.toml file contains the necessary information to load capture_failed_output.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        133 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418-420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_output_max_chars` option is correctly loaded from the `pyproject.toml` file and used to set the capture output character limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'max_chars = 1024\n', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        108 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420-422, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context_bytes from pyproject.toml is correctly loaded and used in tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context bytes are written to tmp_path', 'expected_value': "tmp_path / 'pyproject.toml'", 'actual_value': "tmp_path / 'pyproject.toml'"}</li>
                                            <li>{'name': 'Context bytes are read from tmp_path', 'expected_value': '/tmp/pytest-pyproject-loading-coverage.py', 'actual_value': "tmp_path / 'pyproject.toml'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        155 output =
                                        268 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362-364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_exclude_globs` setting in `pyproject.toml` is correctly excluded from coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context exclude globs are not included in coverage reports', 'description': 'The context_exclude_globs setting in pyproject.toml should be excluded from coverage reports.', 'expected_value': False, 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        125 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368-369, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context file limit is correctly applied when loading a Pytest project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'context_file_limit = 100', 'actual': 'context_file_limit = 50'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        97 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364-366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_include_globs` setting is correctly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context include globs are being loaded correctly', 'expected_value': ['<path_to_context_include_glob>'], 'actual_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        103 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366-368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the HMAC key file is loaded correctly and used for signing messages.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'The HMAC key file should exist in the pyproject.toml file.', 'actual': 'The HMAC key file does not exist or is empty.'}</li>
                                            <li>{'expected': 'The HMAC key file should be loaded correctly from the pyproject.toml file.', 'actual': 'The HMAC key file is not properly formatted or is missing required information.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        141 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `include_param_values` option should be present in the `pyproject.toml` file.', 'expected_value': True, 'message': 'Expected to find the `include_param_values` option.'}</li>
                                            <li>{'name': 'The `include_param_values` option should have a valid value.', 'expected_value': 'True', 'message': 'Expected the value to be True.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        158 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372-374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the include phase is properly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected': '/path/to/pyproject.toml', 'actual': 'exists and is not empty'}</li>
                                            <li>{'name': "pyproject.toml has a 'include' section", 'expected': '/path/to/pyproject.toml', 'actual': "has a 'include' section"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        143 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_pytest_invocation` option is correctly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'contents of pyproject.toml', 'actual': 'contents of pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        105 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426-428, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_invocation_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_invocation_redact_patterns</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `invocation_redact_patterns` are correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml contains invocation_redact_patterns key', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        110 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430-432, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_litellm_api_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_api_base` module is loaded correctly from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The contents of pyproject.toml should contain a section named 'litellm_api_base'."}</li>
                                            <li>{'name': 'pyproject.toml module exports', 'expected': ['litellm_api_base']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        121 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340-342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm API key is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': '/path/to/pyproject.toml', 'expected_content': '...', 'actual_content': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        93 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342-344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm token JSON key is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True', 'actual': 'False'}</li>
                                            <li>{'name': 'pyproject.toml file has correct content', 'expected': "The pyproject.toml file should contain a section named 'tool litellm' with the following key: 'litellm_token_json_key'.", 'actual': 'The pyproject.toml file does not have this section or its key is incorrect.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        170 output =
                                        295 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356-357, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading of `litellm_token_output_format` from `pyproject.toml`</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_token_output_format` is correctly loaded and used in the Pytest project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'File exists', 'expected': 'True', 'actual': 'False'}</li>
                                            <li>{'name': 'pyproject.toml file created', 'expected': 'True', 'actual': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        121 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352-354, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_token_refresh_command` is properly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "pyproject.toml exists and has a 'tool' section", 'expected': "The 'tool' section should exist in the pyproject.toml file."}</li>
                                            <li>{'name': "pyproject.toml has a 'tool.litellm.token_refresh_command' entry", 'expected': "The 'tool.litellm.token_refresh_command' entry should exist in the pyproject.toml file."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        163 output =
                                        288 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344-346, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Loading litellm_token_refresh_interval from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure that the token is refreshed at the correct interval, we need to verify that the 'litellm_token_refresh_interval' configuration value in the pyproject.toml file matches the expected value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected value of litellm_token_refresh_interval', 'value': 300, 'expected_type': 'int'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        110 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348-350, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_malformed_pyproject</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 123, 171, 308, 311-312, 320-325, 449, 451, 453-456, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_concurrency` setting in the `pyproject.toml` file is correctly loaded and used when running tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': "The 'pyproject.toml' file was found at the specified path."}</li>
                                            <li>{'name': 'max_concurrency setting exists in pyproject.toml', 'expected': "The 'max_concurrency' setting in the 'pyproject.toml' file is a valid integer value."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        151 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380-382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Loading max_tests from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure that the coverage is loaded correctly when running tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Coverage is loaded from pyproject.toml', 'description': 'The coverage should be loaded from the specified file in the pyproject.toml.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        83 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378-380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the metadata file is loaded correctly and contains all necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected_value': 'True'}</li>
                                            <li>{'name': 'metadata_file path is correct', 'expected_value': '/path/to/pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        106 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444-446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PyprojectLoadingCoverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ollama_host is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The ollama_host setting should be present in the pyproject.toml file', 'expected_value': 'ollama_host', 'actual_value': 'ollama_host'}</li>
                                            <li>{'name': 'The ollama_host setting should have a valid value', 'expected_value': "a string value (e.g. 'https://example.com/ollama')", 'actual_value': 'https://example.com/ollama'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        152 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336-337, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> PyProjectLoadingCoverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'omit_tests_from_coverage' feature flag is correctly applied to tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'omitting tests from coverage', 'actual': 'omitting tests from coverage'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        83 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for PyProject loading coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `param_value_max_chars` value in `pyproject.toml` is correctly loaded and used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'File exists', 'expected': 'True', 'actual': 'False'}</li>
                                            <li>{'name': "File path contains 'max_chars'", 'expected': 'True', 'actual': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        110 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374-375, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'collect' option in 'report Collect Only' is loaded correctly from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'Collecting all dependencies', 'actual': 'Collecting only dependencies'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        99 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416-418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Loading timeout_seconds from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure that the timeout seconds are correctly loaded into the Pytest plugin.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'True'}</li>
                                            <li>{'name': 'timeout_seconds key exists in pyproject.toml', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        96 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `batch_max_tests` option in the `pyproject.toml` file is correctly loaded and used for token optimization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `batch_max_tests` option should be present in the `pyproject.toml` file', 'value': True}</li>
                                            <li>{'name': 'The value of `batch_max_tests` should be a number', 'value': 10}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        134 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400-402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_parametrized_tests</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Load batch parametrized tests</p>
                                    <p><strong>Why Needed:</strong> To ensure Pytest coverage is accurate for batch parameterized tests</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Pytest test discovery', 'description': 'The pytest test discovery should be able to find and run the specified tests'}</li>
                                            <li>{'name': 'Test execution', 'description': 'The tests should execute successfully and produce the expected output'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        105 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">131 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396-398, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression feature is properly loaded and used in PyProject files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected_value': 'True'}</li>
                                            <li>{'name': 'context_compression section exists', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        106 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402-404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_line_padding` option is correctly loaded and applied to the context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context line padding is applied correctly', 'expected_value': '', 'actual_value': '...'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        90 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404-405, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` is loaded correctly from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `prompt_tier` should be present in the `pyproject.toml` file.', 'expected_value': 'prompt_tier', 'actual_value': 'None'}</li>
                                            <li>{'name': 'The `prompt_tier` should have the correct type (dict).', 'expected_value': 'dict', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        150 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392-393, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the batch_max_tests configuration option has a valid value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'batch_max_tests must be at least 1', 'expected_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        88 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context line padding is not negative and raises an error when it is.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': 'context_line_padding must be 0 or positive', 'value': 'Negative value for context_line_padding'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        99 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the validation of context compression is not affected by invalid settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': 'Invalid context_compression', 'value': "Any error message containing 'Invalid context_compression'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        83 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the validation of invalid `prompt_tier` values does not return any error messages.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'type': 'assertion', 'message': 'Invalid prompt_tier', 'expected': ['Invalid prompt_tier']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        93 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_integration.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the config defaults are correct and safe.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'expected_type': 'Config'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        73 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">124 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378-380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603-605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</p>
                                    <p><strong>Why Needed:</strong> This test ensures that markers are present in the plugin configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytestconfig is not None', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        75 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_both_json_and_html_outputs</span>
                            <div class="test-meta">
                                <span>89ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test generates both JSON and HTML reports for Pytest.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report generation is only done in JSON format, but not in HTML.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should exist at the specified path.</li>
                                            <li>The `report.html` file should exist at the specified path.</li>
                                            <li>Both files should be present in the test directory.</li>
                                            <li>The report generation should work correctly even when run with different output formats (JSON and HTML).</li>
                                            <li>The `pytester.runpytest()` call should successfully generate both JSON and HTML reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        140 output =
                                        419 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</p>
                                    <p><strong>Why Needed:</strong> pytest_collection_finish counts items (line 378)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert data['run_meta']['collected_count'] == 3", 'expected_value': 3}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        198 input +
                                        83 output =
                                        281 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_creates_nested_directory</span>
                            <div class="test-meta">
                                <span>53ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that output directories are created if missing.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the plugin does not create an output directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `nested` subdirectory should be present in the report.json file.</li>
                                            <li>The `report.json` file should exist in the specified location.</li>
                                            <li>The `makepyfile` command should create the necessary directories and files.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        94 output =
                                        341 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 70-71, 73-75, 77, 79, 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_fixture_error_captured</span>
                            <div class="test-meta">
                                <span>59ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fixture errors are captured in report.</p>
                                    <p><strong>Why Needed:</strong> Fixture failures are not properly reported and can lead to false positives or missed issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key in the report contains an error code of 1, indicating a failure.</li>
                                            <li>The 'error' key in the 'summary' dictionary contains the string 'RuntimeError: Fixture failed'.</li>
                                            <li>The test passes even though the fixture failed, due to the captured error being reported as a false positive.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        117 output =
                                        403 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 78-79, 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330, 332, 334-335, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_makereport_captures_all_outcomes</span>
                            <div class="test-meta">
                                <span>143ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_runtest_makereport captures all outcomes</p>
                                    <p><strong>Why Needed:</strong> pytest_runtest_makereport may not capture all outcomes if the test is skipped or fails, leading to incorrect reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the report includes 'passed', 'failed', and 'skipped' outcomes.</li>
                                            <li>The test asserts that there are at least three types of outcomes in the report (passed, failed, and skipped).</li>
                                            <li>The test checks if the report contains all three types of outcomes.</li>
                                            <li>The test ensures that the report does not exclude any outcome by checking for missing values.</li>
                                            <li>The test verifies that the report includes a mix of passing and failing tests.</li>
                                            <li>The test asserts that the report correctly identifies which tests were skipped.</li>
                                            <li>The test checks if the report accurately reflects the number of passed, failed, and skipped tests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        195 output =
                                        530 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">114 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin correctly handles cases where no output is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'exists', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        150 input +
                                        76 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">250 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403-404, 558-559, 562-563, 566-568, 579, 583, 602-603, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_pdf_option_enables_plugin</span>
                            <div class="test-meta">
                                <span>554ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that --llm-pdf option enables the plugin.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the plugin is not enabled due to missing Playwright configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that `pytester.runpytest('--llm-pdf=report.pdf')` exits with code 0 (success) or warning, but definitely runs.</li>
                                            <li>The test checks if collection/hooks run successfully after enabling the plugin via --llm-pdf.</li>
                                            <li>The test verifies that passing only --llm-pdf works to trigger the plugin logic and does not say 'no reports configured'.</li>
                                            <li>The test ensures that the plugin is enabled correctly even when logging a report file name like 'report.pdf'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        435 input +
                                        157 output =
                                        592 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_session_start_records_time</span>
                            <div class="test-meta">
                                <span>56ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the pytest_sessionstart records start time is correctly reported in the report.json file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the start time of the session might not be accurately reported in the report.json file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'start_time' key should be present in the run_meta dictionary within the 'report.json' file.</li>
                                            <li>The value of the 'start_time' key should match the actual start time of the pytest session.</li>
                                            <li>If no start time is recorded, the 'start_time' key should still be present and have a default value (e.g., 0)</li>
                                            <li>Any changes to the start time should be reflected in the report.json file immediately after running pytest</li>
                                            <li>The 'start_time' value should not be affected by any external factors that might impact the session timing (e.g., system clock, network latency)</li>
                                            <li>If multiple sessions are run concurrently, the start times should be correctly reported and consistent across all sessions</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        216 output =
                                        492 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_context_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the requirement marker does not cause any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'does_not_raise', 'expected_output': [], 'actual_output': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        81 output =
                                        171 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestReportGeneration::test_report_writer_integration</span>
                            <div class="test-meta">
                                <span>39ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the integration of report writer with pytest_llm_report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that may occur when using the report writer with pytest_llm_report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that a full report is generated and saved to the specified JSON file.</li>
                                            <li>Verify that the report includes summary data with total count of tests, passed, and failed.</li>
                                            <li>Verify that the HTML report includes references to all test files (test_a.py and test_b.py).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        417 input +
                                        113 output =
                                        530 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">26 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 579-580, 586-587)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</p>
                                    <p><strong>Why Needed:</strong> The `pytest_collectreport` plugin is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_report', 'expected_calls': [1]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        204 input +
                                        76 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 558-559, 562, 566-568, 579-580, 586, 590-592)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</p>
                                    <p><strong>Why Needed:</strong> To ensure that collectreport skips when session is not available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'pytest_collectreport should be called with a session object', 'expected_result': 'No session attribute'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        85 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collectreport plugin behaves correctly when a Pytest session is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_report.session is None', 'expected': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        82 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</p>
                                    <p><strong>Why Needed:</strong> LLM enabled warning is raised when pytest is run with the --llm flag.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM enabled warning should be raised', 'expected_value': True, 'actual_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        92 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</p>
                                    <p><strong>Why Needed:</strong> Validation errors are raised when the plugin is used with invalid configuration files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected a UsageError to be raised', 'message': 'A UsageError should be raised when the plugin is used with an invalid pyproject.toml file.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        97 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">135 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-358, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</p>
                                    <p><strong>Why Needed:</strong> To ensure that the configure function skips on xdist workers as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_config.addinivalue_line.called', 'expected_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        81 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 328-330, 332-334, 336-338, 342-343, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigureFallback::test_pytest_configure_fallback_load</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test fallback to load_config if Config.load is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the plugin would attempt to load configuration files without calling Config.load, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_load.return_value.mock_cfg == mock_cfg</li>
                                            <li># Test that load_config returns the correct mock config object</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        747 input +
                                        230 output =
                                        977 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that CLI options override pyproject.toml options when loading plugin configurations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'pyproject.toml contents'}</li>
                                            <li>{'name': 'load_config function call', 'expected': 'load_config function call'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        110 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</span>
                            <div class="test-meta">
                                <span>97ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin can load configuration from a PyProject file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True'}</li>
                                            <li>{'name': 'pyproject.toml is readable', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        101 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that terminal summary skips when plugin is disabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential regression where the plugin's terminal summary functionality is not properly handled when it is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocked stash.get() with _enabled_key and False returns None, as expected.</li>
                                            <li>Mocked stash.get() with _enabled_key and True does not return None, but instead calls test_terminal_summary() with the provided arguments.</li>
                                            <li>Test_terminal_summary() is called with the provided arguments (0, mock_config) when stash.get(_enabled_key, False) returns False.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        133 output =
                                        414 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 399, 403-404, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for the correct behavior of the `pytest_terminal_summary` plugin when skipping terminal summary workers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is None', 'expected': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        164 input +
                                        86 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 399-400, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::testload_config</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test config loading from pytest objects (CLI) for maximal plugin functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the lllm_report option is not set correctly, potentially leading to incorrect configuration or errors during execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_config.option.llm_report_html == 'out.html'</li>
                                            <li>mock_config.option.llm_report_json == None</li>
                                            <li>mock_config.option.llm_report_pdf == None</li>
                                            <li>mock_config.option.llm_evidence_bundle == None</li>
                                            <li>mock_config.option.llm_dependency_snapshot == None</li>
                                            <li>mock_config.option.llm_requests_per_minute == None</li>
                                            <li>mock_config.option.llm_aggregate_dir == None</li>
                                            <li>mock_config.option.llm_aggregate_policy == None</li>
                                            <li>mock_config.option.llm_aggregate_run_id == None</li>
                                            <li>mock_config.option.llm_aggregate_group_id == None</li>
                                            <li>mock_config.option.llm_max_retries == None</li>
                                            <li>mock_config.option.llm_coverage_source == None</li>
                                            <li>mock_config.option.llm_prompt_tier == None</li>
                                            <li>mock_config.option.llm_batch_parametrized == None</li>
                                            <li>mock_config.option.llm_context_compression == None</li>
                                            <li>mock_config.option.llm_context_bytes == None</li>
                                            <li>mock_config.option.llm_context_file_limit == None</li>
                                            <li>mock_config.option.llm_max_tests == None</li>
                                            <li>mock_config.option.llm_max_concurrency == None</li>
                                            <li>mock_config.option.llm_timeout_seconds == None</li>
                                            <li>mock_config.option.llm_capture_failed == None</li>
                                            <li>mock_config.option.llm_ollama_host == None</li>
                                            <li>mock_config.option.llm_litellm_api_base == None</li>
                                            <li>mock_config.option.llm_litellm_api_key == None</li>
                                            <li>mock_config.option.llm_litellm_token_refresh_command == None</li>
                                            <li>mock_config.option.llm_litellm_token_refresh_interval == None</li>
                                            <li>mock_config.option.llm_litellm_token_output_format == None</li>
                                            <li>mock_config.option.llm_litellm_token_json_key == None</li>
                                            <li>mock_config.option.llm_cache_dir == None</li>
                                            <li>mock_config.option.llm_cache_ttl == None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        639 input +
                                        466 output =
                                        1105 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to verify that makereport skips when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_item.config.stash.get.return_value', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        84 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 558-559, 562-563, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makereport calls collector when enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the plugin does not call the collector when makereport is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest_runtest_makereport` function should be called with the correct mock collector instance.</li>
                                            <li>The `mock_collector.handle_runtest_logreport` method should be called with the provided mock report and item.</li>
                                            <li>The `stash_get` method of the mock item should return True when it is set to `_enabled_key` or `_collector_key`.</li>
                                            <li>The `mock_item.config.stash.get` method should not call the collector instance directly.</li>
                                            <li>The `pytest_runtest_makereport` function should yield a point after calling `send` on the mock outcome.</li>
                                            <li>The `handle_runtest_logreport` method of the mock collector instance should be called with the provided mock report and item.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        371 input +
                                        205 output =
                                        576 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin correctly handles collection_finish when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_session.config.stash.get.return_value', 'expected': {'False': {}}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        81 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 602-603)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PluginSessionHooks</p>
                                    <p><strong>Why Needed:</strong> To test if the `pytest_collection_finish` function calls the `_collector_key` collector when collection_finish is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_finish was called once with mock_session.items', 'expected': 1, 'actual': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        219 input +
                                        88 output =
                                        307 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 602, 606-608)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that sessionstart initializes collector when enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the collector is not created when pytest_sessionstart is called with an enabled configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert _collector_key in mock_stash</li>
                                            <li>assert _start_time_key in mock_stash</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        77 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 558-559, 562, 566-568, 619, 623, 626, 628-629)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_addoption adds expected arguments and verifies specific options.</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption may not add all required arguments if the plugin is not properly configured.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that `--llm-report` and `--llm-coverage-source` are included in the command line arguments.</li>
                                            <li>Check that both options are present in the `args[0]` of each call to `addoption`.</li>
                                            <li>Verify that the correct group name is used for adding options (in this case, `llm-report` and `LLM-enhanced test reports`).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        137 output =
                                        430 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption no longer adds INI options</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'parser.addini was not called', 'expected_result': 0, 'actual_result': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        85 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_coverage_calculation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage percentage calculation logic for terminal summary.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage reporting when terminal summary is enabled and coverage map is loaded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option is set to 'out.html' and the test asserts that the Coverage class correctly reports a coverage percentage of 85.5.</li>
                                            <li>The `stash` dictionary contains `_enabled_key` as True and `_config_key` with the Config object, allowing the test to verify the correct stash configuration.</li>
                                            <li>The mock Coverage class is created with the loaded CoverageMapper instance, ensuring that the coverage report is generated correctly.</li>
                                            <li>The `report` method of the mock Coverage class is called once, verifying that it reports a coverage percentage of 85.5.</li>
                                            <li>The `load` method of the mock Coverage class is called once, verifying that it loads the coverage map correctly.</li>
                                            <li>The `report_html` option is set to 'out.html', allowing the test to verify that the report writer writes the correct HTML file.</li>
                                            <li>The stash dictionary contains the required keys for the Config object, ensuring that the stash configuration is valid.</li>
                                            <li>The mock stash instance is created with the specified stash data, allowing the test to verify its correctness.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        269 output =
                                        664 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">53 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_llm_enabled</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with LLM enabled runs annotations.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in terminal summary functionality when LLM is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the test passes when `llm_enabled` is set to True.</li>
                                            <li>Check if the correct configuration is passed to `pytest_terminal_summary`.</li>
                                            <li>Verify that the `llm_enabled` key is correctly added to the stash dictionary.</li>
                                            <li>Ensure that the `get_provider` method returns the correct provider instance.</li>
                                            <li>Verify that the `annotate_tests` method is called with the correct arguments.</li>
                                            <li>Check if the coverage map is properly updated when LLM is enabled.</li>
                                            <li>Verify that the report writer is able to write to the out.html file correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        166 output =
                                        643 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">66 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-486, 491-494, 497, 499, 502-504, 512-514, 516, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_no_collector</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary creates collector if missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the plugin does not create a collector even when it is supposed to be missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_terminalreporter.call_args[1][0].stash._enabled_key should return True</li>
                                            <li>mock_terminalreporter.call_args[1][0].stash._config_key should return cfg</li>
                                            <li>mock_config.stash._enabled_key should return False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        108 output =
                                        499 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_with_aggregation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with aggregation enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the case where `aggregate_dir` is set to a non-existent directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The stash created by `pytest_terminal_summary` should support both get() and [] indexing.</li>
                                            <li>The aggregator returned by `Aggregator` should be called once with the correct arguments.</li>
                                            <li>The report writer should write JSON and HTML files correctly.</li>
                                            <li>The aggregate function should return a report object.</li>
                                            <li>The stash should not have any invalid keys when set to an empty stash.</li>
                                            <li>The aggregation function should raise an error if `aggregate_dir` is not a valid directory path.</li>
                                            <li>The terminal reporter should be patched with the correct class and arguments.</li>
                                            <li>The terminal writer should write JSON and HTML files correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        441 input +
                                        179 output =
                                        620 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 399, 403, 407, 410-411, 413-414, 417-418, 420, 422-426, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummaryErrors::test_terminal_summary_coverage_error</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage calculation error when load fails during computation.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage calculation fails due to an OSError during load.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `pytest_terminal_summary` should not raise a UserWarning for a valid configuration.</li>
                                            <li>The `load` method of `CoverageMapper` should be called with a valid path.</li>
                                            <li>The `report_writer` should write the coverage report without raising an exception.</li>
                                            <li>The `coverage.Coverage` object should have a valid load method.</li>
                                            <li>The `MagicMock()` instance passed to `pytest_terminal_summary` should not raise a UserWarning.</li>
                                            <li>A valid configuration with a valid path should be loaded successfully.</li>
                                            <li>The coverage map should be created without raising an exception.</li>
                                            <li>The report writer should write the coverage report without raising an exception.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        389 input +
                                        188 output =
                                        577 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">52 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 476-479, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_balanced_context</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler to assemble a balanced context with a test file and dependency.</p>
                                    <p><strong>Why Needed:</strong> The test prevents regression when assembling contexts with unbalanced dependencies, ensuring that only necessary code is included.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'utils.py' file should be present in the assembled context.</li>
                                            <li>A function named `util()` should be found within the `utils.py` file.</li>
                                            <li>Only the `def util()` line from `utils.py` should be included in the assembled context.</li>
                                            <li>No additional code should be included in the assembled context beyond what is necessary for the test.</li>
                                            <li>The 'utils.py' file should not contain any other functions or variables that are not used by `util()`</li>
                                            <li>The 'utils.py' file should have a line count of 2, as specified in the coverage report</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        185 output =
                                        516 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler to assemble a complete context for a test file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler can correctly assemble a complete context for a test file, including all necessary key assertions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'ContextAssembled', 'context_assembled': {'test_1': {}}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        176 input +
                                        88 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139-140, 268-272)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_minimal_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the ContextAssembler can assemble a minimal context for a test file with a single test function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using the minimal context mode, as it ensures that all necessary code is included in the assembly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'test_1' function should be present in the source code of the assembled test file.</li>
                                            <li>The ContextAssembler should return an empty dictionary for the context of the assembled test file.</li>
                                            <li>The test result nodeid should match the path of the test file being tested.</li>
                                            <li>Any additional imports or dependencies required by the test function should be included in the assembly.</li>
                                            <li>No other code should be present in the source code of the assembled test file, except for the 'test_1' function.</li>
                                            <li>The ContextAssembler should return an empty dictionary when no tests are found in the test file.</li>
                                            <li>Any error messages or warnings from the assembler should not affect the correctness of the assembly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        267 input +
                                        213 output =
                                        480 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_balanced_context_limits</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the ContextAssembler correctly limits LLM context size to prevent truncation of long content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler would truncate long code snippets, potentially leading to incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' file is present in the assembled context.</li>
                                            <li>The 'f1.py' file contains the truncated content.</li>
                                            <li>The length of the 'f1.py' file does not exceed 40 bytes (20 + truncation message).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        124 output =
                                        459 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_complete_context_limits_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'complete' mode does not truncate long files when context bytes are set to a small value.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the truncation of long files, which can lead to incorrect results or data loss in certain contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' file is present in the assembled context.</li>
                                            <li>The content of 'f1.py' matches the original content.</li>
                                            <li>Context for 'f1.py' does not contain any 'truncated' keyword.</li>
                                            <li>Context for 'f1.py' has a length equal to its original content.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        361 input +
                                        135 output =
                                        496 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_get_test_source_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the ContextAssembler's ability to handle non-existent file names and nested test names with parameters.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler incorrectly handles files that do not exist or have incorrect paths, leading to unexpected behavior in subsequent tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_get_test_source` returns an empty string when given a non-existent file name.</li>
                                            <li>The function `_get_test_source` correctly includes the nested test name with parameters in its source code output.</li>
                                            <li>The function `_get_test_source` raises an AssertionError when given a file that does not exist or has incorrect path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        275 input +
                                        141 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 33, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_should_exclude</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the ContextAssembler should exclude certain files from being processed by the LLM.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler incorrectly excludes files that are not actually protected by the llm_context_exclude_globs configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>asserts that 'test.pyc' is excluded because it has a .pyc extension</li>
                                            <li>asserts that 'secret/key.txt' is excluded because it does not match any globs in the config</li>
                                            <li>asserts that 'public/readme.md' is included because it matches one of the globs in the config</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        140 output =
                                        367 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 33, 284-287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_minimal_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble minimal mode returns no context files.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where assemble function does not return any context files when run in minimal mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context_files is an empty list.</li>
                                            <li>def test_foo() is present in test_source.</li>
                                            <li>test_file::test_foo is present in the test source.</li>
                                            <li>test_foo.py is present in the test file.</li>
                                            <li>Context files are not generated when assemble function returns no context files.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        115 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_with_context_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble respects llm_context_override from test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the assembly of a test with an overridden LLM context is not using the expected balanced mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The assembler should use balanced mode when the LLM context override is set to 'balanced'.</li>
                                            <li>The coverage entry for module.py should include the line ranges and count of 1.</li>
                                            <li>The test source file (test_bar.py) should be included in the context files.</li>
                                            <li>The context files should contain the modified module file (module.py).</li>
                                            <li>The LLM context override should be respected when assembling a test with an overridden context.</li>
                                            <li>The assembler should report that it is using balanced mode for the assembly of the test.</li>
                                            <li>The coverage entry should include line ranges and count 1, indicating that only one line was executed in module.py.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        362 input +
                                        196 output =
                                        558 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_excludes_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the balanced context excludes files matching exclude patterns.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM context mode is set to 'balanced' and it includes files with glob patterns like '*secret*', which are excluded by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file `secret_config.py` should not be included in the balanced context.</li>
                                            <li>No files matching exclude pattern `*secret*` should be included in the balanced context.</li>
                                            <li>The LLM context mode 'balanced' should exclude files with glob patterns like '*secret*' from being included in the context.</li>
                                            <li>The file paths of excluded files should match the exclude patterns exactly (case-sensitive).</li>
                                            <li>No files with glob patterns like '*secret*' should be found in the directory tree of `tmp_path`.</li>
                                            <li>The LLM context mode 'balanced' should not include any files that are not part of a test or an existing file.</li>
                                            <li>The balanced context should exclude all files that match the exclude patterns, including subdirectories and nested directories.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        225 output =
                                        556 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163-164, 201, 284-286)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</p>
                                    <p><strong>Why Needed:</strong> To test that the ContextAssembler correctly handles a scenario where a balanced context file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context is empty', 'expected_result': {}, 'actual_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        88 output =
                                        289 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-161, 201)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_max_bytes_limit</span>
                            <div class="test-meta">
                                <span>14ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that balanced context respects max bytes limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential memory leak by ensuring the content is truncated when exceeding the maximum bytes limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the content in the source file does not exceed 120 bytes.</li>
                                            <li>The 'truncated' keyword is present in the content if it exceeds the maximum bytes limit.</li>
                                            <li>The content is truncated by removing some buffer for truncation messages.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        405 input +
                                        106 output =
                                        511 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</p>
                                    <p><strong>Why Needed:</strong> To test the balanced context with no coverage returns an empty dict.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': '{}', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        82 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 139-140)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_reaches_max_bytes_before_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that loop exits when max bytes is reached before processing file.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the ContextAssembler exceeds the maximum allowed bytes in a balanced context without reaching the end of any file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context should have only one node (either 'file1.py' or 'file2.py')</li>
                                            <li>context should not exceed max_bytes=5 when both files are processed</li>
                                            <li>context should be empty if neither file is processed</li>
                                            <li>context should contain the first file only (truncated) if it's the only file in the context</li>
                                            <li>context should not contain any other nodes if no files are processed</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        409 input +
                                        150 output =
                                        559 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-157, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</p>
                                    <p><strong>Why Needed:</strong> To ensure that the complete context delegates to balanced correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'inclusion', 'expected_inclusion': ['module.py'], 'actual_inclusion': ['module.py']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        90 output =
                                        301 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_empty_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for _get_test_source with empty nodeid</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function returns an empty string when given an empty nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Result is an empty string', 'expected_value': '', 'actual_value': 'result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        79 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 33, 78-79, 82-83, 86-89)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</p>
                                    <p><strong>Why Needed:</strong> To ensure that source extraction stops at the next function definition, as intended.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The test file contains a def statement immediately after the test function', 'expected_result': 'test_stop.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        95 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py</p>
                                    <p><strong>Why Needed:</strong> To test the edge case where the _get_test_source method returns an empty string when a non-existent file is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result is not None', 'expected_value': '', 'message': 'Expected result to be an empty string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        88 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 33, 78-79, 82-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</p>
                                    <p><strong>Why Needed:</strong> To ensure that the _get_test_source function correctly extracts functions with proper indentation, even when they are nested within other functions or blocks of code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'The extracted function should have correct indentation (2 spaces per level).', 'actual': 'The extracted function has incorrect indentation (1 space per level).'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        113 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_ranges.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that consecutive lines are compressed correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3', 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        69 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_duplicates</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_duplicates</p>
                                    <p><strong>Why Needed:</strong> To test the handling of duplicate ranges in the compress_ranges function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3', 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        71 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_empty_list</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_empty_list</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the function `compress_ranges` does not handle an empty input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        72 output =
                                        164 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 29-30)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of compressing mixed ranges in a list.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5, 10-12, 15', 'actual': '1-3, 5, 10-12, 15'}</li>
                                            <li>{'expected': 'True', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        103 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that non-consecutive lines are correctly compressed to a single value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1, 3, 5', 'actual': '1, 3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        84 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_single_line</p>
                                    <p><strong>Why Needed:</strong> The single line should not use range notation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 5, 'actual': '5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        64 output =
                                        160 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 29, 33, 35-37, 39, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_two_consecutive</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_two_consecutive</p>
                                    <p><strong>Why Needed:</strong> To ensure that two consecutive lines are correctly compressed into a single range.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-2', 'actual': '1-2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        74 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_unsorted_input</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_unsorted_input</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of `compress_ranges` only works with input that is already sorted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '[1, 3]', 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        84 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_empty_string</p>
                                    <p><strong>Why Needed:</strong> The current implementation does not handle empty strings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'value': [], 'description': 'Expected the function to return an empty list when given an empty string.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        82 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 81-82)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_mixed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_mixed</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for the expansion of mixed ranges and singles in the `expand_ranges` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3, 5, 10, 11, 12], 'actual': ['1', '2', '3', '5', '10', '11', '12']}</li>
                                            <li>{'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        119 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_range</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_range</p>
                                    <p><strong>Why Needed:</strong> The range function should expand to a list.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3], 'actual': ['1', '2', '3']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        74 output =
                                        173 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 81, 84-91, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_roundtrip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> compress_ranges and expand_ranges should be inverses.</p>
                                    <p><strong>Why Needed:</strong> Because the problem statement requires that `compress_ranges` and `expand_ranges` are inverses, meaning they should have a round-trip relationship. This ensures that any input to one function can be uniquely recovered from its output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'original input', 'value': [1, 2, 3, 5, 10, 11, 12, 15]}</li>
                                            <li>{'name': 'compressed input', 'value': []}</li>
                                            <li>{'name': 'expanded input', 'value': [1, 2, 3, 5, 10, 11, 12, 15]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        161 output =
                                        295 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67, 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_single_number</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_single_number</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for a specific scenario where the function expands ranges around a single number.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': [5], 'actual_value': ['5']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        77 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81, 84-87, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_render.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the format_duration function with different input values to verify it correctly formats as milliseconds for < 1s.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the function might not be able to accurately format durations less than 1 second.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return '500ms' when given an input of 0.5 seconds.</li>
                                            <li>The function should return '1ms' when given an input of 0.001 seconds.</li>
                                            <li>The function should return '0ms' when given an input of 0.0 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        131 output =
                                        342 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestFormatDuration::test_seconds</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the function format_duration() expects a float value as input, but it receives an integer value in the provided code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'format_duration(1.23)', 'expected': '1.23s'}</li>
                                            <li>{'name': 'format_duration(60.0)', 'expected': '60.00s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        105 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all outcomes map to CSS classes.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in CSS class mapping for different outcome types.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `outcome_to_css_class` should return a valid CSS class for each outcome type.</li>
                                            <li>The function `outcome_to_css_class` should handle all three outcome types ('passed', 'failed', and 'skipped') correctly.</li>
                                            <li>The function `outcome_to_css_class` should map the string 'xfailed' to the correct CSS class ('outcome-xfailed').</li>
                                            <li>The function `outcome_to_css_class` should map the string 'error' to the correct CSS class ('outcome-error').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        150 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</p>
                                    <p><strong>Why Needed:</strong> Unknown outcomes are not handled by the `outcome_to_css_class` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'outcome-unknown', 'actual_value': 'outcome-unknown'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        78 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_basic_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders basic report with fallback HTML.</p>
                                    <p><strong>Why Needed:</strong> Prevents rendering of incomplete or corrupted reports due to plugin or repository issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The '<!DOCTYPE html>' header is present in the rendered HTML.</li>
                                            <li>The 'Test Report' title is included in the rendered HTML.</li>
                                            <li>The 'test::passed' and 'test::failed' node IDs are found in the rendered HTML.</li>
                                            <li>The 'PASSED' and 'FAILED' keywords are displayed in the rendered HTML.</li>
                                            <li>The plugin version and repository version are displayed in the rendered HTML.</li>
                                            <li>The '<strong>Plugin:</strong>' and '<strong>Repo:</strong>' tags contain the expected values in the rendered HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        163 output =
                                        589 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65-67, 79-85, 87, 121-124, 126-127, 131-132, 155-157, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_renders_coverage' verifies that the test renders coverage information and includes it in the rendered HTML.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the test renders coverage information, which is crucial for tracking code coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report root contains a summary with total and passed tests.</li>
                                            <li>The report root contains a summary with total and passed tests.</li>
                                            <li>The report root contains a summary with total and passed tests.</li>
                                            <li>The test renders coverage information in the rendered HTML.</li>
                                            <li>The test renders coverage information in the rendered HTML.</li>
                                            <li>The test renders coverage information in the rendered HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        145 output =
                                        433 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-129, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</p>
                                    <p><strong>Why Needed:</strong> This test prevents the rendering of LLM annotations with a confidence score below 0.8, which could cause authentication bypass issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report includes the 'Tests login flow' scenario.</li>
                                            <li>The report includes the 'Prevents auth bypass' why needed message.</li>
                                            <li>The report includes the 'Confidence:' assertion with value '85%' or higher.</li>
                                            <li>The report does not include any annotations without a confidence score of 0.8 or above.</li>
                                            <li>The report does not contain any annotations without a scenario, why needed, or confidence assertion.</li>
                                            <li>The report is rendered correctly and does not contain any errors or warnings.</li>
                                            <li>The report includes all expected nodes in the HTML output.</li>
                                            <li>The report includes all expected assertions in the HTML output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        199 output =
                                        516 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">64 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-134, 136-137, 140-142, 144, 147, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the test renders source coverage summary with required information.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the source coverage summary is missing or incomplete.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'Source Coverage' section should be present in the HTML report.</li>
                                            <li>'src/foo.py'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        75 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-178, 180-186, 191, 206, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_xpass_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders xpass summary for ReportRoot with Summary containing both xfailed and xpassed entries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a rendering issue where the 'xfailed' and 'xpassed' counts are not displayed correctly when there is an overlap in the report summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The HTML contains both 'XFailed' and 'XPassed' strings.</li>
                                            <li>The HTML does not contain any other text that might interfere with the display of 'XFailed' and 'XPassed'.</li>
                                            <li>The 'XFailed' string is displayed correctly, even if there are multiple xfailed entries in the report summary.</li>
                                            <li>The 'XPassed' string is also displayed correctly, even if there are multiple xpassed entries in the report summary.</li>
                                            <li>No other text is displayed that might interfere with the display of 'XFailed' and 'XPassed'.</li>
                                            <li>There are no duplicate counts for either 'xfailed' or 'xpassed' in the report summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        216 output =
                                        499 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">19 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_different_content</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_different_content</p>
                                    <p><strong>Why Needed:</strong> To ensure that different content produces different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'different', 'actual': 'not equal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        66 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that an empty bytes object produces consistent hash values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected hash1 to be equal to hash2', 'expected_result': 'hash1 == hash2'}</li>
                                            <li>{'message': 'Expected length of hash1 to be 64', 'expected_result': 'len(hash1) == 64'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        104 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_run_meta</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the build_run_meta method returns the correct duration and version information for a test run.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the duration of a test run is not accurately reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The duration of the test run should be accurate (60 seconds in this case).</li>
                                            <li>The pytest version should be present in the metadata.</li>
                                            <li>The plugin version and Python version should also be included in the metadata.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        105 output =
                                        423 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies the ReportWriter to correctly build a summary of all outcome types.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the total count of outcomes is incorrect.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of tests should be equal to 6 (all outcome types).</li>
                                            <li>The passed tests should have 1 outcome type ('passed').</li>
                                            <li>The failed tests should have 1 outcome type ('failed').</li>
                                            <li>The skipped tests should have 1 outcome type ('skipped').</li>
                                            <li>The xfailed and xpassed tests should have 1 outcome type each ('xfailed' or 'xpassed').</li>
                                            <li>The error test should have 1 outcome type ('error').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        336 input +
                                        157 output =
                                        493 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 156-158, 319, 321-322, 324-335, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_counts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `total` attribute of the `Summary` object correctly counts all tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the total count of passed and failed tests is incorrect.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>summary.total should be equal to the number of tests.</li>
                                            <li>summary.passed should be equal to the number of tests that were passed.</li>
                                            <li>summary.failed should be equal to the number of tests that were failed.</li>
                                            <li>summary.skipped should be equal to the number of tests that were skipped.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        123 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 319, 321-322, 324-329, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_create_writer</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `ReportWriter` class initializes correctly and sets default values for its attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `ReportWriter` instance is not properly initialized with the required configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `config` attribute of the `writer` object should be set to an instance of `Config`.</li>
                                            <li>The `warnings` attribute of the `writer` object should be an empty list.</li>
                                            <li>The `artifacts` attribute of the `writer` object should be an empty list.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        199 input +
                                        126 output =
                                        325 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 156-158)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_assembles_tests</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that ReportWriter writes a report with all tests.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression in the case where no output paths are specified for the test reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the report.tests list should be equal to 2.</li>
                                            <li>The total value of report.summary.total should be equal to 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        83 output =
                                        338 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ReportWriter class correctly calculates and returns the total coverage percentage from a report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 85.5, 'actual_value': 'report.summary.coverage_total_percent'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        87 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-199, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_source_coverage</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_includes_source_coverage verifies that the test writes a report with source coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the test does not include source coverage in the report, potentially misleading users about the code's quality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `report.source_coverage` should be 1.</li>
                                            <li>The file path of `report.source_coverage[0]` should match `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        291 input +
                                        107 output =
                                        398 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_merges_coverage</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_merges_coverage verifies that the report writer merges coverage into tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report does not merge coverage into tests, potentially leading to inaccurate or misleading test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report should have a single merged coverage entry for the given test.</li>
                                            <li>The file path of the merged coverage entry should match the expected file path.</li>
                                            <li>All line ranges and counts in the coverage entry should be present.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        115 output =
                                        400 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">99 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186-189, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the ReportWriterWithFiles class falls back to direct write if an atomic write fails and a cross-device link occurs.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that would occur when the atomic write operation fails and a cross-device link is attempted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report file should exist at the specified path.</li>
                                            <li>Any warnings generated by the ReportWriterWithFiles class should have a code of 'W203'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        103 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513-514, 516-519, 522-523)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Report Writer with Files</p>
                                    <p><strong>Why Needed:</strong> The test should create an output directory if it doesn't exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Output Directory Existence', 'expected': True, 'actual': 'exists'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        171 input +
                                        69 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">128 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_ensure_dir_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `test_ensure_dir_failure` test case ensures a directory creation failure is captured as a warning.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the directory creation fails silently and does not raise an exception, potentially leading to unexpected behavior or errors in downstream code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer.warnings` list contains warnings with code 'W201' for any directory creation attempts that fail.</li>
                                            <li>Any directory creation attempt that raises an OSError is captured as a warning with code 'W201'.</li>
                                            <li>The test verifies that the `test_ensure_dir_failure` function correctly identifies and reports directory creation failures.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        147 output =
                                        425 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 156-158, 477-480, 487-491)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_git_info_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `get_git_info` function handles git command failures by returning `None` for both `sha` and `dirty` variables.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the `get_git_info` function fails to return expected values when it encounters a git command failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_git_info` function should return `None` for both `sha` and `dirty` variables in case of a git command failure.</li>
                                            <li>The test should pass even if the `git not found` exception is raised during the execution of `subprocess.check_output`.</li>
                                            <li>The expected values `None` for `sha` and `dirty` variables should be verified after calling `get_git_info`.</li>
                                            <li>The function should handle git command failures without raising an exception or crashing the test process.</li>
                                            <li>The test should verify that the returned values are consistent with the expected behavior in case of a failure.</li>
                                            <li>The test should cover all possible scenarios where `git not found` is raised during the execution of `subprocess.check_output`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        237 output =
                                        468 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_creates_file</span>
                            <div class="test-meta">
                                <span>37ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the report writer creates an HTML file with expected content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the report writer correctly generates an HTML file containing all necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'report.html' file should exist at the specified path.</li>
                                            <li>The 'report.html' file should contain the expected text content.</li>
                                            <li>All required assertions ('test1', 'test2') should be present in the 'report.html' file.</li>
                                            <li>The report writer should correctly identify test results as passed, failed, skipped, XFailed, or XPassed.</li>
                                            <li>Errors and warnings should not be included in the 'report.html' file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        366 input +
                                        152 output =
                                        518 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">120 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_includes_xfail_summary</span>
                            <div class="test-meta">
                                <span>37ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the report writer includes xfail outcomes in the HTML summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regressions where the report writer does not include xfail outcomes in the HTML summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Asserts that 'XFAILED' and 'XPASSED' are present in the HTML string.</li>
                                            <li>Checks if the text content of the HTML includes both 'XFAILED' and 'XPASSED'.</li>
                                            <li>Verifies that 'xfailed' and 'xpassed' keywords are found in the HTML summary.</li>
                                            <li>Ensures that the report writer correctly identifies xfail outcomes as 'xfailed' or 'xpassed'.</li>
                                            <li>Checks if the report includes all required text content for an xfail outcome.</li>
                                            <li>Verifies that the report does not include any other keywords related to failures.</li>
                                            <li>Ensures that the report is properly formatted and includes only necessary information.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        200 output =
                                        508 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-333, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_json_creates_file</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a JSON file is created with the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not create a JSON file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should be created in the specified path.</li>
                                            <li>At least one artifact should be tracked for the report.</li>
                                            <li>The number of artifacts tracked should be greater than zero.</li>
                                            <li>The file exists at the specified path.</li>
                                            <li>The `ReportWriter` class correctly tracks artifacts.</li>
                                            <li>The `write_report` method creates a new JSON file with the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        131 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_creates_file</span>
                            <div class="test-meta">
                                <span>40ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Should create PDF file when Playwright is available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not create a PDF file even if Playwright is available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `write_pdf` method of the `ReportWriter` class should be able to write the contents of the `report.pdf` file to the system.</li>
                                            <li>The `report.pdf` path should be created in the test directory.</li>
                                            <li>Any artifacts generated by the report writer should have a path that matches the expected value for `report.pdf`.</li>
                                            <li>The `write_report` method should raise an exception if Playwright is not available.</li>
                                            <li>If Playwright is available, it should create a PDF file with the specified path and contents.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        478 input +
                                        167 output =
                                        645 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-430, 441-442, 444-450, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_missing_playwright_warns</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a warning is raised when Playwright is missing for PDF output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the 'Warning: Could not find Playwright' message from being displayed when using PDF output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'report.pdf' should exist.</li>
                                            <li>Any warnings with code W204_PDF_PLAYWRIGHT_MISSING should be present in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        311 input +
                                        93 output =
                                        404 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</p>
                                    <p><strong>Why Needed:</strong> To test the Report Writer's ability to handle non-git directory paths and return empty values for SHA1 and dirty flags.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None', 'expected': {'type': 'NoneType', 'value': ''}, 'message': 'Expected get_git_info() to return None for sha parameter'}</li>
                                            <li>{'name': 'assert dirty is None', 'expected': {'type': 'NoneType', 'value': ''}, 'message': 'Expected get_git_info() to return None for dirty parameter'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        159 output =
                                        282 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_git_info` function returns a valid Git SHA and/or a string representation of the Git repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None or isinstance(sha, str)', 'description': 'The test asserts that the returned Git SHA is either None or an instance of str.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        159 input +
                                        109 output =
                                        268 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 67-74, 76-81, 83-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test falls back to git runtime when _git_info import fails.</p>
                                    <p><strong>Why Needed:</strong> To prevent a critical bug where the plugin Git Info cannot be imported and we still rely on it for fallback functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_plugin_git_info()` returns None or a string.</li>
                                            <li>The function `get_plugin_git_info()` does not raise an exception when _git_info import fails.</li>
                                            <li>The assertion `assert sha is None or isinstance(sha, str)` passes even if the fallback via git runtime fails.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        123 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_returns_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetPluginGitInfo</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin's Git information can be retrieved and used correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'str', 'actual_type': 'None'}</li>
                                            <li>{'expected_type': 'str', 'actual_type': 'is None or str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        141 input +
                                        94 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterAtomicWrite::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test atomic write fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure the ReportWriter can handle unexpected errors during atomic writes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Report writer should create a backup report when writing fails', 'description': 'The backup report is created even if the direct write operation fails.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        181 input +
                                        79 output =
                                        260 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_exception</span>
                            <div class="test-meta">
                                <span>114ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright raises exception (lines 424-432).</p>
                                    <p><strong>Why Needed:</strong> Prevents bug where the report writer fails to generate a PDF due to playwright exceptions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer.warnings` list should contain 'W201' warnings for each failed playwright context.</li>
                                            <li>The `writer.warnings` list should contain 'W202' warnings for each successful playwright context.</li>
                                            <li>The `report.pdf` file should be present in the test directory with a PDF extension.</li>
                                            <li>The `report.pdf` file should have a warning code of W201 or W202.</li>
                                            <li>The `report.pdf` file should not be empty.</li>
                                            <li>The `report.pdf` file should be a valid PDF document (not corrupted).</li>
                                            <li>The `writer.write_pdf` method should raise an exception when playwright raises an exception.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        356 input +
                                        190 output =
                                        546 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 156-158, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright is not installed.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the report writer fails to create a PDF file due to playwright being missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'W204' warning should be present in the output of the `writer.write_pdf()` method.</li>
                                            <li>The PDF file 'report.pdf' should not exist after the test is completed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        94 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 156-158, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_creates_temp</span>
                            <div class="test-meta">
                                <span>33ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source creates temp file when no HTML source exists.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails if there is no HTML source provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report writer should create a temporary HTML file.</li>
                                            <li>The temporary HTML file should have the correct suffix (.html).</li>
                                            <li>The path to the temporary HTML file should exist and be accessible.</li>
                                            <li>The suffix of the temporary HTML file should match the expected value (HTML).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        115 output =
                                        380 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 156-158, 455, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_missing_html_file</span>
                            <div class="test-meta">
                                <span>33ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source when configured HTML doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the test fails due to an unresolvable HTML source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` configuration should be able to resolve the HTML source even if it's missing.</li>
                                            <li>The resolved path for the HTML file should exist and not be a temporary file.</li>
                                            <li>The test should still pass even when the HTML file is nonexistent.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        108 output =
                                        378 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 455-457, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_uses_existing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the _resolve_pdf_html_source method uses an existing HTML file as required.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report writer does not use an existing HTML file, potentially leading to incorrect or missing information in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path of the resolved PDF is set to the specified HTML file.</li>
                                            <li>The report is not temporary (is_temp=False).</li>
                                            <li>The resolution method uses an existing HTML file instead of creating a new one.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        266 input +
                                        115 output =
                                        381 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 156-158, 455-458)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_schemas.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_from_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `AnnotationSchema.from_dict` creates a valid annotation from a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in the case where an invalid input is provided, causing the test to fail and potentially introducing bugs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert schema.scenario == "Verify login",</li>
                                            <li>assert schema.why_needed == "Catch auth bugs",</li>
                                            <li>assert schema.key_assertions == ["assert 200", "assert token"]</li>
                                            <li># Correctly asserts all required fields</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        120 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Should convert to dictionary with all fields.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression in authentication logic, ensuring correct data is returned for login scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'Verify login' in data['scenario']</li>
                                            <li>assert 'Catch auth bugs' in data['why_needed']</li>
                                            <li>assert all([item in data['key_assertions'] for item in ['assert 200', 'assert token']])</li>
                                            <li>assert data['confidence'] == 0.95</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        111 output =
                                        384 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 90-92, 94-98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_smoke_pytester.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_report_created</span>
                            <div class="test-meta">
                                <span>86ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The HTML report is generated correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report generation fails due to missing dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report file exists at the specified path.</li>
                                            <li>The report contains the expected test name.</li>
                                            <li>The report includes all necessary HTML tags.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        76 output =
                                        340 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_summary_counts_all_statuses</span>
                            <div class="test-meta">
                                <span>123ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_html_summary_counts_all_statuses verifies that the HTML summary counts include all statuses.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report does not include all statuses, which can make it difficult to diagnose issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>asserts that the 'Total Tests' label is present and has a count of 6.</li>
                                            <li>asserts that the 'Passed' label has a count of 1.</li>
                                            <li>asserts that the 'Failed' label has a count of 1.</li>
                                            <li>asserts that the 'Skipped' label has a count of 1.</li>
                                            <li>asserts that the 'XFailed' label has a count of 1.</li>
                                            <li>asserts that the 'XPassed' label has a count of 1.</li>
                                            <li>asserts that the 'Errors' and 'Error' labels have counts equal to 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        621 input +
                                        191 output =
                                        812 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 78-79, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212-214, 216, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-335, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_json_report_created</span>
                            <div class="test-meta">
                                <span>63ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The JSON report is created and its existence and content are verified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the report generation process fails to create or write the expected JSON file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>report_path.exists()</li>
                                            <li>data['schema_version']</li>
                                            <li>data['summary']['total'] == 2</li>
                                            <li>data['summary']['passed'] == 1</li>
                                            <li>data['summary']['failed'] == 1</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        108 output =
                                        403 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_annotations_in_report</span>
                            <div class="test-meta">
                                <span>55ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LLM annotations are included in the report when a provider is enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions by ensuring LLM annotations are present in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test passes without any errors or warnings.</li>
                                            <li>The 'LLM annotations' key is present in the report.</li>
                                            <li>The 'LLM annotations' value is 'True'.</li>
                                            <li>The 'why_needed' value is 'Prevents regressions'.</li>
                                            <li>The 'key_assertions' list contains the expected assertions.</li>
                                            <li>The 'choices' list within the 'payload' dictionary contains a valid LLM annotation.</li>
                                            <li>The 'message' key within each 'choice' dictionary has a valid message.</li>
                                            <li>The 'content' value of each 'message' dictionary is a valid JSON string.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        385 input +
                                        181 output =
                                        566 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 130-133, 135-137, 139, 141, 143, 190, 194-199, 201, 203, 205, 207, 210, 212-214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419-437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-506, 509, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_error_is_reported</span>
                            <div class="test-meta">
                                <span>89ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM errors are surfaced in HTML output.</p>
                                    <p><strong>Why Needed:</strong> Prevent regression where LLM errors are not reported correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_pass()` should raise an error with a meaningful message.</li>
                                            <li>The function `pytestLLMReport` should be able to detect and report the error.</li>
                                            <li>The HTML output of the test should contain the error message.</li>
                                            <li>The error message should be in the correct format (e.g. 'LLM errors are surfaced in HTML output.')</li>
                                            <li>The error message should not be a simple string but rather an actual error message from `litellm.completion`.</li>
                                            <li>The function `pytestLLMReport` should be able to handle different types of LLM errors (e.g. syntax errors, semantic errors).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        181 output =
                                        494 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-507, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>56ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the LLM opt-out marker is correctly recorded and reported.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM opt-out marker is not properly recorded or reported, potentially leading to incorrect analysis results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_opt_out' marker should be present in the test list.</li>
                                            <li>The 'llm_opt_out' marker should have an associated boolean value of True.</li>
                                            <li>The number of tests with the 'llm_opt_out' marker should be exactly 1.</li>
                                            <li>The first test in the list should have a 'llm_opt_out' marker.</li>
                                            <li>The 'llm_opt_out' marker should not be present for any other tests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        159 output =
                                        449 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181-182, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>55ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify requirement marker is recorded and correctly identified in report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the requirement marker might not be properly recorded or identified in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'requirement' keyword is used to mark requirements with specific names (REQ-001, REQ-002).</li>
                                            <li>The report generated by pytester includes all tests that have been marked as requiring a specific requirement.</li>
                                            <li>The test asserts that there is exactly one test that has been marked with both 'requirement' and 'REQ-001'.</li>
                                            <li>The test asserts that the required requirements are included in the list of tests.</li>
                                            <li>The test verifies that the 'REQ-001' and 'REQ-002' requirements are correctly identified in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        172 output =
                                        479 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-200, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_multiple_xfail_outcomes</span>
                            <div class="test-meta">
                                <span>60ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that multiple xfailed tests are recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where multiple tests fail due to a common cause, such as a test suite being updated or refactored.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of xfailed tests is correctly reported.</li>
                                            <li>Each xfailed test has an outcome of 'xfailed'.</li>
                                            <li>No other outcomes are recorded in the report for this test suite.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        103 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_skip_outcome</span>
                            <div class="test-meta">
                                <span>53ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipped tests are recorded and reported correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the reporting of skipped tests, ensuring they are accurately counted and displayed in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'skipped' key in the report data should contain a value equal to 1.</li>
                                            <li>The 'summary' section of the report data should contain an entry for 'skipped'.</li>
                                            <li>The number of skipped tests should be exactly 1 when reported in the JSON file.</li>
                                            <li>The 'report.json' file should contain a single key-value pair with the key 'skipped' and value 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        143 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_xfail_outcome</span>
                            <div class="test-meta">
                                <span>58ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that xfailed tests are correctly recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where only failed tests are reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key under 'xfailed' is present and contains a value of 1.</li>
                                            <li>The number of failed tests is exactly 1 as expected by the test.</li>
                                            <li>The xfailed count matches the actual number of failed tests in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        102 output =
                                        366 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestParametrization::test_parametrized_tests</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing parameterized tests to ensure correct reporting.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the reporting system by verifying that all parameterized tests are recorded correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of successful parameterized tests is 3.</li>
                                            <li>All parameterized tests are recorded separately and have a 'passed' status.</li>
                                            <li>The report.json file contains accurate data about the test runs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        96 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203-205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</span>
                            <div class="test-meta">
                                <span>48ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure the CLI help text includes usage examples.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'stdout', 'description': 'The test checks if the stdout matches the expected output.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        81 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_markers_registered</span>
                            <div class="test-meta">
                                <span>42ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_markers_registered</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the LLM markers are registered correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'LLM markers are not registered. Expected: True', 'expected': True}</li>
                                            <li>{'message': 'LLM context marker is not registered. Expected: True', 'expected': True}</li>
                                            <li>{'message': 'requirement marker is not registered. Expected: True', 'expected': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        133 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</span>
                            <div class="test-meta">
                                <span>49ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginRegistration</p>
                                    <p><strong>Why Needed:</strong> To verify that the plugin is successfully registered with pytest.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The plugin is registered', 'message': 'Plugin is registered via pytest11'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        64 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestSpecialCharacters::test_special_chars_in_nodeid</span>
                            <div class="test-meta">
                                <span>91ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that special characters in nodeid are handled correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential crash and ensures the HTML is valid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The presence of special characters in the nodeid is detected.</li>
                                            <li>The HTML report generated by pytester is valid.</li>
                                            <li>The '<html>' tag is present in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        86 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_time.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_boundary_one_minute</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_boundary_one_minute</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats a duration of exactly one minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': '1m 0.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        80 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_microseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_microseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats sub-millisecond durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert 'Œºs' in result", 'expected': '500Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        80 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_milliseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_milliseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-second durations as milliseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'ms' in result</li>
                                            <li>assert result == '500.0ms'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        70 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_minutes_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_minutes_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats durations over a minute, including displaying minutes and seconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert 'm' in result", 'expected': "'m'", 'actual': '1m 30.5s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        94 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_multiple_minutes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_multiple_minutes</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats multiple minutes into a human-readable string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '3m 5.0s', 'actual': '3m 5.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        79 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_one_second</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_one_second</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats a duration of exactly one second as '1.00s'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1.00s', 'actual': '1.0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        83 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_seconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_seconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats seconds under a minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "result contains 's'", 'expected': 'True'}</li>
                                            <li>{'name': "result equals '5.50s'", 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        97 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_small_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_small_milliseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats small millisecond durations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 1.0, 'actual': '1.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        75 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_very_small_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_very_small_microseconds</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of formatting very small durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1Œºs', 'actual': '1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        71 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_datetime_with_utc</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ISO Format with UTC</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct formatting of datetime objects in UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': '2024-01-15T10:30:45+00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        75 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</p>
                                    <p><strong>Why Needed:</strong> To ensure that the naive datetime format is correct and consistent across different timezones.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': '2024-06-20T14:00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        84 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_with_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests time formatting with microseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure datetime objects are correctly formatted with microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The result is a string containing the correct microsecond value.', 'expected_result': '123456'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        70 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_has_utc_timezone</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_has_utc_timezone</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `utc_now()` function returns a datetime object with an associated timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result.tzinfo is not None', 'expected_result': "datetime.timezone('UTC')", 'actual_result': 'None'}</li>
                                            <li>{'name': 'assert result.tzinfo == UTC', 'expected_result': "datetime.timezone('UTC')", 'actual_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        130 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_is_current_time</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the function returns a valid JSON response</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the function correctly returns a JSON response with the expected structure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected JSON structure', 'description': 'The returned JSON should have the following structure: `{'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        132 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_returns_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_returns_datetime</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `utc_now()` function returns a datetime object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'isinstance(result, datetime)', 'expected': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        71 output =
                                        165 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_command_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher raises error on command failure when get-token command fails.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the TokenRefresher class does not raise an exception when the get-token command fails, potentially causing unexpected behavior or errors in subsequent operations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit 1' status code is expected to be returned by subprocess.CompletedProcess().</li>
                                            <li>The error message 'Authentication failed' is expected to be included in the error message returned by pytest.raises(TokenRefreshError).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        310 input +
                                        119 output =
                                        429 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_empty_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when given an empty output.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the TokenRefresher does not raise an error when it encounters an empty output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get_token` method is set to an empty string.</li>
                                            <li>An exception of type `TokenRefreshError` is raised with the message 'empty output'.</li>
                                            <li>The assertion passes if the output is indeed empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        110 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-109, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'force_refresh' bypasses cache and returns a new token.</p>
                                    <p><strong>Why Needed:</strong> To ensure the TokenRefresher function behaves as expected when the `refresh_interval` is set to a value other than 3600 (default),</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function correctly returns a new token after force refresh.</li>
                                            <li>The function does not return the cached token.</li>
                                            <li>The function increments the call count correctly.</li>
                                            <li>The function sets the `call_count` variable correctly.</li>
                                            <li>The function updates the `stdout` and `stderr` attributes of the subprocess result correctly.</li>
                                            <li>The function returns a CompletedProcess object with an empty stdout and stderr attribute.</li>
                                            <li>The function does not raise any exceptions when force refreshing a token.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        167 output =
                                        513 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_custom_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `TokenRefresher` class uses a custom JSON key for token refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default JSON key used by the `TokenRefresher` class is not compatible with the expected custom key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `json_key` parameter of the `TokenRefresher` constructor is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        303 input +
                                        117 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `TokenRefresher` extracts a JSON object from the output of the `get-token` command.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the extracted token is not in the expected JSON format, potentially leading to incorrect usage or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get-token` command should be a JSON object with a single key-value pair: `token: 'json-token-value'` and an optional `expires_in` value.</li>
                                            <li>The extracted token should have the correct type (string) and value ('json-token-value').</li>
                                            <li>The presence of an `expires_in` value is optional and should be ignored if present.</li>
                                            <li>The JSON output should not contain any other keys or values that are not relevant to the token extraction process.</li>
                                            <li>The JSON output should be a valid JSON string, with no syntax errors or unexpected characters.</li>
                                            <li>The extracted token should have the correct format (e.g., 'Bearer <token_value>') if present in the output.</li>
                                            <li>The `json_key` parameter is set correctly and does not affect the expected output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        244 output =
                                        552 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_text_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `TokenRefresher` extracts the correct text format from the output of the `get-token` command.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the extracted token is not in the expected text format, potentially leading to incorrect usage or interpretation of the token.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get-token` command contains the string 'my-secret-token'.</li>
                                            <li>The output does not contain any non-text characters (e.g., lines starting with '#', etc.).</li>
                                            <li>The extracted token is in the same case as it appears in the original text.</li>
                                            <li>The extracted token has a length of at least 3 characters.</li>
                                            <li>The extracted token contains only alphanumeric characters and underscores.</li>
                                            <li>The extracted token does not contain any whitespace characters.</li>
                                            <li>The output contains no non-ASCII characters (e.g., emojis, etc.).</li>
                                            <li>The output is a single line of text.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        206 output =
                                        504 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `TokenRefresher` raises an error when given invalid JSON input.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher class incorrectly handles or raises an exception on receiving invalid JSON data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` in `TokenRefresher` should raise a `TokenRefreshError` when given invalid JSON input.</li>
                                            <li>The error message returned by `get_token()` should contain the string 'json'.</li>
                                            <li>The test should fail if the `get_token()` method is called with an invalid JSON argument.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        131 output =
                                        430 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-134, 149-150)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalidate</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher.invalidate() clears cache and returns the expected tokens after a refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not clear its cache after a refresh, leading to stale token values being returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` instance should return two different tokens after a 1-hour refresh.</li>
                                            <li>The function `invalidate()` of the `TokenRefresher` instance should clear its cache and return 2.</li>
                                            <li>The call count variable should be incremented by 2 when calling `invalidate()`.</li>
                                            <li>The returned token from `get_token()` should not be equal to the first token before a refresh.</li>
                                            <li>The returned token from `get_token()` should be different from the second token after a refresh.</li>
                                            <li>The output of `run()` should contain two tokens separated by a space.</li>
                                            <li>The error message from `run()` should be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        211 output =
                                        551 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_missing_json_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when JSON key is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the token refresh fails due to a missing required JSON key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method of the `TokenRefresher` class should raise a `TokenRefreshError` with a message indicating that the 'token' key is not found.</li>
                                            <li>The error message should be in lowercase and contain the word 'not'.</li>
                                            <li>The error message should indicate that the token was not found.</li>
                                            <li>The error message should specify the required JSON key as 'token'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        144 output =
                                        469 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139-141, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_thread_safety</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing thread safety of TokenRefresher by verifying that it returns the same token across multiple threads.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where multiple threads accessing the TokenRefresher instance concurrently could result in different tokens being returned, leading to inconsistencies in the data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>All threads should get the same token (first one to acquire lock)</li>
                                            <li>The length of the set of results should be equal to 1</li>
                                            <li>The first element of the results list should match 'token-1'</li>
                                            <li>Multiple threads accessing the TokenRefresher instance concurrently should not return different tokens</li>
                                            <li>The output format of the returned token should be consistent across all threads</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        427 input +
                                        154 output =
                                        581 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_timeout_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that TokenRefresher handles command timeouts correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the token refresh process times out and fails without providing any meaningful error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>A `TimeoutExpired` exception is raised with a message indicating that the command timed out.</li>
                                            <li>The `get_token()` method of the `TokenRefresher` instance raises an exception with a string containing 'timed out'.</li>
                                            <li>The test asserts that the error message contains the word 'timed out' in lowercase.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        127 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_token_caching</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that TokenRefresher caches tokens and doesn't call command again.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher calls the command multiple times due to caching.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` returns the same token when called with the same arguments.</li>
                                            <li>The `TokenRefresher` instance is only called once, even if it's called multiple times in a short period of time.</li>
                                            <li>No additional output or error messages are produced for repeated calls to `get_token()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        353 input +
                                        123 output =
                                        476 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_command_failure_no_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TokenRefresher's behavior when a command fails with no stderr output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the TokenRefresher incorrectly handles commands that do not produce any stderr output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method of the `TokenRefresher` class raises a `TokenRefreshError` when the command fails with no stderr output.</li>
                                            <li>The error message returned by the `get_token` method includes 'exit 1' as part of it.</li>
                                            <li>The error message also explicitly states that there is no error output produced by the command.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        137 output =
                                        459 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_empty_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TokenRefresherEdgeCases</p>
                                    <p><strong>Why Needed:</strong> Test handling of empty command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The function should raise a TokenRefreshError with the message 'empty' when given an empty command string.", 'expected_value': 'empty'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        75 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_invalid_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_invalid_command_string function to verify it handles an invalid command string (shlex parse error).</p>
                                    <p><strong>Why Needed:</strong> Prevent a TokenRefreshError when encountering an invalid command string during token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `TokenRefresher` constructor should raise a `TokenRefreshError` when given an invalid shell syntax in the `command` argument.</li>
                                            <li>The `get_token()` method of the `TokenRefresher` instance should return a `TokenRefreshError` exception when encountering an invalid command string.</li>
                                            <li>The error message returned by the `get_token()` method should contain the phrase 'Invalid command string'.</li>
                                            <li>The test should fail with a `TokenRefreshError` exception when calling `refresher.get_token()`.</li>
                                            <li>The `refresher` instance is expected to be in an invalid state after encountering an invalid command string.</li>
                                            <li>The `refresh_interval` and `output_format` arguments are not affected by the presence of an invalid command string.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        251 input +
                                        218 output =
                                        469 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-88, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_not_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the TokenRefresher raises a TokenRefreshError when receiving non-dict JSON output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the TokenRefresher incorrectly handles JSON output as a list instead of a dict.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` with an error message indicating that the output is not a JSON object.</li>
                                            <li>The function `get_token()` should assert that the error message contains the string 'Expected JSON object'.</li>
                                            <li>The function `get_token()` should assert that the error message contains the string 'list'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        328 input +
                                        137 output =
                                        465 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-137, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when token value is an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the TokenRefresher incorrectly handles empty or non-string token values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'token' key in the response should be empty or a string.</li>
                                            <li>The 'token' key in the response should not contain any whitespace characters.</li>
                                            <li>The error message should indicate that the token value is either empty or not a string.</li>
                                            <li>The output of the subprocess command should include an empty or non-string token value.</li>
                                            <li>The output of the subprocess command should not include any whitespace characters in the 'token' key.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        324 input +
                                        144 output =
                                        468 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_not_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the TokenRefresher handles non-string token values correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the TokenRefresher incorrectly handles tokens with non-string values, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method of the `TokenRefresher` instance raises a `TokenRefreshError` when it encounters an empty string or a non-string token value.</li>
                                            <li>The error message returned by the `get_token` method includes the phrase 'empty or not a string'.</li>
                                            <li>When a non-string token value is passed to the `get_token` method, the `json.dumps` function is used to convert it to JSON, which may result in an empty string if the token value cannot be converted.</li>
                                            <li>The `json_key` parameter of the `TokenRefresher` instance is set to 'token', which means that any non-string token values will be ignored and not returned by the `get_token` method.</li>
                                            <li>The `output_format` parameter of the `TokenRefresher` instance is set to 'json', which indicates that only JSON output should be produced. If a non-string token value is passed, it will not be included in the output.</li>
                                            <li>The `json_key` and `output_format` parameters are used together to ensure that only valid token values are returned by the `get_token` method.</li>
                                            <li>If a non-string token value is encountered, the `TokenRefreshError` exception will be raised with an error message indicating that the token value was empty or not a string.</li>
                                            <li>The test verifies that the `TokenRefresher` instance correctly handles non-string tokens by asserting that it raises a `TokenRefreshError` exception when such a value is passed to the `get_token` method.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        326 input +
                                        385 output =
                                        711 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_oserror_on_execution</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TokenRefresher's handling of OSError when executing a command.</p>
                                    <p><strong>Why Needed:</strong> Prevents the test from passing if an OSError is raised during execution, which could indicate a bug or regression.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method raises a `TokenRefreshError` with a message indicating that the command was not found.</li>
                                            <li>The error message includes the string 'Failed to execute'.</li>
                                            <li>The `pytest.raises(TokenRefreshError)` assertion checks if the `TokenRefreshError` is raised correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        122 output =
                                        402 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113, 115-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_text_only_whitespace_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when text output has only whitespace lines after initial strip.</p>
                                    <p><strong>Why Needed:</strong> Prevents TokenRefreshError due to incorrect parsing of text with only blank lines after the initial strip.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _parse_output method should raise a TokenRefreshError when given input that has only non-empty lines after the initial strip.</li>
                                            <li>The output wrapper should contain non-whitespace content but only whitespace lines in the parsed output.</li>
                                            <li>The parsing method should correctly handle text with only blank lines after the initial strip and return an error.</li>
                                            <li>The test should fail when given input that meets these conditions to ensure the correct behavior of TokenRefresher.</li>
                                            <li>The output wrapper should contain non-whitespace content but only whitespace lines in the parsed output.</li>
                                            <li>The parsing method should correctly handle text with only blank lines after the initial strip and return an error.</li>
                                            <li>The test should pass when given input that meets these conditions to ensure the correct behavior of TokenRefresher.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        376 input +
                                        213 output =
                                        589 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 132, 153-155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_whitespace_only_command</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_whitespace_only_command to ensure it correctly raises a TokenRefreshError for an empty command string.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the TokenRefresher is unable to handle whitespace-only commands that do not contain any tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` when given an empty command string.</li>
                                            <li>The error message should include the word 'empty' and be case-insensitive (e.g., 'empty token'.').</li>
                                            <li>The test assertion should verify that the error message contains the word 'empty'.</li>
                                            <li>The function should not raise a `TokenRefreshError` when given a non-empty command string.</li>
                                            <li>The test assertion should verify that no error is raised for a non-empty command string.</li>
                                            <li>The function should return an empty token (or None) when given a non-empty command string.</li>
                                            <li>The test assertion should verify that the returned token is indeed empty (or None).</li>
                                            <li>The function should handle whitespace-only commands correctly and raise the expected `TokenRefreshError` instance.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        237 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_usage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_usage.py::test_token_usage_aggregation</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test token usage aggregation with mock stash and pytest config to prevent early binding issues.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in token usage aggregation when using a mock stash and pytest config to avoid early binding issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the total input tokens, total output tokens, and annotations count are correctly calculated for each test.</li>
                                            <li>Verify that the terminal summary is run with the correct information.</li>
                                            <li>Verify that the llm_info dictionary contains the expected values for total_input_tokens, total_output_tokens, and annotations_count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        775 input +
                                        124 output =
                                        899 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-487, 491-494, 497, 499, 502-506, 509, 512-514, 516-521, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
        </div>
        </section>
    </div>
</body>
</html>