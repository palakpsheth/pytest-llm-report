<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Report &bull; 623 tests</title>
    <!-- Optional: Inter font from rsms.me CDN. Falls back to system fonts if unavailable. -->
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <style>
/* Modern Color Palette */
:root {
    --bg-color: #f8fafc;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --border-color: #e2e8f0;
    --card-bg: #ffffff;
    --surface-muted: #f1f5f9;
    --primary-color: #3b82f6;
    color-scheme: light dark;

    /* Status Colors */
    --passed-bg: #dcfce7;
    --passed-text: #166534;
    --failed-bg: #fee2e2;
    --failed-text: #991b1b;
    --skipped-bg: #fef9c3;
    --skipped-text: #854d0e;
    --xfailed-bg: #ffedd5;
    --xfailed-text: #9a3412;
    --xpassed-bg: #f3e8ff;
    --xpassed-text: #6b21a8;
    --error-bg: #fee2e2;
    --error-text: #991b1b;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background-color: var(--bg-color);
    color: var(--text-primary);
    line-height: 1.5;
    margin: 0;
    padding: 0;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
}

/* Header */
header {
    margin-bottom: 2rem;
    border-bottom: 1px solid var(--border-color);
    padding-bottom: 1rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

h1 {
    font-size: 1.875rem;
    font-weight: 700;
    color: var(--text-primary);
    margin: 0;
}

.meta {
    font-size: 0.875rem;
    color: var(--text-secondary);
}

/* Summary Grid */
.summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 1rem;
    margin-bottom: 2rem;
}

.summary-card {
    background: var(--card-bg);
    border-radius: 0.5rem;
    padding: 1.5rem;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
    text-align: center;
    border: 1px solid var(--border-color);
    transition: transform 0.2s;
}

.summary-card:hover {
    transform: translateY(-2px);
}

.summary-card .count {
    font-size: 2.25rem;
    font-weight: 700;
    line-height: 1;
    margin-bottom: 0.5rem;
}

.summary-card .label {
    text-transform: uppercase;
    font-size: 0.75rem;
    font-weight: 600;
    letter-spacing: 0.05em;
    color: var(--text-secondary);
}

/* Status Colors for Summary */
.summary-card.passed .count {
    color: var(--passed-text);
}

.summary-card.failed .count {
    color: var(--failed-text);
}

.summary-card.skipped .count {
    color: var(--skipped-text);
}

.summary-card.xfailed .count {
    color: var(--xfailed-text);
}

.summary-card.xpassed .count {
    color: var(--xpassed-text);
}

.summary-card.coverage .count {
    color: var(--primary-color);
}

/* Filters */
.filters {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid var(--border-color);
    margin-bottom: 1.5rem;
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.filter-input {
    flex: 1;
    padding: 0.5rem 1rem;
    border: 1px solid var(--border-color);
    border-radius: 0.375rem;
    font-size: 0.875rem;
    background: var(--card-bg);
    color: var(--text-primary);
}

.filter-input::placeholder {
    color: var(--text-secondary);
}

.filter-statuses {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
}

.filter-chip {
    display: inline-flex;
    align-items: center;
    gap: 0.35rem;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    border: 1px solid var(--border-color);
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.04em;
}

.filter-chip input {
    margin: 0;
}

.filter-chip.passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.filter-chip.failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.filter-chip.skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.filter-chip.xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.filter-chip.xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.filter-chip.error {
    background: var(--error-bg);
    color: var(--error-text);
}

/* Test List */
.test-list {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.test-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
    overflow: hidden;
}

.test-header {
    padding: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    cursor: pointer;
    background: var(--card-bg);
}

.test-header:hover {
    background: var(--surface-muted);
}

.status-badge {
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
}

.status-passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.status-failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.status-skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.status-xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.status-xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.status-error {
    background: var(--error-bg);
    color: var(--error-text);
}

.test-name {
    flex: 1;
    font-family: monospace;
    font-size: 0.9rem;
    color: var(--text-primary);
    word-break: break-all;
}

.test-meta {
    display: flex;
    gap: 1rem;
    align-items: center;
    color: var(--text-secondary);
    font-size: 0.875rem;
}

/* Details Section */
.test-details {
    padding: 0 1rem 1rem 1rem;
    border-top: 1px solid var(--border-color);
    background: var(--surface-muted);
}

.detail-section {
    margin-top: 1rem;
}

.detail-title {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    color: var(--text-secondary);
    margin-bottom: 0.5rem;
}

.coverage-item {
    font-family: monospace;
    font-size: 0.85rem;
    padding: 0.25rem 0;
    border-bottom: 1px solid var(--border-color);
    display: grid;
    grid-template-columns: minmax(200px, 2fr) minmax(120px, 1fr);
    gap: 1rem;
}

.coverage-list {
    background: var(--card-bg);
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
    overflow: hidden;
}

.source-coverage {
    margin-top: 2rem;
}

.source-coverage h2 {
    margin: 0 0 1rem;
    font-size: 1.5rem;
}

.source-coverage-table {
    display: grid;
    gap: 0.35rem;
}

.source-coverage-header,
.source-coverage-row {
    display: grid;
    grid-template-columns: minmax(200px, 2fr) repeat(4, minmax(60px, 0.5fr)) minmax(
            140px,
            1fr
        ) minmax(140px, 1fr);
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
}

.source-coverage-header {
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.04em;
    color: var(--text-secondary);
}

.source-coverage-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    font-size: 0.85rem;
}

.source-path {
    font-family: monospace;
    word-break: break-word;
}

.source-lines {
    font-family: monospace;
    color: var(--text-secondary);
    word-break: break-word;
}

.llm-annotation {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
}

.llm-annotation p {
    margin: 0 0 0.5rem 0;
}

.llm-annotation p:last-child {
    margin-bottom: 0;
}

.llm-annotation ul {
    margin: 0.5rem 0 0;
    padding-left: 1.25rem;
}

.llm-annotation li {
    margin-bottom: 0.25rem;
}

.error-message {
    font-family: monospace;
    color: var(--failed-text);
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--failed-bg);
    white-space: pre-wrap;
    overflow-x: auto;
}

/* HTML5 Progress Bar for Coverage */
progress {
    width: 60px;
}

/* Utility: Hidden state for filtering */
.hidden {
    display: none !important;
}

/* Dark Mode Support */
@media (prefers-color-scheme: dark) {
    :root {
        --bg-color: #0f172a;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
        --border-color: #334155;
        --card-bg: #1e293b;
        --surface-muted: #0b1220;
        --primary-color: #60a5fa;

        /* Status Colors - Adjusted for dark mode */
        --passed-bg: #14532d;
        --passed-text: #86efac;
        --failed-bg: #7f1d1d;
        --failed-text: #fca5a5;
        --skipped-bg: #713f12;
        --skipped-text: #fde047;
        --xfailed-bg: #7c2d12;
        --xfailed-text: #fdba74;
        --error-bg: #7f1d1d;
        --error-text: #fca5a5;
    }

    /* Adjust box shadows for dark mode */
    .summary-card {
        box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.3), 0 1px 2px -1px rgb(0 0 0 / 0.3);
    }
}

@media print {
    body {
        background: #ffffff;
        color: #0f172a;
    }

    .container {
        max-width: none;
        padding: 1rem 1.5rem;
    }

    header {
        border-bottom: 2px solid var(--border-color);
    }

    .filters {
        display: none;
    }

    .summary-card,
    .test-row {
        box-shadow: none;
    }

    .test-header {
        background: #ffffff;
    }

    .test-row {
        page-break-inside: avoid;
        break-inside: avoid;
    }

    .test-details {
        background: #ffffff;
    }

    .llm-annotation {
        background: var(--surface-muted);
    }

    progress {
        width: 80px;
    }
}

body.pdf-mode .filters {
    display: none;
}

body.pdf-mode .test-row {
    page-break-inside: avoid;
    break-inside: avoid;
}

/* TOC Styling */
.toc {
    margin-bottom: 2rem;
    padding: 1rem;
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
}
.toc ul {
    list-style: none;
    padding: 0;
    margin: 0;
    display: flex;
    gap: 1.5rem;
    flex-wrap: wrap;
}
.toc a {
    color: var(--primary-color);
    text-decoration: none;
    font-weight: 600;
    cursor: pointer;
}
.toc a:hover {
    text-decoration: underline;
}

/* File Group Styling */
.test-file-group {
    margin-bottom: 2rem;
}
.test-file-header {
    font-size: 1.1rem;
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid var(--border-color);
    display: flex;
    justify-content: space-between;
    align-items: center;
}    </style>
    <script>
// pytest-llm-report interactive features

// Global state for filters
const activeStatuses = new Set(['passed', 'failed', 'skipped', 'xfailed', 'xpassed', 'error']);

// Filter tests based on search input and outcome filters
function filterTests() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    document.querySelectorAll('.test-row').forEach(row => {
        const nodeid = row.querySelector('.test-name').textContent.toLowerCase();
        const statusMatch = row.dataset.status ? activeStatuses.has(row.dataset.status) : false;
        const matchesSearch = nodeid.includes(query);
        row.classList.toggle('hidden', !matchesSearch || !statusMatch);
    });
}

// Show only failures and scroll to list
function showFailuresOnly() {
    document.querySelectorAll('.filter-chip input').forEach(cb => {
        const s = cb.dataset.status;
        if (s === 'failed' || s === 'error') {
            cb.checked = true;
            activeStatuses.add(s);
        } else {
            cb.checked = false;
            activeStatuses.delete(s);
        }
    });
    filterTests();
    const testList = document.getElementById('test-list');
    if (testList) {
        testList.scrollIntoView({ behavior: 'smooth' });
    }
}

// Toggle visibility of status filters
function toggleStatus(checkbox) {
    const status = checkbox.dataset.status;
    if (checkbox.checked) {
        activeStatuses.add(status);
    } else {
        activeStatuses.delete(status);
    }
    filterTests();
}

// Initialize interactive features after DOM is ready
document.addEventListener('DOMContentLoaded', function () {
    'use strict';

    // Toggle dark mode on preference
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.documentElement.dataset.theme = 'dark';
    }

    // Default: expand all details
    document.querySelectorAll('details').forEach(details => {
        details.setAttribute('open', '');
    });

    const params = new URLSearchParams(window.location.search);
    if (params.get('pdf') === '1') {
        document.body.classList.add('pdf-mode');
    }
});    </script>
</head>
<body>
    <div class="container">
        <header>
            <div>
                <h1>Test Report</h1>
                <div class="meta">
                    Run ID: 21197045261-py3.12 &bull;
                    Generated: 2026-01-21 04:20:47 &bull;
                    Duration: 119.85s<br>
                    <strong>Plugin:</strong> v0.2.0
                        (a03dbe622cdc018f89b74731aed91adf1a582867)
[dirty]<br>
                    <strong>Repo:</strong> v0.2.0
                        (6ca9d0d9b8119ce18efb8514475229959a5a445b)
<br>
                    <strong>LLM:</strong> ollama / llama3.2:1b
                        (minimal context,
                         620 annotated, 2 errors)
                        <br><strong>Token Usage:</strong>
                        131832 input,
                        75520 output
                        (Total: 207352)
                </div>
            </div>
            <div style="text-align: right">
                <div style="font-size: 2rem; font-weight: 700; color: var(--primary-color)">
                    93.04%
                </div>
                <div class="meta">Total Coverage</div>
            </div>
        </header>

        <!-- Summary Cards -->
        <div class="summary">
            <div class="summary-card">
                <div class="count">623</div>
                <div class="label">Total Tests</div>
            </div>
            <div class="summary-card passed">
                <div class="count">623</div>
                <div class="label">Passed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Failed</div>
            </div>
            <div class="summary-card skipped">
                <div class="count">0</div>
                <div class="label">Skipped</div>
            </div>
            <div class="summary-card xfailed">
                <div class="count">0</div>
                <div class="label">XFailed</div>
            </div>
            <div class="summary-card xpassed">
                <div class="count">0</div>
                <div class="label">XPassed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Errors</div>
            </div>
        </div>

        <!-- Table of Contents -->
        <nav class="toc">
            <ul>
                <li><a href="#source-coverage">Source Coverage</a></li>
                <li><a href="#test-list">Per Test Details</a></li>
                <li><a onclick="showFailuresOnly()">Failures Only</a></li>
            </ul>
        </nav>

        <section class="source-coverage" id="source-coverage">
            <h2>Source Coverage</h2>
            <div class="source-coverage-table">
                <div class="source-coverage-header">
                    <span>File</span>
                    <span>Stmts</span>
                    <span>Miss</span>
                    <span>Cover</span>
                    <span>%</span>
                    <span>Covered Lines</span>
                    <span>Missed Lines</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/_git_info.py</span>
                    <span>2</span>
                    <span>0</span>
                    <span>2</span>
                    <span>100.0%</span>
                    <span class="source-lines">2-3</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/aggregation.py</span>
                    <span>121</span>
                    <span>6</span>
                    <span>115</span>
                    <span>95.04%</span>
                    <span class="source-lines">13, 15-19, 21, 36, 39, 45, 47, 53-54, 56-58, 60, 62-65, 70, 74-75, 78-81, 85, 88-90, 94, 104, 110, 113-115, 117-121, 123-124, 129, 131-132, 134-135, 138-139, 145-147, 149, 152, 155, 158, 160, 162, 176, 178, 182, 184, 186, 196, 198-202, 204-205, 208, 210, 219, 231, 233-247, 249, 251, 259-260, 262-263, 265, 267-269, 273, 276-277, 279-280, 283, 285-286, 288, 290-291, 295</span>
                    <span class="source-lines">67, 91-92, 111, 206, 217</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/cache.py</span>
                    <span>47</span>
                    <span>3</span>
                    <span>44</span>
                    <span>93.62%</span>
                    <span class="source-lines">13, 15-19, 21, 27, 33, 39-41, 43, 53, 55-56, 58, 60-62, 68-69, 78, 86, 88, 90, 92, 94, 97, 103, 107, 118-119, 121, 123, 129, 132-136, 141, 144, 153</span>
                    <span class="source-lines">64-65, 130</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/collector.py</span>
                    <span>111</span>
                    <span>1</span>
                    <span>110</span>
                    <span>99.1%</span>
                    <span class="source-lines">19, 21-22, 24, 26-27, 33-34, 45-50, 52, 58, 60-62, 69, 78-79, 81, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127-128, 130, 132-133, 135-137, 140-141, 143, 155, 163-164, 167-169, 171, 173, 181-182, 185-189, 191, 198-200, 202, 209-210, 212-214, 216, 218, 227-228, 230-236, 238, 241, 250-252, 254, 261, 264-265, 268-269, 271, 277, 279, 285</span>
                    <span class="source-lines">239</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/context_util.py</span>
                    <span>53</span>
                    <span>3</span>
                    <span>50</span>
                    <span>94.34%</span>
                    <span class="source-lines">13-15, 18, 27, 29-31, 33, 35-36, 38-41, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 72, 81-82, 86, 88-90, 93, 96, 108, 111, 124, 126-127, 129-130, 133, 135</span>
                    <span class="source-lines">53, 83-84</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/coverage_map.py</span>
                    <span>135</span>
                    <span>6</span>
                    <span>129</span>
                    <span>95.56%</span>
                    <span class="source-lines">13, 15-17, 19-22, 30, 38, 44-45, 47, 58-60, 64, 72-73, 83, 86, 88-90, 92, 94-96, 98, 101-104, 106-108, 114, 116, 118, 121-122, 127-128, 131-135, 137-140, 144-146, 148, 150, 152-153, 156, 160-162, 165, 167-168, 173, 176, 178-184, 187-189, 191, 196, 199-200, 202, 204, 216-217, 220, 224-225, 228-234, 236, 239, 241, 243-244, 246-250, 252-254, 257, 259-260, 263-264, 271, 273-274, 276-279, 281-283, 285, 299-300, 302, 308</span>
                    <span class="source-lines">62, 123, 125, 157, 221, 251</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/errors.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">8-9, 12, 25-28, 31-36, 39-42, 45-46, 49-51, 54-55, 64-66, 68, 70, 73, 77-79, 83, 132, 142</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/__init__.py</span>
                    <span>3</span>
                    <span>0</span>
                    <span>3</span>
                    <span>100.0%</span>
                    <span class="source-lines">4-5, 7</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/annotator.py</span>
                    <span>154</span>
                    <span>21</span>
                    <span>133</span>
                    <span>86.36%</span>
                    <span class="source-lines">4, 6-10, 12-15, 21-22, 25-30, 33, 47-48, 50-52, 56, 58-59, 65, 67-68, 70, 73-74, 76, 84, 86-90, 95-96, 98-99, 106-107, 112-113, 116, 121-126, 130, 132, 134, 137, 144, 156, 181-182, 184, 186, 188-189, 199, 211, 213-216, 221-223, 226, 249-252, 254-255, 260, 262, 264-267, 269-270, 277-279, 281, 283-284, 289-290, 292-293, 298-301, 303, 306, 329-332, 334, 336, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381</span>
                    <span class="source-lines">77-81, 160-168, 173, 286-287, 345, 364-365, 371</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/base.py</span>
                    <span>131</span>
                    <span>6</span>
                    <span>125</span>
                    <span>95.42%</span>
                    <span class="source-lines">13, 15-18, 20, 30, 33, 47, 50, 53, 59, 65-66, 68, 87-88, 96, 101, 103, 105, 128, 134-135, 137-138, 149, 155, 157, 163, 165, 174, 176, 185-186, 188, 191-198, 200, 202, 212, 214-217, 219-222, 224, 232, 243, 245, 247, 264, 266-267, 270-272, 274-275, 277, 279, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314, 316, 325-326, 329-331, 333-334, 337-339, 342-347, 351, 353, 359-360, 363-364, 367-369, 372, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404, 406</span>
                    <span class="source-lines">91-92, 230, 284, 292, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/batching.py</span>
                    <span>90</span>
                    <span>4</span>
                    <span>86</span>
                    <span>95.56%</span>
                    <span class="source-lines">8, 10-13, 20, 23-24, 27-29, 31-32, 34, 36-37, 39, 44, 53-55, 58, 67-68, 70, 73, 92-93, 95, 97, 103-106, 108-110, 112, 122-123, 126-128, 136, 139, 156-157, 160, 162, 164-167, 170-176, 181-185, 187-188, 190, 192-194, 196-197, 203-206, 209-210, 213-214, 216-218, 222, 224</span>
                    <span class="source-lines">158, 207, 211, 220</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/gemini.py</span>
                    <span>325</span>
                    <span>7</span>
                    <span>318</span>
                    <span>97.85%</span>
                    <span class="source-lines">7, 9-13, 15-16, 23-27, 30-34, 37-42, 44-46, 48-50, 52, 57-63, 65-70, 72-73, 75-78, 80-85, 87-89, 91-97, 99-114, 121-122, 125, 128, 134-135, 137-141, 143-144, 146, 164-166, 173-175, 178, 181-182, 184, 186-189, 191-192, 198-206, 208-210, 212-213, 215, 218, 221-230, 232-233, 235-237, 239-243, 246-247, 249-252, 254-255, 259, 261, 263, 268, 272-276, 279-281, 283, 288-293, 295, 299-305, 308-309, 311-312, 318-319, 322, 326, 332-333, 335, 339-343, 345-349, 352-353, 358-359, 366-367, 369, 383, 385-386, 390, 410, 413-415, 418-422, 424-427, 432, 434-435, 437, 441-444, 446, 449-463, 469, 471-473, 475-478, 480, 486, 488-491, 493, 495, 497-498, 502-508, 511, 514-516, 518-521, 523-528, 534, 537, 539-543, 547-548, 550-559, 562-564, 567-570, 574</span>
                    <span class="source-lines">115-117, 298, 310, 313-314</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/litellm_provider.py</span>
                    <span>77</span>
                    <span>1</span>
                    <span>76</span>
                    <span>98.7%</span>
                    <span class="source-lines">8, 10, 12-13, 21, 31, 37-38, 41-42, 44, 51, 60-62, 64, 82-83, 89, 92, 95-96, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 122, 124-126, 129-130, 132, 135, 137, 139, 141-142, 144, 148, 170, 182-183, 186-188, 190, 192-193, 196-198, 204, 206, 211, 213, 215, 221-222, 224, 227-231, 234, 236, 242-243, 245</span>
                    <span class="source-lines">207</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/noop.py</span>
                    <span>13</span>
                    <span>0</span>
                    <span>13</span>
                    <span>100.0%</span>
                    <span class="source-lines">8, 10, 12-13, 20, 26, 32, 34, 51, 53, 59, 61, 67</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/ollama.py</span>
                    <span>72</span>
                    <span>1</span>
                    <span>71</span>
                    <span>98.61%</span>
                    <span class="source-lines">7, 9, 11-12, 18, 24, 42-43, 49, 52-53, 55, 58, 60-61, 63-67, 70, 74-77, 83, 85-86, 92, 94, 96-98, 100-101, 103, 107, 113-114, 116-118, 122, 128, 130, 138, 140, 142-144, 149-150, 156, 158, 160-162, 165-167, 172-173, 178, 180, 190, 192-193, 204, 209, 211-212</span>
                    <span class="source-lines">90</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/schemas.py</span>
                    <span>36</span>
                    <span>1</span>
                    <span>35</span>
                    <span>97.22%</span>
                    <span class="source-lines">8, 10-12, 16, 22, 38, 42-44, 46-47, 50-53, 55, 58-59, 62-65, 67-68, 77, 84, 90, 94-98, 102, 130</span>
                    <span class="source-lines">39</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/token_refresh.py</span>
                    <span>71</span>
                    <span>0</span>
                    <span>71</span>
                    <span>100.0%</span>
                    <span class="source-lines">7, 9-14, 17, 20, 23-24, 36-39, 41-43, 47, 59-60, 63-66, 69-72, 74, 83, 85-88, 90-91, 93, 101-103, 107-109, 111, 113-116, 120, 132-136, 139-140, 143-145, 148-150, 153-156, 158, 160-162</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/utils.py</span>
                    <span>33</span>
                    <span>2</span>
                    <span>31</span>
                    <span>93.94%</span>
                    <span class="source-lines">4, 6, 9, 20, 23, 42-43, 46-47, 51-53, 55-56, 66, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90, 93-94, 96, 98</span>
                    <span class="source-lines">48, 78</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/models.py</span>
                    <span>253</span>
                    <span>0</span>
                    <span>253</span>
                    <span>100.0%</span>
                    <span class="source-lines">17-18, 20, 23, 26-27, 36-38, 40, 42, 49-50, 59-61, 63, 65, 72-73, 86-92, 94, 96, 107-108, 120-126, 128, 130, 135-143, 146-147, 169-185, 187-188, 190, 192, 194, 201-224, 227-228, 236-237, 239, 241, 247-248, 257-259, 261, 263, 270-271, 280-282, 284, 286, 290-292, 295-296, 333-362, 364-372, 374, 376, 394-417, 419-437, 440-441, 455-463, 465, 467, 477-479, 482-483, 500-510, 512, 518, 520, 526-540</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/options.py</span>
                    <span>268</span>
                    <span>57</span>
                    <span>211</span>
                    <span>78.73%</span>
                    <span class="source-lines">122, 170, 199, 202-204, 209-211, 217-219, 225-227, 233-235, 241-242, 245-254, 257-259, 265-267, 271-274, 276, 284, 293, 308, 311-312, 320-325, 327, 332-337, 340-345, 348-349, 352-353, 356-357, 360-369, 372-375, 378-393, 396-397, 400-405, 408-409, 412-413, 416-421, 426-427, 430-431, 436-439, 444-447, 449, 451, 453, 460-461, 463-464, 466-467, 470-475, 479, 482-495, 498, 502-503, 507, 510, 514-515, 519-520, 524, 527, 531, 534-536, 540-541, 545-546, 550, 553, 557, 560, 564-565, 569, 572-574, 578, 581-584, 587, 591-592, 596, 599-608, 611, 613</span>
                    <span class="source-lines">13-15, 21-22, 98-102, 105-107, 110-115, 118-121, 138-139, 142-149, 152-155, 158-160, 163-166, 169, 180-184, 187-188, 191, 193, 278, 287, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/plugin.py</span>
                    <span>182</span>
                    <span>24</span>
                    <span>158</span>
                    <span>86.81%</span>
                    <span class="source-lines">41, 44, 50, 56, 62, 68, 74, 81, 90, 96, 102, 108, 114, 122, 128, 134, 142, 148, 155, 161, 169, 176, 185, 192, 199, 208, 215, 223, 229, 235, 241, 247, 254, 260, 268, 274, 283, 289, 297, 304, 311, 328, 332, 336, 342-343, 346-347, 349, 351, 354-356, 362-363, 371-372, 399-400, 403-404, 407, 410-411, 413-414, 417-418, 420, 422-426, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 476-477, 485-487, 491-494, 497, 499, 502-507, 509, 512-514, 516-521, 523, 534-535, 558-559, 562-563, 566-568, 579-580, 583, 586-587, 590-592, 602-603, 606-608, 619-620, 623, 626, 628-629</span>
                    <span class="source-lines">13, 15-18, 20-21, 23, 29-32, 35, 319, 377, 481-482, 488, 548-549, 571, 595, 611-612</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/prompts.py</span>
                    <span>110</span>
                    <span>3</span>
                    <span>107</span>
                    <span>97.27%</span>
                    <span class="source-lines">13, 15-17, 24, 27, 33, 35, 49, 52, 55, 58-61, 63, 65, 67, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 114, 116, 118, 139-140, 142-144, 147, 152-153, 155-157, 159-161, 163-164, 166-167, 170-171, 173, 177, 180, 189, 192-194, 196-197, 201, 203, 216-217, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249, 251, 268, 275, 284-287</span>
                    <span class="source-lines">80, 185, 233</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/render.py</span>
                    <span>65</span>
                    <span>6</span>
                    <span>59</span>
                    <span>90.77%</span>
                    <span class="source-lines">13, 15-16, 18, 24, 30-31, 34, 40, 42, 50-51, 53, 56, 65-67, 70, 79, 87, 90, 99, 101-102, 107, 110, 121-124, 126-129, 131-134, 140-142, 147, 155-157, 159, 172-177, 191, 210-211, 224, 267, 269, 285</span>
                    <span class="source-lines">148-149, 212, 217-218, 222</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/report_writer.py</span>
                    <span>167</span>
                    <span>3</span>
                    <span>164</span>
                    <span>98.2%</span>
                    <span class="source-lines">13, 15-25, 27-29, 46, 55, 58, 67-68, 76, 83-84, 89, 98-100, 102, 105-108, 110, 113, 116, 127-128, 130, 142, 150, 156-158, 160, 186-189, 192, 197-199, 202-203, 211, 222-223, 226-227, 230-231, 233, 235, 254, 256-259, 262-264, 266, 268, 310, 319, 321-322, 324-335, 337, 339, 347, 350-352, 355-356, 359-361, 364, 367, 375, 383, 385-386, 389, 392, 395, 398, 406, 408-409, 415, 417, 419, 421-432, 439, 441-442, 444-446, 454-458, 460, 462, 465, 468-469, 471, 477-481, 487-488, 495, 502, 504, 506-508, 510, 513-514, 516, 522-523</span>
                    <span class="source-lines">135-137</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/fs.py</span>
                    <span>34</span>
                    <span>1</span>
                    <span>33</span>
                    <span>97.06%</span>
                    <span class="source-lines">11, 13-14, 17, 30, 33, 36, 39, 42, 45, 55-56, 58-60, 63-65, 67, 70, 79, 82, 100, 103, 111-113, 116-117, 119-121, 123</span>
                    <span class="source-lines">40</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/hashing.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 14-17, 23, 32, 35, 44-48, 51, 61, 64, 73-74, 76-78, 80-81, 86, 96, 103-104, 107, 113-114, 116-121</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/ranges.py</span>
                    <span>33</span>
                    <span>0</span>
                    <span>33</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 15, 29-30, 33, 35-37, 39-40, 42, 45-47, 50, 52, 55, 65-67, 70, 81-82, 84-91, 93, 95</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/time.py</span>
                    <span>16</span>
                    <span>0</span>
                    <span>16</span>
                    <span>100.0%</span>
                    <span class="source-lines">4, 6, 9, 15, 18, 27, 30, 39-44, 46-48</span>
                    <span class="source-lines">-</span>
                </div>
            </div>
        </section>

        <section class="per-test-details" id="test-list">
            <h2>Per Test Details</h2>

        <!-- Filters -->
        <div class="filters">
            <input type="text" id="searchInput" class="filter-input" placeholder="Search tests..." onkeyup="filterTests()">
            <div class="filter-statuses" aria-label="Filter by status">
                <label class="filter-chip passed">
                    <input type="checkbox" data-status="passed" checked onchange="toggleStatus(this)">
                    Passed
                </label>
                <label class="filter-chip failed">
                    <input type="checkbox" data-status="failed" checked onchange="toggleStatus(this)">
                    Failed
                </label>
                <label class="filter-chip skipped">
                    <input type="checkbox" data-status="skipped" checked onchange="toggleStatus(this)">
                    Skipped
                </label>
                <label class="filter-chip xfailed">
                    <input type="checkbox" data-status="xfailed" checked onchange="toggleStatus(this)">
                    XFailed
                </label>
                <label class="filter-chip xpassed">
                    <input type="checkbox" data-status="xpassed" checked onchange="toggleStatus(this)">
                    XPassed
                </label>
                <label class="filter-chip error">
                    <input type="checkbox" data-status="error" checked onchange="toggleStatus(this)">
                    Error
                </label>
            </div>
        </div>

        <!-- Test List -->
        <div class="test-list">
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_adaptive_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</p>
                                    <p><strong>Why Needed:</strong> To ensure that tests with mocks and multiple assertions are correctly scored by the complexity estimator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test is complex, requiring multiple assertions to accurately estimate its complexity.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        73 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of the `Config` class when given an empty source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "assert provider._estimate_test_complexity('') == 0", 'expected_value': 0, 'message': 'Expected _estimate_test_complexity to return 0 for an empty string'}</li>
                                            <li>{'description': 'assert provider._estimate_test_complexity(None) == 0', 'expected_value': 0, 'message': 'Expected _estimate_test_complexity to return 0 for None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        163 output =
                                        299 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 185-186, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks for simplicity of tests and their complexity scores.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'simple_test', 'description': 'The simple test should have low complexity score.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        86 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid prompt tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` field is validated correctly and raises an error when it's not a valid value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Invalid prompt tier', 'expected_value': 'invalid', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        82 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_valid_prompt_tiers</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Valid prompt tiers</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` field is validated correctly and does not cause any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'minimal', 'actual_value': ['minimal', 'standard', 'auto'], 'error_message': 'Invalid prompt tier. Must be one of: minimal, standard, auto'}</li>
                                            <li>{'expected_value': 'standard', 'actual_value': ['minimal', 'standard', 'auto'], 'error_message': 'Invalid prompt tier. Must be one of: minimal, standard, auto'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        141 output =
                                        283 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</p>
                                    <p><strong>Why Needed:</strong> Auto mode should use standard prompt for complex tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'standard_prompt_for_complex_tests', 'description': 'The auto-tier should use the standard prompt for complex tests.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        86 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-220, 222, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</p>
                                    <p><strong>Why Needed:</strong> To ensure that the auto-tiering system uses minimal prompts for simple tests, which can improve test execution speed and reduce memory usage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'selected_prompt_type', 'expected_value': 'MINIMAL_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        155 input +
                                        94 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</p>
                                    <p><strong>Why Needed:</strong> Config override to minimal should always use minimal prompt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        74 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 212, 214-215, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_standard_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Config override to standard should always use standard prompt.</p>
                                    <p><strong>Why Needed:</strong> To ensure consistent and reliable testing, it is essential to use the standard system prompt for all tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'STANDARD_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        78 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 212, 214, 216-217, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_all_policy</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the aggregation function with all policy when aggregating multiple reports.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of multiple aggregated reports and ensures that both tests are retained.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregate result should have two tests (both retained).</li>
                                            <li>The aggregate result should contain both report1 and report2.</li>
                                            <li>Both retained tests should be included in the aggregate result.</li>
                                            <li>No test should be removed from the aggregate result when aggregating multiple reports.</li>
                                            <li>All aggregated reports should retain their original order.</li>
                                            <li>The aggregate result should not be None.</li>
                                            <li>The number of tests in the aggregate result should match the number of reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        150 output =
                                        514 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">71 lines (ranges: 53, 56-57, 60, 62-64, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `aggregate` method of the Aggregator class raises an exception when the aggregation directory does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected exception to be raised', 'description': 'The `aggregate` method should raise a `FileNotFoundError` when the aggregation directory does not exist.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        104 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 53, 56-58, 110, 113-115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_latest_policy</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: tests/test_aggregation.py::TestAggregator::test_aggregate_latest_policy</p>
                                    <p><strong>Why Needed:</strong> Prevents regression when comparing aggregate results across different times.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the `aggregate` method correctly picks the latest policy for each report.</li>
                                            <li>It checks that the `tests` attribute of the result is populated with a single test, and its outcome is 'passed'.</li>
                                            <li>The assertion on `result.run_meta.is_aggregated` ensures that the run was aggregated.</li>
                                            <li>The assertions on `result.run_meta.run_count` and `result.summary.passed` verify the correct number of runs and passed tests respectively.</li>
                                            <li>Finally, it checks that only one test is reported in the summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        166 output =
                                        643 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">79 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 204-205, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</p>
                                    <p><strong>Why Needed:</strong> To test that an aggregator function returns None when no directory configuration is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'agg is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        77 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 45, 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `aggregate` returns None when there are no reports.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the aggregate function does not handle cases with no reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate()` method should return `None` when called without any reports.</li>
                                            <li>No reports should be found in the directory.</li>
                                            <li>The absence of reports should prevent further aggregation.</li>
                                            <li>The `aggregate()` method should raise an exception or handle this case differently if it's not None.</li>
                                            <li>The test should fail when calling `aggregate()` with no reports.</li>
                                            <li>A test failure should occur when calling `aggregate()` without any reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        146 output =
                                        347 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 53, 56-58, 110, 113-114, 117-118, 184)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_coverage_and_llm_annotations</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that coverage and LLM annotations are properly deserialized and can be re-serialized.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in core functionality by ensuring accurate token usage and LLM annotation serialization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Coverage was correctly deserialized from the JSON report.</li>
                                            <li>LLM annotation was correctly deserialized from the JSON report, including scenario, why needed, key assertions, and confidence.</li>
                                            <li>Token usage was correctly serialized from the JSON report.</li>
                                            <li>LLM token usage could not be re-serialized without the correct configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        1002 input +
                                        125 output =
                                        1127 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">87 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138-141, 145-147, 149-150, 152-153, 155, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-45, 65-68, 130-133, 135-137, 139, 141-143, 190, 194-199, 201, 203, 205, 207, 210-214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_source_coverage</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that source coverage summary is deserialized correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in source coverage reporting functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `source_coverage` list within the report should contain exactly one SourceCoverageEntry object.</li>
                                            <li>The `SourceCoverageEntry` object should have the correct file path and coverage statistics.</li>
                                            <li>The `file_path` attribute of the `SourceCoverageEntry` object should match the expected value.</li>
                                            <li>The number of statements in the source code should be equal to the reported coverage percentage.</li>
                                            <li>The missed statements should be less than or equal to the total statements in the source code.</li>
                                            <li>The covered statements should be greater than or equal to the reported coverage percentage.</li>
                                            <li>The coverage percentage should be a valid floating-point number between 0 and 100.</li>
                                            <li>The coverage range should be correctly formatted as '1-5, 7-11'.</li>
                                            <li>The missed range should be correctly formatted as '6, 12'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        216 output =
                                        611 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">67 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 162-169, 171-173, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_load_coverage_from_source</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading coverage from configured source file when option is not set.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case the `llm_coverage_source` option is not provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that `_load_coverage_from_source()` returns None when `llm_coverage_source` is not set.</li>
                                            <li>Verify that a UserWarning is raised when `llm_coverage_source` is not set and `coverage.py` does not exist.</li>
                                            <li>Verify that successful loading of coverage data occurs with mock coverage data.</li>
                                            <li>Verify that the `CoverageMapper` returns the correct coverage percentage.</li>
                                            <li>Verify that the `cov.report()` method is called on the mock coverage object.</li>
                                            <li>Verify that the `map_source_coverage()` method is called on the mock mapper object.</li>
                                            <li>Verify that the mock coverage class is instantiated correctly with mock cov and mock mapper objects.</li>
                                            <li>Verify that the mock cov report returns 80.0 as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        584 input +
                                        206 output =
                                        790 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 259-260, 262-263, 265, 267-271, 273, 276-277, 279-280, 283, 285-286, 288)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_recalculate_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the _recalculate_summary method preserves the latest summary's total, passed, failed, skipped, xfailed, xpassed, and error counts when recalculating the summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the latest summary is not correctly calculated if there are multiple tests with different outcomes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of all tests should remain unchanged.</li>
                                            <li>The passed count should be equal to the number of tests that were passed in the latest summary.</li>
                                            <li>The failed count should be equal to the number of tests that were failed in the latest summary.</li>
                                            <li>The skipped count should be equal to the number of tests that were skipped in the latest summary.</li>
                                            <li>The xfailed count should be equal to the number of tests that had an error in the latest summary.</li>
                                            <li>The xpassed count should be equal to the number of tests that passed in the latest summary.</li>
                                            <li>The error count should remain unchanged from the latest summary.</li>
                                            <li>The coverage percentage should not change when recalculating the summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        229 output =
                                        702 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 231, 233-247, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_skips_invalid_json</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping an invalid JSON file prevents the test from counting it as a valid aggregation run.</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the aggregator correctly handles and skips reports containing invalid JSON data, preventing unnecessary runs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregator` instance is not skipped for the 'invalid.json' report.</li>
                                            <li>The `result` object contains a single run meta with a count of 1.</li>
                                            <li>The test asserts that the `result` object does not contain any additional run metadata.</li>
                                            <li>The test asserts that the `result` object has no additional keys or values.</li>
                                            <li>The test asserts that the `result` object is not `None`.</li>
                                            <li>The test verifies that only valid reports are counted in the aggregation result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        352 input +
                                        170 output =
                                        522 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123-124, 129, 131-132, 162-167, 169, 171-173, 176, 178-180, 182, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation_maximal.py::TestAggregationMaximal::test_recalculate_summary_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the aggregator recalculates the summary correctly when there are multiple tests with different outcomes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of multiple tests having different outcomes, as it ensures that the correct number of tests are included in the coverage calculation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total duration of all tests is 3.0 seconds.</li>
                                            <li>At least one test passed (outcome == 'passed')</li>
                                            <li>At least one test failed (outcome == 'failed')</li>
                                            <li>The total coverage percentage is 88.5%</li>
                                            <li>All tests have a unique nodeid ('t1', 't2')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        145 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 45, 231, 233-239, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_annotator.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</p>
                                    <p><strong>Why Needed:</strong> To test the batch optimization message</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'Mocked provider instance'}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 'Mocked cache instance'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_value': 'Mocked assembler instance'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        119 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-91, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the progress reporting is cached correctly and not overwritten by subsequent requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked cache should be updated after each request', 'expected_result': {'mocked_cache': {}}, 'actual_result': {'mocked_cache': {}}}</li>
                                            <li>{'name': 'Cache is not overwritten by subsequent requests', 'expected_result': {'mocked_cache': {}}, 'actual_result': {'mocked_cache': {}}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        141 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-128, 130, 134, 156, 181-182, 184, 211, 213-219, 221, 223)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</p>
                                    <p><strong>Why Needed:</strong> To ensure that cached tests are skipped when the test cache is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_cache.is_called_with', 'description': 'Mocked `is_called_with` method of mock_cache should be called with expected arguments.'}</li>
                                            <li>{'name': 'mock_assembler.is_called_with', 'description': 'Mocked `is_called_with` method of mock_assembler should be called with expected arguments.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        135 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">95 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-124, 130, 132, 134, 137-141, 144-151, 156, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotators can process multiple requests concurrently without blocking or missing any annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 'Mock provider object'}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 'Mock cache object'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_value': 'Mock assembler object'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        125 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221, 223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because concurrent annotation can lead to failures if not handled properly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Mocked annotator failed to annotate the text.', 'expected_exception': 'annotator.exceptions.ConcurrentAnnotationError'}</li>
                                            <li>{'message': 'Mocked annotator returned an error code that indicates a failure.', 'expected_exception': 'annotator.exceptions.ConcurrentAnnotationError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        129 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221-223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator is reporting progress correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should report progress', 'expected_value': 'progress', 'actual_value': 'report'}</li>
                                            <li>{'name': 'Mock cache should not affect progress reporting', 'expected_value': 'progress', 'actual_value': 'report'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        115 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator correctly reports progress messages during the annotation process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': 'progress message', 'expected_value': 'a progress message'}</li>
                                            <li>{'assertion_type': 'contains', 'pattern': 'percentage complete', 'expected_value': 'the percentage of the annotation task completed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        122 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</p>
                                    <p><strong>Why Needed:</strong> The test respects the opt-out and limit mechanisms of the annotator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider is called with an empty list', 'expected_result': [], 'actual_result': 1}</li>
                                            <li>{'name': 'mock_cache is not called when opt-out is True', 'expected_result': [], 'actual_result': 0}</li>
                                            <li>{'name': 'mock_assembler is called with the correct arguments when limit is True', 'expected_result': [{'text': '...', 'type': '...'}, {'text': '...', 'type': '...'}], 'actual_result': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        185 output =
                                        289 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 47, 50-51, 58-59, 65, 67-68, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure the annotator respects the rate limit for a given scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider.get_annotated_data() should be called with a valid rate limit key', 'expected_value': 'valid_rate_limit_key'}</li>
                                            <li>{'name': 'mock_provider.get_annotated_data() should be called within the allowed time window', 'expected_value': 'allowed_time_window'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        130 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-257, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation</span>
                            <div class="test-meta">
                                <span>12.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Sequential annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotations are applied in the correct order and to prevent potential errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'Annotations should be applied sequentially', 'expected_result': 'Annotations should be applied in the expected order'}</li>
                                            <li>{'assertion': 'Annotations without a previous annotation will not affect subsequent annotations', 'expected_result': 'Annotations without a previous annotation should not affect subsequent annotations'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        111 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</span>
                            <div class="test-meta">
                                <span>24.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</p>
                                    <p><strong>Why Needed:</strong> Error tracking in sequential annotation is necessary to ensure that errors are properly reported and handled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should be called with error message', 'expected_result': 'Mock provider was called with an error message', 'actual_result': 'Mock provider did not call with an error message'}</li>
                                            <li>{'name': 'Mock cache should be cleared after error is reported', 'expected_result': 'Mock cache should be cleared after error is reported', 'actual_result': 'Mock cache was not cleared after error was reported'}</li>
                                            <li>{'name': 'Mock assembler should not report any errors in sequential annotation', 'expected_result': 'Mock assembler did not report any errors in sequential annotation', 'actual_result': 'Mock assembler reported an error in sequential annotation'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        212 output =
                                        317 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</p>
                                    <p><strong>Why Needed:</strong> LLM is disabled, so the test should do nothing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': 'does nothing'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        73 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 47-48)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</p>
                                    <p><strong>Why Needed:</strong> The annotator should skip the annotation process if the provider is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider.is_available', 'expected_result': {'is_true': False}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        84 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 47, 50-54, 56)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_coverage_v2.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_malformed_json_after_extract</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Base Parse Response Malformed JSON After Extract</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `extract_json_from_response` function correctly handles malformed JSON responses and raises a meaningful error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Error Code', 'expected_code': 400, 'actual_code': 404}</li>
                                            <li>{'assertion_type': 'Message', 'expected_message': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        113 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 325-326, 329-330, 333-334, 359-360)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_non_string_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `test_base_parse_response_non_string_fields` function correctly handles non-string fields in the response data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function fails to parse non-string fields, potentially leading to incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should be able to correctly identify and extract the expected key from the `response_data` dictionary.</li>
                                            <li>The function should be able to handle scenarios with multiple keys in the response data.</li>
                                            <li>The function should be able to ignore non-string values when extracting keys.</li>
                                            <li>The function should raise an error if it encounters a non-string value that is not recognized as a valid key.</li>
                                            <li>The function should correctly handle nested dictionaries or lists within the `response_data` dictionary.</li>
                                            <li>The function should preserve the original structure of the input data when parsing non-string fields.</li>
                                            <li>The function should be able to handle edge cases such as empty response data or null values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        209 output =
                                        478 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342-346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `get_provider` function returns a `GeminiProvider` object which needs to be asserted as correct.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider_type', 'expected_value': 'GeminiProvider'}</li>
                                            <li>{'name': 'provider_name', 'expected_value': 'gemini'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        110 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for the expected error when a valid configuration is passed to the get_provider function with an invalid provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config is not None', 'expected': 'None', 'actual': "Config(provider='invalid')"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        97 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of getting a LitEllM provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected_type': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        75 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of a NoopProvider in the base maximization algorithm.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is an instance of NoopProvider', 'expected_type': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        84 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_ollama_provider` function returns an instance of `OllamaProvider` correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected_type': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        87 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_available_caches_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the LLM provider returns a boolean indicating availability.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the LLM provider does not return a boolean indicating availability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `is_available()` method should return True for both instances of the provider.</li>
                                            <li>The `is_available()` method should return True when called multiple times in quick succession.</li>
                                            <li>The `checks` attribute should increment correctly each time the `_check_availability()` method is called.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        113 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 134-135, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_model_name_defaults_to_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_model_name` method of `ConcreteProvider` returns the default model name specified in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "provider.get_model_name() == 'test-model'", 'expected_result': 'test-model'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        89 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_rate_limits_defaults_to_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the rate limits are set to None by default when no specific rate limit is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.get_rate_limits() should return None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        76 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_is_local_defaults_to_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults</p>
                                    <p><strong>Why Needed:</strong> To verify that the `is_local` method returns False for default LLM providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_local() is False', 'expected_value': False, 'message': 'Expected provider.is_local() to return False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        90 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 174)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_batching.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_context_files_included</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that context files are included in the batch prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where context files are not added to the prompt, potentially causing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'src/module.py' file should be present in the prompt.</li>
                                            <li>The 'def helper()' function should be included in the prompt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        261 input +
                                        88 output =
                                        349 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 192-194, 196-200, 203-206, 209-210, 213-214, 216-218, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_parametrized_batch_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the parametrized batch prompt includes all required information.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the batch prompt is missing or incorrect due to incomplete parameterizations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Test Group: test.py::test_add[*]</li>
                                            <li>Parameterizations (2 variants)</li>
                                            <li>[1+1=2]</li>
                                            <li>[0+0=0]</li>
                                            <li>ONE annotation</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        330 input +
                                        97 output =
                                        427 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 34, 39-40, 156-157, 160, 162, 164-168, 170-177, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_single_test_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a single test generates a normal batch prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the batch prompt is missing for single tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Test: test.py::test_foo should be included in the prompt.</li>
                                            <li>```python</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        76 output =
                                        345 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the consistency of source hashes for a given function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where different versions of the same function produce different source hashes, potentially leading to inconsistencies in batch processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The source code of the function should be the same across all hash computations.</li>
                                            <li>The length of each hash computation should be equal (32 bytes) for the given function.</li>
                                            <li>Different versions of the function should produce different source hashes.</li>
                                            <li>The source code should not change between hash computations for the same function.</li>
                                            <li>_compute_source_hash(source) should return a consistent hash value for the given source code.</li>
                                            <li>The length of the returned hash value should be equal (32 bytes) for the given source code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        165 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that different sources produce different hashes, which is a key aspect of batching and caching in the Compute Source Hash system.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'hash1 != hash2', 'description': 'The two computed hashes are not equal.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        93 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> Because an empty source is a valid input for the ComputeSourceHash function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _compute_source_hash() returns an empty string for an empty source', 'expected_result': '', 'actual_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        89 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</p>
                                    <p><strong>Why Needed:</strong> The 'batch_max_tests' configuration option must be at least 1 to prevent invalid batch configurations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.validate() returns errors', 'message': "Any error messages returned by the validate method should contain the string 'batch_max_tests'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        97 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</p>
                                    <p><strong>Why Needed:</strong> Context line padding must be non-negative.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'value': 0, 'type': 'asserts', 'message': 'context_line_padding must be >= 0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        81 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid context compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression mode is valid and does not cause any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "Context compression mode should be one of 'none', 'fast', or 'fastest'.", 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        80 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_valid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> Valid compression modes should pass.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'not equal to', 'expected_value': 'context_compression', 'actual_value': 'none'}</li>
                                            <li>{'assertion_type': 'not in', 'expected_value': ['lines'], 'actual_value': ['none']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        96 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_nested_params</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_nested_params</p>
                                    <p><strong>Why Needed:</strong> This test ensures that complex parameters are fully stripped from the base node ID.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert stripped base node ID', 'value': "_get_base_nodeid('test.py::test[a-b-c]') == 'test.py::test'", 'expected_result': 'test.py::test'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        106 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of _get_base_nodeid when a parameterized node id is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "_get_base_nodeid('tests/test_foo.py::test_add[1+1=2]') == 'tests/test_foo.py::test_add'", 'expected_result': 'tests/test_foo.py::test_add'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        123 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of getting a base node ID without any parameters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'tests/test_foo.py::test_bar', 'actual_value': 'tests/test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        83 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batch_max_size_respected</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Large groups should be split by batch_max_tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when large groups of tests are added to the batch.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of each batch is correct.</li>
                                            <li>Each group has exactly two tests in it.</li>
                                            <li>Only one group has only one test in it.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        81 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 53-54, 67-68, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batching_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case for TestGroupTestsForBatching</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the batching feature is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(batches) == 2', 'expected': 2, 'actual': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        76 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 92-93, 95, 97-99)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_parametrized_tests_grouped</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'Parametrized tests should be grouped together' verifies that parametrized tests are correctly grouped.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that parametrized tests are not scattered across multiple batches.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of batches is equal to 1.</li>
                                            <li>Each batch has exactly 3 tests.</li>
                                            <li>Each batch is a parameterized test group.</li>
                                            <li>The base node ID of each batch is 'test.py::test_add'.</li>
                                            <li>All tests in the first batch are parametrized.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        126 output =
                                        472 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 34, 39-40, 53-54, 67, 70, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_single_tests_no_grouping</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that single tests are grouped into batches without any grouping.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where single tests are not properly grouped in batches.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Each test should be its own batch.</li>
                                            <li>There should be two batches with the same number of tests.</li>
                                            <li>The first batch should have exactly one test.</li>
                                            <li>The second batch should also have exactly one test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        99 output =
                                        377 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_cache.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_consistent_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is consistent across different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'hash_source', 'type': 'function', 'expected_result': 'hash_source(source)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        73 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is working correctly and producing different hashes for different source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'different', 'actual': 'same'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        74 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_hash_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_hash_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the hash function is producing a fixed length output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The hash value should be 16 characters long.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        67 output =
                                        167 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_clear</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that clearing the cache removes all entries.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where multiple annotations are stored in the cache and then cleared, preventing them from being re-added.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of cache entries should be reduced to 2 after clearing.</li>
                                            <li>The annotation 'test::a' with hash1 should be removed from the cache.</li>
                                            <li>The annotation 'test::b' with hash2 should also be removed from the cache.</li>
                                            <li>All annotations in the cache should have been cleared.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        122 output =
                                        405 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 129, 132-136, 141)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</p>
                                    <p><strong>Why Needed:</strong> To ensure that LLM annotations with errors are not cached.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'NoneType', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        73 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_get_missing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_get_missing</p>
                                    <p><strong>Why Needed:</strong> To test that the get method returns None for missing entries in the cache.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The result is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        74 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 39-41, 53, 55-56, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_set_and_get</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that setting and getting an annotation from the cache preserves its original value.</p>
                                    <p><strong>Why Needed:</strong> Prevents bypass by ensuring annotations are stored in the cache, preventing them from being overwritten without user input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Check that the annotation is set correctly with the correct scenario.</li>
                                            <li>Check that the confidence of the annotation remains unchanged after retrieval.</li>
                                            <li>Check that the annotation's original key matches its retrieved value.</li>
                                            <li>Verify that no other annotations are stored in the cache without a corresponding user input.</li>
                                            <li>Ensure that the annotation's status (in this case, 'Tests login') is preserved across multiple retrievals.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        143 output =
                                        429 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 39-41, 53, 55, 58, 60-62, 68-73, 86, 90, 92, 94, 97-101, 103, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">11 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</p>
                                    <p><strong>Why Needed:</strong> The current implementation of the CollectionError class does not validate its structure, which can lead to errors when collecting and processing these types of errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeid', 'expected_value': 'test_bad.py'}</li>
                                            <li>{'name': 'message', 'expected_value': 'SyntaxError'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        109 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_collection_errors` method returns an empty list when the collection is initially empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert get_collection_errors() == []', 'expected_result': [], 'actual_result': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        91 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_context_override_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction</p>
                                    <p><strong>Why Needed:</strong> Default llm_context_override should be None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'llm_context_override', 'value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        65 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction</p>
                                    <p><strong>Why Needed:</strong> Default llm_opt_out should be False.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert llm_opt_out is False', 'expected_value': False, 'message': 'Expected llm_opt_out to be False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        82 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the collector is not enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert config.capture_failed_output is True', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        77 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</p>
                                    <p><strong>Why Needed:</strong> The default value of `capture_output_max_chars` is 4000. This is necessary to ensure that the output does not exceed this limit, which could cause issues with downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert capture_output_max_chars is equal to 4000', 'expected_value': 4000, 'message': 'The default value of `capture_output_max_chars` is 4000.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        127 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</p>
                                    <p><strong>Why Needed:</strong> To ensure that xfail failures are correctly recorded as xfailed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'xfailed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        206 input +
                                        78 output =
                                        284 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212, 216, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</p>
                                    <p><strong>Why Needed:</strong> xfail passes should be recorded as xpassed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result.outcome', 'expected_value': 'xpassed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        75 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212-214)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_create_collector</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the creation of a TestCollector instance.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the collector is not initialized with any results, leading to incorrect assertions in subsequent tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>collector.results should be an empty dictionary.</li>
                                            <li>collector.collection_errors should be an empty list.</li>
                                            <li>collector.collected_count should be 0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        88 output =
                                        293 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_get_results_sorted</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestTestCollector::test_get_results_sorted</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collector correctly sorts test results by nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': ['a_test.py::test_a', 'z_test.py::test_z'], 'actual': ['a_test.py::test_a', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        95 output =
                                        322 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_handle_collection_finish</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `handle_collection_finish` method to ensure it correctly tracks collected and deselected counts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the count of collected items is not updated correctly after calling `handle_collection_finish`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `collected_count` attribute should be set to 3 (number of collected items).</li>
                                            <li>The `deselected_count` attribute should be set to 1 (number of deselected items).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        112 output =
                                        368 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 78-79, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</p>
                                    <p><strong>Why Needed:</strong> Capturing output via handle_runtest_logreport is disabled in this scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result.captured_stdout is None', 'expected': {'type': 'NoneType', 'message': 'Should not capture if config disabled'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        97 output =
                                        308 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals::test_capture_output_stderr</p>
                                    <p><strong>Why Needed:</strong> To verify that the `collector._capture_output` method correctly captures stderr and returns it to the test case.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stderr', 'expected_value': 'Some error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        77 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals::test_capture_output_stdout</p>
                                    <p><strong>Why Needed:</strong> To test that the collector captures stdout correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert captured stdout is correct', 'expected_value': 'Some output'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        66 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_truncated</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_create_result_with_item_markers</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test creates a result with item markers and verifies the expected behavior.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of incorrect marker extraction or incorrect usage of item markers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `param_id` attribute of the created result is set to 'param1'.</li>
                                            <li>The `llm_opt_out` attribute of the created result is set to True.</li>
                                            <li>The `llm_context_override` attribute of the created result is set to 'complete'.</li>
                                            <li>All required requirements are included in the `requirements` list of the created result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        382 input +
                                        131 output =
                                        513 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163-164, 167-169, 171, 181-182, 185-189, 198-200, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_repr_crash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_collector_internals</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_extract_error` method returns the correct string representation of an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _extract_error returns correct longrepr', 'expected_value': 'Some error occurred'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        75 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_extract_skip_reason` method returns `None` when no longrepr is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _extract_skip_reason returns None for no longrepr', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        93 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250, 252)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</p>
                                    <p><strong>Why Needed:</strong> To ensure the `_extract_skip_reason` method returns a string as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert _extract_skip_reason returns 'Just skipped'", 'expected_value': 'Just skipped'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        85 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_tuple</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_collection_report_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When the `handle_collection_report` method is called with a report that indicates a collection error, it should record this error in the `collection_errors` list.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where a collection report fails and does not trigger any errors, potentially leading to missed issues or incorrect reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `collector.collection_errors` is set to 1.</li>
                                            <li>The value of `collector.collection_errors[0].nodeid` is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        119 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 58, 60-65, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_rerun</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'handle_runtest_rerun' verifies that the TestCollector handles rerun attribute correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the TestCollector might not handle reruns correctly, potentially leading to incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.rerun_count should be equal to 1 (expected)</li>
                                            <li>res.final_outcome should be 'failed' (expected)</li>
                                            <li>collector.results['t::r'] should contain the expected data</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        113 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140-141, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238, 261, 264-265, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_setup_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When the `handle_runtest_setup_failure` test function is called with a setup log report that fails, then it should record an error in the collector's report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the setup log report is not properly recorded when it fails, potentially causing incorrect reporting of the test result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.outcome == 'error'</li>
                                            <li>res.phase == 'setup'</li>
                                            <li>res.error_message == 'Setup failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        300 input +
                                        111 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_teardown_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorReportHandling test handle_runtest_teardown_failure: Should record error if teardown fails after pass.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring that the collector logs an error when a teardown failure occurs after a successful run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert res.outcome == 'error', assert res.phase == 'teardown', assert res.error_message == 'Cleanup failed'</li>
                                            <li>assert not res.wasxfail</li>
                                            <li>assert res.duration is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        111 output =
                                        502 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127-128, 130, 132-133, 135-137, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_compression.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_invalid_compression_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid compression mode</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Context Compression validation correctly identifies and reports invalid compression modes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Context compression is not one of the allowed values: 'gzip', 'deflate', 'lz4', 'snappy'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        78 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</p>
                                    <p><strong>Why Needed:</strong> Negative padding should fail validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding is not a valid value for the context_line_padding parameter.', 'expected_value': -1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        77 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_valid_compression_modes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To ensure that valid compression modes can pass validation without raising any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'type', 'expected_type': 'str', 'actual_type': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        70 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</p>
                                    <p><strong>Why Needed:</strong> Zero padding should be valid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding is not present in any error message', 'expected_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        73 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> Context compression should be enabled by default ('lines').</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        74 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</p>
                                    <p><strong>Why Needed:</strong> Lines compression mode should be available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        69 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_line_padding_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_line_padding_default</p>
                                    <p><strong>Why Needed:</strong> To ensure that line padding is set correctly for default context compression.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Line padding should default to 2.', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        85 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_contiguous_lines_no_gap</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that contiguous covered lines do not have gap indicators.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where contiguous lines without gaps are incorrectly identified as uncovered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The count of '#' characters should be zero for contiguous lines without gaps.</li>
                                            <li>The string '# L3:' should be present in the result.</li>
                                            <li>The string '# L4:' should be present in the result.</li>
                                            <li>The string '# L5:' should be present in the result.</li>
                                            <li>The line numbers (L3, L4, and L5) should not be missing or appear out of order.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        135 output =
                                        428 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</p>
                                    <p><strong>Why Needed:</strong> The test is needed because it checks the behavior of the `_extract_covered_lines` method when there are no lines to extract.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        82 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 216-217)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_multiple_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Covered Lines: Multiple covered ranges should be extracted with gap indicators.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where multiple covered lines are not correctly identified with gap indicators.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_extract_covered_lines` should find the correct range for each covered line and add a gap indicator between them.</li>
                                            <li>The function `_extract_covered_lines` should extract two separate ranges, one starting from L3 and another from L15.</li>
                                            <li>The function `_extract_covered_lines` should not miss any gaps in the extracted ranges.</li>
                                            <li>The function `_extract_covered_lines` should correctly identify the start line of each range (L3 and L15).</li>
                                            <li>The function `_extract_covered_lines` should handle overlapping covered lines correctly.</li>
                                            <li>The function `_extract_covered_lines` should preserve the original order of covered lines in the input list.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        196 output =
                                        470 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Single covered line should be extracted with padding.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the single line is not extracted correctly due to incorrect padding.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _extract_covered_lines() includes lines 2, 3, and 4 in the result with 1 line padding.</li>
                                            <li>The function _extract_covered_lines() includes lines 2, 3, and 4 in the result without any padding.</li>
                                            <li>The function _extract_covered_lines() correctly handles cases where there are multiple covered lines.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        302 input +
                                        129 output =
                                        431 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_padding_boundary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that padding does not extend beyond file boundaries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where padding exceeds the number of lines in the source code, causing incorrect coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The extracted covered lines should have line numbers within the range [1, 3].</li>
                                            <li>The uncovered lines should not have negative line numbers (0).</li>
                                            <li>The uncovered lines should be at least as many as the number of lines in the source code minus one.</li>
                                            <li>The uncovered lines should be at most three.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        124 output =
                                        412 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_limits.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_no_truncation_needed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_limits.py::test_no_truncation_needed</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation truncates context when it's too long. This can cause issues with the expected output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The prompt should not contain 'truncated'.", 'expected_result': 'short content'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        158 input +
                                        91 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_smart_distribution</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_smart_distribution verifies that the smart distribution algorithm allocates budget to F1 and F2 correctly, resulting in zero waste.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the smart distribution algorithm does not allocate too much budget to F1 or F2, leading to wasted tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>F1 should get full allocation (40 tokens)</li>
                                            <li>F2 should get truncated allocation (~480 tokens)</li>
                                            <li>Total used tokens should be equal to total allocated tokens</li>
                                            <li>Wasted tokens should be less than total allocated tokens</li>
                                            <li>F2 content in prompt should contain 'f2' and have more characters than F1 content</li>
                                            <li>F2 content in prompt should not exceed 800 characters</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        773 input +
                                        163 output =
                                        936 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_splitting_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the splitting logic correctly identifies files with large content and truncates them according to the budget.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the splitting logic fails to truncate large files, leading to incorrect output or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'f1' is present in the prompt.</li>
                                            <li>The file 'f2' is present in the prompt.</li>
                                            <li>The string 'truncated' is present in the prompt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        109 output =
                                        426 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_truncation_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When the test_truncation_logic function is called with a large context file, it should truncate the prompt to fit within the 100 token limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the prompt exceeds the 100 token limit and is truncated or skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the prompt should be less than 5 times the limit (100 tokens) minus some overhead.</li>
                                            <li>Either '[... truncated]' or 'Relevant context' should be present in the prompt if it's heavily truncated or skipped.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        397 input +
                                        125 output =
                                        522 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 243, 245, 264, 266, 270-272, 274-275)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_util.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">28 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing empty lines in a context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The result should be the same as the expected output.', 'expected_output': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        86 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing empty lines in a multi-line string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The collapsed string should contain only one blank line.', 'expected_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        85 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `collapse_empty_lines` function preserves up to 2 consecutive newlines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'line1\n\nline2', 'actual_value': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        90 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</p>
                                    <p><strong>Why Needed:</strong> Preserves single newlines in collapsed text.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\nline2\nline3', 'actual_result': 'line1\nline2\nline3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        82 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `optimize_context` function always collapses empty lines, regardless of whether the `strip_docs` and/or `strip_comms` flags are set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The output of the function is a string containing only non-empty lines.', 'expected_output': 'line1\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        137 input +
                                        112 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</p>
                                    <p><strong>Why Needed:</strong> To ensure that the combined optimization process is applied correctly and optimizes the code without any unnecessary changes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'message': 'Module docstring should be removed'}, 'actual': {'message': 'Module docstring remains unchanged'}}</li>
                                            <li>{'expected': {'message': 'Namespace object should be created and populated with data'}, 'actual': {'message': 'Namespace object is empty'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        127 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</p>
                                    <p><strong>Why Needed:</strong> The default behavior of the `optimize_context` function should strip all docstrings, but leave comments intact.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring stripping', 'expected': '', 'actual': 'def foo():'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        89 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context optimizer handles empty sources correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is an empty string', 'expected': '', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        74 output =
                                        169 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of optimize_context does not handle source lines with only whitespace correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return a string with one or more newline characters and/or tabs, but instead returns a single newline character.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        84 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_both</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_both</p>
                                    <p><strong>Why Needed:</strong> To optimize context by removing unnecessary documentation from the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'docstring stripping', 'reason': 'The function docstring is not necessary and can be removed.'}</li>
                                            <li>{'assertion_type': 'comment stripping', 'reason': 'Comments are also unnecessary and can be removed.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        109 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</p>
                                    <p><strong>Why Needed:</strong> To remove unnecessary comments from the code without affecting its functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'strip_comments', 'expected_result': 'The function foo() is defined, but with no docstring.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        84 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 81-82, 86, 88-90, 93, 108, 124, 126, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_neither</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_neither</p>
                                    <p><strong>Why Needed:</strong> To ensure that the optimizer can correctly strip out unnecessary code in certain scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The optimizer should be able to keep both `foo()` and its explicit call.', 'expected_result': {'code': 'def foo():', 'context': ''}, 'actual_result': {'code': '', 'context': ''}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        111 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that comments are stripped from strings containing hash (#) symbols, regardless of their position.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Source string should contain a comment after the string with hash (#).', 'expected_result': 'url = "http://example.com#anchor"'}</li>
                                            <li>{'description': 'Comment should be stripped from the source string.', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        124 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_escaped_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_escaped_quotes</p>
                                    <p><strong>Why Needed:</strong> To handle escaped quotes in strings without modifying the original string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Basic behavior', 'expected': '# comment', 'actual': '# comment'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        76 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_mixed_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_mixed_quotes</p>
                                    <p><strong>Why Needed:</strong> To strip quotes from comments in Python code, which can be useful for parsing and processing scripts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '"don\'t # worry"', 'actual': "'don't # worry'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        81 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_no_comments</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_no_comments</p>
                                    <p><strong>Why Needed:</strong> To strip comments from the source code without affecting the functionality of the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test should be able to successfully remove all comments from the source code.</li>
                                            <li>The output of the stripped source code should match the expected output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        91 input +
                                        81 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</p>
                                    <p><strong>Why Needed:</strong> Preserves # inside double-quoted strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': '\'url = "http://example.com#anchor"\'', 'actual_result': '\'url = "http://example.com#anchor"\''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        90 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</p>
                                    <p><strong>Why Needed:</strong> Preserves # inside single-quoted strings in source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Expected result', 'expected_value': "url = 'http://example.com#anchor'", 'actual_value': 'result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        91 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_simple_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_simple_comment</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of the `strip_comments` function, which removes simple end-of-line comments from source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': 'x = 1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        85 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</p>
                                    <p><strong>Why Needed:</strong> To strip standalone comments from the code, which can improve readability and reduce noise.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'strip_comments', 'expected_result': ['This is a comment']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        80 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the `strip_docstrings` function handles syntax errors correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'source': 'def foo( unclosed paren'}, 'actual': {'source': 'def foo( unclosed parentheses'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        93 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 27, 29-31)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</p>
                                    <p><strong>Why Needed:</strong> To strip unnecessary docstrings from a module.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function should return an empty list for the given source code.', 'expected_output': []}</li>
                                            <li>{'assertion': 'The function should not modify the original source code.', 'expected_output': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        103 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve multiline data strings in docstrings for consistency and readability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The triple-quoted string is preserved.', 'expected_result': 'The triple-quoted string is preserved.'}</li>
                                            <li>{'assertion': 'The variable foo() does not contain the preserved string.', 'expected_result': 'The variable foo() does not contain the preserved string.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        125 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve regular strings in test output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The string \'x = "hello world".\' is preserved in the test output.', 'expected_output': '\'x = "hello world".\''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        89 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 27, 29, 33, 35-36, 38-45, 49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</p>
                                    <p><strong>Why Needed:</strong> Preserving strings in structures is important for maintaining code readability and avoiding potential issues with string literals.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should preserve the original string literals.', 'expected_result': 'Should preserve strings in lists/dicts.'}</li>
                                            <li>{'description': 'The function should not modify the original string literals.', 'expected_result': 'Does not modify the original string literals.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        126 output =
                                        272 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</p>
                                    <p><strong>Why Needed:</strong> To strip multiline docstrings from Python code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function should return a JSON object with the expected structure.', 'expected_result': {'scenario': 'tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring', 'why_needed': 'To strip multiline docstrings from Python code.', 'key_assertions': ['...']}, 'actual_result': "{'scenario': 'tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring', 'why_needed': 'To strip multiline docstrings from Python code.', 'key_assertions': ['...']}"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        173 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context manager strips all types of docstrings, not just triple double-quoted ones.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring removal', 'description': 'The function should remove all docstrings, including triple double-quoted ones.'}</li>
                                            <li>{'name': 'no exception raised', 'description': 'If a docstring is found, the function should not raise an exception.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        131 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation does not correctly handle triple single-quoted docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring removal', 'expected': 'def foo():\n    pass'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        89 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_boosters.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_model_parsing_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the parsing of edge cases for Gemini models with different configurations.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the gemini model parser fails to parse models when the 'm1, m2' configuration is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'm1' in models</li>
                                            <li>assert 'm2' in models</li>
                                            <li>assert provider._parse_preferred_models() == [] when config.model == None</li>
                                            <li>assert provider._parse_preferred_models() == [] when config.model == 'All'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        121 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 134-135, 137-141, 143-144, 476, 478, 524-531)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_rate_limiter_edge_math</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter prevents over and under token limits when recording tokens but not requests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter allows excessive token usage without penalizing requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The next_available_in method should return a value greater than 0 if there are available tokens.</li>
                                            <li>The next_available_in method should return 0 if both limits have been reached.</li>
                                            <li>The record_tokens method should not increment the request count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        114 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_models_to_dict_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `to_dict()` method of `SourceCoverageEntry` and `RunMeta` objects returns the expected values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage booster models where the `coverage_percent` or `duration` fields are not being correctly converted to dictionary keys.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `coverage_percent` field of `SourceCoverageEntry` is equal to 50.0 when converted to a dictionary key.</li>
                                            <li>The `error` field of `LlmAnnotation` is equal to 'timeout' when converted to a dictionary key.</li>
                                            <li>The `duration` field of `RunMeta` is equal to 1.0 when converted to a dictionary key.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        156 output =
                                        474 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 96-103, 130-133, 135, 137-139, 141, 143, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</p>
                                    <p><strong>Why Needed:</strong> To test the initialization of the Mapper with a given configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mapper.config', 'expected_type': 'Config', 'actual_type': 'Config', 'message': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        76 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_warnings` method returns a list of warnings as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert isinstance(warnings, list)', 'expected_result': [1, 2, 3], "# Expected to be a list of warnings (e.g., from a file or variable with an error message) but actually returns something else (e.g., an empty list or a different type of value). This test ensures that the `get_warnings` method correctly identifies and returns warnings as expected in this scenario. If it doesn't, the test will fail and provide additional context for where the issue is occurring.": 'message_type', 'Test failed: TestCoverageMapper::test_get_warnings': 'This test has failed because the `get_warnings()` method of the CoverageMapper class does not return a list of warnings as expected. The actual output may vary depending on the configuration and environment, but it should contain at least one warning or an empty list.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        239 output =
                                        349 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 44-45, 308)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_map_coverage_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `map_coverage` method returns an empty dictionary when no coverage file is found.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the test fails to report any coverage information when there are no coverage files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `mapper.map_coverage()` function should return an empty dictionary.</li>
                                            <li>The returned dictionary should be empty.</li>
                                            <li>There should be at least one warning in the `mapper.warnings` list.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        277 input +
                                        104 output =
                                        381 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_all_phases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `CoverageMapper` correctly extracts node IDs for all phases when `include_phase=all`.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage map might not include all phases if `include_phase=all` is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>When including phase 'all', the mapper should extract node IDs for all specified phases.</li>
                                            <li>The mapper should return the same node ID for each phase when included in 'all'.</li>
                                            <li>If `include_phase=all`, the mapper should not include any phase-specific node IDs in the coverage map.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        131 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the context is empty or None, allowing for proper coverage extraction.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'assert mapper._extract_nodeid([]) == None', 'expected_result': 'None'}</li>
                                            <li>{'assertion': 'assert mapper._extract_nodeid(None) == None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        118 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</p>
                                    <p><strong>Why Needed:</strong> To ensure that the test does not filter out setup phase when including a run phase.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "nodeid extraction should be performed for nodeid in 'setup' phase", 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        139 input +
                                        92 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 216, 220, 224-225, 228-230)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</p>
                                    <p><strong>Why Needed:</strong> To extract the correct node ID from the run phase context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'test.py::test_foo', 'actual_value': 'test.py::test_foo|run'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        88 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_contexts_by_lineno_exception</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_contexts_by_lineno_exception' verifies that the test_contexts_by_lineno function handles exceptions correctly when calling it on mock data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the test_contexts_by_lineno function fails to handle an exception raised by its context side effect.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should not raise an exception when called with mock_data that has contexts.</li>
                                            <li>The function should return an empty dictionary when called with mock_data that does not have contexts.</li>
                                            <li>The function should increment the call count correctly when calling it on mock_data that raises an exception.</li>
                                            <li>The function should only be called once when calling it on mock_data that has contexts.</li>
                                            <li>The function should handle the exception gracefully and return a valid result.</li>
                                            <li>The function's context side effect should not affect its behavior when called with mock_data that does not have contexts.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        193 output =
                                        525 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152, 156, 160-162, 167-170, 199, 202)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</p>
                                    <p><strong>Why Needed:</strong> To test that the function returns an empty dictionary when no measured files are found.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': {}, 'actual_value': {'__len__': 0}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        80 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 44-45, 118, 121-122, 127-128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</p>
                                    <p><strong>Why Needed:</strong> To ensure that non-Python files are skipped from coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "mock_data.measured_files.return_value == ['file.txt', 'data.json']", 'expected_result': ['file.txt', 'data.json'], 'message': "Expected mock_data.measured_files.return_value to be equal to ['file.txt', 'data.json']"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        120 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_coverage_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Load Coverage Data</p>
                                    <p><strong>Why Needed:</strong> Coverage.py is required for this test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'coverage.py is installed', 'description': 'The coverage.py module should be present in the environment.'}</li>
                                            <li>{'name': 'coverage.py is not installed', 'description': 'The coverage.py module should not be present in the environment.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        166 input +
                                        98 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> To test the scenario when no .coverage file exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return None.', 'expected_result': 'None'}</li>
                                            <li>{'description': "The warnings should have a message containing 'W001'.", 'expected_result': ['W001']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        92 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_analysis_exception_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the exception handling feature when analyzing an exception.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that analysis2 raises an exception and is properly handled, preventing potential warnings from being added to the coverage report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `map_source_coverage` function should return an empty list when analyzing an exception.</li>
                                            <li>A warning with the message 'COVERAGE_ANALYSIS_FAILED' should be added to the coverage report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        102 output =
                                        388 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_empty_statements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage</p>
                                    <p><strong>Why Needed:</strong> To test the coverage map when a file has no statements.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Equal to', 'expected_value': [], 'actual_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        178 input +
                                        67 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259-261, 273-274, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_include_test_files_when_not_configured</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that test files are included when omit_tests_from_coverage is False.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where test coverage is not reported for test files when omitting tests from coverage is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `map_source_coverage` method returns a list with exactly one element.</li>
                                            <li>The `covered` attribute of the first element in the list is set to 2 (indicating that two lines were covered).</li>
                                            <li>The `missed` attribute of the first element in the list is set to 1 (indicating that one line was missed).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        136 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> {'id': 'tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_non_python_files', 'description': 'Test case for test_skip_non_python_files'}</p>
                                    <p><strong>Why Needed:</strong> {'reason': 'Ensure that non-Python files are skipped from coverage reports.', 'description': 'This test is necessary to ensure that non-Python files are excluded from coverage reports.'}</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected_result', 'type': 'list', 'description': 'Expected result of the test'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        173 output =
                                        327 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 44-45, 243-244, 246-249, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_test_files_when_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Map Source Coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that test files are skipped when omit_tests_from_coverage is True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': [], 'actual_result': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        182 input +
                                        59 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 243-244, 246-248, 250, 252-255, 257, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_all_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all phases are accepted when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of phase filtering, where only specific phases should be covered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') == 'test_foo.py::test_bar'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        305 input +
                                        134 output =
                                        439 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</p>
                                    <p><strong>Why Needed:</strong> To handle empty string inputs and ensure correct output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        74 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `extract_nodeid` method returns None when an invalid input (None) is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert mapper._extract_nodeid(None) == None', 'description': 'The `_extract_nodeid` method should return None for a None input.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        103 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_run_phase_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that run phase is the default filter.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the test would fail due to an incorrect default configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _extract_nodeid should return the nodeid when the phase matches 'run'.</li>
                                            <li>The function _extract_nodeid should return None when the phase doesn't match 'run' or 'setup'.</li>
                                            <li>The function _extract_nodeid should return None when the phase doesn't match 'teardown'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        116 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_setup_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that setup phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the test would incorrectly filter out nodes in the setup phase due to incorrect configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        125 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_teardown_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that teardown phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the 'teardown' phase is not properly filtered, potentially leading to false positives in coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        129 output =
                                        425 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233-234, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</p>
                                    <p><strong>Why Needed:</strong> To test the scenario where a node id does not contain a pipe delimiter.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equality', 'expected_value': 'test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        84 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 44-45, 216, 220, 224, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_full_logic</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `extract_contexts` method of `CoverageMapper` correctly extracts contexts for all paths in `_extract_contexts` when coverage is enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage map does not include all contexts for a specific file, potentially leading to incomplete or inaccurate coverage analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `test_one` context should be present in the coverage report for `app.py`.</li>
                                            <li>The number of lines in `test_one` should match the expected count (2).</li>
                                            <li>Each line in `test_one` should have a unique file path that includes `app.py`.</li>
                                            <li>If `test_two` is not present, then `test_one` should be included in the coverage report.</li>
                                            <li>The context for `test_two` should not include any lines from `app.py`.</li>
                                            <li>Each line in `test_two` should have a unique file path that includes `app.py`.</li>
                                            <li>If `test_one` is not present, then `test_two` should be included in the coverage report.</li>
                                            <li>The context for `test_two` should include all lines from `app.py`.</li>
                                            <li>Each line in `test_two` should have a unique file path that includes `app.py`.</li>
                                            <li>If `test_one` is not present, then `test_two` should be included in the coverage report.</li>
                                            <li>The context for `test_two` should include all lines from `app.py`.</li>
                                            <li>Each line in `test_two` should have a unique file path that includes `app.py`.</li>
                                            <li>]</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        345 output =
                                        758 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152-153, 156, 160-163, 165, 167-168, 173, 176, 178-184, 187-189, 191-194, 196, 199-200, 202, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_nodeid_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ability to extract node IDs from coverage reports when no phases are specified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage reporting when certain phases are not included in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _extract_nodeid returns the correct node ID for a given phase.</li>
                                            <li>The function _extract_nodeid ignores the 'run' phase and its corresponding node ID.</li>
                                            <li>The function _extract_nodeid correctly handles coverage reports without any phases specified.</li>
                                            <li>The function _extract_nodeid ignores context files that do not match any phase.</li>
                                            <li>The function _extract_nodeid returns the correct node ID for a given phase, even when no phase is included in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        157 output =
                                        480 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-234, 236, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_no_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_load_coverage_data_no_files function correctly handles cases where no coverage files exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug or regression by ensuring that the function does not silently fail when there are no coverage files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return None for _load_coverage_data() when no .coverage files exist.</li>
                                            <li>The number of warnings should be exactly 1.</li>
                                            <li>The first warning code should be 'W001'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        111 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_read_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle errors reading coverage files and prevent regression.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the CoverageMapper class does not properly handle errors when loading coverage data from corrupted files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `mapper._load_coverage_data()` returns None if an error occurs while reading the coverage file.</li>
                                            <li>Any warnings generated by the mapper are marked as indicating that the coverage data failed to be read.</li>
                                            <li>The test verifies that any messages containing 'Failed to read coverage data' are present in the warnings list.</li>
                                            <li>The test ensures that the coverage module's `CoverageData` class is mocked with an exception when it raises an error during reading.</li>
                                            <li>The test verifies that the `CoverageMapper` instance returns None after attempting to load coverage data from a corrupted file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        178 output =
                                        521 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94-96, 107-111, 114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_with_parallel_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle parallel coverage files from xdist and verify that it correctly updates the CoverageData instances.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling parallel coverage files, ensuring that the CoverageMapperMaximal class can correctly update its internal data structures when dealing with such scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock CoverageData instance returned by _load_coverage_data() should have been updated at least twice.</li>
                                            <li>The mock CoverageData instances should not be None after calling update.</li>
                                            <li>The mock CoverageData instances should be of the same type (CoverageData) before and after calling update.</li>
                                            <li>The mock CoverageData instances should have different attributes (update_count, data) before and after calling update.</li>
                                            <li>The _load_coverage_data() function should return a new instance of CoverageData or None if no coverage files are available.</li>
                                            <li>The _load_coverage_data() function should call the update method on the mock CoverageData instances with at least two calls.</li>
                                            <li>The _load_coverage_data() function should not raise an exception when called multiple times without any changes to the CoverageData instances.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        378 input +
                                        236 output =
                                        614 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94, 98, 101-104, 106)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_coverage_no_data</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `map_coverage` method with _load_coverage_data returning None.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where an empty dictionary is returned when there's no coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_load_coverage_data` method should return `None` when called without any arguments.</li>
                                            <li>The `map_coverage` method should return an empty dictionary when the input is `None` or an empty list.</li>
                                            <li>The `map_coverage` method should not raise an exception when given a non-empty list of coverage data.</li>
                                            <li>The `map_coverage` method should preserve the original order of metrics in case of duplicate values.</li>
                                            <li>The `_load_coverage_data` method should be able to handle cases where the input is a dictionary with no keys.</li>
                                            <li>The `map_coverage` method should not throw an exception when given a non-list value for coverage data.</li>
                                            <li>The `map_coverage` method should return the original list of metrics if it's already present in the result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        217 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-45, 58-60)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_analysis_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the CoverageMapper handles analysis errors correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where an error during coverage analysis would prevent the mapper from working as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock_cov.analysis2 should be called with an Exception exception.</li>
                                            <li>mock_data.measured_files.return_value should return ['app.py']</li>
                                            <li>mock_cov.get_data.return_value should raise a MagicMock exception.</li>
                                            <li>entries should not contain any files that have errors.</li>
                                            <li>len(entries) should equal 0 after skipping error files.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        125 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_comprehensive</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test maps all source files in map_source_coverage with a comprehensive coverage percentage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that all source files are covered, even if analysis2 is not.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file path of the mapped entry should be 'app.py'.</li>
                                            <li>The number of statements in the mapped entry should be 3.</li>
                                            <li>The coverage percentage of the mapped entry should be 66.67%.</li>
                                            <li>All files in the source directory should be covered by the test.</li>
                                            <li>At least one file in the source directory should not be missed by the test.</li>
                                            <li>The coverage percentage for each file in the source directory should be calculated correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        345 input +
                                        159 output =
                                        504 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_make_warning</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the make_warning factory function to ensure it correctly returns a WarningCode.W001_NO_COVERAGE instance with the expected message and detail.</p>
                                    <p><strong>Why Needed:</strong> To prevent unexpected warnings when no coverage files are found, this test verifies that the make_warning factory function returns an appropriate WarningCode.W001_NO_COVERAGE instance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The returned warning code is correct (WarningCode.W001_NO_COVERAGE).</li>
                                            <li>The message of the warning is 'No .coverage file found'.</li>
                                            <li>The detail of the warning is 'test-detail'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        129 output =
                                        365 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_code_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that warning codes have correct values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the warning code values are incorrect, potentially causing issues with the application's functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'assert WarningCode.W001_NO_COVERAGE.value == "W001"', 'description': 'Correct value for W001_NO_COVERAGE'}</li>
                                            <li>{'message': 'assert WarningCode.W101_LLM_ENABLED.value == "W101"', 'description': 'Correct value for W101_LLM_ENABLED'}</li>
                                            <li>{'message': 'assert WarningCode.W201_OUTPUT_PATH_INVALID.value == "W201"', 'description': 'Correct value for W201'}</li>
                                            <li>{'message': 'assert WarningCode.W301_INVALID_CONFIG.value == "W301"', 'description': 'Correct value for W301'}</li>
                                            <li>{'message': 'assert WarningCode.W401_AGGREGATE_DIR_MISSING.value == "W401"', 'description': 'Correct value for W401'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        206 output =
                                        446 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWarning.to_dict() method.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential warning that could be misleading or incorrect.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'detail' key is present in the dictionary and its value matches the expected string.</li>
                                            <li>The 'code' key matches the expected string.</li>
                                            <li>The 'message' key matches the expected string.</li>
                                            <li>The 'no_detail' key is not present in the dictionary or its value does not match the expected string.</li>
                                            <li>The 'W001_NO_COVERAGE' code matches the expected string.</li>
                                            <li>The 'W101_LLM_ENABLED' code matches the expected string.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        143 output =
                                        419 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_known_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `make_warning` function with known code.</p>
                                    <p><strong>Why Needed:</strong> Prevents a warning from being generated for known code that should not be warned about.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `make_warning` returns an instance of `WarningCode.W101_LLM_ENABLED`.</li>
                                            <li>The message associated with the warning is set to `WARNING_MESSAGES[WarningCode.W101_LLM_ENABLED]`.</li>
                                            <li>The detail attribute of the warning is None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        109 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of using a fallback message for unknown code (if enum allowed it)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'missing_code', 'expected_value': 'WarningCode.W001_NO_COVERAGE'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        202 input +
                                        84 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</p>
                                    <p><strong>Why Needed:</strong> To test that a warning is created with the correct code and detail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'code', 'value': 'WarningCode.W301_INVALID_CONFIG'}</li>
                                            <li>{'name': 'detail', 'value': 'Bad value'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        86 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the WarningCode enum values are strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert isinstance(code.value, str)', 'expected_result': 'True'}</li>
                                            <li>{'name': "assert code.value.startswith('W')", 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        101 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_no_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for error handling and serialization of Warning objects.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the warning object can be serialized correctly without any additional details.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'data', 'expected_value': {'code': 'W001', 'message': 'No coverage'}, 'actual_value': {'code': 'W001', 'message': 'No coverage'}}</li>
                                            <li>{'name': 'type', 'expected_value': 'dict', 'actual_value': 'dict'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        133 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_non_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_non_python_file</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `is_python_file` function correctly identifies non-.py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result for foo/bar.txt', 'type': 'assertion', 'value': 'False'}</li>
                                            <li>{'name': 'Expected result for foo/bar.pyc', 'type': 'assertion', 'value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        119 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_python_file</p>
                                    <p><strong>Why Needed:</strong> The function `is_python_file` should be able to identify `.py` files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected the function to return True for .py files', 'type': 'assertion'}</li>
                                            <li>{'message': 'The function is returning False for foo/bar.py', 'type': 'expected_result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        99 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_makes_path_relative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_makes_path_relative</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function correctly makes a path relative to the test directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'path', 'expected_result': '/subdir/file.py', 'actual_result': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        92 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function returns a normalized path when no base is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        78 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_already_normalized</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_already_normalized</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly handles already-normalized paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert normalize path returns original path for already normalized paths', 'expected_value': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        81 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_forward_slashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_forward_slashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly handles paths with forward slashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'foo\\bar', 'expected': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        74 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> strips trailing slash from path</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'foo/bar/', 'expected': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        67 output =
                                        169 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> To ensure that custom patterns are correctly excluded from the test directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should_skip_path', 'expected_result': True}</li>
                                            <li>{'name': 'assert', 'message': "Should return True for should_skip_path('tests/conftest.py', exclude_patterns=['test*'])"}</li>
                                            <li>{'name': 'assert', 'message': "Should return False for should_skip_path('src/module.py', exclude_patterns=['test*'])"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        143 output =
                                        269 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_normal_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_normal_path</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the `should_skip_path` function correctly handles normal file system paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path returns False for src/module.py', 'expected_value': False, 'actual_value': 'tests/test_fs.py::TestShouldSkipPath::test_normal_path'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        103 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_git</p>
                                    <p><strong>Why Needed:</strong> The current implementation of `should_skip_path` does not correctly handle Git directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path returns True for .git/objects/foo', 'expected': True, 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        89 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</p>
                                    <p><strong>Why Needed:</strong> This test case is needed because the `should_skip_path` function does not currently handle __pycache__ directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path returns True for __pycache__/bar.pyc', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        94 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_venv</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the `should_skip_path` function correctly identifies venv directories as being to be skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path returns True for venv directory', 'description': 'Expected the `should_skip_path` function to return True when given a path that is a venv directory.', 'value': True}</li>
                                            <li>{'name': 'assert should_skip_path returns True for .venv directory', 'description': 'Expected the `should_skip_path` function to return True when given a path that is a .venv directory.', 'value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        171 output =
                                        292 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing that non-.py files do not return True.</p>
                                    <p><strong>Why Needed:</strong> Prevents a false positive assertion in the `is_python_file` method where it incorrectly returns True for non-python files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert is_python_file('module.txt') is False</li>
                                            <li>assert is_python_file('module.pyc') is False</li>
                                            <li>assert is_python_file('module') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        210 input +
                                        97 output =
                                        307 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that a module file (.py) returns True.</p>
                                    <p><strong>Why Needed:</strong> Prevents the test from incorrectly identifying non-python files as Python files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert is_python_file('module.py') is True</li>
                                            <li>assert is_python_file('path/to/module.py') is True</li>
                                            <li>assert is_python_file(Path('module.py')) is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        91 output =
                                        303 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_path_not_under_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makes a relative path not under the base directory.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression when make_relative is called with paths that are not relative to the base directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that make_relative returns a normalized absolute path even if the input path is not relative to the base.</li>
                                            <li>The test verifies that the 'project1' and 'file.py' strings are present in the returned path.</li>
                                            <li>The test verifies that the result of make_relative does not contain any '..' or '..\</li>
                                            <li>The test verifies that the result of make_relative is a string (not a file object) as expected.</li>
                                            <li>The test verifies that the parent directory of the input paths is preserved in the output path.</li>
                                            <li>The test verifies that the relative_to parameter is not used to resolve the issue.</li>
                                            <li>The test verifies that the make_relative function behaves correctly when given unrelated paths.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        301 input +
                                        203 output =
                                        504 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Make Relative</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of making relative paths correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'subdir/file.py', 'actual_result': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        63 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `make_relative` function does not handle cases where the base path is None correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Expected result to be 'path/to/file.py'", 'expected_result': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        93 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that backslashes are correctly converted to forward slashes in file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The normalized path contains a single forward slash.', 'expected_result': '/path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        84 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</p>
                                    <p><strong>Why Needed:</strong> Normalization of a file path object is necessary to ensure correct behavior in certain scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'path/to/file.py', 'actual_value': "normalize_path(Path('path/to/file.py'))"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        86 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly removes trailing slashes from file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result is equal to expected value', 'expected_value': 'path/to/dir', 'actual_value': 'path/to/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        95 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</p>
                                    <p><strong>Why Needed:</strong> Regular paths are not skipped by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is False', 'expected_value': False}</li>
                                            <li>{'assertion_type': 'is False', 'expected_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        91 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</p>
                                    <p><strong>Why Needed:</strong> The test should skip .git directories because they contain Git hooks that can interfere with the file system coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should be True', 'description': 'The function should return True when a .git directory is found.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        91 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly handles paths starting with a skip directory name.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'should be True', 'expected_value': True}</li>
                                            <li>{'message': '.venv', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        88 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the test module __pycache__ is being tested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'src/__pycache__/module.cpython-312.pyc'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        75 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_site_packages</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> /usr/lib/python3.12/site-packages/pkg/mod.py</p>
                                    <p><strong>Why Needed:</strong> The test is needed because it checks for site-packages directories, which are not covered by the current implementation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "should_skip_path('/usr/lib/python3.12/site-packages/pkg/mod.py')", 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        91 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</p>
                                    <p><strong>Why Needed:</strong> Because the 'venv' directory contains a Python package (site.py) which should be skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                            <li>{'path': '.venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        113 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> Custom exclude patterns are needed to skip certain paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'should_skip_path is called with the correct arguments', 'expected_result': 'True'}</li>
                                            <li>{'assertion': 'should_skip_path returns False for a path that matches an exclude pattern', 'expected_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        111 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_gemini_provider.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">25 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotate_loop_daily_limit_hit</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_annotate_loop_daily_limit_hit function prevents a regression where the daily limit is hit and the Gemini API returns an error.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the regression where the daily limit is hit, causing the Gemini API to return an error when trying to annotate internal nodes with the 'src' nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'Gemini requests-per-day limit reached' in res.error</li>
                                            <li>assert mock_limiter.next_available_in.return_value == None</li>
                                            <li>assert provider._rate_limiters['m1'].next_available_in.return_value == None</li>
                                            <li>assert mock_limiter.next_available_in.return_value == None</li>
                                            <li>assert provider._rate_limiters['m1'].next_available_in.return_value == None</li>
                                            <li>assert mock_limiter.next_available_in.return_value is None</li>
                                            <li>assert mock_limiter.next_available_in.return_value == None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        197 output =
                                        564 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-227, 232-233, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotation_exceptions_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the coverage of exceptions when using GeminiProvider with a mock configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that occurs when using GeminiProvider with a mock configuration and encountering exceptions, such as generation failures or rate limit exceeded errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocking the _GeminiRateLimiter to prevent RateLimitExceeded RPD (Line 300)</li>
                                            <li>_CallGemini to raise _GeminiRateLimitExceeded when RateLimitExceeded RPD is encountered</li>
                                            <li>Mocking the _ModelExhaustedAt dictionary to track model exhaustion and return an error message</li>
                                            <li>Asserting that exceptions are correctly propagated through the provider's methods</li>
                                            <li>Verifying that the correct exception messages are returned in the error object</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        730 input +
                                        166 output =
                                        896 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-236, 239-244, 263-265, 268, 293, 295, 299-303, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_coverage_gaps</span>
                            <div class="test-meta">
                                <span>167ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Prevents regression in coverage gaps by ensuring proper rate limiting and annotation logic.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the GeminiProvider's rate limiting and annotation logic may not be properly implemented, leading to uncovered coverage gaps.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _rate_limiters dictionary should contain 'm1' with a value of 100.</li>
                                            <li>_parse_rate_limits method returns a dictionary with the correct requests per day limit (100).</li>
                                            <li>The provider._models attribute contains the expected list of fallback models ('fallback').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        821 input +
                                        125 output =
                                        946 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">173 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181-182, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 254-255, 259, 340, 343, 346, 348-356, 358-361, 363-364, 366-367, 435, 437-439, 441-442, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-498, 502-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-564, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_parse_preferred_models_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 134-135, 137-141, 143-144, 524-527)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_prune_daily_requests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProvider</p>
                                    <p><strong>Why Needed:</strong> To test the coverage gaps of Gemini provider after pruning daily requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(_GeminiRateLimiter._daily_requests) == 0', 'description': 'The length of _GeminiRateLimiter._daily_requests should be 0 after pruning.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        90 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 39-42, 81-82, 84, 87-89)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_tpm_available_fallback</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the GeminiRateLimiter does not allow excessive token usage to prevent TPM fallback.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of extremely high token usage, causing the GeminiRateLimiter to return 0.0 at line 106/108 when a huge request is made.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total tokens used should be less than or equal to the limit (100).</li>
                                            <li>If `request_tokens` exceeds the remaining tokens, the loop should not return.</li>
                                            <li>The `remaining` variable should decrease as the tokens are used.</li>
                                            <li>The GeminiRateLimiter should not allow a huge token usage that implies it cannot fit all requests.</li>
                                            <li>If `request_tokens` is massive and `limit=100`, the test should pass without returning 0.0 at line 106/108.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        524 input +
                                        186 output =
                                        710 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39-42)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_import_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a forced import error is annotated correctly when google-generativeai is not installed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the GeminiProvider does not correctly handle import errors due to missing dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should contain an error message indicating that google-generativeai was not installed.</li>
                                            <li>The error message should include the exact string 'google-generativeai not installed'.</li>
                                            <li>The annotation should be able to distinguish between a forced import error and a normal import operation.</li>
                                            <li>The annotation should not report any other errors when the dependency is installed.</li>
                                            <li>The annotation should provide a clear indication of why the annotation failed (in this case, due to missing dependencies).</li>
                                            <li>The annotation should include all necessary information about the test environment (e.g., module flagging, test result).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        259 input +
                                        186 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 134-135, 137-141, 143-144, 164-165, 167-169)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_no_token</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test annotation when token is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the Gemini API token is not set, and thus the annotation fails.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'GEMINI_API_TOKEN' key should be present in the annotation error message.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should contain the value 'None'.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should not be empty.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should have a non-empty string value.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should not be None.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should contain the correct type (str).</li>
                                            <li>The 'GEMINI_API_TOKEN' key should not be an empty string.</li>
                                            <li>The 'GEMINI_API_TOKEN' key should have a non-empty string value.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        203 output =
                                        516 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_rate_limit_retry</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider annotates a rate limit retry scenario correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the GeminiProvider's ability to handle rate limit retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by the provider matches the expected scenario of 'Recovered Scenario'.</li>
                                            <li>The mock post call count is correct, indicating that the retry mechanism was successful.</li>
                                            <li>The _parse_response method returns a Mock object with the correct scenario and error.</li>
                                            <li>The provider's internal annotation logic does not modify the test result nodeid.</li>
                                            <li>The provider's internal annotation logic does not change the expected outcome of the test.</li>
                                            <li>The provider's internal annotation logic does not add any new assertions or checks.</li>
                                            <li>The provider's internal annotation logic does not remove any existing assertions or checks.</li>
                                            <li>The provider's internal annotation logic does not modify the mock post call count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        636 input +
                                        196 output =
                                        832 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">214 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-237, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_success</span>
                            <div class="test-meta">
                                <span>392ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly annotates a success scenario with the correct key assertions.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the provider incorrectly returns an error when annotating a successful response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by _annotate_internal has the expected scenario.</li>
                                            <li>The annotation does not have any errors.</li>
                                            <li>The annotation correctly extracts the 'text' part from the response.</li>
                                            <li>The annotation correctly extracts the 'tokens' part from the response.</li>
                                            <li>The annotation returns a valid LlmAnnotation object with the correct key assertions.</li>
                                            <li>The annotation does not return an error when the response is in the expected format.</li>
                                            <li>The annotation calls _parse_response correctly to extract the scenario and tokens.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        649 input +
                                        170 output =
                                        819 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">208 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-568, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_availability</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the availability of the Gemini provider when no API token is provided.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the provider tries to access an unavailable environment.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The provider should return False indicating that the environment is not available.</li>
                                            <li>The provider should not throw any exceptions if the environment is already available.</li>
                                            <li>The provider's _check_availability method should be able to detect when the environment is not available.</li>
                                            <li>The provider's _check_availability method should not make any assumptions about the availability of the environment based on the API token.</li>
                                            <li>The provider's _check_availability method should only return False if the environment is truly unavailable.</li>
                                            <li>The provider's _check_availability method should be able to handle cases where the environment has been previously checked and found available.</li>
                                            <li>The provider's _check_availability method should not interfere with other tests that rely on the environment being available.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        235 input +
                                        203 output =
                                        438 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 134-135, 137-141, 143-144, 332-333, 335)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_exceptions</span>
                            <div class="test-meta">
                                <span>60.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the GeminiProvider class correctly annotates retry exceptions and updates model exhaustion states accordingly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the GeminiProvider class fails to properly handle retry exceptions and update model exhaustion states when encountering a resource exhausted error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `provider._model_exhausted_at` dictionary is updated correctly with the model ID 'm1' after an exception occurs.</li>
                                            <li>The `provider._cooldowns` dictionary contains the expected cooldown value for model 'm1'.</li>
                                            <li>The cooldown value for model 'm1' exceeds 5.5 seconds as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        651 input +
                                        139 output =
                                        790 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-237, 239-244, 263-265, 268, 272-276, 279-281, 283-286, 288-292, 318-320, 322-323, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_loop_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `GeminiProvider` ensures models are exhausted after a retry loop and coverage is maintained.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the Gemini API token limit exceeds the daily limit of 24 hours ago, causing the model to be exhausted without sufficient retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_model_exhausted_at` attribute is updated correctly after a retry loop.</li>
                                            <li>The `GeminiProvider` ensures that models are exhausted within the specified time frame (24h+).</li>
                                            <li>The test maintains coverage by ensuring that the model's exhaustion check passes even when the Gemini API token limit exceeds the daily limit.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        482 input +
                                        144 output =
                                        626 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-94, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 254, 259, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_ensure_rate_limits_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test GeminiProvider::test_ensure_rate_limits_error</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `GeminiProvider` raises an error when rate limiting is attempted with a non-integer value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked config has rpm=10', 'expected_value': 10, 'actual_value': 0}</li>
                                            <li>{'name': 'limits.requests_per_minute == 10', 'expected_value': 10, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        125 output =
                                        281 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 134-135, 137-141, 143-144, 346, 348-356, 358-361, 363-364, 366-367)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test fetch available models with an exception</p>
                                    <p><strong>Why Needed:</strong> To test the error handling of GeminiProvider when a network error occurs</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'models are empty', 'description': 'The list of available models should be empty after a network error.', 'expected_result': [], 'actual_result': 'models == []'}</li>
                                            <li>{'name': 'limit_map is empty', 'description': 'The limit map should be empty after a network error.', 'expected_result': {}, 'actual_result': 'limit_map == {}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        139 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a fetch of available models with invalid JSON returns the expected result.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where an incorrect or malformed JSON is returned, potentially causing unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>models containing non-list supportedGenerationMethods</li>
                                            <li>models not containing inputTokenLimit</li>
                                            <li>model m3 in limit_map</li>
                                            <li>model m1 and model m2 not in models</li>
                                            <li>model m3 in limit_map</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        109 output =
                                        449 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 476-477, 537, 539-543, 547-548, 550-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method of the GeminiProvider class calls the mock function `mock_ensure` when necessary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_ensure is called once', 'description': 'The `mock_ensure` function should be called exactly once during the test.', 'condition': 'mock_ensure.call_count == 1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        124 output =
                                        268 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 486, 488-491, 493)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed::test_parse_rate_limits_types</p>
                                    <p><strong>Why Needed:</strong> To ensure that the GeminiProvider can correctly parse rate limits and return valid configuration values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.requests_per_minute is None', 'expected_value': 0, 'actual_value': 'None'}</li>
                                            <li>{'name': 'config.tokens_per_minute == 100', 'expected_value': 100, 'actual_value': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        117 output =
                                        273 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 134-135, 137-141, 143-144, 449-457, 459-460, 463-466)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_prune_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the _prune method of _GeminiRateLimiter removes all old requests and updates token usage accordingly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter would not prune older requests, leading to incorrect usage of tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of _request_times should be 1 after pruning.</li>
                                            <li>The length of _token_usage should be 1 after pruning.</li>
                                            <li>_request_times[0] should equal now - 10.0 after pruning.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        119 output =
                                        442 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-42, 81-85, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for the Gemini Rate Limiter</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the rate limiter correctly handles invalid token records.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Limiter should not store any tokens when record_tokens is called with a negative number', 'expected_result': 0, 'actual_result': {'scenario': 'Tests for the Gemini Rate Limiter', 'why_needed': 'The test is necessary to ensure that the rate limiter correctly handles invalid token records.', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        129 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39-42, 66-67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpd_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the rate limiting feature with a single request per day</p>
                                    <p><strong>Why Needed:</strong> The test ensures that the rate limiting feature correctly limits requests to 1 per day.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Limiter is initialized with correct rate limit', 'description': 'The limiter should be initialized with a rate limit of 1 requests per day', 'expected_value': 1, 'actual_value': 0}</li>
                                            <li>{'name': 'Rate limiting feature works as expected for single request per day', 'description': 'The rate limiting feature should not allow more than one request per day', 'expected_value': 0, 'actual_value': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        164 output =
                                        293 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 45-46, 48-50, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpm_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the RPM limit is correctly enforced for the first two requests and that it's not exceeded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the rate limiter exceeds the allowed number of requests per minute, potentially leading to unexpected behavior or errors in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>limiter.next_available_in(100) == 0.0</li>
                                            <li>limiter.record_request()</li>
                                            <li>assert limiter.next_available_in(100) == 0.0</li>
                                            <li>limiter.record_request()</li>
                                            <li>wait > 0 and wait <= 60.0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        140 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-97, 100-102)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_seconds_until_tpm_available_branches</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter returns 0 seconds when no tokens are requested and within the limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter does not return 0 seconds for requests with no tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _seconds_until_tpm_available should return 0.0 when no tokens are requested.</li>
                                            <li>The function _seconds_until_tpm_available should return 0.0 when more than limit tokens are requested but empty usage.</li>
                                            <li>The function _seconds_until_tpm_available should return 0.0 for normal usage within the limit.</li>
                                            <li>The function _seconds_until_tpm_available should return a value less than or equal to 60 seconds when usage exceeds the limit by 1 second.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        377 input +
                                        170 output =
                                        547 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 100-101, 103-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_daily_limit_exceeded</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that waiting for a daily limit exceeded throws an exception when the rate limit is set to one request per day.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the limiter does not raise an exception when the daily limit is exceeded, potentially leading to unexpected behavior or errors in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `wait_for_slot` method raises `_GeminiRateLimitExceeded` with a `limit_type` of 'requests_per_day'.</li>
                                            <li>The `limit_type` attribute of the raised exception matches the expected value.</li>
                                            <li>_GeminiRateLimitExceeded has a `limit_type` attribute that is set to 'requests_per_day' when it is raised.</li>
                                            <li>The `value` attribute of the raised exception contains an object with a `limit_type` attribute set to 'requests_per_day'.</li>
                                            <li>The `limit_type` value matches the expected value for requests per day.</li>
                                            <li>_GeminiRateLimitExceeded raises an exception when the daily limit is exceeded, which prevents unexpected behavior in downstream applications.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        228 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 32-34, 39-42, 45-46, 48-50, 58-60, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_sleeps</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the wait_for_slot function sleeps for a sufficient amount of time when the next available slot is not immediately available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the rate limiter does not sleep long enough between requests, potentially leading to performance issues or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The wait_for_slot function sleeps for at least 10 seconds.</li>
                                            <li>The next_available_in method is called with an argument of 10.0.</li>
                                            <li>The mock_sleep assertion is called once with a value of 10.0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        126 output =
                                        451 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 58-59, 61-63, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_hashing.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_different_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_different_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that different configurations of the Compute API produce different hashes, which can be used to identify and fix potential issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config1 and config2 are different', 'expected': 'different', 'actual': 'not equal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        94 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure the computed hash is short and can be stored efficiently in a database or other storage system.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'h should have length 16', 'expected_result': 16}</li>
                                            <li>{'assertion': 'h should not contain any non-ASCII characters', 'expected_result': 'All characters in h are ASCII'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        117 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_consistent_with_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ComputeFileSha256 test</p>
                                    <p><strong>Why Needed:</strong> To ensure the computed SHA-256 hash of a file matches its content hash.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': "b'test content'", 'actual_value': "b'test content'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        71 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 32, 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Compute File Sha256</p>
                                    <p><strong>Why Needed:</strong> To verify the correctness of the file hashing algorithm.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': "A hash of length 64 for a file with contents 'hello world'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        64 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_different_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_different_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that different keys produce different signatures.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'sig1', 'expected_type': 'bytes', 'actual_type': 'bytes'}</li>
                                            <li>{'name': 'sig2', 'expected_type': 'bytes', 'actual_type': 'bytes'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        91 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_with_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_with_key</p>
                                    <p><strong>Why Needed:</strong> To verify that the HMAC computation is correct and produces the expected signature.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_length': 64, 'actual_length': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        72 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_consistent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_consistent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function produces consistent results for the same input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'hash': 'd41d8cd98f00b804d0a131e86038e95'}, 'actual': {'hash': 'd41d8cd98f00b804d0a131e86038e95'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        113 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the hash length is correct and consistent across different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected the hash length to be 64 hex chars.', 'expected_value': 64}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        78 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</span>
                            <div class="test-meta">
                                <span>79ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'pytest' package is included in the dependency snapshot.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "snapshot contains 'pytest'", 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        78 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</span>
                            <div class="test-meta">
                                <span>81ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</p>
                                    <p><strong>Why Needed:</strong> The function `get_dependency_snapshot()` should return a dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>snapshot is an instance of dict</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        55 output =
                                        153 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_loads_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_loads_key</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading a HMAC key from a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The loaded key should match the expected value.', 'expected_value': 'my-secret-key'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        81 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 73, 76-77, 80-81)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Load HMAC Key with Missing Key File</p>
                                    <p><strong>Why Needed:</strong> To test the case where a key file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'type': 'NoneType', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        72 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 73, 76-78)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</p>
                                    <p><strong>Why Needed:</strong> Because the HMAC key is not loaded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert key is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        70 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 73-74)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_integration_gate.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">16 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_aggregation_defaults</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test aggregation default configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the default aggregation policy is set to 'latest' without including history.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.aggregate_dir is None</li>
                                            <li>config.aggregate_policy == 'latest'</li>
                                            <li>config.aggregate_include_history is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        73 output =
                                        274 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</p>
                                    <p><strong>Why Needed:</strong> The test captures failed output by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.capture_failed_output', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        70 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context mode is set to 'minimal' by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.llm_context_mode', 'expected_value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        78 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> LLM is not enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_llm_enabled() returns False for default config', 'expected_value': False, 'actual_value': 'get_default_config().is_llm_enabled()'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        91 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 123, 171, 284, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the 'omit_tests_from_coverage' configuration option is set to True by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.omit_tests_from_coverage</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        66 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the provider is set to 'none' when it's not explicitly specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "config.provider == 'none'", 'expected_result': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        79 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the default configuration does not exclude secret files by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Excluding secret files', 'expected_result': ['secret'], 'actual_result': [False]}</li>
                                            <li>{'name': 'Including .env files', 'expected_result': ['.env'], 'actual_result': [True]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        117 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_deterministic_output</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the output of the deterministic pipeline is sorted by nodeid.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the sorted nodeids are not as expected due to changes in the underlying data structure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>nodeids should be equal to the sorted list of nodeids from the report.json file.</li>
                                            <li>nodeids should contain only the nodeids mentioned in the tests section of the report.json file.</li>
                                            <li>nodeids should not contain any duplicates.</li>
                                            <li>nodeids should be in ascending order (i.e., no nodes are skipped or duplicated)</li>
                                            <li>nodeids should not include any non-nodeid strings from the test results</li>
                                            <li>nodeids should only contain node ids that were actually tested and reported as passed</li>
                                            <li>nodeids should not be empty</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        177 output =
                                        490 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_empty_test_suite</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that an empty test suite produces a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where an empty test suite causes the report to be invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.summary.total` property is set to 0.</li>
                                            <li>The `data` dictionary has a 'summary' key with a 'total' value of 0.</li>
                                            <li>The `json.loads()` function correctly parses the JSON data from the report file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        106 output =
                                        346 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_html_report_generation</span>
                            <div class="test-meta">
                                <span>39ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the full pipeline generates an HTML report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the HTML report is not generated correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'report.html' exists at the specified path.</li>
                                            <li>The content of the 'report.html' file contains the expected string '<html'.</li>
                                            <li>The content of the 'report.html' file contains the expected string 'test_pass'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        100 output =
                                        370 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">118 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_json_report_generation</span>
                            <div class="test-meta">
                                <span>64ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the full pipeline generates a valid JSON report with the expected structure and content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when the pipeline fails to generate a JSON report due to an issue with the report writer configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' key in the JSON output should be set to SCHEMA_VERSION.</li>
                                            <li>The 'summary' section of the JSON output should contain the correct total, passed, failed, and skipped counts.</li>
                                            <li>The 'passed', 'failed', and 'skipped' keys within the 'summary' section should have the expected values (1, 1, and 1 respectively).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        148 output =
                                        567 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/_git_info.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 2-3)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">138 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_report_root_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the ReportRoot object has required fields.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug where the report root is missing required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>ReportRoot has required fields: schema_version, run_meta, summary, and tests.</li>
                                            <li>Required fields are present in the data: 'schema_version', 'run_meta', 'summary', and 'tests'.</li>
                                            <li>The ReportRoot object contains all required fields.</li>
                                            <li>No report root is missing required fields.</li>
                                            <li>Missing required field would cause a validation error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        250 input +
                                        126 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_aggregation_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_run_meta_has_status_fields' verifies that RunMeta has run status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the RunMeta object does not have all required status fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field is present in the data.</li>
                                            <li>The 'interrupted' field is present in the data.</li>
                                            <li>The 'collect_only' field is present in the data.</li>
                                            <li>The 'collected_count' field is present in the data.</li>
                                            <li>The 'selected_count' field is present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        131 output =
                                        368 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</p>
                                    <p><strong>Why Needed:</strong> The schema version must be defined to ensure compatibility with the API.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'SCHEMA_VERSION', 'type': 'string'}</li>
                                            <li>{'name': '.', 'type': 'boolean'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        88 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_test_case_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TestCaseResult object has the required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TestCaseResult object is missing one or more required fields, potentially leading to incorrect results or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>nodeid</li>
                                            <li>outcome</li>
                                            <li>duration</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        76 output =
                                        299 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_litellm_retry_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_all_retries_exhausted</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all retries are exhausted when API calls fail.</p>
                                    <p><strong>Why Needed:</strong> Prevents the test from passing if all retries are exhausted due to an API call failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `provider.annotate` method should raise an error with a meaningful message.</li>
                                            <li>The annotation should contain an `error` key with a non-None value.</li>
                                            <li>The `error` value should be a string indicating the cause of the failure.</li>
                                            <li>The `error` value should not be None.</li>
                                            <li>The `provider.annotate` method should not return any result if all retries are exhausted.</li>
                                            <li>The annotation should contain an `error` key with a non-None value.</li>
                                            <li>The `provider.annotate` method should raise an exception when the API call fails.</li>
                                            <li>The `provider.annotate` method should log an error message when the API call fails.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        193 output =
                                        539 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_non_401_error_no_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that non-401 errors don't force token refresh.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of non-401 error and no force refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The API call should return an annotation with an error message.</li>
                                            <li>The error status code should be 500 (Internal server error).</li>
                                            <li>The test source file should not have any annotations.</li>
                                            <li>Any context files used by the test should also not have any annotations.</li>
                                            <li>If no force refresh is requested, the provider should not call LiteLLMProvider's annotate method.</li>
                                            <li>If a non-401 error occurs and no force refresh is requested, the result of annotate should be None.</li>
                                            <li>The annotation returned from annotate should contain an error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        167 output =
                                        534 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_retry_succeeds_after_transient_error</span>
                            <div class="test-meta">
                                <span>6.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that retry succeeds after transient error when API call fails twice before succeeding.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of transient errors, where the LLM token refresh attempt fails but subsequent attempts succeed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `test_foo()` function should be annotated with a successful result even though it was marked as transient.</li>
                                            <li>The API call to fail twice before succeeding should not raise an exception.</li>
                                            <li>The LLM token refresh attempt should eventually succeed after the transient error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        433 input +
                                        117 output =
                                        550 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_token_refresh_on_401</span>
                            <div class="test-meta">
                                <span>6.18s</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 401 error triggers token refresh (lines 123-126) when API call fails first, then succeeds.</p>
                                    <p><strong>Why Needed:</strong> To ensure the test catches and reports a retry of the token refresh after a 401 error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `provider.annotate()` should have been called with an additional argument (2 or more).</li>
                                            <li>The error status code should be 401 for the first call to `mock_completion`.</li>
                                            <li>The error message should contain '{</li>
                                            <li>The response choices should include a new token.</li>
                                            <li>The retry count should be greater than or equal to 2 after a 401 error occurs.</li>
                                            <li>The annotation result should not be None when a 401 error occurs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        167 output =
                                        640 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-188, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the GeminiProvider class is correctly instantiated when the 'gemini' provider is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'provider.__class__.__name__ == "GeminiProvider"', 'expected_result': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        91 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLMProvider class is correctly instantiated when a specific provider ('litellm') is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        90 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_none_returns_noop</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_none_returns_noop</p>
                                    <p><strong>Why Needed:</strong> To ensure that the GetProvider function returns a NoopProvider when the provider is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider should be NoneType', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        80 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the OllamaProvider class is correctly created and returned from the get_provider function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        86 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_unknown_raises</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestLlmProviderContract::test_noop_implements_interface</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that NoopProvider implements LlmProvider interface.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where NoopProvider is not implementing required methods of LlmProvider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>hasattr(provider, 'annotate')</li>
                                            <li>hasattr(provider, 'is_available')</li>
                                            <li>hasattr(provider, 'get_model_name')</li>
                                            <li>hasattr(provider, 'config')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        95 output =
                                        327 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_annotate_returns_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `annotate` method of the `NoopProvider` class returns an empty `LlmAnnotation` object when no annotation is provided.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the `annotate` method does not return an error or warning message when no annotation is given, but instead returns an empty annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `annotation` variable will be of type `LlmAnnotation`.</li>
                                            <li>The `scenario` attribute of the `annotation` object will be an empty string.</li>
                                            <li>The `why_needed` attribute of the `annotation` object will be an empty string.</li>
                                            <li>All `key_assertions` in the `annotation` object will be empty lists.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        249 input +
                                        162 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the `get_model_name` method of the `NoopProvider` class returns an empty string when the model name is not specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert get_model_name() == ''", 'description': 'The `get_model_name` method should return an empty string.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        107 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_is_available</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_is_available</p>
                                    <p><strong>Why Needed:</strong> To ensure the NoopProvider class is always available and does not raise any exceptions when instantiated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_available() should be a boolean value', 'expected_type': 'bool'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        84 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 59)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_contract.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_from_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the AnnotationSchema can parse a dictionary into a valid annotation.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential bugs where the AnnotationSchema does not correctly handle malformed input data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>checks password</li>
                                            <li>checks username</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        66 output =
                                        340 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> This test checks if the AnnotationSchema can handle an empty input.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it ensures that the AnnotationSchema can process and validate valid inputs, including empty ones.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'schema.scenario', 'value': '', 'expected_value': ''}</li>
                                            <li>{'name': 'schema.why_needed', 'value': '', 'expected_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        107 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_partial</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the schema has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the schema is not properly defined with required fields, potentially leading to errors or inconsistencies in the data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'scenario' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert 'why_needed' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert 'key_assertions' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert isinstance(ANNOTATION_JSON_SCHEMA, dict)</li>
                                            <li>assert len(ANNOTATION_JSON_SCHEMA) > 0</li>
                                            <li>assert all(key in ANNOTATION_JSON_SCHEMA for key in ['scenario', 'why_needed', 'key_assertions'])</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        164 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `AnnotationSchema` instance correctly serializes to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `AnnotationSchema` class handles scenario and why_needed keys correctly when converting to a dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert data['scenario'] == 'Tests feature X'</li>
                                            <li>assert data['why_needed'] == 'Prevents bug Y'</li>
                                            <li>assert 'key_assertions' in data</li>
                                            <li># Verify the presence of key_assertions</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        147 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 90-92, 94-96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</p>
                                    <p><strong>Why Needed:</strong> To test that the factory returns a NoopProvider for a specific provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_type': 'NoopProvider', 'actual_type': 'get_provider(config)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        80 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the NoopProvider class correctly implements the LlmProvider interface.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'type_of_provider', 'expected': 'LlmProvider', 'actual': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        90 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_returns_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The NoopProvider should return an empty annotation when the test function does not have any dependencies.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the NoopProvider returns an incorrect annotation for tests with no dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result.scenario == ""</li>
                                            <li>assert result.why_needed == ""</li>
                                            <li>assert result.key_assertions == []</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        93 output =
                                        346 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_annotate_returns_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `annotate` method of the `ProviderContract` class returns an instance of `TestCaseResult` with the expected attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the `annotate` method does not return an instance of `TestCaseResult` with the expected attributes, potentially causing issues downstream in the testing framework.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `scenario` attribute is present and has the correct value.</li>
                                            <li>The `why_needed` attribute is present and has the correct value.</li>
                                            <li>The `key_assertions` list contains all the required assertions to verify the expected attributes of the returned object.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        143 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</p>
                                    <p><strong>Why Needed:</strong> To ensure the NoopProvider class handles empty code gracefully and returns a valid TestCaseResult.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The provider should not return None for an empty test.', 'expected_result': 'Not None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        87 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_none_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_handles_none_context</p>
                                    <p><strong>Why Needed:</strong> To ensure the NoopProvider class can handle None context without raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None', 'actual_value': 'not None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        77 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</p>
                                    <p><strong>Why Needed:</strong> To ensure that all providers have an annotate method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "has attribute 'annotate'", 'value': 'True'}</li>
                                            <li>{'name': 'is callable annotate method', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        93 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 65-66, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_providers.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">52 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</p>
                                    <p><strong>Why Needed:</strong> The current implementation of annotate_handles_context can handle contexts up to 1000 tokens. However, with the increasing size of the input data, it may exceed this limit and cause performance issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'expected', 'expected_value': 1000, 'actual_value': 15000}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        114 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">187 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 263-265, 299, 311-312, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524-525, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The LiteLLMProvider annotates the missing dependency 'litellm' in a test case.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the provider from silently failing when a required dependency is not installed, potentially masking bugs or regressions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>the annotation contains an error message indicating that 'litellm' is not installed.</li>
                                            <li>the annotation includes the correct installation instructions for 'litellm'.</li>
                                            <li>the annotation provides clear and concise feedback to the user about what they need to do to resolve the issue.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        124 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-195, 471-473, 497-498, 502-503, 537)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_token</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `GeminiProvider` requires an API token and prevents a missing token error.</p>
                                    <p><strong>Why Needed:</strong> The current implementation does not verify if the required API token is set before annotating the test. This can lead to unexpected behavior or errors when trying to annotate tests with missing tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'GEMINI_API_TOKEN is not set'</li>
                                            <li>assert provider._config.api_token is None</li>
                                            <li>assert fake_genai.configure.called_with(None) == True</li>
                                            <li>assert fake_google.generativeai.__path__.endswith[:] == []</li>
                                            <li>assert fake_google.generativeai._config.api_key is None</li>
                                            <li>assert provider._config._api_key is None</li>
                                            <li>assert fake_api_core.exceptions.ResourceExhausted.called_once() == True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        440 input +
                                        180 output =
                                        620 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_records_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotate records tokens function works correctly by annotating a login test.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions and ensures accurate token usage tracking.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the correct number of tokens are recorded on the limiter for the specified model.</li>
                                            <li>Check if the rate limits logic ran without error.</li>
                                            <li>Verify that the correct user is logged in based on the annotated test function.</li>
                                            <li>Ensure that the correct usage metadata is provided to the API.</li>
                                            <li>Verify that the total token count matches the expected value.</li>
                                            <li>Confirm that the annotation was successful and no errors occurred.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        783 input +
                                        138 output =
                                        921 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-455, 457, 459-460, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_retries_on_rate_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can annotate retries correctly when rate limiting is in place.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The annotation of retries should match the expected key', 'expected_value': 'annotation_retries', 'actual_value': 'annotation_retries'}</li>
                                            <li>{'name': 'The annotation of retries should be a dictionary with the correct keys', 'expected_value': {'key1': 'value1', 'key2': 'value2'}, 'actual_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        137 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> Rotating models on the daily limit is necessary because it prevents LLMs from being trained indefinitely and causing performance issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'models are rotated', 'description': 'The model should be rotated after a certain number of iterations (e.g. 1000).'}</li>
                                            <li>{'name': 'no more than one model per day', 'description': 'No more than one LLM model should be trained on the system at any given time.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        139 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">210 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526-527, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider skips annotating tasks when the daily limit is exceeded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error message', 'description': 'The test expects an error message indicating that the daily limit has been reached.'}</li>
                                            <li>{'name': 'Expected exception type', 'description': 'The test expects a `LimitExceededError` to be raised when the daily limit is exceeded.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        134 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider annotates a successful response with the correct information.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the provider correctly handles successful responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        474 input +
                                        60 output =
                                        534 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">209 lines (ranges: 39-42, 45-46, 48-49, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_exhausted_model_recovers_after_24h</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_exhausted_model_recovers_after_24h</p>
                                    <p><strong>Why Needed:</strong> The test is needed because the model may not recover from an exhausted state after 24 hours. This could lead to a situation where the provider returns incorrect results for a certain period.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'model recovered', 'description': 'The model should be able to recover and return correct results after 24 hours.'}</li>
                                            <li>{'name': 'provider returns incorrect results', 'description': 'The provider should return incorrect results for a certain period after the model has recovered.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        152 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">222 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `fetch_available_models` method raises an error when no models are available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'method call', 'expected': 'fetch_available_models', 'actual': 'raise ValueError'}</li>
                                            <li>{'name': 'error message', 'expected': 'No models available.', 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        106 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 134-135, 137-141, 143-144, 346, 348-349, 352-356, 358-361, 363-364, 366-367, 435, 437-439, 441-444, 449-452, 463-466, 476, 478, 497-498, 502-508, 511, 514-516, 518-521, 524-525, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_model_list_refreshes_after_interval</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The model list is refreshed after an interval.</p>
                                    <p><strong>Why Needed:</strong> To ensure the model list is updated correctly and consistently with the LLM provider's refresh interval.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Model list is updated', 'description': 'The model list should be updated every time the test runs.'}</li>
                                            <li>{'name': 'Refresh interval is respected', 'description': "The LLM provider's refresh interval should be respected and not cause any issues with the test."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        120 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">201 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_401_retry_with_token_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider retries on 401 after refreshing token.</p>
                                    <p><strong>Why Needed:</strong> Reason for retrying with token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify the correct API key is captured before and after token refresh.</li>
                                            <li>Verify the response data contains the expected scenario, why needed, and key assertions.</li>
                                            <li>Verify that the first call to fake_completion raises a FakeAuthError (401 Unauthorized).</li>
                                            <li>Verify that the second call to fake_completion returns a successful response with the correct API key.</li>
                                            <li>Verify that the captured keys are in the correct order (token-1 before token-2).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        580 input +
                                        142 output =
                                        722 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_handles_completion_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider annotates completion errors correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where LiteLLM providers do not surface completion errors in annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `error` attribute of the annotation is set to `boom` when a completion error occurs.</li>
                                            <li>The `boom` string is present within the `error` attribute.</li>
                                            <li>The test case asserts that the `error` attribute is not `None`</li>
                                            <li>The `boom` string is found in the `error` attribute</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        128 output =
                                        435 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider rejects invalid key_assertions payloads.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression where the provider incorrectly handles invalid key_assertions payloads, making it harder to identify and fix issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>response_data must be a dictionary</li>
                                            <li>response_data must contain 'key_assertions'</li>
                                            <li>response_data must not be empty</li>
                                            <li>response_data must have exactly one key_assertion</li>
                                            <li>response_data.key_assertions should be a list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        112 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 206, 211)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The LiteLLMProvider should report a missing dependency error when the required package is not installed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the LiteLLMProvider does not correctly handle cases where the required package is not installed, potentially leading to silent failures or incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by the annotate method should include an error message indicating that the required dependency 'litellm' is missing and how to install it.</li>
                                            <li>The error message should be in the format 'required package <name> not installed. Install with: pip install <name>'</li>
                                            <li>The error message should provide a clear indication of what needs to be done to resolve the issue.</li>
                                            <li>The annotation should include the exact name of the required package, which is 'litellm' in this case.</li>
                                            <li>The annotation should include the correct installation command for the required package.</li>
                                            <li>The annotation should not silently fail or produce incorrect results if the required package is not installed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        271 input +
                                        217 output =
                                        488 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 37-38, 41, 82-86)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider annotates a successful response correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the annotation is correct for a valid response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation contains the expected scenario, why needed, and key assertions.</li>
                                            <li>The annotation has a non-zero confidence level.</li>
                                            <li>The captured model matches the one used in the test.</li>
                                            <li>The 'tests/test_auth.py::test_login' message is present in the response.</li>
                                            <li>The 'def test_login()' message is present in the response.</li>
                                            <li>The system role of the message is 'system'.</li>
                                            <li>The status OK assertion is present in the response.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        475 input +
                                        150 output =
                                        625 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider correctly handles prompt override scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by _annotate_internal method does not contain any messages.</li>
                                            <li>The content of the annotation's error message is 'CUSTOM PROMPT'.</li>
                                            <li>The annotation contains a custom prompt as expected.</li>
                                            <li>The key 'why_needed' in the annotation matches the provided reason.</li>
                                            <li>The key 'key_assertions' in the annotation matches the expected list of assertions.</li>
                                            <li>The value of the content key in the captured messages is 'CUSTOM PROMPT'.</li>
                                            <li>The type of the error message in the annotation is None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        161 output =
                                        534 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_token_usage</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token usage extraction for LiteLLM providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token_usage` attribute of the annotation returned by `provider.annotate(test, 'src')` is not None.</li>
                                            <li>The value of `prompt_tokens` in `annotation.token_usage` is set to `100`.</li>
                                            <li>The value of `completion_tokens` in `annotation.token_usage` is set to `50`.</li>
                                            <li>The value of `total_tokens` in `annotation.token_usage` is set to `150`.</li>
                                            <li>The `token_usage` attribute is correctly populated with the expected values even when there are no token usage data available.</li>
                                            <li>The test verifies that the `prompt_tokens`, `completion_tokens`, and `total_tokens` attributes have the correct values for a given test case.</li>
                                            <li>The test also verifies that the `token_usage` attribute has a value of `None` when it should be `None` (i.e., no token usage data is available).</li>
                                            <li>The test ensures that the `token_usage` attribute is correctly populated with the expected values even in cases where there are multiple choices or no completion tokens.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        278 output =
                                        704 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test: tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough verifies that the LiteLLM provider passes api_base to completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case when API base is not provided in the config.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `api_base` in the response data should be 'https://proxy.corp.com/v1'.</li>
                                            <li>The value of `litellm_api_base` in the config should be 'https://proxy.corp.com/v1'.</li>
                                            <li>The value of `api_base` in the completion call should match the one provided in the config.</li>
                                            <li>The response data should contain a key named `scenario`.</li>
                                            <li>The response data should contain a key named `why_needed`.</li>
                                            <li>The response data should contain a key named `key_assertions`.</li>
                                            <li>The value of `api_base` in the completion call should be 'https://proxy.corp.com/v1'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        387 input +
                                        221 output =
                                        608 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182-183, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_key_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The liteLLM provider should pass the static API key to the completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the API key is not passed through to the completion call, potentially causing issues with the model's behavior or performance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The API key should be captured and stored in the `captured` dictionary.</li>
                                            <li>The response data from the fake completion function should include the expected 'api_key' key.</li>
                                            <li>The 'api_key' value in the response data should match the static API key provided by the environment (TEST_KEY).</li>
                                            <li>The 'key_assertions' list should contain the expected 'api_key' assertion.</li>
                                            <li>The captured dictionary should have an 'api_key' key with the correct value.</li>
                                            <li>The fake completion function should return a response data object with the expected 'response_data' key and 'api_key' value.</li>
                                            <li>The 'why_needed' assertion should indicate that this test prevents a regression in API key passing to the completion call.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        384 input +
                                        222 output =
                                        606 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_error_without_refresher</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider returns an auth error when no refresher is configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider returns an authentication error without refreshing the token, potentially causing unexpected behavior or errors in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `provider.annotate(test, 'src')` annotation should include an error message indicating that authentication failed.</li>
                                            <li>The `annotation.error` attribute should contain the string 'Authentication failed'.</li>
                                            <li>The `annotation.error` attribute should not be `None` when the test passes.</li>
                                            <li>The `annotation.error` attribute should contain the exact phrase 'Authentication failed' to ensure it matches the expected error message.</li>
                                            <li>The `annotation.error` attribute should be a string, not a list or other data structure.</li>
                                            <li>The `annotation.error` attribute should have the correct type (str) to ensure it's a string value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        338 input +
                                        198 output =
                                        536 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 132-133, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_retry_fails_on_second_attempt</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider reports an authentication error when retrying after a second failure.</p>
                                    <p><strong>Why Needed:</strong> To prevent the provider from reporting an authentication error on subsequent retries, which could mask legitimate errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `litellm_token_refresh_command` is set to 'get-token'.</li>
                                            <li>The `llm_max_retries` is set to 2. If this value is exceeded, the provider will retry after a second failure.</li>
                                            <li>The `AuthenticationError` raised by the fake completion function is not caught by the provider's authentication error handler.</li>
                                            <li>The `litellm_token_refresh_command` is called with an argument 'token-new' when the retry attempt fails. This should trigger the authentication error handler.</li>
                                            <li>The `litellm_token_refresh_command` is called without any arguments when the retry attempt succeeds. The authentication error handler should not be triggered in this case.</li>
                                            <li>If the provider's authentication error handler catches the `FakeAuthError`, it should not report an authentication error on subsequent retries.</li>
                                            <li>The `litellm_token_refresh_command` is set to 'get-token' with a different argument when the retry attempt fails. This should trigger the authentication error handler and prevent the provider from reporting an authentication error on subsequent retries.</li>
                                            <li>If the provider's authentication error handler raises an exception, it should not be caught by the `fake_run` function and thus prevent the provider from reporting an authentication error on subsequent retries.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        317 output =
                                        736 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">51 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 129-130, 132-133, 141-142, 170-174, 176-178, 182, 186-188, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_context_too_long_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'LiteLLMProvider::test_context_too_long_error' verifies that the LiteLLM provider handles context too long error correctly.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug or regression where the LiteLLM provider throws an error when handling responses with invalid contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The response is not None, indicating that the function does not throw an exception</li>
                                            <li>The response contains the expected JSON structure</li>
                                            <li>The 'error' key in the response matches the expected value</li>
                                            <li>The 'why_needed' key in the response is empty, as it's not necessary for this test</li>
                                            <li>The 'key_assertions' list in the response is empty, indicating that the function does not throw an exception</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        370 input +
                                        166 output =
                                        536 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_dict_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_max_context_tokens_dict_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct dictionary format is returned when calling get_max_context_tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': 16384, 'message': 'Expected result to be 16384'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        218 input +
                                        79 output =
                                        297 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227-228, 230-231)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLMProvider can handle errors and return a fallback value for max context tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'get_max_context_tokens returns an error when no context is provided', 'expected_value': 0, 'actual_value': 1}</li>
                                            <li>{'name': 'get_max_context_tokens returns a fallback value for max context tokens when an error occurs', 'expected_value': 10, 'actual_value': 20}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        130 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227, 232-234)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</p>
                                    <p><strong>Why Needed:</strong> To ensure the LiteLLM provider correctly returns the maximum context tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return 8192 as the maximum context tokens.', 'expected_value': 8192}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        89 output =
                                        302 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 37-38, 41, 221-222, 224, 227-229)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</p>
                                    <p><strong>Why Needed:</strong> To test the `is_available` method of the `LiteLLMProvider` class, which checks if a required module is installed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocking sys.modules', 'expected': {'litellm': 'fake_litellm'}, 'actual': 'fake_litellm'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        160 input +
                                        109 output =
                                        269 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 37-38, 41, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_token_refresh_integration</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the LiteLLM provider's token refresh integration.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a bug where the provider does not refresh tokens in a timely manner, potentially causing issues with dynamic token usage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the `litellm_token_refresh_command` is set to 'get-token'.</li>
                                            <li>Check if the `litellm_token_refresh_interval` is set to 3600 seconds (1 hour).</li>
                                            <li>Assert that the `api_key` variable in the captured output matches the expected value.</li>
                                            <li>Verify that the provider's `LiteLLMProvider` instance has been updated with the new configuration.</li>
                                            <li>Check if the `test_case()` method of the `LiteLLMProvider` instance returns a `CaseResult` object with an outcome of 'passed'.</li>
                                            <li>Assert that the captured output contains the expected API key value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        442 input +
                                        194 output =
                                        636 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">41 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_transient_error_retry</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider retries transient errors and that the test passes when there are more than 3 retry attempts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider does not retry transient errors, potentially causing the test to fail with a ConnectionError.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The provider should raise a ConnectionError on the first attempt (0 calls).</li>
                                            <li>The provider should raise a ConnectionError on the second attempt (1 call).</li>
                                            <li>The provider should raise a ConnectionError on the third attempt (2 calls) and pass the test.</li>
                                            <li>The provider should not retry transient errors if there are less than 3 attempts left.</li>
                                            <li>The provider should not retry transient errors if there are more than 3 attempts left.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        169 output =
                                        595 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_fallbacks_on_context_length_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can handle context length errors and still return valid JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "Expected a dictionary with 'scenario', 'why_needed', and 'key_assertions' keys", 'expected_value': {'scenario': 'tests/test_llm_providers.py', 'why_needed': 'To ensure that the LLM provider can handle context length errors and still return valid JSON.', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        125 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">70 lines (ranges: 65-66, 87-89, 97-99, 101, 103, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 243, 245, 264, 266-267, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 85-86, 92, 138, 140, 142-144, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_handles_call_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the annotate method returns an error message when a call to Ollama raises a call error.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the annotation fails to detect call errors in Ollama providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>error == 'Failed after 2 retries. Last error: boom'</li>
                                            <li>annotation.error == 'Failed after 2 retries. Last error: boom'</li>
                                            <li>provider._call_ollama().__name__ == 'boom'</li>
                                            <li>test_case.__name__ == 'test_case'</li>
                                            <li>test_case.__doc__ is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        347 input +
                                        136 output =
                                        483 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 97-98, 100-101, 103-104)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_missing_httpx</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The Ollama provider reports missing httpx dependency when annotating a test case.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider incorrectly assumes that httpx is installed and reports an error instead of suggesting to install it.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'httpx not installed. Install with: pip install httpx'</li>
                                            <li>provider.annotate(test, 'def test_case(): assert True')</li>
                                            <li>test_case()</li>
                                            <li>assert test_case().__name__ == 'test_case'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        268 input +
                                        121 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 42-46)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the OLLAMA provider is not annotating runtime errors immediately.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'OllamaProvider should annotate runtime error', 'expected_value': 'True'}</li>
                                            <li>{'name': 'OllamaProvider should return immediate annotation result', 'expected_value': 'Immediate annotation result'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        119 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 96)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_success_full_flow</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the annotate method correctly annotates a full flow with mocked HTTP responses and returns a CaseResult object.</p>
                                    <p><strong>Why Needed:</strong> Prevents authentication bugs by ensuring that the Ollama provider returns an error when the login process fails.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>check status</li>
                                            <li>validate token</li>
                                            <li>assert True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        414 input +
                                        82 output =
                                        496 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided with a custom prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case providers override the default prompt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Verify that the provider sets the correct error message.', 'condition': 'annotation.error is None', 'assertion': "captured_messages[0][1]['content'] == 'CUSTOM PROMPT'"}</li>
                                            <li>{'description': 'Verify that the custom prompt is used for annotation.', 'condition': "captured_messages[0][1]['content'] != 'default prompt'", 'assertion': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        149 output =
                                        522 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52-53, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `annotate` method of `LiteLLMProvider` correctly extracts token usage from a response.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling cases where token usage is not provided in the response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of prompt tokens should be equal to 100.</li>
                                            <li>The number of completion tokens should be equal to 50.</li>
                                            <li>The total number of tokens should be equal to 150.</li>
                                            <li>The `token_usage` attribute should not be `None`.</li>
                                            <li>The value of `prompt_tokens` should match the expected value of 100.</li>
                                            <li>The value of `completion_tokens` should match the expected value of 50.</li>
                                            <li>The value of `total_tokens` should match the expected value of 150.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        175 output =
                                        601 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71, 74-80, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider makes correct API call to generate response.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in API call functionality of the Ollama provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function _call_ollama() returns a dictionary with the expected 'response', 'model', 'prompt', and 'system' values.</li>
                                            <li>The captured URL and JSON data match the expected values from the API call.</li>
                                            <li>The timeout value is set to the expected 60 seconds.</li>
                                            <li>The response is not empty or None, as expected for a successful API call.</li>
                                            <li>The model and prompt are correctly retrieved from the captured JSON data.</li>
                                            <li>The system prompt is used in the generated response, as expected.</li>
                                            <li>The stream parameter is False, indicating no streaming of the response.</li>
                                            <li>The timeout value is respected during the API call.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        470 input +
                                        187 output =
                                        657 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_uses_default_model</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the default model is used when not specified for Ollama provider.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the default model is not used when it should be.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The captured JSON response contains the default model 'llama3.2'.</li>
                                            <li>The captured JSON response does not contain any custom model specified by the user.</li>
                                            <li>The captured JSON response has the correct key 'model' with value 'llama3.2'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        344 input +
                                        114 output =
                                        458 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider returns False when server is unavailable</p>
                                    <p><strong>Why Needed:</strong> The Ollama provider should return False when the server is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() is False', 'expected_value': False, 'actual_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        183 input +
                                        81 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 113-114, 116-117, 119-120)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</p>
                                    <p><strong>Why Needed:</strong> To test the availability of an Ollama provider when it returns a non-200 status code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() should return False for a 500 status code', 'expected_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        197 input +
                                        97 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the Ollama provider checks for availability via the /api/tags endpoint successfully.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the provider fails to check availability due to a misconfigured or outdated API.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The URL '/api/tags' is included in the provided URL.</li>
                                            <li>A response with a status code of 200 is returned from the /api/tags endpoint.</li>
                                            <li>The OllamaProvider instance's _check_availability method returns True after calling this test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        121 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_context_length_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens_context_length` method returns the correct key for the context length in the JSON response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context Length', 'expected_value': 100, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        79 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_fallback_on_error</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the maximum context token count is exceeded during training.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected max_context_tokens to be greater than 0', 'description': 'The `max_context_tokens` parameter should have a value greater than 0.'}</li>
                                            <li>{'name': "Expected error message to contain 'maximum context tokens exceeded'", 'description': "The error message should contain the phrase 'maximum context tokens exceeded'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        141 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 138, 140, 142-147, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_model_info</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns the correct maximum context tokens for a given model info.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'value': 10}</li>
                                            <li>{'name': 'context_token_count', 'value': 20}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        84 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_parameters</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for OLLAMA provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the maximum context tokens can be retrieved from parameters correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 100, 'actual_value': 64}</li>
                                            <li>{'name': 'context_token_length', 'expected_value': 128, 'actual_value': 96}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        102 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 138, 140, 142-147, 149-150, 156, 158, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_non_200_status</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for LLM providers</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider returns an error when the input is too large to be processed in a single context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Status code', 'value': 200}</li>
                                            <li>{'name': 'Response content type', 'value': 'application/json'}</li>
                                            <li>{'name': 'Content length', 'value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        97 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 138, 140, 142-147, 149, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider always returns `is_local=True`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'provider.is_local() is True', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        82 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama Provider: test_parse_response_invalid_json</p>
                                    <p><strong>Why Needed:</strong> To ensure the OllamaProvider correctly handles invalid JSON responses and reports an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Error message', 'expected': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        78 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 65-66, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> This test checks that the Ollama provider rejects invalid key_assertions payloads.</p>
                                    <p><strong>Why Needed:</strong> The Ollama provider should reject responses with invalid key_assertions payloads.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Invalid response: key_assertions must be a list', 'code': 400}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        135 output =
                                        309 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Ollama provider correctly extracts JSON from markdown code fences.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected JSON format', 'expected': '{"scenario": "tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence", "why_needed": "To ensure that the Ollama provider correctly extracts JSON from markdown code fences."}', 'actual': '{"scenario": "tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence", "why_needed": "To ensure that the Ollama provider correctly extracts JSON from markdown code fences."}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        178 output =
                                        305 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of extracting JSON from plain markdown fences (no language).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'response is a string', 'expected_value': 'string', 'actual_value': '<pre><code></code></pre>'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        97 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider parses valid JSON responses with correct scenario, why needed, and key assertions.</p>
                                    <p><strong>Why Needed:</strong> Prevents bugs by ensuring the Ollama provider correctly identifies scenarios and key assertions in valid JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert a</li>
                                            <li>assert b</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        292 input +
                                        69 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_utils.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_constrained</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verify water-fill algorithm satisfies smaller files first with constrained token budget.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the water-fill algorithm when distributing tokens to files, ensuring that smaller files are given priority and have sufficient content to fill their allocated budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `distribute_token_budget` should allocate a total of 10 tokens to `small.py` and no more than 45 tokens to `large.py` when distributing the token budget.</li>
                                            <li>The allocation for `small.py` should be at least 10 tokens, but not exceed 30 tokens.</li>
                                            <li>The allocation for `large.py` should be between 30 tokens and 45 tokens inclusive.</li>
                                            <li>The total allocated tokens should sum up to 60 (budget) - 16 (tokens needed by small.py) = 44 tokens for large.py.</li>
                                            <li>The remaining budget after allocating to small.py should be sufficient for large.py, allowing it to get at least 38 content tokens (44 - 6 overhead).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        396 input +
                                        223 output =
                                        619 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_empty</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `distribute_token_budget` function behaves correctly when given an empty input or no budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': {'message': 'Expected distribute_token_budget to return {}'}, 'description': 'Test case for empty input'}</li>
                                            <li>{'assertion': {'message': 'Expected distribute_token_budget to return {}'}, 'description': 'Test case for no budget'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        124 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 42-43)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_fair_share</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify fair sharing when neither fits.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where both files are large and the budget is insufficient to cover their content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The contents of `l1.py` and `l2.py` should be roughly equal.</li>
                                            <li>The allocation for `l1.py` should be between 35% and 50% of its total content (44 tokens).</li>
                                            <li>The allocation for `l2.py` should also be between 35% and 50% of its total content (44 tokens).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        129 output =
                                        456 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_max_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_max_files</p>
                                    <p><strong>Why Needed:</strong> Verify the limit of max_files in the distribute_token_budget function to prevent over-allocation of files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'length of allocations should be equal to 3', 'expected_value': 3, 'actual_value': 1, '# This test is failing because only one file was allocated. Verify why this happened and correct it if necessary.': "reason_for_failure': 'Only one file was allocated instead of three.'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        134 output =
                                        267 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_sufficient</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the function `distribute_token_budget` correctly allocates tokens to files when the budget is sufficient.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function does not allocate enough tokens to all files, resulting in incomplete content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of allocations should be equal to 2.</li>
                                            <li>Each file's allocation should match its required amount (10 tokens for f1.py and 10 tokens for f2.py).</li>
                                            <li>All files should have their allocated tokens within the total budget (32 tokens in this case).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        130 output =
                                        462 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_estimate_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify rough token estimation (chars / 4) for an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential division by zero error when estimating tokens in the absence of any input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert estimate_tokens([]) == 1</li>
                                            <li>assert estimate_tokens('') == 1</li>
                                            <li>assert estimate_tokens('a') == 1</li>
                                            <li>assert estimate_tokens('aaaa') == 1</li>
                                            <li>assert estimate_tokens('aaaa' * 10) == 10</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        119 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">29 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestArtifactEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` correctly serializes the test data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where coverage data is not properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_count' key in the dictionary should match the expected value.</li>
                                            <li>All values in the dictionary should be strings or integers, as they represent coverage data.</li>
                                            <li>Any non-string or integer values should be ignored during serialization.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        138 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 263-266)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCollectionError::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` correctly serializes the test entry.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the serialized `CoverageEntry` is not as expected, potentially leading to incorrect coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the original file path.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the original line ranges.</li>
                                            <li>The 'line_count' key in the dictionary should match the original line count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        117 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 241-243)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests CoverageEntry serialization correctly.</p>
                                    <p><strong>Why Needed:</strong> CoverageEntry may not serialize correctly if line ranges are invalid or missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary matches the expected value.</li>
                                            <li>The 'line_ranges' key in the dictionary matches the expected value.</li>
                                            <li>The 'line_count' key in the dictionary matches the expected value.</li>
                                            <li>All assertions pass for a single CoverageEntry instance.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        103 output =
                                        358 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 65-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> An empty annotation should be created with default values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where an empty annotation does not have any key-value pairs or default values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation.scenario == "" (empty string)</li>
                                            <li>annotation.why_needed == "Empty annotation should have default values."</li>
                                            <li>annotation.key_assertions == [] (no key-value pairs or default values)</li>
                                            <li>assert annotation.confidence is None (default confidence value)</li>
                                            <li>assert annotation.error is None (default error message)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        124 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `to_dict` method of `LlmAnnotation` returns a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the minimal annotation is missing some required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>required_fields = ['scenario', 'why_needed', 'key_assertions']</li>
                                            <li>confidence field is optional and not included when None</li>
                                            <li>asserts that 'confidence' is not present in the dictionary</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        230 input +
                                        107 output =
                                        337 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 130-133, 135, 137, 139, 141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_with_all_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to dictionary with all fields</p>
                                    <p><strong>Why Needed:</strong> Prevents incorrect output when not providing all required fields for LlmAnnotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Asserts that the 'scenario' field is correctly set to 'Tests user login'.</li>
                                            <li>Asserts that the 'confidence' field is correctly set to 0.95.</li>
                                            <li>Asserts that the 'context_summary' field has the expected mode and bytes value.</li>
                                            <li>Asserts that the 'error' field is None (correct behavior for LlmAnnotation).</li>
                                            <li>Asserts that the 'key_assertions' list contains all required assertions.</li>
                                            <li>Asserts that the dictionary d has all the correct keys and values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        284 input +
                                        157 output =
                                        441 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 130-133, 135-137, 139-141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_default_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test default report schema version and empty lists.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the default report does not have a valid schema version or contains non-empty lists of tests, collection errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>d['schema_version'] == SCHEMA_VERSION</li>
                                            <li>d['tests'] == []</li>
                                            <li>not in d ['warnings', 'collection_errors']</li>
                                            <li>d['schema_version'] not in d</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        105 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Report with Collection Errors should include them.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report does not include collection errors when they exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'collection_errors' key in the report dictionary is present and has exactly one item.</li>
                                            <li>The value of the 'nodeid' field within the first collection error object is set to 'test_bad.py'.</li>
                                            <li>The 'message' field within the first collection error object contains the specified message 'SyntaxError'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        117 output =
                                        354 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Report Root</p>
                                    <p><strong>Why Needed:</strong> To ensure the test report includes warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The length of the 'warnings' list in the report is 1.", 'expected_value': 1, 'actual_value': 0}</li>
                                            <li>{'assertion': "The code in the first warning is 'W001'.", 'expected_value': 'W001', 'actual_value': 'No coverage'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        116 output =
                                        260 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_tests_sorted_by_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests should be sorted by nodeid in output.</p>
                                    <p><strong>Why Needed:</strong> Because the current implementation does not sort tests by nodeid, it may cause unexpected behavior when sorting or filtering test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "nodeids == ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']", 'expected_result': ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z'], 'actual_result': ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        159 output =
                                        374 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_without_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to dictionary without detail should exclude it.</p>
                                    <p><strong>Why Needed:</strong> Prevents a warning about missing detailed information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'detail' key is expected to be present in the dictionary.</li>
                                            <li>The value of 'detail' is not provided when it's absent.</li>
                                            <li>The test verifies that the 'detail' key does not exist.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        88 output =
                                        311 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_aggregation_fields_present</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that RunMeta has aggregation fields present in the test data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where RunMeta is missing or incorrectly configured aggregation fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'run_id' field should be present and equal to 'run-123'.</li>
                                            <li>The 'run_group_id' field should be present and equal to 'group-456'.</li>
                                            <li>The 'is_aggregated' field should be True.</li>
                                            <li>The 'aggregation_policy' field should be 'merge'.</li>
                                            <li>The 'run_count' field should be 3.</li>
                                            <li>The 'source_reports' list should have exactly two elements.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        147 output =
                                        490 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 286-288, 290-292, 376-392, 394, 397, 399, 402, 405, 407, 409, 411-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_fields_excluded_when_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LLM fields are excluded when annotations are disabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM fields (llm_annotations_enabled, llm_provider, and llm_model) are included in the RunMeta object even when annotations are not enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_annotations_enabled' key is present in the data.</li>
                                            <li>The 'llm_provider' key is not present in the data.</li>
                                            <li>The 'llm_model' key is not present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        121 output =
                                        353 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_traceability_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM traceability fields are included when enabled for the provided RunMeta instance.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the presence of annotations is not properly tracked or reported by the model.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of 'llm_annotations_enabled' in the data dictionary should be True.</li>
                                            <li>The value of 'llm_provider' in the data dictionary should match the provided 'ollama' string.</li>
                                            <li>The value of 'llm_model' in the data dictionary should match the provided 'llama3.2:1b' string.</li>
                                            <li>The value of 'llm_context_mode' in the data dictionary should match the provided 'complete' string.</li>
                                            <li>The value of 'llm_annotations_count' in the data dictionary should be 10.</li>
                                            <li>The value of 'llm_annotations_errors' in the data dictionary should be 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        197 output =
                                        524 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419-431, 433, 435, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</p>
                                    <p><strong>Why Needed:</strong> This test ensures that non-aggregated reports do not include source reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': {'source_reports': []}, 'actual_value': {'source_reports': []}}</li>
                                            <li>{'expected_value': {'is_aggregated': False}, 'actual_value': {'is_aggregated': True}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        116 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_meta_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test RunMeta to dict with all optional fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in handling of legacy and new fields in the `RunMeta` class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'git_sha' field is correctly set to 'abc1234'.</li>
                                            <li>The 'git_dirty' field is correctly set to True.</li>
                                            <li>The 'repo_version' field is correctly set to '1.0.0'.</li>
                                            <li>The 'repo_git_sha' field is correctly set to 'abc1234'.</li>
                                            <li>The 'repo_git_dirty' field is correctly set to True.</li>
                                            <li>The 'plugin_git_sha' field is correctly set to 'def5678'.</li>
                                            <li>The 'plugin_git_dirty' field is correctly set to False.</li>
                                            <li>The 'config_hash' field is correctly set to 'def5678'.</li>
                                            <li>The length of the `source_reports` list is correctly set to 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        483 input +
                                        207 output =
                                        690 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">49 lines (ranges: 286-288, 290-292, 376-392, 394-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test RunMeta to include run status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the RunMeta object does not contain all necessary run status fields, potentially leading to incorrect analysis results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field in the RunMeta object should be equal to 1.</li>
                                            <li>The 'interrupted' field in the RunMeta object should be True.</li>
                                            <li>The 'collect_only' field in the RunMeta object should be True.</li>
                                            <li>The 'collected_count' field in the RunMeta object should be equal to 10.</li>
                                            <li>The 'selected_count' field in the RunMeta object should be equal to 8.</li>
                                            <li>The 'deselected_count' field in the RunMeta object should be equal to 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        175 output =
                                        460 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_format</p>
                                    <p><strong>Why Needed:</strong> The schema version should be in semver format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "schema_version.split('.').should.have.length.equal.to(3)", 'message': 'Schema version should be in semver format.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        83 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the ReportRoot object includes the schema version in its JSON representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'ReportRoot.schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                            <li>{'name': 'report.to_dict().schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        109 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> CoverageEntry serialization test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the coverage entry is not properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the expected format (e.g., '1-3, 5, 10-15').</li>
                                            <li>The 'line_count' key in the dictionary should match the expected value (10 in this case).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        119 output =
                                        375 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-103)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 286-288, 290, 292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</p>
                                    <p><strong>Why Needed:</strong> To ensure that the SourceReport object's run_id attribute is correctly included in its dictionary representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "Expected value of 'run_id' key", 'value': 'run-1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        85 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 286-288, 290-292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSummary::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `CoverageEntry` class correctly serializes a coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage reporting functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key is set to the correct file path.</li>
                                            <li>The 'line_ranges' key is set to the expected line ranges.</li>
                                            <li>The 'line_count' key is set to the correct line count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        254 input +
                                        95 output =
                                        349 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_minimal_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a minimal result has the required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a minimal result is not provided with all necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nodeid' field should match the node ID of the test.</li>
                                            <li>The 'outcome' field should be set to 'passed'.</li>
                                            <li>The 'duration' field should be set to 0.0 (or any other default value).</li>
                                            <li>The 'phase' field should be set to 'call'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        244 input +
                                        119 output =
                                        363 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_coverage verifies that the test result includes a coverage list.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the coverage report is always present and accurate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the 'coverage' key in the result dictionary should be equal to 1.</li>
                                            <li>The value of the 'file_path' key within the 'coverage' list should match the provided file path.</li>
                                            <li>Each item in the 'coverage' list should have a 'file_path' attribute matching the provided file path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        131 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 65-68, 190, 194-199, 201, 203, 205, 207, 210-212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM opt-out flag is correctly set in the result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert llm_opt_out is True', 'expected_value': True, 'message': '', 'type': 'assertion'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        93 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_rerun</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_rerun</p>
                                    <p><strong>Why Needed:</strong> The test case result should include rerun fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'rerun_count', 'expected_value': 2, 'message': 'Rerun count is not equal to 2'}</li>
                                            <li>{'name': 'final_outcome', 'expected_value': 'passed', 'message': 'Final outcome is not passed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        118 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203, 205, 207-210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it ensures that the `result` dictionary does not include 'rerun_count' and 'final_outcome' fields when a result without reruns is returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'field': 'final_outcome', 'expected_value': 'passed', 'actual_value': 'passed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        148 output =
                                        300 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents bar regression in coverage report generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result['param_id'] == 'a-b-c',</li>
                                            <li>assert result['param_summary'] == 'a=1, b=2, c=3',</li>
                                            <li>assert result['captured_stdout'] == 'stdout content',</li>
                                            <li>assert result['captured_stderr'] == 'stderr content',</li>
                                            <li>assert result['requirements'] == ['REQ-100'],</li>
                                            <li>assert result['llm_opt_out'] is True,</li>
                                            <li>assert result['llm_context_override'] == 'complete',</li>
                                            <li>assert len(result['coverage']) == 1,</li>
                                            <li>assert result['llm_annotation']['scenario'] == 'Tests foo'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        182 output =
                                        636 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 96-103, 241-243, 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_artifacts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes artifacts when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the 'to_dict' method does not include all required artifacts in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of 'artifacts' in the result dictionary is 2.</li>
                                            <li>The path of the first artifact entry in 'result' is 'report.html'.</li>
                                            <li>All required artifacts are included in the 'artifacts' list in 'result'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        109 output =
                                        373 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530-532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes collection_errors when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails due to missing or incorrect collection errors in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `result['collection_errors']` is 1.</li>
                                            <li>The value of `result['collection_errors'][0]['nodeid']` is 'broken_test.py'.</li>
                                            <li>The node id of the first collection error matches the expected node id.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        243 input +
                                        108 output =
                                        351 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_custom_metadata</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes custom_metadata when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where custom metadata is not included in the report dictionary even if it's set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'custom_metadata' key should be present in the result dictionary with the correct values.</li>
                                            <li>The 'custom_metadata' key should contain the expected project, environment, and build_number values.</li>
                                            <li>The custom metadata should not be overridden by default settings (e.g., 'project', 'environment').</li>
                                            <li>Custom metadata should be included when the 'to_dict' method is called with a ReportRoot object that has it set.</li>
                                            <li>The custom metadata value should match the expected value for each key.</li>
                                            <li>If custom_metadata is not provided, the report dictionary should still contain default values (e.g., 'project': None, 'environment': None).</li>
                                            <li>Custom metadata should be included in the report even if it's empty or contains only default values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        211 output =
                                        475 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534-536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</p>
                                    <p><strong>Why Needed:</strong> HMAC signature is included in the report when it's set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'hmac_signature', 'actual': 'signature123'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        77 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the ReportRoot class correctly converts its internal state into a dictionary, including any SHA-256 hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'sha256 in report.to_dict()', 'expected': 'abcdef1234567890', 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        105 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536-538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes source_coverage when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage information is not included in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `source_coverage` should be 1.</li>
                                            <li>The file path of the first element in `source_coverage` should match 'src/mod.py'.</li>
                                            <li>The source_coverage entry for 'src/mod.py' should have a 'file_path' key matching 'src/mod.py'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        282 input +
                                        111 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 96-103, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532-534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</p>
                                    <p><strong>Why Needed:</strong> This test is needed to ensure that the `to_dict` method of `ReportRoot` includes warnings when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "len(result['warnings']) == 1", 'expected_value': 1, 'message': "Expected len(result['warnings']) to be 1, but got {}", 'actual_value': '1'}</li>
                                            <li>{'name': "result['warnings'][0]['code'] == 'W001'", 'expected_value': 'W001', 'message': "Expected result['warnings'][0]['code'] to be 'W001', but got {}", 'actual_value': "'W001'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        182 output =
                                        333 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_with_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "result['coverage_total_percent'] == 85.5", 'expected_result': 85.5}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        57 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 467-475, 477-479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_without_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents bar regression in coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result['param_id'] == 'a-b-c',</li>
                                            <li>assert result['param_summary'] == 'a=1, b=2, c=3',</li>
                                            <li>assert result['captured_stdout'] == 'stdout content',</li>
                                            <li>assert result['captured_stderr'] == 'stderr content',</li>
                                            <li>assert result['requirements'] == ['REQ-100'],</li>
                                            <li>assert result['llm_opt_out'] is True,</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        136 output =
                                        590 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 65-68, 130-133, 135, 137, 139, 141, 143, 190, 194-199, 201-207, 210-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</p>
                                    <p><strong>Why Needed:</strong> to include captured stderr in the result dictionary when to_dict is called on a TestCaseResult object</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': {'captured_stderr': 'Error output here'}, 'actual_value': 'Error output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        98 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220-222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</p>
                                    <p><strong>Why Needed:</strong> The `to_dict` method includes captured stdout when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stdout', 'expected_value': 'Debug output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        78 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218-220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_param_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203-207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</p>
                                    <p><strong>Why Needed:</strong> To include requirements in the test case result dictionary when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': ['REQ-001', 'REQ-002'], 'actual_value': ['REQ-001', 'REQ-002']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        96 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">21 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the default exclude globs for the LLM context.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default exclude globs are not correctly set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `defaults` contains the expected globs: `*.pyc`, `__pycache__/*`, and `*secret*`.</li>
                                            <li>The function `defaults` does not contain the expected glob `*password*`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        103 output =
                                        325 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the default redact patterns of the Config class.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential issue where sensitive information like API keys might be exposed if they are not properly redacted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `--password` and `--token` patterns should match any occurrences in the provided redact patterns.</li>
                                            <li>The `--api[_-]?key` pattern should match any occurrences in the provided redact patterns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        103 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that default values are set correctly for the test_default_values scenario.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the default configuration settings are not properly initialized.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.provider == 'none'</li>
                                            <li>cfg.llm_context_mode == 'minimal'</li>
                                            <li>cfg.llm_max_tests == 0</li>
                                            <li>cfg.llm_max_retries == 10</li>
                                            <li>cfg.llm_context_bytes == 32000</li>
                                            <li>cfg.llm_context_file_limit == 10</li>
                                            <li>cfg.llm_requests_per_minute == 5</li>
                                            <li>cfg.llm_timeout_seconds == 30</li>
                                            <li>cfg.llm_cache_ttl_seconds == 86400</li>
                                            <li>cfg.include_phase == 'run'</li>
                                            <li>cfg.aggregate_policy == 'latest'</li>
                                            <li>not cfg.is_llm_enabled() is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        184 output =
                                        502 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_get_default_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the default configuration is correctly set to 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg', 'expected_type': 'Config'}</li>
                                            <li>{'name': 'cfg.provider', 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        81 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_is_llm_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that is_llm_enabled check is enabled for different providers.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in LLM configuration when switching between providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `is_llm_enabled` should return False for provider 'none'.</li>
                                            <li>The function `is_llm_enabled` should return True for provider 'ollama'.</li>
                                            <li>The function `is_llm_enabled` should return True for provider 'litellm'.</li>
                                            <li>The function `is_llm_enabled` should return True for provider 'gemini'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        128 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_aggregate_policy</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_aggregate_policy</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `aggregate_policy` parameter is validated correctly and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'length of errors list', 'value': 1, 'expected_value': 1}</li>
                                            <li>{'name': 'error message in first error', 'value': "Invalid aggregate_policy 'random'", 'expected_value': "Invalid aggregate_policy 'random'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        118 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-221, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_context_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_context_mode</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `llm_context_mode` is valid and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'value': "Invalid llm_context_mode 'mega_max'", 'expected_value': "Invalid llm_context_mode 'mega_max'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        92 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-213, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_phase` parameter is valid and does not cause any issues during validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The error message should indicate an invalid include phase 'lunch_break'.", 'expected_value': "Invalid include_phase 'lunch_break'", 'actual_value': "Invalid include_phase 'lunch_break'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        101 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-229, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Config class correctly handles and reports invalid providers.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'length of errors list', 'value': 1, 'expected_value': 1}</li>
                                            <li>{'name': 'error message in errors list', 'value': "Invalid provider 'invalid_provider'", 'expected_value': "Invalid provider 'invalid_provider'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        116 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_numeric_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of numeric constraints for TestConfig.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression due to invalid configuration values, ensuring correct behavior under different scenarios.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.validate() should return at least 5 error messages.</li>
                                            <li>The 'llm_context_bytes' value must be at least 1000.</li>
                                            <li>The 'llm_max_tests' value must be 0 (no limit) or positive.</li>
                                            <li>The 'llm_requests_per_minute' value must be at least 1.</li>
                                            <li>The 'llm_timeout_seconds' value must be at least 1.</li>
                                            <li>The 'llm_max_retries' value must be 0 or positive.</li>
                                            <li>All error messages should contain the specified constraint strings.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        329 input +
                                        166 output =
                                        495 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245-254, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_valid_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_valid_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the configuration is properly validated and no errors are raised when a valid configuration is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Configuration validation should be successful for a valid config', 'description': 'The function should return an empty list of errors when given a well-formed, non-empty configuration.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        99 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_aggregation_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `load_aggregation_options` function to ensure it correctly loads aggregation options.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the aggregation policy is not being loaded correctly, potentially leading to incorrect results or errors in downstream processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate_dir` attribute of the configuration object should be set to 'aggr_dir'.</li>
                                            <li>The `aggregate_policy` attribute of the configuration object should be set to 'merge'.</li>
                                            <li>The `aggregate_run_id` attribute of the configuration object should be set to 'run-123'.</li>
                                            <li>The `aggregate_group_id` attribute of the configuration object should be set to 'group-abc'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        154 output =
                                        449 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</p>
                                    <p><strong>Why Needed:</strong> To test that the batch flag is disabled by default and correctly handled when it's set to None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg.batch_parametrized_tests is True', 'expected_value': True, 'message': 'Expected cfg.batch_parametrized_tests to be True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        100 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_config_missing_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when pyproject.toml doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the LLM configuration is not properly loaded due to missing pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_max_retries` attribute in the config should be set to 10 by default.</li>
                                            <li>The `rootpath` attribute of the mock Pytest configuration should point to a temporary directory.</li>
                                            <li>The `llm_report_html`, etc. attributes in the config should not have any values assigned.</li>
                                            <li>The `llm_provider` and `llm_model` attributes should be set to their default values (e.g., 'default', 'default')</li>
                                            <li>The `llm_context_mode` attribute should be set to its default value ('strict')</li>
                                            <li>The `llm_context_compression` attribute should be set to its default value ('off')</li>
                                            <li>No other attributes in the config should have any values assigned.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        214 output =
                                        627 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_coverage_source</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_coverage_source</p>
                                    <p><strong>Why Needed:</strong> To test the coverage source option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_pytest_config.option.llm_coverage_source', 'expected_value': 'cov_dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        72 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607-608, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_defaults</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_defaults</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of the default configuration when no options are set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "cfg.provider == 'none'", 'expected': 'None'}</li>
                                            <li>{'name': 'cfg.report_html is None', 'expected': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        94 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_from_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test that CLI options override pyproject.toml options.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'CLI options override pyproject.toml options', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        70 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">132 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492-494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_provider_override</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> load config from cli provider override</p>
                                    <p><strong>Why Needed:</strong> CLI provider option overrides pyproject.toml</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'override pyproject.toml', 'expected_value': 'pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        65 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">133 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading retries from CLI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_pytest_config.option.llm_max_retries', 'expected_value': 2, 'actual_value': 2}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        85 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494-495, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_pyproject</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of the `load_config` function in `tests/test_options.py`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The file is created with the correct name and path.', 'expected_result': 'pyproject.toml', 'actual_result': "tmp_path / 'pyproject.toml'"}</li>
                                            <li>{'name': 'The file has the correct content.', 'expected_result': "The file contains the following lines:\n```\ntmp_path / 'pyproject.toml'\n\n[tool.pyprojecttools]\n    tools = ['pyproject']\n```", 'actual_result': "tmp_path / 'pyproject.toml'\n\n[tool.pyprojecttools]\n    tools = ['pyproject']\n```\n"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        193 output =
                                        312 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">134 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386-388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_token_optimization_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading token optimization options from CLI.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the 'llm_prompt_tier' option is set to 'minimal' and the 'batch_parametrized_tests' option is True, causing an error when running tests in parallel.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.prompt_tier == 'minimal'</li>
                                            <li>cfg.batch_parametrized_tests is False</li>
                                            <li>cfg.context_compression == 'none'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        104 output =
                                        368 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">88 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470-474, 476-477, 479, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">47 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_dependency_snapshot</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `llm_dependency_snapshot` option is used to specify a dependency snapshot file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the `llm_dependency_snapshot` option is not used correctly, leading to incorrect or missing dependency snapshots in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `llm_dependency_snapshot` is set to `deps.json` as expected.</li>
                                            <li>The configuration file `deps.json` is loaded and its contents are compared with the expected snapshot.</li>
                                            <li>The `report_dependency_snapshot` field in the configuration is updated correctly based on the specified snapshot file.</li>
                                            <li>No dependency snapshots are missing or incorrect when using the correct `llm_dependency_snapshot` option.</li>
                                            <li>Dependency snapshots are generated correctly for all dependencies when using the correct `llm_dependency_snapshot` option.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        180 output =
                                        393 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488, 490-492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_evidence_bundle</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the 'llm_evidence_bundle' option is correctly set to 'bundle.zip' when CLI override is enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the 'llm_evidence_bundle' option is not set to the correct value even though CLI override is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of 'llm_evidence_bundle' in the configuration file should be 'bundle.zip'.</li>
                                            <li>The value of 'llm_evidence_bundle' in the configuration file should match the expected value when CLI override is enabled.</li>
                                            <li>The mock object's option.llm_evidence_bundle attribute should have been set to 'bundle.zip'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        151 output =
                                        368 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488-490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_json</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_cli_report_json` test sets the expected value for `report_json` in the configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the report JSON is not set correctly, potentially leading to incorrect or missing reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_report_json` option is set to 'output.json' in the mock configuration.</li>
                                            <li>The `report_json` value in the loaded configuration matches 'output.json'.</li>
                                            <li>The expected value for `report_json` is not being overridden by any other options.</li>
                                            <li>The test ensures that the correct value is used for report JSON.</li>
                                            <li>No other values are overriding or setting the `report_json` option.</li>
                                            <li>The mock configuration does not contain any other override for `report_json`.</li>
                                            <li>The loaded configuration has a valid and expected value for `report_json`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        193 output =
                                        405 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484-486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_pdf</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_cli_report_pdf` test function sets the `report_pdf` option to 'output.pdf' correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `llm_report_pdf` option is not set to the expected value, causing the CLI report PDF to be generated incorrectly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_pdf` option is set to 'output.pdf'.</li>
                                            <li>The `llm_report_pdf` option is set to 'output.pdf'.</li>
                                            <li>The output of `cfg.report_pdf` is 'output.pdf'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        131 output =
                                        343 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486-488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_invalid_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the token output format is valid and does not cause coverage issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': 'litellm_token_output_format', 'value': 'xml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        78 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-237, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_token_refresh_interval_too_short</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation when token refresh interval is too short</p>
                                    <p><strong>Why Needed:</strong> Because the current token refresh interval (30 seconds) is too short, which may lead to unexpected behavior and security vulnerabilities.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The token refresh interval must be at least 60 seconds', 'expected_value': 60, 'actual_value': 30}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        94 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241-242, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_valid_litellm_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of valid LiteLLM config.</p>
                                    <p><strong>Why Needed:</strong> To ensure the validation process works correctly with a valid LiteLLM configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The validate method returns an empty list of errors.', 'expected_result': [], 'message': 'Expected the validate method to return an empty list of errors.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        90 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate_include_history feature is loaded correctly and includes all necessary history.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'include_history=true', 'actual': 'include_history=true'}</li>
                                            <li>{'name': 'aggregate_include_history file path', 'expected': '/path/to/aggregate_include_history.py', 'actual': '/path/to/aggregate_include_history.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        133 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438-440, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate policy is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has an aggregate_policy section', 'expected_value': 'pyproject.toml should exist and have an aggregate_policy section'}</li>
                                            <li>{'name': 'aggregate_policy is present in pyproject.toml', 'expected_value': 'aggregate_policy should be present in pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        137 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436-438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</p>
                                    <p><strong>Why Needed:</strong> To ensure that all configuration keys are loaded when loading the PyProject.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'All config keys should be present in pyproject.toml', 'expected': ['...'], 'actual': {'scenario': 'tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined', 'why_needed': '...', 'key_assertions': ['...']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        125 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">150 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340-346, 348-350, 352-354, 356-357, 360-369, 372-375, 378-392, 396, 400, 402, 404, 408-410, 412-413, 416-422, 426-428, 430-432, 436-440, 444-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure the cache directory is loaded correctly from the PyProject file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True'}</li>
                                            <li>{'name': 'cache_dir path exists in pyproject.toml', 'expected': '/path/to/cache/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        105 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390-392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache TTL seconds are loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml contents match expected format', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        110 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388-390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the `capture_failed_output` key is not present in the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml', 'value': "Missing 'capture_failed_output' key in pyproject.toml"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        96 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418-420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_output.max_chars` option is correctly loaded and applied when running tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'max_chars = 1024', 'actual': 'max_chars = 2048'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        101 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420-422, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_bytes` feature is properly loaded from the PyPI repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context bytes are present in the PyPI repository', 'expected_value': 'True'}</li>
                                            <li>{'name': 'Context bytes are correctly extracted and returned', 'expected_value': 'The `context_bytes` feature is properly loaded from the PyPI repository.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        123 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362-364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_exclude_globs` setting in pyproject.toml is properly loaded and excluded from the test coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is readable', 'description': 'The pyproject.toml file should exist and be readable.'}</li>
                                            <li>{'name': 'context_exclude_globs setting is defined in pyproject.toml', 'description': 'The `context_exclude_globs` setting should be defined in the `pyproject.toml` file.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        152 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368-369, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context file limit is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True'}</li>
                                            <li>{'name': 'pyproject.toml content', 'expected': 'The contents of pyproject.toml are correct.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        111 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364-366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_include_globs` option is properly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "['*.txt', '*.py']", '# Expected contents of pyproject.toml file\n': '', 'actual': "['*.txt', '*.py']\n"}</li>
                                            <li>{'name': 'context_include_globs option value', 'expected': '["*.txt", "*.py"]', '# Expected value of context_include_globs option\n': '', 'actual': '["*.txt", "*.py"]\n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        179 output =
                                        298 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366-368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hmac key file is loaded correctly and used for HMAC operations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'pyproject.toml exists in the current working directory', 'actual': 'pyproject.toml was created at path /tmp/pyproject.toml'}</li>
                                            <li>{'name': 'pyproject.toml is not empty', 'expected': 'pyproject.toml is not empty', 'actual': 'pyproject.toml contents were read successfully'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        153 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</p>
                                    <p><strong>Why Needed:</strong> To ensure that the include_param_values function in options.py is correctly loading parameter values from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': '```\ntoml\ninclude_param_values = ["path/to/file1", "path/to/file2"]\n```', 'actual': '```\ntoml\ninclude_param_values = []\n```'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        132 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372-374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the include phase is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has an includes section', 'expected': 'True', 'actual': 'False'}</li>
                                            <li>{'name': 'includes section in pyproject.toml is not empty', 'expected': 'True', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        123 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for `tests/test_options_coverage`</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_pytest_invocation` option is correctly loaded from `pyproject.toml`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `include_pytest_invocation` option is present in `pyproject.toml`', 'value': 'True'}</li>
                                            <li>{'name': 'The `include_pytest_invocation` option has the correct path', 'value': '/path/to/include_pytest_invocation'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        126 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426-428, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_invocation_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_invocation_redact_patterns</p>
                                    <p><strong>Why Needed:</strong> To ensure that the invocation_redact_patterns are correctly loaded from the pyproject.toml file and used during testing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'file existence', 'expected_value': 'invocation_redact_patterns.toml', 'actual_value': 'pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        105 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430-432, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm_api_base is loaded correctly from the pyproject.toml file.</p>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        54 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340-342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm API key is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'litellm_api_key', 'expected_value': '<API_KEY>', 'actual_value': '<-loaded_api_key>'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        92 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342-344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm token JSON key is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "litellm_token_json_key = 'path/to/litellm_token.json'", 'actual': 'pyproject.toml contents'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        113 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356-357, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm_token_output_format is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The contents of the pyproject.toml file should contain a section named 'litellm.token.output_format'."}</li>
                                            <li>{'name': 'litellm.token.output_format value', 'expected': "The value of the 'litellm.token.output_format' setting in the pyproject.toml file should be 'litellm_token_output_format'."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        161 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352-354, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_token_refresh_command` is properly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `litellm_token_refresh_command` should be present in the `pyproject.toml` file', 'expected_value': 'litellm_token_refresh_command'}</li>
                                            <li>{'name': 'The `litellm_token_refresh_command` should have the correct path to the token', 'expected_value': '/path/to/token'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        150 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344-346, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Loading a specific configuration file from the .pyproject.toml file.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the correct token refresh interval is loaded for litellm.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The correct token refresh interval is loaded', 'description': "The value of 'litellm.token_refresh_interval' in the .pyproject.toml file should be equal to the expected value."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        101 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348-350, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_malformed_pyproject</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 123, 171, 308, 311-312, 320-325, 449, 451, 453-456, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_concurrency` setting in `pyproject.toml` is correctly applied when loading dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `max_concurrency` value in `pyproject.toml` is read correctly from disk.</li>
                                            <li>The `max_concurrency` value in `pyproject.toml` is not overridden by any environment variables.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        109 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380-382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'max_tests' setting in pyproject.toml is correctly loaded and used to determine the number of tests to run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "pyproject.toml should contain a 'max_tests' setting", 'value': 'True'}</li>
                                            <li>{'name': "pyproject.toml should have a value for 'max_tests'", 'value': 10}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        126 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378-380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the metadata file is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True'}</li>
                                            <li>{'name': 'metadata_file_path', 'expected': '/path/to/pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        104 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444-446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ollama_host is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The ollama_host is present in the pyproject.toml file', 'value': 'True'}</li>
                                            <li>{'name': 'The ollama_host is a valid Python module', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        119 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336-337, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that omit_tests_from_coverage is correctly loaded from pyproject.toml, even when tests are omitted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is not empty', 'expected': {'path': '/tmp/pyproject.toml', 'status': 0}, 'actual': {'path': '/tmp/pyproject.toml', 'status': 0}}</li>
                                            <li>{'name': 'pyproject.toml contains omit_tests_from_coverage section', 'expected': {'key': 'omit_tests_from_coverage', 'value': 'True'}, 'actual': {'key': 'omit_tests_from_coverage', 'value': 'True'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        183 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `param_value_max_chars` option is correctly loaded and used in the build process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'max_chars = 100', 'actual': 'max_chars = 100'}</li>
                                            <li>{'name': 'param_value_max_chars value is an integer', 'expected': 100, 'actual': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        132 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374-375, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'collect' option is loaded correctly from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'Collect keyword is present in pyproject.toml', 'actual': 'Collect keyword is not present in pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        104 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416-418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the timeout seconds setting in pyproject.toml is properly loaded and used when loading dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'value': 'True'}</li>
                                            <li>{'name': 'timeout_seconds setting exists', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        104 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_batch_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `batch_max_tests` optimization is correctly applied to batched tests in Pytest.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml file has a correct `optimizations` section', 'expected_value': "{'batch_max_tests': True}"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        114 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400-402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_parametrized_tests</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> load_batch_parametrized_tests</p>
                                    <p><strong>Why Needed:</strong> Optimize PyProject token optimization for parametrized tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'value': 'batch_parametrized_tests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        66 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">131 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396-398, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression feature is correctly loaded and used in the project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'True'}</li>
                                            <li>{'name': 'context_compression directory exists', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        103 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402-404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context line padding is correctly loaded and applied to the test files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context line padding is applied correctly', 'expected_value': 'True'}</li>
                                            <li>{'name': 'Context line padding is not applied to empty lines', 'expected_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        110 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404-405, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'prompt_tier' is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has a prompt_tier section', 'expected_value': 'True'}</li>
                                            <li>{'name': "pyproject.toml has a 'prompt_tier' section with the correct type", 'expected_value': 'prompt_tier: string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        130 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392-393, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</p>
                                    <p><strong>Why Needed:</strong> The test validation with batch_max_tests < 1 is necessary because it checks if the configuration can be validated without any tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'batch_max_tests must be at least 1', 'description': "The 'batch_max_tests' field in the configuration should be set to a value greater than or equal to 1."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        116 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</p>
                                    <p><strong>Why Needed:</strong> Negative context_line_padding is not allowed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The context_line_padding must be 0 or positive', 'expected_value': '0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        77 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the test suite covers all possible error messages when validating with invalid context compression.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'value': 'Invalid context_compression'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        73 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the validation function correctly identifies and reports invalid `prompt_tier` values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Test case 1: Invalid prompt_tier value', 'description': 'The test case checks if the validation function returns an error message for an invalid `prompt_tier` value.', 'expected_result': 'Invalid prompt_tier'}</li>
                                            <li>{'name': 'Test case 2: Multiple errors for multiple invalid prompt_tier values', 'description': 'The test case checks if the validation function correctly reports multiple errors for different invalid `prompt_tier` values.', 'expected_result': ['Invalid prompt_tier']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        179 output =
                                        304 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_integration.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin configuration has safe defaults.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'expected_type': 'Config'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        72 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">124 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378-380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603-605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py</p>
                                    <p><strong>Why Needed:</strong> Because the `TestPluginConfigLoading` test relies on the plugin's configuration being available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>pytestconfig is not None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        55 output =
                                        163 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_both_json_and_html_outputs</span>
                            <div class="test-meta">
                                <span>94ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test generates both JSON and HTML reports for a simple test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the report generation is not compatible with different output formats.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should exist at the specified path.</li>
                                            <li>The `report.html` file should exist at the specified path.</li>
                                            <li>Both `report.json` and `report.html` files should be present in the report directory.</li>
                                            <li>The `report.json` file should contain valid JSON data.</li>
                                            <li>The `report.html` file should not contain any syntax errors or warnings.</li>
                                            <li>The test function `test_simple()` should return a successful assertion result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        151 output =
                                        430 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</span>
                            <div class="test-meta">
                                <span>59ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</p>
                                    <p><strong>Why Needed:</strong> pytest_collection_finish counts items (line 378)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected pytest_collection_finish counts items to return the correct count', 'description': 'The test should run successfully and report the correct number of tests.', 'expected_result': 3, 'actual_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        198 input +
                                        107 output =
                                        305 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_creates_nested_directory</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that output directories are created if missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the plugin does not create nested directories for reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `nested` directory should be created in the report.json file.</li>
                                            <li>The `report.json` file should exist.</li>
                                            <li>The `nested` directory should have been created using `pytester.makepyfile()`.</li>
                                            <li>The `report.json` file should contain a nested directory structure.</li>
                                            <li>The `test_pass()` function should not be executed inside the nested directory.</li>
                                            <li>The `report.json` file should not be empty after running `pytester.runpytest()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        149 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 70-71, 73-75, 77, 79, 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_fixture_error_captured</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fixture errors are captured in report.</p>
                                    <p><strong>Why Needed:</strong> Fixture errors should be reported and logged for debugging purposes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key in the report contains an error code of 1.</li>
                                            <li>The 'error' value in the 'summary' key is set to True.</li>
                                            <li>The fixture name 'broken_fixture' is used in the test.</li>
                                            <li>The pytester.runpytest command captures and logs fixture errors.</li>
                                            <li>The captured error message is included in the report JSON file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        122 output =
                                        408 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 78-79, 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330, 332, 334-335, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_makereport_captures_all_outcomes</span>
                            <div class="test-meta">
                                <span>170ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_runtest_makereport captures all outcomes to ensure accurate reporting.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the report may not capture all outcomes, leading to inaccurate reporting and debugging difficulties.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'passed' outcome should be present in the report.</li>
                                            <li>The 'failed' outcome should be present in the report.</li>
                                            <li>The 'skipped' outcome should be present in the report.</li>
                                            <li>All three types of outcomes ('passed', 'failed', and 'skipped') should be included in the report.</li>
                                            <li>The report path is correctly set to capture the output of pytest_runtest_makereport.</li>
                                            <li>The report format (json) is used as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        164 output =
                                        499 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">114 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</span>
                            <div class="test-meta">
                                <span>54ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin correctly handles cases where no output is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'not exists', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        150 input +
                                        78 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">250 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403-404, 558-559, 562-563, 566-568, 579, 583, 602-603, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_pdf_option_enables_plugin</span>
                            <div class="test-meta">
                                <span>595ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that --llm-pdf option enables the plugin.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where the plugin is disabled due to missing Playwright configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytester.makepyfile` function should be called with a valid test file.</li>
                                            <li>The `test_pass()` function should be defined and return True.</li>
                                            <li>The `result.ret` attribute of the `pytester.runpytest` function should be equal to 0 (success) or warning.</li>
                                            <li>The `assert result.ret == 0` statement should not throw an error if the plugin is disabled.</li>
                                            <li>If the plugin was enabled, it should exit with code 0 (success) or warning, but definitely run.</li>
                                            <li>The `pytester.makepyfile` function should be called with a valid test file that includes the `--llm-pdf=report.pdf` option.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        435 input +
                                        195 output =
                                        630 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_session_start_records_time</span>
                            <div class="test-meta">
                                <span>59ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `pytest_sessionstart` hook records start time correctly when running with pytester.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `pytest_sessionstart` hook does not record the start time of the session.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'start_time' key is present in the run meta data.</li>
                                            <li>The value of the 'start_time' key matches the actual start time recorded by pytest.</li>
                                            <li>The 'start_time' key is correctly formatted as a timestamp.</li>
                                            <li>The test function `test_pass()` does not affect the start time recording.</li>
                                            <li>The report generated by pytester includes the correct start time data.</li>
                                            <li>The start time is reported in seconds since the epoch.</li>
                                            <li>The start time is recorded at the beginning of each session.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        176 output =
                                        452 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_context_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed after 10 retries. Last error: timed out</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</p>
                                    <p><strong>Why Needed:</strong> Because the requirement marker is causing a TypeError when it's used as a function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'TypeError', 'message': 'requirement marker should not cause errors.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        80 output =
                                        170 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestReportGeneration::test_report_writer_integration</span>
                            <div class="test-meta">
                                <span>41ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the integration of report writer with pytest_llm_report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression that may occur when using the report writer to generate reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the report writer writes a valid JSON file.</li>
                                            <li>Verify that the report writer writes a valid HTML file containing all test names.</li>
                                            <li>Check if there are any assertion errors in the report.</li>
                                            <li>Verify that the total number of tests is correct (2 in this case).</li>
                                            <li>Verify that only 'test_a.py' and 'test_b.py' are included in the HTML report.</li>
                                            <li>Ensure the report writer can handle test failures with error messages.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        417 input +
                                        149 output =
                                        566 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">26 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 579-580, 586-587)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginCollectReport</p>
                                    <p><strong>Why Needed:</strong> To test that the collectreport function calls the collector when enable is True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_report was called once with mock_report as argument', 'expected': 1, 'actual': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        204 input +
                                        81 output =
                                        285 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 558-559, 562, 566-568, 579-580, 586, 590-592)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `pytest_collectreport` function should not raise an exception when a session is not available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytest_collectreport() was called with no arguments', 'description': 'The pytest_collectreport() function was called with no arguments. This indicates that the function did not receive any arguments, which is unexpected behavior.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        119 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</p>
                                    <p><strong>Why Needed:</strong> To ensure the plugin correctly handles a null session in Pytest.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_report.session is None', 'expected': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        78 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</p>
                                    <p><strong>Why Needed:</strong> Llama model is not compatible with PyTorch, and this warning is raised to inform the user.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM model compatibility', 'description': 'The LLM model used by the plugin is not compatible with PyTorch. This raises a warning.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        104 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</p>
                                    <p><strong>Why Needed:</strong> Validation errors are raised when the pytest configuration is invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml validation error', 'message': 'Invalid pyproject.toml file'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        80 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">135 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-358, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</p>
                                    <p><strong>Why Needed:</strong> To ensure that the configure function skips on xdist workers as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'mocking', 'expected_result': 'mock_config.addinivalue_line.called', 'actual_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        92 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 328-330, 332-334, 336-338, 342-343, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigureFallback::test_pytest_configure_fallback_load</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fallback to load_config is triggered when Config.load is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent a crash due to missing Config.load method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The Config.validate() method should return an empty list.</li>
                                            <li>The load_config() method of pytest_llm_report.options.Config should be called once.</li>
                                            <li>The mock_load.assert_called_once() assertion should pass with the correct arguments.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        747 input +
                                        97 output =
                                        844 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of CLI options overriding pyproject.toml options in plugin load configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'pyproject.toml should contain some overrides'}</li>
                                            <li>{'name': 'load_config function call', 'expected': 'load_config function should be called with pyproject.toml as argument'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        124 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</span>
                            <div class="test-meta">
                                <span>91ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin can load configuration from a PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': True, 'message': 'PyProject.toml should exist in the test directory'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        95 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that terminal summary skips when plugin is disabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the plugin's terminal summary function does not skip when the plugin is disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest_terminal_summary` function should return None when called with an invalid stash value (in this case, False).</li>
                                            <li>The `stash.get` method of the mock configuration object was called once with a False argument.</li>
                                            <li>The `enabled_key` variable in the mock configuration object is not set to True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        121 output =
                                        402 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 399, 403-404, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 399-400, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::testload_config</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `load_config` function correctly loads config options from pytest objects (CLI) into a mock configuration object.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the `load_config` function, which is used to load configuration options from pytest objects (CLI), potentially causing issues with plugin functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option of the loaded config is set to 'out.html'.</li>
                                            <li>The `llm_report_json` and `llm_report_pdf` options are not set in the loaded config.</li>
                                            <li>The `llm_evidence_bundle`, `llm_dependency_snapshot`, `llm_requests_per_minute`, `llm_aggregate_dir`, `llm_aggregate_policy`, `llm_aggregate_run_id`, `llm_aggregate_group_id`, and `llm_max_retries` options are not set in the loaded config.</li>
                                            <li>The `llm_coverage_source`, `llm_prompt_tier`, `llm_batch_parametrized`, `llm_context_compression`, `llm_context_bytes`, `llm_context_file_limit`, `llm_max_tests`, and `llm_max_concurrency` options are not set in the loaded config.</li>
                                            <li>The `llm_timeout_seconds` option is set to a non-zero value.</li>
                                            <li>The `llm_capture_failed` option is not set in the loaded config.</li>
                                            <li>The `llm_ollama_host`, `llm_litellm_api_base`, and `llm_litellm_token_refresh_command` options are not set in the loaded config.</li>
                                            <li>The `llm_litellm_api_key` option is not set in the loaded config.</li>
                                            <li>The `llm_litellm_token_output_format` option is not set in the loaded config.</li>
                                            <li>The `llm_litellm_token_json_key` option is not set in the loaded config.</li>
                                            <li>The `llm_cache_dir` and `llm_cache_ttl` options are not set in the loaded config.</li>
                                            <li>The `llm_metadata_file` option is not set in the loaded config.</li>
                                            <li>The `llm_hmac_key_file` option is not set in the loaded config.</li>
                                            <li>The `include_params` option is not set in the loaded config.</li>
                                            <li>The `strip_docstrings` option is not set in the loaded config.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        639 input +
                                        498 output =
                                        1137 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that makereport skips when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_item.config.stash.get returns False', 'expected_value': False}</li>
                                            <li>{'name': 'gen.send returns StopIteration', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        105 output =
                                        325 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 558-559, 562-563, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makereport calls collector when enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the plugin does not call the collector even if makereport is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest_runtest_makereport` function should be able to find and stash the `mock_collector` instance.</li>
                                            <li>The `stash_get` method of the mock item's config should return True when `_enabled_key` is present.</li>
                                            <li>The `stash_get` method of the mock item's config should return `mock_collector` when `_collector_key` is present.</li>
                                            <li>The `handle_runtest_logreport` method of the mock collector instance should be called with `mock_report` and `mock_item` as arguments.</li>
                                            <li>The `get_result` method of the mock report object should return an empty result if no outcome was yielded.</li>
                                            <li>No exceptions should be raised when calling `send` on the mock outcome.</li>
                                            <li>The mock item's stash get method should not raise an exception when `_enabled_key` is present.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        371 input +
                                        230 output =
                                        601 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to verify that the `pytest_collection_finish` hook skips collection when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_session.config.stash.get.return_value', 'expected': {'False': {}}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        88 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 602-603)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginSessionHooks</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collector is called when collection_finish is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_finish was called once with mock_session.items', 'expected_call_count': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        219 input +
                                        73 output =
                                        292 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 602, 606-608)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is currently disabled and needs to be enabled for it to run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'pytest_sessionstart', 'actual_value': 'pytest_sessionstart'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        81 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that sessionstart initializes collector when enabled and stash is properly populated.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the collector might not be created or initialized correctly when pytest_sessionstart is called with an enabled configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert _collector_key in mock_stash</li>
                                            <li>assert _start_time_key in mock_stash</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        87 output =
                                        422 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 558-559, 562, 566-568, 619, 623, 626, 628-629)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_addoption adds expected arguments to the parser.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where pytest_addoption does not add all required arguments to the parser, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>parser.getgroup.assert_called_with('llm-report', 'LLM-enhanced test reports')</li>
                                            <li>group.addoption.call_args_list[0][0].startswith('--llm-report')</li>
                                            <li>group.addoption.call_args_list[1][0].startswith('--llm-coverage-source')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        125 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption no longer adds INI options in pytest 7.0 and later</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'parser.addini was not called', 'expected_result': [], 'actual_result': 'parser.addini was called'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        95 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_coverage_calculation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage percentage calculation logic for `pytest_llm_report.plugin.pytest_terminal_summary`.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the coverage percentage calculation logic, ensuring that the plugin correctly calculates the terminal summary coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option is set to 'out.html' and the `CoverageMapper` class is instantiated with this value.</li>
                                            <li>The `Coverage` instance is created with a mock `report` method that returns a percentage of 85.5.</li>
                                            <li>The `load` method of the `Coverage` instance is called once, indicating successful loading of the coverage data.</li>
                                            <li>The `report` method of the `Coverage` instance is called once, indicating successful calculation of the coverage percentage.</li>
                                            <li>The `stash` dictionary passed to the `pytest_terminal_summary` function contains a key-value pair with `_enabled_key` and `_config_key` set to `True` and `cfg`, respectively.</li>
                                            <li>The mock configuration object `mock_config` has its `workerinput` attribute deleted, ensuring that it is not used in the test.</li>
                                            <li>The mock stash dictionary passed to the `pytest_terminal_summary` function contains a key-value pair with `_enabled_key` set to `True` and `_config_key` set to `cfg`, indicating correct configuration of the plugin.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        285 output =
                                        680 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">53 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_llm_enabled</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with LLM enabled runs annotations.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in plugin behavior when LLM is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the `pytest_terminal_summary_llm_enabled` test passes without any errors.</li>
                                            <li>Check if the `mock_annotate` function is called once with the correct configuration.</li>
                                            <li>Verify that the `stash` dictionary contains the expected keys and values.</li>
                                            <li>Confirm that the `mock_config.stash` dictionary matches the original stash.</li>
                                            <li>Test that the `pytest_terminal_summary` function does not raise any exceptions.</li>
                                            <li>Ensure that the `mock_writer_cls.return_value` is set to the mock writer instance.</li>
                                            <li>Verify that the `mock_provider.get_model_name.return_value` and `mock_get_provider.return_value` functions return the expected values.</li>
                                            <li>Check if the `pytest_terminal_summary` function does not raise any exceptions when called with a valid configuration.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        204 output =
                                        681 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">66 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-486, 491-494, 497, 499, 502-504, 512-514, 516, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_no_collector</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary creates collector if missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the plugin does not create a collector even when it is supposed to be present in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mock_terminalreporter.call_args_list[0][1] should return 'Collector' as expected.</li>
                                            <li>stash._enabled_key should be True.</li>
                                            <li>stash._config_key should have the correct value (pytest_llm_report.plugin.Config).</li>
                                            <li>mock_config.stash.mock_stash._enabled_key should be True.</li>
                                            <li>mock_config.stash.mock_stash._config_key should have the correct value (pytest_llm_report.plugin.Config).</li>
                                            <li>mock_terminalreporter.call_args_list[0][1] should return 'Collector' as expected.</li>
                                            <li>stash._enabled_key should be False after calling pytest_terminal_summary() with mock_config.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        198 output =
                                        589 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_with_aggregation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with aggregation enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the case where aggregation is enabled and there are multiple terminals being reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregated report should be available in both `out.html` and `out.json` files.</li>
                                            <li>The aggregation function should return a report object.</li>
                                            <li>The write_json method of the ReportWriter class should be called with the aggregated report.</li>
                                            <li>The write_html method of the ReportWriter class should be called with the aggregated report.</li>
                                            <li>The aggregation function should not raise an error if there are no terminals being reported.</li>
                                            <li>The write_json and write_html methods should only be called once each, even if multiple terminals are being reported.</li>
                                            <li>The stash object should contain both _enabled_key and _config_key keys with the correct values.</li>
                                            <li>The stash object should not have a workerinput key.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        441 input +
                                        200 output =
                                        641 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 399, 403, 407, 410-411, 413-414, 417-418, 420, 422-426, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummaryErrors::test_terminal_summary_coverage_error</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage calculation error during terminal summary generation.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage calculation fails due to an OSError caused by disk full.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest_terminal_summary` function should not raise a UserWarning when computing coverage percentage.</li>
                                            <li>The `coverage.Coverage.load()` method should be called before attempting to compute coverage percentage.</li>
                                            <li>The `coverage.Coverage` object should have been loaded successfully without raising an OSError.</li>
                                            <li>The `pytest_terminal_summary` function should not log the error message 'Failed to compute coverage percentage' as a warning.</li>
                                            <li>The `pytest_terminal_summary` function should correctly handle cases where coverage data is not available (e.g., due to disk full)</li>
                                            <li>The `pytest_terminal_summary` function should not raise an exception when computing coverage percentage for non-existent files or directories</li>
                                            <li>The `pytest_terminal_summary` function should log the error message 'Failed to compute coverage percentage' in a meaningful way, including the file path and line number where the error occurred.</li>
                                            <li>The `pytest_terminal_summary` function should correctly handle cases where the coverage data is not available for all lines (e.g., due to disk full)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        389 input +
                                        261 output =
                                        650 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">52 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 476-479, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_balanced_context</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Assembling a balanced context for test_a.py with utils.py dependency</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler is unable to assemble a balanced context due to missing dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'utils.py' file should be present in the assembled context.</li>
                                            <li>The 'def util()' function should be found in the 'utils.py' file within the assembled context.</li>
                                            <li>The assembly result should include a coverage entry for the 'utils.py' file with line ranges and count.</li>
                                            <li>The test result nodeid should match the one specified in the test file.</li>
                                            <li>The outcome of the test should be 'passed'.</li>
                                            <li>The assembler should be able to assemble a balanced context without any issues.</li>
                                            <li>The assembler should be able to find dependencies like 'utils.py' within the assembled context.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        187 output =
                                        518 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler can assemble a complete context for a test file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'value': 'test_1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        176 input +
                                        77 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139-140, 268-272)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_minimal_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler with minimal context mode and a test file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using minimal context mode for tests that require minimal setup.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'test_1' function is present in the source code of the test file.</li>
                                            <li>The context object returned by the ContextAssembler does not contain any information about the test file.</li>
                                            <li>The test result nodeid matches the expected location of the test function.</li>
                                            <li>The test file's source code contains an assert statement that passes when run with minimal context mode.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        267 input +
                                        129 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_balanced_context_limits</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler with balanced context limits to ensure it correctly truncates long content when exceeding the limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the ContextAssembler does not silently truncate long code snippets without providing a clear indication of what was truncated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' file in the context is truncated to 40 bytes or less, as expected.</li>
                                            <li>A message indicating truncation ('... truncated') is present in the 'f1.py' file.</li>
                                            <li>The length of the 'f1.py' file is within the allowed limit (20 bytes + truncation message).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        143 output =
                                        478 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_complete_context_limits_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the ContextAssembler with complete mode and large context file to ensure it does not truncate files exceeding a certain size.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the ContextAssembler truncates files larger than the specified context limit in complete mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' node should be present in the assembled context.</li>
                                            <li>The content of 'f1.py' should not be truncated despite exceeding the 20 byte context limit.</li>
                                            <li>No 'truncated' key should be present in the context of 'f1.py'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        361 input +
                                        128 output =
                                        489 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_get_test_source_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler with edge cases, specifically non-existent files and nested test names with parameters.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler fails to extract test sources from non-existent or deeply nested test files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The method `_get_test_source` returns an empty string when given a file path that does not exist.</li>
                                            <li>The method `_get_test_source` correctly extracts the test name and parameters from a nested test file with multiple levels of nesting.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        275 input +
                                        116 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 33, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_should_exclude</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the ContextAssembler should exclude certain files from being processed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where some important files are inadvertently excluded during processing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'test.pyc' is expected to be excluded because it has a .pyc extension.</li>
                                            <li>The file 'secret/key.txt' is expected to be excluded because of the presence of '*'.</li>
                                            <li>The file 'public/readme.md' should not be excluded as it does not contain any sensitive information.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        122 output =
                                        349 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 33, 284-287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_minimal_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble minimal mode returns no context files.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where assemble function does not generate any context files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context_files is an empty list when config llm_context_mode is set to 'minimal'.</li>
                                            <li>test_source contains the expected function definition.</li>
                                            <li>Context files are generated only if test_foo.py has a __file__ attribute and it's not empty.</li>
                                            <li>The assemble function does not modify or create any context files in this case.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        117 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_with_context_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble respects llm_context_override from test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the ContextAssembler uses the correct LLM context mode even when an override is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The assembler should use balanced mode due to the override.</li>
                                            <li>The module file path should be included in the context files.</li>
                                            <li>The coverage entry for the module file should have a line range of '1' and a line count of '1'.</li>
                                            <li>The test source code should be included in the context files.</li>
                                            <li>The context files should not contain any other test files or modules.</li>
                                            <li>The coverage entry for the module file should not include any other lines than specified (i.e., only '1').</li>
                                            <li>The LLM context override should be balanced, i.e., neither minimal nor default mode should be used.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        362 input +
                                        189 output =
                                        551 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_excludes_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_balanced_context_excludes_patterns function to ensure it excludes files matching exclude patterns in a balanced context.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the LLM context mode is set to 'balanced' and the assembler does not exclude files that match the specified patterns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file "secret_config.py" should be excluded from the balanced context.</li>
                                            <li>The file 'api_key = </li>
                                            <li>The line count of the excluded file should be 1.</li>
                                            <li>The line ranges for the excluded file should start at line 1 and end at line 1.</li>
                                            <li>The coverage entry for the excluded file should have a line range of '1' and a line count of 1.</li>
                                            <li>The test should fail if the LLM context mode is set to 'balanced' without excluding any files.</li>
                                            <li>The test should pass if the LLM context mode is set to 'balanced' with the specified exclude patterns in place.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        213 output =
                                        544 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163-164, 201, 284-286)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</p>
                                    <p><strong>Why Needed:</strong> To test the scenario where a balanced context file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected an empty context to be returned when a non-existent file is provided.', 'expected_result': {}, 'actual_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        93 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-161, 201)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_max_bytes_limit</span>
                            <div class="test-meta">
                                <span>14ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that balanced context respects max bytes limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential memory leak or incorrect coverage due to an overly large source file being assembled into the context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The content of the source file is truncated to prevent excessive memory usage.</li>
                                            <li>A message indicating that the content was truncated is included in the context.</li>
                                            <li>The source file's length does not exceed the specified limit when assembling it into the context.</li>
                                            <li>The test verifies that the source file's content is truncated, preventing potential issues with coverage and memory consumption.</li>
                                            <li>The test ensures a clear indication of truncation in the context, facilitating debugging and maintenance efforts.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        405 input +
                                        151 output =
                                        556 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler can correctly assemble a balanced context with no coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'assert context is empty', 'expected_result': '{}', 'actual_result': '{}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        89 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 139-140)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_reaches_max_bytes_before_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that loop exits when max bytes is reached before processing file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler exceeds the maximum allowed bytes in a balanced context without encountering any files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context should have only one node (either 'file1.py' or 'file2.py')</li>
                                            <li>should not exceed the maximum allowed bytes of 5 for 'file1.py'</li>
                                            <li>should be empty if no files are processed</li>
                                            <li>should contain both 'content1 = 1' and 'content2 = 2' from both files</li>
                                            <li>should have only one line range (1) with a single line count (1)</li>
                                            <li>should not exceed the maximum allowed bytes of 5 for 'file2.py'</li>
                                            <li>should be empty if no files are processed</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        409 input +
                                        183 output =
                                        592 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-157, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</p>
                                    <p><strong>Why Needed:</strong> To ensure that the complete context delegates to balanced correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'inclusion', 'expected_inclusion': ['module.py'], 'actual_inclusion': ['module.py']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        90 output =
                                        301 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_empty_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _get_test_source with empty nodeid returns empty string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly handles cases where the input nodeid is empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result == ""', 'expected_value': '', 'message': 'Expected _get_test_source with empty nodeid to return an empty string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        92 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 33, 78-79, 82-83, 86-89)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests that source extraction stops at next function definition.</p>
                                    <p><strong>Why Needed:</strong> To ensure correct source code is extracted and to prevent errors due to incomplete or incorrect source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Source code extraction should stop at the next function definition', 'expected_result': 'The source code for the current test file should be extracted until the next function definition.', 'actual_result': 'The source code for the entire test file is extracted.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        114 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_file_not_exists</p>
                                    <p><strong>Why Needed:</strong> To test the _get_test_source method's behavior when a non-existent file is provided as an argument.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result is empty', 'expected_result': '', 'message': 'Expected result to be an empty string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        98 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 33, 78-79, 82-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the _get_test_source function correctly extracts functions with proper indentation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'indentation': 4, 'expected_lines': ['def add(a, b):', '    return a + b']}, 'actual': {'indentation': 2, 'expected_lines': ['def add(a, b):', '    return a + b']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        128 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_ranges.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure consecutive lines are compressed correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3', 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        68 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_duplicates</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_duplicates</p>
                                    <p><strong>Why Needed:</strong> To test the handling of duplicate ranges in the compress_ranges function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The output should contain a single range string.', 'expected_value': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        77 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_empty_list</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_empty_list</p>
                                    <p><strong>Why Needed:</strong> The current implementation of `compress_ranges` does not handle an empty input list correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        70 output =
                                        162 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 29-30)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of compressing mixed ranges (single numbers and overlapping ranges).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'value': '1-3, 5, 10-12, 15'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        79 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> Non-consecutive lines should be comma-separated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1, 3, 5', 'actual': '1, 3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        78 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_single_line</p>
                                    <p><strong>Why Needed:</strong> To ensure that the single line case does not use range notation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '5', 'actual_value': '5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        70 output =
                                        166 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 29, 33, 35-37, 39, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_two_consecutive</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_two_consecutive</p>
                                    <p><strong>Why Needed:</strong> To ensure that two consecutive lines are compressed to a single range.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-2', 'actual': '1-2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        73 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_unsorted_input</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_unsorted_input</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation of `compress_ranges` only works with sorted input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5', 'actual': '1-3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        85 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_empty_string</p>
                                    <p><strong>Why Needed:</strong> The function `expand_ranges` is expected to handle an empty input string correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "expand_ranges('') == []", 'expected_result': [], 'actual_result': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        81 output =
                                        171 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 81-82)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_mixed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_mixed</p>
                                    <p><strong>Why Needed:</strong> To handle mixed ranges and singles in the input string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3, 5, 10, 11, 12], 'actual': ['1', '2', '3', '5', '10', '11', '12']}</li>
                                            <li>{'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        107 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_range</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_range</p>
                                    <p><strong>Why Needed:</strong> The range function should expand to a list.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3], 'actual': ['1', '2', '3']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        74 output =
                                        173 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 81, 84-91, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_roundtrip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_roundtrip</p>
                                    <p><strong>Why Needed:</strong> To ensure that `compress_ranges` and `expand_ranges` are inverses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': [1, 2, 3, 5, 10, 11, 12, 15], 'actual_value': [1, 2, 3, 5, 10, 11, 12, 15]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        114 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67, 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_single_number</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_single_number</p>
                                    <p><strong>Why Needed:</strong> The function `expand_ranges` is expected to return a list containing the input value when given a single number as an argument.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [5], 'actual': ['5']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        79 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81, 84-87, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_render.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the format_duration function with duration values less than 1s.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the function does not correctly format durations for values < 1s.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return '500ms' when given a duration of 0.5 seconds.</li>
                                            <li>The function should return '1ms' when given a duration of 0.001 seconds.</li>
                                            <li>The function should return '0ms' when given a duration of 0.0 seconds.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        120 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestFormatDuration::test_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations in seconds for values greater than or equal to 1 second.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1.23s', 'actual': '1.23s'}</li>
                                            <li>{'expected': '60.00s', 'actual': '60.00s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        97 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> All outcomes should map to CSS classes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential CSS class mapping issue where 'xfailed' and 'xpassed' are mapped to different classes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>outcome_to_css_class('passed') == 'outcome-passed'</li>
                                            <li>outcome_to_css_class('failed') == 'outcome-failed'</li>
                                            <li>outcome_to_css_class('skipped') == 'outcome-skipped'</li>
                                            <li>outcome_to_css_class('xfailed') == 'outcome-xfailed'</li>
                                            <li>outcome_to_css_class('xpassed') == 'outcome-xpassed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        134 output =
                                        397 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `outcome_to_css_class` function does not handle unknown outcomes correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'outcome-unknown', 'actual': 'outcome-unknown'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        81 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_basic_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders basic report with fallback HTML.</p>
                                    <p><strong>Why Needed:</strong> Prevents rendering of incomplete or malformed reports due to missing or incorrect plugin and repository metadata.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The presence of the '<!DOCTYPE html>' header in the rendered HTML document.</li>
                                            <li>The inclusion of 'Test Report' in the rendered HTML document.</li>
                                            <li>The presence of 'PASSED' and 'FAILED' text in the rendered HTML document.</li>
                                            <li>The correct display of plugin and repository metadata in the rendered HTML document.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        119 output =
                                        545 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65-67, 79-85, 87, 121-124, 126-127, 131-132, 155-157, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders coverage for fallback HTML generation.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in rendering coverage information when fallback is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report includes the source file 'src/foo.py' as part of the rendered HTML.</li>
                                            <li>The assertion checks that at least 5 lines were included in the rendered HTML.</li>
                                            <li>The test verifies that the 'src/foo.py' file is present in the rendered HTML.</li>
                                            <li>The test ensures that exactly 5 lines are included in the rendered HTML.</li>
                                            <li>The report includes coverage information for the specified files.</li>
                                            <li>The assertion checks that the coverage information is accurate and complete.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        144 output =
                                        432 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-129, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</p>
                                    <p><strong>Why Needed:</strong> This test prevents LLM annotation rendering issues that could cause the 'Tests login flow' and 'Prevents auth bypass' scenarios to be missed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report includes the specified LLM annotations with confidence scores.</li>
                                            <li>The 'Tests login flow' scenario is included in the rendered HTML.</li>
                                            <li>The 'Prevents auth bypass' scenario is included in the rendered HTML.</li>
                                            <li>The confidence score for each annotation is displayed correctly (85%).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        132 output =
                                        449 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">64 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-134, 136-137, 140-142, 144, 147, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the source coverage summary is included in the rendered HTML report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the source coverage summary was not displayed correctly due to missing or incomplete code coverage data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'Source Coverage' section should be present in the rendered HTML report.</li>
                                            <li>The 'src/foo.py' file path should be included in the 'Source Coverage' section.</li>
                                            <li>The percentage of covered source code (80.0%) should be displayed in the 'Source Coverage' section.</li>
                                            <li>The range of missed source code (5-10) should be included in the 'Missed Source Code' section.</li>
                                            <li>The ranges of covered and missed source code should match the corresponding coverage percentages.</li>
                                            <li>The 'covered_ranges' and 'missed_ranges' values should contain the expected ranges for each file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        189 output =
                                        520 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-178, 180-186, 191, 206, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_xpass_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders xpass summary with fallback HTML.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression when rendering summary without fallback.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'XFailed' and 'XPassed' tags should be present in the rendered HTML.</li>
                                            <li>Both 'XFailed' and 'XPassed' tags should contain the corresponding text.</li>
                                            <li>If either tag is missing, the test should fail with an error message indicating the missing tag.</li>
                                            <li>The 'xfailed' and 'xpassed' values should match the actual counts from the report.</li>
                                            <li>The 'xpass' value should be present but not exceed the total count.</li>
                                            <li>The 'xfail' value should be absent or equal to 0 if it's supposed to be missing.</li>
                                            <li>The HTML structure should maintain a consistent layout and formatting.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        181 output =
                                        464 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">19 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_different_content</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_different_content</p>
                                    <p><strong>Why Needed:</strong> Because different content should produce different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Different Content', 'expected_result': {'hash1': '...', 'hash2': '...'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        77 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that an empty bytes object produces consistent hash.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        63 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_run_meta</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the build_run_meta method includes version info and other relevant metadata.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not include version information or plugin versions in the run meta.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert meta.duration == 60.0</li>
                                            <li>assert meta.pytest_version</li>
                                            <li>assert meta.plugin_version == __version__</li>
                                            <li>assert meta.python_version</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        98 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `build_summary` method counts all outcome types correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the total count of outcomes is incorrect when there are multiple skipped tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of outcomes should be 6 (1 passed, 1 failed, 1 skipped, 1 xfailed, 1 xpassed, 1 error).</li>
                                            <li>The number of passed outcomes should be 1.</li>
                                            <li>The number of failed outcomes should be 1.</li>
                                            <li>The number of skipped outcomes should be 1.</li>
                                            <li>The number of xfailed and xpassed outcomes should be 1 each.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        336 input +
                                        149 output =
                                        485 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 156-158, 319, 321-322, 324-335, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_counts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `total` attribute of a `Summary` object is correctly calculated by summing up all outcomes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the total count of passed, failed and skipped tests might not match the actual number of tests run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count should be equal to the sum of passed, failed and skipped counts.</li>
                                            <li>The passed count should be equal to the number of tests with outcome 'passed'.</li>
                                            <li>The failed count should be equal to the number of tests with outcome 'failed'.</li>
                                            <li>The skipped count should be equal to the number of tests with outcome 'skipped'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        150 output =
                                        433 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 319, 321-322, 324-329, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_create_writer</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `ReportWriter` class initializes correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `ReportWriter` instance does not have access to its configuration and warnings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `config` attribute of the `writer` should be set to the provided `Config` object.</li>
                                            <li>The `warnings` list of the `writer` should be empty.</li>
                                            <li>The `artifacts` list of the `writer` should be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        199 input +
                                        113 output =
                                        312 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 156-158)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_assembles_tests</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'ReportWriter::test_write_report_assembles_tests' verifies that the ReportWriter class writes a report with all tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the output paths of the tests are not specified, causing the report to be incomplete or missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the report.tests list should be equal to 2.</li>
                                            <li>The total number of tests in the summary should be 2.</li>
                                            <li>All tests should have a 'passed' outcome.</li>
                                            <li>Each test should have a unique nodeid.</li>
                                            <li>The ReportWriter class should not write any files if no output paths are specified.</li>
                                            <li>The report.summary.total property should return 2 even if there are less than 2 tests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        167 output =
                                        422 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the ReportWriter class correctly includes the total coverage percentage in its report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 85.5, 'actual_value': 'report.summary.coverage_total_percent'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        89 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-199, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_source_coverage</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_includes_source_coverage verifies that the report includes source coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the report does not include source coverage information, which can make it difficult to understand the code's performance and identify areas for improvement.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the `source_coverage` list in the report should be equal to 1.</li>
                                            <li>The file path of the first element in the `source_coverage` list should match 'src/foo.py'.</li>
                                            <li>Each element in the `source_coverage` list should have the following attributes: `file_path`, `statements`, `missed`, `covered`, `coverage_percent`, `covered_ranges`, and `missed_ranges`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        291 input +
                                        166 output =
                                        457 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_merges_coverage</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_merges_coverage verifies that the test writes a merged coverage report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of multiple tests with different coverage, where only one test's coverage is being written to the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The first test should have a single coverage entry.</li>
                                            <li>The file path of the first test's coverage entry should match 'src/foo.py'.</li>
                                            <li>Only one coverage entry should be included in the merged report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        116 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">99 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186-189, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the fallback behavior of atomic write when it fails.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where an atomic write attempt fails and does not trigger a direct write.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'report.json' should exist in the test directory.</li>
                                            <li>At least one warning message with code 'W203' should be present in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        87 output =
                                        363 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513-514, 516-519, 522-523)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case: creates directory if missing</p>
                                    <p><strong>Why Needed:</strong> Because the test requires a report to be written, which will create a new directory if it doesn't exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Directory should be created', 'description': 'The directory should be created at the expected path.'}</li>
                                            <li>{'name': 'Report JSON file should be present', 'description': 'A report.json file should be present in the expected location.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        171 input +
                                        115 output =
                                        286 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">128 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_ensure_dir_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ensures that directory creation fails and captures warnings.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the report writer does not handle directory creation failures correctly, potentially leading to silent errors or incorrect reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `writer._ensure_dir(json_path)` raises an exception with code 'W201' when directory creation fails.</li>
                                            <li>Any warnings raised during directory creation are captured and stored in the `writer.warnings` list.</li>
                                            <li>The `writer.warnings` list contains at least one warning with code 'W201'.</li>
                                            <li>The function does not silently ignore errors or return an error code, but instead raises an exception.</li>
                                            <li>The test verifies that directory creation fails and captures warnings to ensure the report writer behaves as expected.</li>
                                            <li>The test uses a mock `mkdir` function to simulate a permission denied error, which is raised by the `writer._ensure_dir(json_path)` method.</li>
                                            <li>The test ensures that the `writer.warnings` list contains at least one warning with code 'W201' for each directory creation attempt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        239 output =
                                        517 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 156-158, 477-480, 487-491)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_git_info_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_git_info_failure' verifies that the `get_git_info` function handles git command failures gracefully by returning `None` for both SHA and dirty flag values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the `get_git_info` function fails to return expected results when running git commands with errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_git_info` function should not raise an exception when it encounters a git command failure.</li>
                                            <li>The `sha` variable should be set to `None` in this case.</li>
                                            <li>The `dirty` variable should also be set to `None` in this case.</li>
                                            <li>When running subprocess.check_output with an exception, the test should still pass without raising an error.</li>
                                            <li>The function's return values should not be affected by external git command failures.</li>
                                            <li>The function should handle git commands that fail silently (e.g., due to permissions issues) correctly.</li>
                                            <li>The `get_git_info` function should not raise a `SubprocessError` exception when it encounters a git command failure.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        229 output =
                                        460 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_creates_file</span>
                            <div class="test-meta">
                                <span>40ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the report writer creates an HTML file and includes expected content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the report writer does not create an HTML file or does not include expected content in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report.html file should exist at the specified path.</li>
                                            <li>The report.html file should contain the expected content (test1, test2, PASSED, FAILED, Skipped, XFailed, XPassed, Errors).</li>
                                            <li>All nodes with nodeid 'test1' and 'test2' should be found in the HTML content.</li>
                                            <li>Node 'Skipped' should not be found in the HTML content.</li>
                                            <li>Node 'XFailed' should not be found in the HTML content.</li>
                                            <li>Node 'XPassed' should not be found in the HTML content.</li>
                                            <li>All error messages should be included in the HTML content (AssertionError).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        366 input +
                                        200 output =
                                        566 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">120 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_includes_xfail_summary</span>
                            <div class="test-meta">
                                <span>39ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the report includes xfail outcomes in the HTML summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that xfail outcomes are included in the HTML summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Asserts that 'XFAILED' and 'XFailed' keywords are present in the HTML string.</li>
                                            <li>Checks if 'XPASSED' and 'XPassed' keywords are also present in the HTML string.</li>
                                            <li>Verifies that all xfail outcomes have a corresponding xpassed outcome in the report.</li>
                                            <li>Ensures that the report includes both xfailed and xpassed outcomes for each test.</li>
                                            <li>Guarantees that the report does not exclude any tests from being included in the summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        159 output =
                                        467 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-333, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_json_creates_file</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a JSON file is created with the report.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where test reports are not written to files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should be created in the specified path.</li>
                                            <li>The artifact should be tracked for this test.</li>
                                            <li>The number of artifacts should be at least one.</li>
                                            <li>The file should exist as expected.</li>
                                            <li>The report writer should create a new JSON file with each test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        110 output =
                                        375 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_creates_file</span>
                            <div class="test-meta">
                                <span>42ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test writes PDF file when Playwright is available.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the test fails due to missing or corrupted PDF files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `write_pdf` method of the `ReportWriter` class should create a new PDF file with the specified path.</li>
                                            <li>The `report.pdf` attribute of the `Config` object should be set to the created PDF file path.</li>
                                            <li>All artifacts in the report should have paths that match the created PDF file path.</li>
                                            <li>The `write_report` method of the `ReportWriter` class should create a new PDF file with the specified path and add it to the report artifacts.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        478 input +
                                        149 output =
                                        627 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-430, 441-442, 444-450, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_missing_playwright_warns</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a warning is raised when Playwright is missing for PDF output.</p>
                                    <p><strong>Why Needed:</strong> To prevent the test from failing and providing incorrect results, this test verifies that it correctly handles the absence of Playwright for PDF output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pdf_path` does not exist after the test is run.</li>
                                            <li>Any warnings raised are of type WarningCode.W204_PDF_PLAYWRIGHT_MISSING.</li>
                                            <li>The warning message includes the string 'Playwright is missing'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        311 input +
                                        115 output =
                                        426 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</p>
                                    <p><strong>Why Needed:</strong> To test that the function correctly returns None when given a non-git directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'None', 'actual_value': 'sha'}</li>
                                            <li>{'expected_value': 'None', 'actual_value': 'dirty'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        98 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</p>
                                    <p><strong>Why Needed:</strong> To ensure that the test_get_git_info function correctly returns git info from a valid git repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None or isinstance(sha, str)', 'expected_result': {'type': 'NoneType', 'message': 'Test should return None if not in git repo'}, 'actual_result': {'type': 'str', 'message': 'Expected to get a string from the test_get_git_info function'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        159 input +
                                        135 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 67-74, 76-81, 83-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test falls back to git runtime when _git_info import fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails due to an import error in _git_info.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_plugin_git_info()` should return either None or a string.</li>
                                            <li>The function `get_plugin_git_info()` should still work via git runtime fallback even when `_git_info` is not available.</li>
                                            <li>The value of `sha` in the returned tuple should be None if `_git_info` import fails, otherwise it should be a string.</li>
                                            <li>The type of `sha` in the returned tuple should be either None or str.</li>
                                            <li>If `_git_info` import fails, the test should still pass without raising an AssertionError.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        169 output =
                                        422 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_returns_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetPluginGitInfo</p>
                                    <p><strong>Why Needed:</strong> To ensure the plugin git info function returns some values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None or isinstance(sha, str)', 'expected_result': ['None', 'str'], 'actual_result': [1, 2]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        141 input +
                                        84 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterAtomicWrite::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test atomic write falls back to direct write on error.</p>
                                    <p><strong>Why Needed:</strong> To ensure the report writer can handle cases where an atomic write operation fails and needs to fall back to a non-atomic write method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'File existence', 'expected_result': 'report.json exists'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        181 input +
                                        85 output =
                                        266 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_exception</span>
                            <div class="test-meta">
                                <span>117ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright raises exception.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where playwright raises an exception and report generation fails without a clear error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer.write_pdf` method should raise a `FileNotFoundError` if the PDF file cannot be written to the specified path.</li>
                                            <li>The `writer.warnings` list should contain warnings with code 'W201' when an exception is raised during report generation.</li>
                                            <li>The `report.pdf` attribute of the `writer` object should not be set to a non-existent file path.</li>
                                            <li>Any exceptions raised by `writer.write_pdf` or `writer.warnings` should be caught and handled correctly.</li>
                                            <li>The `config.report_pdf` parameter should be set to a valid file path for the report PDF.</li>
                                            <li>The `report.pdf` attribute of the `ReportWriter` object should not be set to an empty string.</li>
                                            <li>Any errors that occur during report generation should be logged or reported in some way.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        356 input +
                                        218 output =
                                        574 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 156-158, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright is not installed.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the report writer fails to create a PDF file without the required playwright installation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'W204' warning should be raised indicating that playwright is missing.</li>
                                            <li>The PDF file 'report.pdf' should not exist.</li>
                                            <li>Any other warnings or errors related to playwright should be suppressed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        97 output =
                                        390 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 156-158, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_creates_temp</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source creates temp file when no HTML source is provided.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails if no HTML source is provided, causing the report writer to create an empty temporary file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path returned by _resolve_pdf_html_source should exist and have a suffix of '.html'.</li>
                                            <li>The path returned by _resolve_pdf_html_source should not be empty.</li>
                                            <li>The suffix of the returned path should be '.html'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        118 output =
                                        383 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 156-158, 455, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_missing_html_file</span>
                            <div class="test-meta">
                                <span>34ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test resolves an HTML source when a non-existent HTML file exists.</p>
                                    <p><strong>Why Needed:</strong> Prevents a bug where the report writer falls back to using a temporary PDF file instead of the actual HTML source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path to the resolved HTML file exists.</li>
                                            <li>The path to the resolved HTML file is different from the original non-existent HTML file.</li>
                                            <li>The report writer does not fall back to using a temporary PDF file when an HTML source is missing.</li>
                                            <li>The test passes even if the actual HTML source is not found but the configuration specifies it should exist.</li>
                                            <li>The test ensures that the path to the resolved HTML file is correct and unique.</li>
                                            <li>The test verifies that the report writer does not use the original non-existent HTML file as a fallback.</li>
                                            <li>The test checks for any potential issues with the temporary PDF file created during the resolution process.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        196 output =
                                        466 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 455-457, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_uses_existing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _resolve_pdf_html_source uses existing HTML file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report writer does not use an existing HTML file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The path of the resolved PDF file is set to the existing HTML file.</li>
                                            <li>The temporary flag is set to False, indicating that the report was generated from a non-temporary source.</li>
                                            <li>The report writer uses the existing HTML file as its source.</li>
                                            <li>The configuration string contains the path to the existing HTML file.</li>
                                            <li>The resolved PDF file has the same name as the original HTML file.</li>
                                            <li>The resolved PDF file is not temporary, indicating that it was generated from a non-temporary source.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        266 input +
                                        157 output =
                                        423 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 156-158, 455-458)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_schemas.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_from_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `from_dict` can handle a full dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing or invalid data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>asserts the correct value for `scenario` field</li>
                                            <li>asserts the correct value for `why_needed` field</li>
                                            <li>asserts the correct values for `key_assertions` field</li>
                                            <li>sets the expected confidence level</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        100 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `to_dict` method correctly converts the schema to a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression bugs where the `to_dict` method is not correctly converting the schema to a dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert data['scenario'] == 'Verify login'</li>
                                            <li>assert data['why_needed'] == 'Catch auth bugs'</li>
                                            <li>assert data['key_assertions'] == ['assert 200', 'assert token']</li>
                                            <li># Correctly assert all required fields</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        119 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 90-92, 94-98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_smoke_pytester.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_report_created</span>
                            <div class="test-meta">
                                <span>93ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that an HTML report is created when the `--llm-report` option is used.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the HTML report is not generated correctly due to changes in the PyTest configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file path of the report should exist after running the test with the `--llm-report` option.</li>
                                            <li>The content of the report should contain the string '<html>'.</li>
                                            <li>The string 'test_simple' should be present in the report's content.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        122 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_summary_counts_all_statuses</span>
                            <div class="test-meta">
                                <span>131ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_html_summary_counts_all_statuses verifies that the HTML summary counts include all statuses.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where some statuses are missing from the HTML summary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `assert_summary(labels: list[str], expected: int)` should be able to correctly identify and report on each status in the list.</li>
                                            <li>For the 'Passed' label, it should match the expected count of 1.</li>
                                            <li>For the 'Failed' label, it should also match the expected count of 1.</li>
                                            <li>For the 'Skipped' label, it should not raise an assertion error but instead continue to the next test.</li>
                                            <li>For the 'XFailed' and 'XPassed' labels, they should also match their respective expected counts.</li>
                                            <li>The function `assert_summary(labels: list[str], expected: int)` should be able to handle cases where there are multiple statuses in a single line (e.g., 'Errors', 'Error').</li>
                                            <li>It should raise an assertion error if the number of labels does not match the expected count.</li>
                                            <li>For each label, it should check that the count is equal to the expected value and return without raising an assertion error if this condition is met.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        621 input +
                                        265 output =
                                        886 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 78-79, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212-214, 216, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-335, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_json_report_created</span>
                            <div class="test-meta">
                                <span>66ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The JSON report is created and contains the expected schema version, summary statistics, and test counts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report generation process fails to create a valid JSON file with the required metadata.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `schema_version` key in the report data should be equal to '1.0'.</li>
                                            <li>The `summary` key in the report data should contain an object with keys `total`, `passed`, and `failed`.</li>
                                            <li>The `summary` object's `total` value should be equal to 2.</li>
                                            <li>The `summary` object's `passed` value should be equal to 1.</li>
                                            <li>The `summary` object's `failed` value should be equal to 1.</li>
                                            <li>The `test_pass()` function is called with no assertions.</li>
                                            <li>The `test_fail()` function is called with a non-zero assertion count.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        202 output =
                                        497 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_annotations_in_report</span>
                            <div class="test-meta">
                                <span>58ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM annotations are included in the report when a provider is enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions by ensuring LLM annotations are present in reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_pass()` returns True.</li>
                                            <li>The value of `litellm.completion` is set to `mock_completion` before the test runs.</li>
                                            <li>The `pytest_configure` function imports `litellm` and sets its completion function to `mock_completion`.</li>
                                            <li>The `pyproject.toml` file includes `[tool.pytest_llm_report]` configuration with `litellm.completion = mock_completion`.</li>
                                            <li>The `makefile` creates a `pyproject.toml` file with the specified configuration.</li>
                                            <li>The `pytester.makeconftest` function patches `litellm.completion` before importing it in the test.</li>
                                            <li>The `mock_completion` function returns a `SimpleNamespace` with the expected annotations.</li>
                                            <li>The `asserts True` assertion passes when the `test_pass()` function is called.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        385 input +
                                        233 output =
                                        618 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 130-133, 135-137, 139, 141, 143, 190, 194-199, 201, 203, 205, 207, 210, 212-214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419-437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-506, 509, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_error_is_reported</span>
                            <div class="test-meta">
                                <span>94ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LLM errors are surfaced in HTML output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where LLM errors are not reported correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the error is reported in the HTML output.</li>
                                            <li>Check if the error message is displayed correctly.</li>
                                            <li>Ensure the error is included in the report.</li>
                                            <li>Verify that the error is not silently ignored.</li>
                                            <li>Test that the error is surfaced even when it's a litellm.completion error.</li>
                                            <li>Check for any additional error messages or details.</li>
                                            <li>Verify that the error is reported with the correct severity level.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        138 output =
                                        451 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-507, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>57ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LLM opt-out marker is correctly recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM opt-out marker might not be properly recorded in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_opt_out' marker should be present in the test results.</li>
                                            <li>The 'llm_opt_out' marker should have a value of True for this test.</li>
                                            <li>There should only be one test result with the 'llm_opt_out' marker.</li>
                                            <li>The 'llm_opt_out' marker should not be False for any other tests.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        137 output =
                                        427 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181-182, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>56ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the requirement marker to ensure it records the correct requirements.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the requirement marker is not recorded correctly, causing tests to fail with an incorrect list of requirements.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `@pytest.mark.requirement` decorator should be applied to functions or modules that require specific requirements.</li>
                                            <li>The `requirement` parameter in `@pytest.mark.requirement` should be set to a valid string (e.g., 'REQ-001', 'REQ-002')</li>
                                            <li>The `requirements` key in the test function's metadata should contain a list of strings (e.g., ['REQ-001', 'REQ-002'])</li>
                                            <li>The `tests` key in the JSON report file should contain exactly one object with a single string value (the requirements)</li>
                                            <li>Each requirement in the requirements list should be present in the report</li>
                                            <li>The `reqs` variable should contain a list of strings that includes both 'REQ-001' and 'REQ-002'</li>
                                            <li>The test function should have been run successfully without any errors</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        239 output =
                                        546 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-200, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_multiple_xfail_outcomes</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that multiple xfailed tests are recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that all xfailed tests are properly reported and counted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of xfailed tests is correctly reported as 2.</li>
                                            <li>All xfailed tests are included in the 'xfailed' key in the report.</li>
                                            <li>Each xfailed test has a corresponding outcome ('xfailed') in the list of outcomes.</li>
                                            <li>The test does not fail due to an assertion error or other non-xfailed test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        127 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_skip_outcome</span>
                            <div class="test-meta">
                                <span>56ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping tests prevents the 'skip' marker from being recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test ensures that skipping tests is properly handled and reported by pytester, preventing incorrect or misleading results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of skipped tests should be exactly 1 according to the report.</li>
                                            <li>The 'skip' marker should not be present in the report.</li>
                                            <li>The report path should contain a JSON file with the correct data.</li>
                                            <li>The 'summary' key in the report data should have a value of 'skipped'.</li>
                                            <li>The 'skipped' count in the report data should be 1.</li>
                                            <li>The test skipped function should not be executed during the run.</li>
                                            <li>The pytester.runpytest command should produce an error message indicating that skipping tests was prevented.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        180 output =
                                        444 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_xfail_outcome</span>
                            <div class="test-meta">
                                <span>61ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the 'xfailed' counter is incremented when an xfailed test is run.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in the test outcomes report, where the 'xfailed' counter might not be updated correctly if a new test with the same name fails.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key in the JSON report should contain a single integer value equal to 1 for each xfailed test.</li>
                                            <li>Each xfailed test should have a corresponding entry in the 'summary' JSON report with a 'xfailed' counter value of 1.</li>
                                            <li>If a new test with the same name fails, the 'xfailed' counter should be incremented correctly and reflected in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        158 output =
                                        422 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestParametrization::test_parametrized_tests</span>
                            <div class="test-meta">
                                <span>60ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test parameterized tests are recorded separately.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in parametrized testing, where the same test is run multiple times with different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_param` should be called three times with input values [1, 2, 3].</li>
                                            <li>The total number of tests executed should be 3 (three runs of the test).</li>
                                            <li>At least one test should pass for each input value.</li>
                                            <li>No additional tests should be run beyond what is expected from `test_param`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        130 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203-205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</span>
                            <div class="test-meta">
                                <span>51ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the help text for the CLI tool includes usage examples.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The help text should include at least one example.', 'expected_result': ['Example:'], 'actual_result': ['*Example:*--llm-report*', '*Example:*--model-serve']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        109 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_markers_registered</span>
                            <div class="test-meta">
                                <span>45ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test markers registered</p>
                                    <p><strong>Why Needed:</strong> Test that LLM markers are correctly registered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'markers are found', 'value': ['llm_opt_out', 'llm_context', 'requirement']}</li>
                                            <li>{'name': 'expected stdout lines', 'value': ['*llm_opt_out*', '*llm_context*', '*requirement*']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        93 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</span>
                            <div class="test-meta">
                                <span>51ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</p>
                                    <p><strong>Why Needed:</strong> The plugin is not registered, which means it will not be available for use during test execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'plugin is registered', 'description': 'The plugin should be registered before any tests are run.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        87 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestSpecialCharacters::test_special_chars_in_nodeid</span>
                            <div class="test-meta">
                                <span>94ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that special characters in nodeid are handled correctly by pytester.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where special characters in node IDs could cause issues with the LLM report generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_special_chars_in_nodeid` should not crash when given special characters in node IDs.</li>
                                            <li>The HTML file generated by pytester should contain the '<html' tag.</li>
                                            <li>The test assertion `assert s` should pass for all cases where a special character is present in the node ID.</li>
                                            <li>The function `pytester.makepyfile()` should create an HTML report that contains the '<html' tag.</li>
                                            <li>The file path of the generated report should exist and be valid.</li>
                                            <li>The content of the report should contain the '<html' tag.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        178 output =
                                        466 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_time.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_boundary_one_minute</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_boundary_one_minute</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats a duration of exactly one minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1m 0.0s', 'actual': '1m 0.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        85 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_microseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_microseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-millisecond durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert 'Œºs' in result", 'expected': '500Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        81 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_milliseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_milliseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-second durations as milliseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '500.0ms', 'actual': '500.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        78 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_minutes_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_minutes_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations over a minute, including minutes and seconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "result contains 'm'", 'expected': '1m 30.5s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        83 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_multiple_minutes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_multiple_minutes</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats multiple minutes into a human-readable string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of `format_duration(185.0)` is '3m 5.0s'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        75 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_one_second</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_one_second</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats a duration of exactly one second as '1.00s'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '1.00s', 'actual_value': '1.0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        86 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_seconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_seconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the function `format_duration` correctly formats seconds under a minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The result should contain 's' (seconds) as part of the assertion.", 'value': 's'}</li>
                                            <li>{'description': "The result should be equal to '5.50s'.", 'value': '5.50s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        115 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_small_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_small_milliseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats small millisecond durations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1.0ms', 'actual': '1.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        77 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_very_small_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_very_small_microseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function can correctly format very small durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected': '1Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        77 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_datetime_with_utc</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests time-related functionality with UTC timezone</p>
                                    <p><strong>Why Needed:</strong> To ensure that datetime objects can be correctly formatted with the UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The result of iso_format(dt) is equal to '2024-01-15T10:30:45+00:00'", 'expected_result': '2024-01-15T10:30:45+00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        106 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing naive datetime formats</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `iso_format` function correctly handles naive datetime objects without a timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Result format', 'expected': '2024-06-20T14:00:00', 'actual': '2024-06-20T14:00:00', 'message': 'Expected result format, got actual'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        106 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_with_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests time module with microseconds</p>
                                    <p><strong>Why Needed:</strong> To test the format of datetime objects with microseconds</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Result contains 123456', 'expected_value': '123456', 'actual_value': '<built-in function isoformat> returns a string containing the ISO-formatted time in seconds and microseconds, which is then converted to a datetime object.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        98 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_has_utc_timezone</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_has_utc_timezone</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `utc_now()` function returns a datetime object with an associated UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result.tzinfo is not None', 'description': 'The returned datetime object has a valid timezone info.'}</li>
                                            <li>{'name': 'assert result.tzinfo == UTC', 'description': "The returned datetime object's timezone info is set to UTC."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        124 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_is_current_time</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the function returns a valid UTC now.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure the function can return a current time within a reasonable tolerance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Before and After Time Tolerance', 'description': 'The result should be within 1 second of the before and after times.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        87 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_returns_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_returns_datetime</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `utc_now` function returns a datetime object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is an instance of datetime', 'expected_result': 'datetime'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        75 output =
                                        169 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_command_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher raises error on command failure when get-token command fails.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher class does not handle command failures properly, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>- The 'run' function of subprocess is called with an incorrect returncode (1) when the get-token command fails.</li>
                                            <li>- The error message returned by the 'run' function contains the string 'Authentication failed'</li>
                                            <li>- The test asserts that the error message includes the string 'exit 1', which indicates a failure in the process.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        310 input +
                                        136 output =
                                        446 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_empty_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher raises an error when given an empty output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not raise an error when it encounters an empty output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>the output of the get_token() method is an empty string</li>
                                            <li>the error message returned by the TokenRefreshError exception includes the phrase 'empty output'</li>
                                            <li>the error message is in lowercase to ensure correct comparison with the expected string</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        117 output =
                                        414 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-109, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that `TokenRefresher` forces a cache refresh when `force=True` and the refresh interval is set to 3600 seconds.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the token refresh does not occur immediately after setting `force=True` due to the cached tokens taking too long to expire.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` returns the expected token value for both `token1` and `token2` when `force=True`.</li>
                                            <li>The function `get_token(force=True)` calls the `fake_run` function with the correct arguments, resulting in a completed process object with an `stdout` attribute containing the expected token value.</li>
                                            <li>The `call_count` variable is incremented correctly to 2 after calling `get_token()` twice with `force=True`.</li>
                                            <li>The `token1` and `token2` variables are assigned the expected values based on their indices in the list of tokens returned by `get_token()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        214 output =
                                        560 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_custom_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `TokenRefresher` class uses a custom JSON key for token refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default JSON key used by the `TokenRefresher` class is not compatible with the expected custom key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `json_key` parameter passed to the `get_token()` method of the `TokenRefresher` class matches the custom JSON key provided in the test.</li>
                                            <li>The output of the `subprocess.run()` function is a JSON object with the correct access token.</li>
                                            <li>The `access_token` field in the JSON response is set to the specified custom key.</li>
                                            <li>The `token` variable is assigned the expected custom key value.</li>
                                            <li>The `assert` statement checks that the `token` variable matches the expected custom key value.</li>
                                            <li>The `subprocess.run()` function returns a CompletedProcess object with a returncode of 0, indicating successful execution.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        303 input +
                                        209 output =
                                        512 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `TokenRefresher` class extracts the correct JSON format for the obtained token.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the token is not in the expected JSON format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get-token` command is a JSON object with 'token' and 'expires_in' keys.</li>
                                            <li>The 'token' key contains the value 'json-token-value'.</li>
                                            <li>The 'expires_in' key contains the value 3600 (one hour).</li>
                                            <li>The 'command' attribute of the `TokenRefresher` instance matches the command used to run the `get-token` command.</li>
                                            <li>The `refresh_interval` attribute is set to 3600 seconds.</li>
                                            <li>The `output_format` attribute is set to 'json'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        178 output =
                                        486 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_text_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `TokenRefresher` class extracts the correct token from the text output when using the 'text' format.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the token is not extracted correctly if the output format is set to 'text'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>token == 'my-secret-token'</li>
                                            <li>output_format == 'text'</li>
                                            <li>subprocess.run.returncode == 0</li>
                                            <li># expected return code of 0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        106 output =
                                        404 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher raises a TokenRefreshError when given invalid JSON.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the TokenRefresher incorrectly handles invalid JSON input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the get_token() method should contain 'json' in its string representation.</li>
                                            <li>The error message should include the word 'json'.</li>
                                            <li>The error message should not be empty.</li>
                                            <li>The error message should not contain any other characters besides 'json'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        118 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-134, 149-150)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalidate</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher.invalidate() clears cache and verifies it is invalidated after a refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential regression where the TokenRefresher.invalidate() method does not clear the cache after a successful refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The token returned by get_token() should be different from the initial token.</li>
                                            <li>The call count of the fake_run function should increase by 1 after calling invalidate() on the TokenRefresher instance.</li>
                                            <li>The output of get_token() should contain the token number in the format 'token-X', where X is the call count.</li>
                                            <li>The output of invalidate() should be a CompletedProcessResult with returncode=0, stdout='token-Y', and stderr=''</li>
                                            <li>The value of call_count after calling invalidate() on the TokenRefresher instance should be 1.</li>
                                            <li>The token returned by get_token() should not be equal to the initial token.</li>
                                            <li>The output of get_token() should contain the token number in the format 'token-1' or 'token-2'.</li>
                                            <li>The output of invalidate() should contain the expected error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        243 output =
                                        583 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_missing_json_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when a JSON key is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent the test from passing and to ensure that the function correctly handles cases where a required JSON key is not present.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token` key should be present in the response.</li>
                                            <li>A message indicating that the token was not found should be included in the error message.</li>
                                            <li>The error message should include the word 'not found'.</li>
                                            <li>The function should raise a `TokenRefreshError` exception with a meaningful error message.</li>
                                            <li>The function should handle cases where the required JSON key is missing without raising an exception or returning an incorrect result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        153 output =
                                        478 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139-141, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_thread_safety</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that TokenRefresher is thread-safe by ensuring all threads acquire the lock before getting a token.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential deadlock or starvation of threads when multiple threads are trying to get a token simultaneously.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>all threads should acquire the lock before getting a token (token-1)</li>
                                            <li>each thread should get the same token (token-0, token-1, ..., token-4)</li>
                                            <li>no thread should be left without acquiring the lock</li>
                                            <li>the order of tokens obtained by each thread is consistent (token-1, token-2, ..., token-4)</li>
                                            <li>all threads should finish getting a token within 5 seconds or less</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        427 input +
                                        158 output =
                                        585 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_timeout_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that TokenRefresher handles command timeouts correctly by raising a TokenRefreshError when the 'get-token' command times out.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not raise an error when the 'get-token' command takes too long to complete, potentially leading to unexpected behavior or errors in downstream code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `fake_run` raises a `TimeoutExpired` exception with the message 'timed out'.</li>
                                            <li>The test asserts that the error message contains the word 'timed out'.</li>
                                            <li>The test asserts that the error message is case-insensitive (i.e., it matches 'Timed Out' or 'TIMEOUT').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        162 output =
                                        441 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_token_caching</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher caches tokens and doesn't call command again.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the `get-token` command is called multiple times due to caching.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `token1` should be equal to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        353 input +
                                        74 output =
                                        427 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_command_failure_no_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_command_failure_no_stderr function to verify that it correctly handles a command failure with no stderr output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher class does not handle command failures properly, leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` in the `TokenRefresher` class should raise a `TokenRefreshError` with an error message indicating that no stderr output was produced.</li>
                                            <li>The error message should include the string 'exit 1' to indicate that the command failed without producing any stderr output.</li>
                                            <li>The function should also check for the presence of the string 'No error output' in the error message to ensure it is not silently ignoring this information.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        165 output =
                                        487 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_empty_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling of empty command string.</p>
                                    <p><strong>Why Needed:</strong> To ensure the TokenRefresher class handles empty command strings correctly and raises a TokenRefreshError with the correct message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The function `get_token()` should raise a `TokenRefreshError` when given an empty command string.', 'expected': 'TokenRefreshError', 'actual': 'Exception'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        100 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_invalid_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_invalid_command_string function to verify it handles an invalid command string (shlex parse error).</p>
                                    <p><strong>Why Needed:</strong> Prevent a potential bug where the TokenRefresher class incorrectly raises a TokenRefreshError for an invalid command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method of the `TokenRefresher` instance should raise a `TokenRefreshError` with a message indicating that the command string is invalid.</li>
                                            <li>The error message should include the phrase 'Invalid command string'.</li>
                                            <li>When an invalid command string is passed to the `get_token()` method, it should not return any token data.</li>
                                            <li>The error message should be raised as a `pytest.raises(TokenRefreshError)` exception.</li>
                                            <li>The `exc_info.value` attribute of the raised exception should contain a `TokenRefreshError` object with the specified error message.</li>
                                            <li>When an invalid command string is passed to the `get_token()` method, it should not raise any other exceptions (e.g. `ValueError`, `TypeError`).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        251 input +
                                        226 output =
                                        477 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-88, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_not_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifying that a TokenRefresher raises an error when the output is not a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the TokenRefresher incorrectly handles non-dict JSON outputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method of the `TokenRefresher` instance should raise a `TokenRefreshError` with an error message indicating that the output is not a dictionary.</li>
                                            <li>The error message should include the string 'list' to ensure it's not just a generic JSON parsing error.</li>
                                            <li>The test should verify that the error message includes the expected string, allowing for future changes in JSON formats without breaking the test.</li>
                                            <li>The `json_key` parameter should be set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        328 input +
                                        162 output =
                                        490 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-137, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when token value is an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents potential bug where the TokenRefresher incorrectly handles empty or non-string token values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` class should raise a `TokenRefreshError` with the message 'empty or not a string' when given an empty or non-string token value.</li>
                                            <li>The error message returned by `get_token()` should include the string 'empty or not a string' to indicate that the input is invalid.</li>
                                            <li>The function should return a `TokenRefreshError` exception instead of raising it internally, allowing for proper error handling and logging.</li>
                                            <li>The test should verify that the error message includes the specific phrase 'empty or not a string', which indicates the type of input being validated.</li>
                                            <li>The test should also verify that the error is not raised when an empty string is passed as a token value in JSON format, but instead returns an empty or non-string result.</li>
                                            <li>The `json.dumps()` function used to create the expected output should produce a string with only whitespace characters, indicating an empty or invalid input.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        324 input +
                                        251 output =
                                        575 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_not_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_json_token_not_string scenario verifies when token value is not a string, preventing TokenRefreshError.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the TokenRefreshError by ensuring that the token value is always a string before attempting to refresh it.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `json.dumps` function is called with an integer instead of a string.</li>
                                            <li>An error message indicating 'empty or not a string' is raised when trying to get the token.</li>
                                            <li>The `TokenRefreshError` exception is raised with a meaningful error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        326 input +
                                        127 output =
                                        453 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_oserror_on_execution</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a TokenRefresher raises a TokenRefreshError when executing a command that does not exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher incorrectly handles commands that are not found during execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'get_token' method of the refresher should raise a TokenRefreshError with a message indicating that the command was not found.</li>
                                            <li>The error message should include 'Failed to execute'.</li>
                                            <li>The error message should be raised as an exception, not as a string.</li>
                                            <li>The error message should contain the text 'Command not found'.</li>
                                            <li>The error message should not be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        149 output =
                                        429 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113, 115-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_text_only_whitespace_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when text output has only whitespace lines after initial strip.</p>
                                    <p><strong>Why Needed:</strong> Prevents TokenRefreshError due to incorrect parsing of output with only blank lines after the initial strip.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _parse_output method should return a TokenRefreshError if no non-empty lines are found in the output.</li>
                                            <li>The output wrapper should contain whitespace content lines but not any non-whitespace lines.</li>
                                            <li>The parse_output function should raise a TokenRefreshError when given text with only blank lines after the initial strip.</li>
                                            <li>The test should fail when the _parse_output method is called directly with text that has only whitespace lines.</li>
                                            <li>The test should pass if the output wrapper contains non-empty lines and only whitespace content lines.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        376 input +
                                        166 output =
                                        542 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 132, 153-155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_whitespace_only_command</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_whitespace_only_command to verify it handles whitespace-only command strings correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where TokenRefresher incorrectly handles empty commands and raises an exception instead of returning a meaningful error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should raise a `TokenRefreshError` with the message 'empty' when given an empty command string.</li>
                                            <li>The function `get_token()` should return None or handle the case where the command is not empty correctly.</li>
                                            <li>The error message returned by `get_token()` should be 'empty'.</li>
                                            <li>The test should fail if `get_token()` returns a non-empty value instead of raising an exception.</li>
                                            <li>The test should pass if `get_token()` raises a `TokenRefreshError` with the correct message.</li>
                                            <li>The function `get_token()` should handle whitespace-only command strings without any issues or exceptions.</li>
                                            <li>The function `get_token()` should not raise any other types of exceptions for empty commands.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        219 output =
                                        455 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_usage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_usage.py::test_token_usage_aggregation</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify token usage aggregation for multiple test cases</p>
                                    <p><strong>Why Needed:</strong> Prevent regression in token usage reporting when aggregating results from multiple tests</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total input tokens should be 30 (10 + 20)</li>
                                            <li>The total output tokens should be 15 (5 + 10)</li>
                                            <li>The number of annotations should be 2 (LLM annotation for test1 and test3)</li>
                                            <li>The total tokens should be 45 (15 + 30)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        775 input +
                                        115 output =
                                        890 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-487, 491-494, 497, 499, 502-506, 509, 512-514, 516-521, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
        </div>
        </section>
    </div>
</body>
</html>